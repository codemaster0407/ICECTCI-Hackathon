,query,data
0,a-droplet-evaporation,"HiI would like to simulate evaporation time for a droplet under forced-convection, using SimNET
I referred to the heat-sink example for problem setting becasue basic physics is similar
however, for the evaporation, boundary is changing as a droplet becomes smaller
in such case, how should i set up boundary conditions ?
could you give me a clue or recommend examples i should take a look ?thanksHello,This sounds like a great problem! I may need some extra information about your problem to answer though. You can parameterize geometric properties in time. We don’t have any example of this but if you look in the wave equation example you can see how to do transient simulations. Then if you see the 3D parameterized 3 fin example you will see that you can parameterize the geometry with arbitrary values. Basically you will just use the t Symbol to parameterize the geometry. This can allow you to have time dependent geometric boundary conditions.It could be that you are looking to two way couple the droplet size to the thermal simulation. If this is the case then it is not entirely obvious how to do this in SimNet yet. This would actually require changing the geometric boundary condition based on the current simulation solution. This may not be possible in SimNet yet.Hi there!
Working on a similar problem over here.So if my geometry depends on let’s say a variable width, should I write:
width =Function(“width”)({“t”: t_symbol})And then just use the width variable when building my geometry?Sorry for the late reply, you can parameterize the geometry by giving a symbol t for the paramaterized quantities. For example, this code would give a circle parameterized by t.I should note that there is also a paper here that solves boundary free problems similar to what you are describing [2006.05311] Deep learning of free boundary and Stefan problems. In the up coming release we should be able to implement approaches like this however we will not have an example problem for boundary free problems yet.Hello,Is it possible now on Modulus 22.04 to implement moving boundary conditions? I tried to implement the Stefan problem in this paper on Modulus 21.06 and cannot couple the variables.Powered by Discourse, best viewed with JavaScript enabled"
1,cannot-git-clone-modulus,"As title, always get "" You will receive an email from GitLab with instructions on accessing the [Modulus Gitlab repository]"" but never receive any email.My user account is xunger.Many thanks.Hi @huangxunHow did you get this email? Was this from a few weeks back?We have moved the repos completely to Github where there are no access constraints. Thanks!Thanks. Issue resolved.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
2,add-grid-points-manually,"I am trying to run a physics problem wherein only specific grid points are to be used for training the model with PDE based loss. In Modulus, the problem geometry needs to be defined, which is used to sample the points for training the model (correct me if I am wrong here). Is there a way to select the training points inside the geometry manually without being sampled automatically?To be more precise, I want to construct a 1D domain with a circle centred at each x-location. I tried parameterizing the x-location of centre of circle with symbol ‘x’. But this approach resulted in an error. Is there a way to specify circle at each point on a 1D line which will be sampled by Modulus for training? Can this be achieved without manually constructing the grid? If not, then how can the construction of grid be achieved?Hi @shubhamsp2195For manually specifying input points I would suggest building a dictionary of numpy arrays or CSV file with the points you want to sample was well as the target values.You can then use some of Modulus’ utilities to then construct a constraint:We do this a lot for validation where we have data on a discrete set of points rather than a continuous domain (E.g. see the annular ring example).Thank you @ngeneva for your your quick reply to my query. I apologize if my question was not clear in my previous post. I am trying to use loss based on PDEs only (no data-driven loss) which would mean that there are no target values to be specified in the dictionary of numpy arrays or CSV file(mentioned in your reply to first query). Is it possible to sample points for training in this unsupervised setting? This is how my domain looks like.I want to construct a 1D domain with circles centered at each x-location of this domain. I tried parameterizing the x-location of center of circle with symbol ‘x’. The circles themselves must have a cloud of points which can be sampled randomly. But this approach resulted in an error. Is there a way to specify circle at each point on a 1D line which will be sampled by Modulus for training? Can this be achieved without manually constructing the grid? If not, then how can the construction of grid be achieved?It would be better if I am more direct in this case. The problem that I am trying to tackle is the psedo-2 dimensional model of Li-ion battery (Newman, Doyle, 1995) wherein spherical active particles are present at each x-location of 1D domain. 5 PDEs are solved in the 1D domain and one PDE is solved in the spherical particle located at each point on 1D domain. These two systems of PDEs are coupled through boundary conditions. Following is the rough figure for reference.Hi @shubhamsp2195I am trying to use loss based on PDEs only (no data-driven loss) which would mean that there are no target values to be specified in the dictionary of numpy arrays or CSV file(mentioned in your reply to first query). Is it possible to sample points for training in this unsupervised setting?Even for PDE loss training you have target values. These target values end up being the PDE residual being equal to zero. So using the the PointwiseConstraint.from_numpy() method, an example would be maybe I would have:this is still training with just PDE losses.I want to construct a 1D domain with circles centered at each x-location of this domain. I tried parameterizing the x-location of center of circle with symbol ‘x’. The circles themselves must have a cloud of points which can be sampled randomly. But this approach resulted in an error. Is there a way to specify circle at each point on a 1D line which will be sampled by Modulus for training?While I have not done this set up myself, I would image it is achievable using the geometry module. You could parameterize the center point of the circle. Then, in your constraint or geometry object, use the parameterization argument to define some sample range this center point could exist. If you can get this to work, the geometry module is well suited for these type of problems. There’s an example of this parameterization for a circle in the geometry section of our docs.Thank you @ngeneva for sharing this information. I will try to implement my problem along similar lines.Hi @ngeneva
This information helped me create a grid manually for my problem. I was trying to extend this to multidimensional arrays of the formBut the execution is stalling before the training startsThe execution does not proceed after this point. I waited for more than an hour.This issue is not present when 1D arrays are used for specifying constraintsIs it because multidimensional arrays are not supported in modulus constraints?Hi @shubhamsp2195That is correct. Modulus looks at training points without any underlying structure. This makes sampling training points from arrays and continuous geometry the same under-the-hood. The first dimension is treated at the number of training points you have, and the second is the dimensionality of that variable (typically 1). So you should always flatten your input arrays to [N,1].Hi,I am thinking of using my OpenFOAM / Pointwise generated grids as collocation /training points so that the collocation points can be clustered together better to the wall boundary. So can use the above recommended method to do so?Thanks.Based on the above hints, I have tried 2 approaches to using my own points for training:Error executing job with overrides: 
Traceback (most recent call last):
File “FX63-180_2_element_airfoil2.py”, line 420, in run
OF_grid = PointwiseConstraint.from_numpy(
File “/home/users/nus/tsltaywb/.local/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/domain/constraint/continuous.py”, line 178, in from_numpy
dataset = DictPointwiseDataset(
File “/home/users/nus/tsltaywb/.local/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/dataset/continuous.py”, line 35, in init
super().init(invar=invar, outvar=outvar, lambda_weighting=lambda_weighting)
File “/home/users/nus/tsltaywb/.local/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/dataset/dataset.py”, line 99, in init
self.lambda_weighting = Dataset._to_tensor_dict(lambda_weighting)
File “/home/users/nus/tsltaywb/.local/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/dataset/dataset.py”, line 49, in _to_tensor_dict
tensor_dict = {
File “/home/users/nus/tsltaywb/.local/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/dataset/dataset.py”, line 50, in 
key: torch.as_tensor(value, dtype=tf_dt, device=device)
File “/home/users/nus/tsltaywb/.local/lib/python3.8/site-packages/sympy/core/expr.py”, line 325, in float
raise TypeError(“can’t convert expression to float”)
TypeError: can’t convert expression to floatError is:Error executing job with overrides: 
Traceback (most recent call last):
File “FX63-180_2_element_airfoil2.py”, line 424, in run
outvar={‘momentum_x’: np.zeros(of_grid_n, 1), ‘momentum_y’: np.zeros(of_grid_n,1)},
TypeError: Cannot interpret ‘1’ as a data typeAny suggestion on how to solve the problem?Hello @tsltaywb
As highlighted by @ngeneva , the arrays must be flattened to the shape (N,1) before using them as input and output variables in PointwiseConstraint.from_numpy()  function. It seems like the arrays “of_grid_x” and “of_grid_y” have a different shape altogether.Hi @shubhamsp2195,Thanks for the reply. What I did is that I loaded my OpenFOAM grid, then I separate them into the x and y coordinates (of_grid_x and of_grid_y).Their shape are:of_grid_x.shape = (92260, 1)
of_grid_y.shape = (92260, 1)So doesn’t it mean that they’ve been flattened to the shape (N,1)?Hi @tsltaywbThe error listed in your post above TypeError: Cannot interpret ‘1’ as a data type looks like a Numpy API error. I believe your use of np.zeros is incorrect. Unlike PyTorch the shape needs to be in a tuple.E.g. np.zeros((of_grid_n,1)) not np.zeros(of_grid_n,1)Thanks @ngeneva  I made the change and now got the error:In the end, I managed to get rid of it by removing:I wonder why I had to remove it . Will it affect the accuracy of the training?Also, is there any way to check that the grid has been correctly used?Powered by Discourse, best viewed with JavaScript enabled"
3,running-into-errors-with-helmholtz-py,"Traceback (most recent call last):
File “helmholtz.py”, line 3, in 
import modulus
File “/home/datascience/conda/nmodulusv1_0/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/init.py”, line 7, in 
from .hydra.utils import main, compose
File “/home/datascience/conda/nmodulusv1_0/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/hydra/init.py”, line 1, in 
from .utils import (
File “/home/datascience/conda/nmodulusv1_0/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/hydra/utils.py”, line 18, in 
from modulus.models.arch import Arch
File “/home/datascience/conda/nmodulusv1_0/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/models/arch.py”, line 6, in 
import functorch
File “/home/datascience/conda/nmodulusv1_0/lib/python3.8/site-packages/functorch/init.py”, line 13, in 
from . import _C
ImportError: /home/datascience/conda/nmodulusv1_0/lib/python3.8/site-packages/functorch/_C.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESsHi @santosh.kumar.ramarathnamSeems this is an issue arising from functorch, is this using the docker image? I see you’re in a Conda environment so I would focus on getting functorch working in your Python environment before running Modulus.Also what operating system are you using?Powered by Discourse, best viewed with JavaScript enabled"
4,modulus-release-22-09-git-lfs-pull-fails-for-the-helmholz-validation-example-csv-file-with-invalid-cross-device-link,"Hi,In Modulus release_22.09 I’m trying to pull a git LFS Modulus example file and it failsCan someone help with this? Thanks!Everything runs fine if my examples folder is in $HOME/modulus.Hi @maricThis looks like an issue related to where (the hardware location) you’re trying to clone the examples repo. I would just clone the examples repo from scratch in a different spot. If this isn’t possible I would suggest you do some digging on why this would show for Git repos in general. Some stack overflow questions may lend some insight.Yep, I cloned the repo in $HOME/modulus, this works, see my answer from Nov 3 above, thanks for the hints!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
5,modulus-docker-image-23-05-update,"The latest Modulus docker image (23.05) does not have the recent updates in Modulus Git repository. The modulus examples such as vortex_shedding_mgn do not work with this image and need modification. What is the expected timeline for releasing the new version of the docker image with recent updates?ThanksHi @parisaPresently we plan for a quarterly release cycle of the docker container. This may be offset with some intermediate wheel updates. Some immediate options are to build / modify the current docker image on NVCR, build your own docker container using the docker files in the Github repos, pip install from source in a python environment.Powered by Discourse, best viewed with JavaScript enabled"
6,where-to-get-the-example-of-graphcast,"Hello, I saw an example of GraphCast in the update of Modulus, but I can’t find this example. Can you tell me where I can see it? Thanks in advance.
image1307×830 63.4 KBHi @978982001The graphcast training example can be found in Modulus Launch. Presently this in a bit of a beta state, so complete documentation is forthcoming. Thanks!Powered by Discourse, best viewed with JavaScript enabled"
7,problem-with-bare-metal-install-for-22-09-in-wsl-cuda-graphs-may-only-be-used-in-pytorch-built-with-cuda-11,"Hi,I have problems with docker in WSL for 22.09. Hence, I tried to do a bare metal install. I tried to run the helmholtz example. It ran for a few steps but gave the error:So how can I solve this error?Thanks.Hi @tsltaywbTry turning cuda graphs off in the config.yaml file by adding: cuda_graphs: False.Have a look at helmholtz/conf/config_hardBC.yaml as an example with this setting. This will disable cuda graph compiling. Keep in mind Cuda graphs is a beta feature in PyTorch so support may be limited like seems to be the case here.Hi,I have the same problem as @tsltaywb but, in my case the file config_hardBC.yaml was already modified with the solution you expressed. The problem persists even if i change cuda_graphs: True , so it looks like this is not the source of the problem.I have CUDA 11.3 and the correct version of pytorch (installed from this link with conda).How can i solve?ThanksHi @tom_02Its not 100% clear what your problem is. The original post is specifically regarding a Cuda graphs error which should not appear with cuda graphs off.To shut if off, you need to edit the config for the example you are running (for example, for this issue in the original post this needs to be added to examples/helmholtz/conf/config.yaml). The hardBC config is for helmholtz_hardBC.py.Let me know if helmholtz.py does not run after modifying the correct config file.Thanks, this worked for me.Powered by Discourse, best viewed with JavaScript enabled"
8,parameterized-geometry-linear-elasticity,"Hello,
I am trying to solve the linear elasticity for parameterized geometry. My usecase is a cantilever beam where the length, breadth, height are varied. Thus the geometry has 3 parameters namely L, B and H. From the three-fin tutorial example, I see that the geometry dimensions are just added as additional features along with the spatial inputs namely (x,y,z) coordinates. Linear elasticity physics loss function needs to compute the gradients of displacement and stress with respect to the input. In our case, the inputs are (x,y,z,l,b,h)
If the geometry is definied as parameterized in Modulus, does it automatically apply the chain rule to compute the derivates?
for example if the output of the network is displacement u,
du/dx = du/dL * dL/dx + du/dw * dw/dx + du/dh * dh/dx
In other words, how are the dimensions of the geometry considered in the Physics residual loss computation thereby it generalizes.
ThanksHi @k.narayananFor learning systems with parameterized geometry using a point wise methods, our examples use a explicit parameterization where  these params are model inputs as you mentioned. That means the output quantity is directly related to the current geometry. For the 3-fin example see the list of inputs here.Because the inputs of the neural network are partly the geometry parameterizations, the PDE loss depends on them since they are used to calculate the state variable which is needed for gradients as well. While unlike the spatial point inputs, we may not have explicit gradients of these terms they still impact the optimization akin to normal data-driven training.Powered by Discourse, best viewed with JavaScript enabled"
9,reflecting-periodic-boundary-condition-in-modulus,"Hello all,I am struggling with some problem making PDE solver by implementing PINN using modulus.Is it possible to implement some reflecting or periodic boundary conditions in Modulus?For example, u(-1,t) = u(1,t) and u_x(-1,t) = u_x(1,t)I tried to implement with tutorials but it fails…https://docs.nvidia.com/deeplearning/modulus/user_guide/notebook/notebook.htmlI am proceeding on my work based on the code above.Any suggestions, links, or advice would be highly appreciated.Thanks.For periodic boundaries some of our models support periodic inputs. The idea is to transform the input to the NN using a sinusoidal function so the inputs are always periodic.Some examples that use this technique are the 2D channel flow and Taylor Green problems in the user-guide.Thank you! I’ll try it and solved.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
10,what-are-the-specifications-on-the-surface-mount-capacitors-resistors-on-a-gtx-1080-gp104-die,"I need to know the specifications of the surface-mount capacitors/resistors on a GTX 1080 (GP104) die in order to replace two that have been detached. I don’t know if they’re all the same, so I will describe where the two are missing.Looking at the die right-side up (writing in normal position, triangle in top-left corner), the two missing surface-mount components are:A picture of the two spots are also attached (shown with black arrows).Also, I would like to know the same specifications of a few other surface-mount components that are still on, though need replacing:A picture of the three spots are also attached (shown with red arrows).I would like to know the specifications/part numbers to order replacements for these. Thank you for your help.
gp104480×640 118 KB
Powered by Discourse, best viewed with JavaScript enabled"
11,unable-to-install-nvidia-modulus-on-redhat7-7,"I’m trying to install nvidia module on linux redhat machine and following below instructionsThe installation guide can be found in Installation — Modulus 22.09 documentationI’m getting the error while loading the modulus_image_vxx.xx.tar.gz. Please suggestError:symlink …/c37e8281a6d7a8a129b2208d3bbe1d474bac6beb50270d420188c63be383b7a4/diff /var/lib/docker/overlay2/l/6PWD4ZLMOXXVIOWY7GGMPWR6ZQ: no such file or directoryNote: Docker already installed on this machine/usr/bin/dockerDocker version 20.10.17, build 100c701Hi @chandusoft028Sorry this isn’t working for you. We don’t test on RedHat so we aren’t able to capture these issues at the moment.Are you able to run the PyTorch 22.08-py3 container from NGC (This is the base image of Modulus)? If for some reason that works and the Modulus one does not, you could consider a bare metal install or build a container from scratch without PySDF modifying the dockerfile.Powered by Discourse, best viewed with JavaScript enabled"
12,error-when-running-cylinder-2d-py-example-gtx-1660,"Hi,I have a student learning Modulus. His GPU is GTX 1660 Super. He’s using the docker file from pytorch under WSL. We installed Modulus 22.09 based on the instructions here:https://forums.developer.nvidia.com/t/problem-using-modulus-22-07-in-wsl2/226578/2The ldc_2d.py and helmotz.py examples worked but the cylinder_2d.py failed. The error msg is:root@8210ecb7e13a:/mini_examples_22.09/cylinder2# python cylinder_2d.py
[13:03:04] - JIT using the NVFuser TorchScript backend
[13:03:04] - JitManager: {‘_enabled’: True, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[13:03:04] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
length scale is 20 meter
time scale is 20.0 second
mass scale is 8000.0 kilogram
[13:03:08] - attempting to restore from: outputs/cylinder_2d
[13:03:08] - optimizer checkpoint not found
[13:03:08] - model flow_network.0.pth not found
/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/eq/derivatives.py:85: UserWarning: FALLBACK path has been taken inside: runCudaFusionGroup. This is an indication that codegen Failed for some reason.
To debug try disable codegen fallback path via setting the env variable export PYTORCH_NVFUSER_DISABLE=fallback
*** (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/manager.cpp:329.)***
***  grad = gradient(var, grad_var)***
Error executing job with overrides: []
Traceback (most recent call last):
***  File “cylinder_2d.py”, line 176, in run***
***    slv.solve()***
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 159, in solve***
***    self._train_loop(sigterm_handler)***
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 521, in _train_loop***
***    loss, losses = self._cuda_graph_training_step(step)***
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 702, in _cuda_graph_training_step***
***    self.loss_static, self.losses_static = self.compute_gradients(***
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 54, in adam_compute_gradients***
***    losses_minibatch = self.compute_losses(step)***
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 52, in compute_losses***
***    return self.domain.compute_losses(step)***
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/domain/domain.py”, line 133, in compute_losses***
***    constraint.forward()***
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/domain/constraint/continuous.py”, line 116, in forward***
***    self._output_vars = self.model(self._input_vars)***
***  File “/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py”, line 1186, in _call_impl***
***    return forward_call(input, kwargs)
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/graph.py”, line 220, in forward***
***    outvar.update(e(outvar))***
***  File “/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py”, line 1186, in _call_impl***
***    return forward_call(input, kwargs)
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/eq/derivatives.py”, line 85, in forward***
***    grad = gradient(var, grad_var)***
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
***  File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/eq/derivatives.py”, line 24, in gradient***
***    “”""***
***    grad_outputs: List[Optional[torch.Tensor]] = [torch.ones_like(y, device=y.device)]***
***    grad = torch.autograd.grad(***
***           ~~~~~~~~~~~~~~~~~~~ <— HERE***
***        [***
***            y,***
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
***  File “”, line 119, in fallback_cuda_fuser***
***            def backward(grad_output):***
***                input_sigmoid = torch.sigmoid(self)***
***                return grad_output * (input_sigmoid * (1 + self * (1 - input_sigmoid)))***
***                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <— HERE***
***            return result, backward***
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
root@8210ecb7e13a:/mini_examples_22.09/cylinder2#May I know what’s wrong? Is it due to the GPU or driver problem?Thanks.Hi @tsltaywbTypically when you see these RuntimeError: The following operation failed in the TorchScript interpreter. its a torch script / Just-In-Time (JIT) failure.For this problem try shutting off JIT via the problem config.yaml:ok sure. I’ll give it a try.Btw, do u have any idea why it happened?Because I have similar docker image under WSL but I didn’t encounter this problem. The hardware is different though.Thanks!Powered by Discourse, best viewed with JavaScript enabled"
13,validating-models-from-v20-12-in-the-new-release-v21-06,"Hi!There was a problem, all the models that I trained before the release of v21.06 now do not work out, I have to retrain. What could be the mistake?I attach the text of the logs
problem (9.6 KB)There has been a few changes to the neural network architectures and tensorflow variables in v21.06, and you won’t be able to load your checkpoints trained with the previous versions unless you manually make some changes to the SimNet source. Here the network expects a global_step variable of type int64, but the saved one in your network checkpoint is of type int32. We have changed the type of this variable from int32 to int64 in v.21.06.Powered by Discourse, best viewed with JavaScript enabled"
14,clarifications-about-conjugate-heat-transfer-example,"Hi,
i’m working on a project based on the example “conjugate heat transfer” where I have a hot inlet flow that heats a piece placed inside a channel. Since “conjugate heat transfer” is very similar to my project i have some questions about it:I ask you if this have sense, and  why in the example “conjugate heat transfer” you didn’t write the code like that and you preferred the constraint “pressure=0”.Thanks to your support I was able to solve various problems and I hope that this time too you can give me some help.Hi @tom_02Why you add outlet constraint “pressure=0”?Since Navier-Stokes depends on the pressure gradient, the outlet defines the value/range of the pressure for the flow. This is not the only approach however, similar to fluid simulations there are multiple inlet, outlet and interior constraint combos that can be used (some with better convergence than others). So don’t interpret whats in the example as the only solution!Is the use of integral constraint in the example similar to what i have explain in the last question? I ask this because from the example it seems that the integral planes is added with the constraint of have the same “normal_dot_vel”.The integral constraints greatly help with the convergence of fluid flow problems. For many of the more complex problems, we have found these constraints to be essential to avoid having the network converge to a trivial solution.Where i can find more information about the normal_dot_vel parameter and what it represent? If it represent something connected to the volumetric flow why didn’t you insert an integral plane also in the outlet?The normal dot vel returns the velocity dot normal vector. The normal direction is provided by the geometry module.Inside your channel you don’t have constant pressure, but if i want to add this constraint, can this be done using “PointwiseInteriorConstraint”?Correct, this is the purpose of the outlet constraint. If you want to have an interior pressure constraint what you have would be the right approach.Hi @ngeneva,
thanks for the answer.
Is the unit of pressure to specify in the constraint the pascal or the bar?Pascal since we are typically in SI. But remember that most of the time the units/field variables should be interpreted as normalized/non-dimensionalized.Powered by Discourse, best viewed with JavaScript enabled"
15,about-transfer-learning-with-modulus,"I would like to try transfer learning using Modulus.
Is it possible to do transfer learning like the following?Powered by Discourse, best viewed with JavaScript enabled"
16,variable-inlet-boundary-condition,"Hi, is it possible to implement a variable boundary condition?For e.g.: inlet vel = V_constsin(2pift)In this case, the inlet velocity varies with time.Else, where in the source code can we modify it to add this feature?Thanks.Hi, the way to do this is to make a variable and assign a param_ranges in the boundary condition. For example:
t = Symbol(‘t’)
Wall = rec.boundary_bc(outvar_sympy={‘u’: t},
param_ranges={t: (0, 1.)},
batch_size_per_area=100)
self.add(Wall, name=“Wall”)For more detail, you may take a look at section 4 Transient physics: 1D Wave Equation, Case Setup.
Hope this can help!Thanks, I will give it a try!Powered by Discourse, best viewed with JavaScript enabled"
17,note-using-experimental-fast-data-loading-logic-to-disable-pass-load-fast-false-and-report-issues-on-github,"I keep getting this message when running the lcd example in Modulus.
The tensorboard link does not work and I have tried using the command in the github page.How else do I go about this so I can visualize the results?

tensorboard _error777×515 74.8 KB
Tensorboard is the primary method for visualizing Modulus results. I would suggest looking online for tensorboard solutions to help solve your problem. Alternatively, one can always modify Modulus to write out losses and plots to file:Powered by Discourse, best viewed with JavaScript enabled"
18,applicability-for-fluid-simulations,"Hi,
I would like to know, if it is possible to use SimNet for Simulating a fluid (e.g. water) in a predefined object (e.g. glass) and how to do so. Thanks in AdvancePowered by Discourse, best viewed with JavaScript enabled"
19,two-equation-turbulence-model,"Hello,
I tried to add two-equation turbulence model (k-epsilon turbulence model) for simulating air flow behaviour in an air cooled heat exchanger. I referred to the heat sink example for problem setting because the basic physics is similar. However, I always encountered a problem “loss went to Nans” during training.  My SimNet version is 21.06.
Would you please tell me what’s wrong it is and share some experience to improve the convergence? What’s more, I am wondering if you could kindly send me an example (two-equation turbulence model) for reference.Thanks,
Zhiyong WuHello @wuzhy55 , At the time you tested this the k-epsilon turbulence model was very finicky. We now have dedicated examples for k-epsilon and k-omega you can take a look at.Powered by Discourse, best viewed with JavaScript enabled"
20,evaluation-of-the-model-after-training,"once a model is trained in Modulus, how can I evaluate the results for a range of inputs? I’m expecting to get the outputs instantaneously without running the simulations.Hi @smraniakiThere are a couple of ways, the first “Modulus workflow” approach is using the evaluate mode built into the solver: solver.eval(). This will just run any inferencer / validators you’ve added. See the _eval function in the trainer: https://gitlab.com/nvidia/modulus/modulus/-/blob/release_22.09/modulus/trainer.py#L749Alternatively you could look at loading the model checkpoint manually using a Modulus model. This checkpoint is saved in the outputs folder of your run. Then running inference manually in a typical PyTorch method:
https://gitlab.com/nvidia/modulus/modulus/-/blob/release_22.09/modulus/models/arch.py#L165This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
21,blog-using-physics-informed-deep-learning-for-transport-in-porous-media,"Flow in a Porous Media - Traditional solvers introduce diffusion due to mesh discretization converting a hyperbolic problem to a parabolic one. Kudos to Cedric Fraces who solved the hyperbolic problem with SimNet. Read our blog here : Using Physics-Informed Deep Learning for Transport in Porous Media | NVIDIA Technical BlogTo view this GTC’21 session, see : Physics-Informed Neural Network for Flow and Transport in Porous Media | NVIDIA On-DemandPowered by Discourse, best viewed with JavaScript enabled"
22,cant-solve-high-density-fluid-flow,"Hello,I would like to solve a high density fluid flow(e.g. water) that is 3D and unsteady.I’m trying the taylor-green example with water property(nu=0.000001, rho=1000) but the reduction of train loss is much slower than one in the original setting(nu=0.002, rho=1.0) and the flow doesn’t evolve with time at all.I used 22.07 for taylor-green and 22.03 for some other problem with high density flow.
All of their results are not well.If you have idea to solve high density fluid flow, please let me knowRegards,Hi @yokoi.toshiakiSuccess in physics-informed learning greatly depends on proper scaling of the different quantities present in the physical system. For example the domain may be adjusted for a higher viscosity, etc. There’s on info on this here. Without a proper scaling of the physical system, the machine learning will be nearly impossible. This can include material properties, extremes rarely work without a lot of work.I have not personally tried Taylor Green on the parameters, but the very small viscosity is effectively removing the influence of the diffusion term. This could be causing the model to fall into a local minima based on the initial condition that it cannot escape for learning any dynamics in time. This is just speculation of course.Regardless, by reducing your dynamic viscosity and increasing density will make the Reynolds number very large entering turbulence, which will be extremely challenging (not possible presently) for PINNs with zero data. Hence the reason PINNs is typically used for lower Reynolds number flows.Thanks for your detailed reply.As you mention the fundamental problem depends on scaling and optimization I think too.I’m going to investigate it more.Thanks,Hello,Is there any progress made since then?I’m facing the exact same issue, but didn’t find a way to solve it yet, even with scaling and adjusting my network and weighting.
It would be really helpful to know if anyone has solved this problem and how.Thanks a lot in advance.Powered by Discourse, best viewed with JavaScript enabled"
23,modulus-22-03-installation-instructions-and-user-manual,"Similar to Modulus 21.06, is there any user guide for Modulus 22.03? Like What modifications were done to FNOs and AFNOs? Is Modulus still using signed distance functions?Modulus documentation is now available online here: Modulus User Guide — Modulus 22.07 documentationThanks a lot. I could not find this link when downloading Modulus.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
24,not-able-to-write-streamline-for-stl-geometry-as-input-file,"After completing example available with Modulus “Forward simulation using STL geometry: Blood Flow in Intracranial Aneurysm” , I am able to write Pressure Contour Lines or Velocity Contour Lines using Paraview, but not able to write Streamlines. Seek help from Nvidia Modulus TeamHi @priyanshu.aryanCan you provide some additional information regarding what file you are trying to visualize and if it shows any data at all inside paraview?After completing the training of example available with Modulus
“Forward simulation using STL geometry: Blood Flow in Intracranial Aneurysm”
I got different output folders each for Training, Validation and Monitor domain.Using ParaView, I am able to get pressure contours using “Val_pred.vtu” file (available in val_domain → Results→Val_pred.vtu )But I am not able to write Streamlines.
Flow streamlines inside the aneurysm generated from Modulus simulation919×671 155 KB

I want to draw, Flow streamlines inside the aneurysm generated from Modulus simulation, as shown in the attached image available with Modulus use guideHi @priyanshu.aryanI am unsure where you are getting the Val_pred.vtu file, is this converted from validator.vtp? The output files are point wise files with no mesh information. Let me know if I’m missing something (Latest Modulus version).You won’t be able to calculate streamlines from just  a point cloud. So you could:Please see the VTK page in our user guide for some infomation on the different formats.I have not used validator.vtp and have not done any conversion.
I was using v21.06 of Modulus. By using different class (ValidationDomain, TrainDomain, MonitorDomain ) available with the Modulus library, I have got different output files.
I am attaching the image showing output folder names for your reference.
I have installed recent version of Modulus and will try to run the program.
As we know that in Modulus there is no need of creating any mesh?? but for getting streamlines, do we have to create the mesh?

A31473×659 114 KB
Hi @priyanshu.aryanAh I see, yes your output makes sense using the older Modulus versions. Sorry for confusion.Regarding the streamlines, yes, you need continuous cell data (mesh data) for the streamlines to integrate over. To generate this figure in the user guide, we interpolated the point cloud onto the openFOAM mesh (we do not provide this). The reason is that the streamline integration needs a continuous function space to work, thus cell data is needed. You likely just have a point cloud right now (this is even what is produced from current modulus).The three options still stand granted number 2 and 3 are using the current version of Modulus. I would highly suggest looking into option 2. You can do option 1 right now in Paraview but it can be very slow.
There’s some examples of this in the industrial heat sink problem in the training scripts.Thank you very much, I will try to use option 2nd and will update you later.
The link you have specified in "" [training scripts ]"" seems not working, may you please recheck.Hi @priyanshu.aryanThe link does seem to be working for me. No matter, the urls for both follow:Link 1 (industrial):https://docs.nvidia.com/deeplearning/modulus/user_guide/advanced/industrial_heat_sink.htmlLink 2 (Training scripts):https://gitlab.com/nvidia/modulus/examples/-/blob/release_22.09/limerock/limerock_hFTB/limerock_flow.py#L151Powered by Discourse, best viewed with JavaScript enabled"
25,importerror-cannot-import-name-modulusconfig-from-modulus-hydra,"Running Modulus 22.9 on Ubuntu 20.04 bare metal, with Python 3.8
Cloned git repository from GitLab
Ran setup.py
Cloned ‘examples’ git repository
Got the import error trying to run any of the examplesFile “helmholtz.py”, line 4, in 
from modulus.hydra import to_absolute_path, instantiate_arch, ModulusConfig
ImportError: cannot import name ‘ModulusConfig’ from ‘modulus.hydra’ (/usr/local/lib/python3.8/dist-packages/modulus/hydra/init.py)Fixed by removing older version of Modulus: 22.3This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
26,dynamic-linear-elasticity-problem,"Hi,
I am interested in simulating the dynamic extension for a linear elastic material. Its a simple geometry which is to be pulled from the top, whose extension is a linear function of time.I am using the equations of linear elasticity to figure out the stress and strain generated. But I am unable to get the desired results, infact the extensions are not even equal to those for boundary conditionsThough the loss function is in orders of 10^-5 even then there is visible error. Thus I am struggling with genrating required results.Is there is problem with configuration, batch size, learning rate or with the physics?Scripts:but U_y should have been max and the top region should have been red (max) as per the point 4 but its not, which forces me to question whether my model is correct or not.Thank you,Hi @nihalpushkar11If a particular boundary or region is not converging fully (assuming your PDE and problem set are all good), consider tuning the lambda_weighting of your constraints. For example, if your top region is incorrect try increasing the weighting of the top boundary constraint.If things still look incorrect, then perhaps its a set up issue. But try experimenting with the weighting first, this is looking like you may be in the hyper-parameter search/tuning phase.Powered by Discourse, best viewed with JavaScript enabled"
27,stopcriterion-with-modulus-container,"I see that there is a bug with the stop_criterion code as discussed in this post:
https://forums.developer.nvidia.com/t/problem-with-using-criterion-based-stopping/233377/2?u=pattersonDoes anyone know of a workaround for this bug (other than bare metal install)?  I was going to use a brief bash script and sed to replace the problematic lines when a user launches my program, but the modulus code is read-only.Hi @pattersonApologies for not having an updated image quite yet. Its unusual that you’re not able to edit the source code in your container (although this would not change the image).My suggestion would be to use create a extended docker container, using the current Modulus one as a base image and reinstall a patched modulus on top in your dockerfile. That or mount patched modulus source code when your run your container and install it inside the container (full install or develop install)Hi @ngeneva,No problem, I have been using the time to expand on the parameterization of my problem.I’m using a singularity container created from the docker container, so that may be where the read only permissions snuck in.  I’ll try pulling the docker container, modifying, and then converting over.Thanks!Powered by Discourse, best viewed with JavaScript enabled"
28,error-when-changing-activation-function,"Hi there,I would like to change the activation function for my physics-based model (cylinder example). I have used the method described in the manual and used the correct import I found in this forum.However, I receive the following error:How can I fix this? It happens for different activation functions.Many thanks in advance.Hi @jflatterWhich activation functions are you trying?  Could you post that portion of your config file?Hi @pattersonI was trying different activiation functions such as tanh and silu.I used the code provided here: Modulus Configuration - NVIDIA DocsI didn’t change my config file, the portion of it is:The Python code in my case is:Many thanks in advance.Hi @jflatterLooks like this is a bug with the instantiate_arch function which is designed to work with the config files. Here are two solutions that should work for you:This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
29,problem-while-solving-a-backward-facing-step-problem,"Hi all,
I am trying to solve a backward-facing step problem using SimNet. I have created a mesh using SimNet only and gave proper BC. But in this case, my solution is not moving at all. It is not improving after running a long time and loss is also not decreasing.
Also, I am not understanding, how to create validation data for such problem as I don’t have an OpenFOAM case file for it.
I am attaching my code here.back_step.py (5.5 KB)Please helpThank youThanks for posting this, I will try to get some help. Just for completeness can you provide some information about the O/S and GPU that you are using.Thanks for your patience.Powered by Discourse, best viewed with JavaScript enabled"
30,problem-during-installing-nvidia-drivers,"Hello all,
I am trying to install a SimNet using the docker method, on an azure machine where Ubuntu 18.04 OS is installed. It has a tesla k80 GPU accelerator.
While installing NVIDIA CUDA Toolkit,  for installing MLNX_OFED, I used this command which was given in the instructions.
"" sudo ./mlnxofedinstall --with-nvmf --with-nfsrdma --enable-gds --add-kernel-support"". It said command not found.
I tried to install it by downloading and unzipping the file also, but then it said “Current operation system not supported.” Please tell me, where I am doing mistake here?
Does my machine does not meet the necessary hardware requirements or is there any other issue?ThanksSorry for the delay getting a response. There was a small problem with notifications of this post not reaching the SimNet team - I believe that is now resolved and I will also ping the team.
Thanks for making time to report this.Powered by Discourse, best viewed with JavaScript enabled"
31,is-modulus-free,"Is Modulus free? Or are there any restrictions? Thanks.It is free for students I believeModulus is free for anyone. You have to accept a license when downloading though.Is it possible to use the MODULUS for research and publication purposes?Hi @bivaspanigrahiModulus is open-sources available under MIT license, so yes. Preferably with proper citation in publications.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
32,point-cloud-in-csv-file-as-output-only-data-driven,"I have a set of 3d CFD simulations of a seawater intake, in which I have parameterized the speed of the seawater current and the suction speed of the seawater intake, from the simulations I have extracted a cloud of points with position information (x, y, z) and its respective velocity magnitude for each simulation, this in CSV format.
Each point cloud information is in a separate csv file.I want to train a neural network with two input variables (the speeds that I have mentioned) and as output variable a cloud of points with the variables indicated above (x, y, z) and speed magnitude.My question is how to tell modulus that my output is a csv file that contains the information of the cloud of points.Hi @matiyanezYes you can make data-driven models inside of Modulus. CSV is a great format for the data to be in.Reading from a CSV is done in a lot of our examples for reference, such as the cylinder flow problem.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
33,modulus-example-case-helmholtz-value-error,"I am running the /example/helmholtz/ case as described in the installation guide. The output/ folder is also created. however, I am getting an error as follows:/examples/helmholtz# python3 helmholtz.py
[17:05:59] - JIT using the NVFuser TorchScript backend
[17:05:59] - JitManager: {‘_enabled’: True, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[17:05:59] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
Error executing job with overrides: 
ValueError: could not convert string to float: ‘oid sha256:xxxx’The above exception was the direct cause of the following exception:Traceback (most recent call last):
File “helmholtz.py”, line 72, in run
openfoam_var = csv_to_dict(to_absolute_path(“validation/helmholtz.csv”), mapping)
File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/utils/io/csv_rw.py”, line 33, in csv_to_dict
values = np.loadtxt(filename, skiprows=1, delimiter=delimiter, unpack=False)
File “/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py”, line 1338, in loadtxt
arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,
File “/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py”, line 999, in _read
arr = _load_from_filelike(
ValueError: could not convert string ‘oid sha256:xxxxxxxxxxxxx’ to float64 at row 0, column 1.Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.Hi @mitanshtripThis is an issue with not having Git LFS installed properly. Please see the following post or the warning box in our install notes:Let us know if your still having problems even with Git LFS installed. Thanks.I was able to install it correctly. I am getting a different error now:C:\Users\tripatmn.conda\envs\tfgpu\lib\site-packages\hydra_internal\callbacks.py:26: UserWarning: Callback ModulusCallback.on_job_start raised RuntimeError: Running CUDA fuser is only supported on CUDA builds.
warnings.warn(
Error executing job with overrides: 
Traceback (most recent call last):
File “C:\Users\tripatmn\ModFiles\examples\helmholtz\helmholtz.py”, line 52, in run
interior = PointwiseInteriorConstraint(
File “C:\Users\tripatmn.conda\envs\tfgpu\lib\site-packages\modulus-22.9-py3.9.egg\modulus\domain\constraint\continuous.py”, line 493, in init
super().init(
File “C:\Users\tripatmn.conda\envs\tfgpu\lib\site-packages\modulus-22.9-py3.9.egg\modulus\domain\constraint\constraint.py”, line 55, in init
self.model = Graph(
File “C:\Users\tripatmn.conda\envs\tfgpu\lib\site-packages\modulus-22.9-py3.9.egg\modulus\graph.py”, line 141, in init
necessary_nodes[i] = FuncArch(
File “C:\Users\tripatmn.conda\envs\tfgpu\lib\site-packages\modulus-22.9-py3.9.egg\modulus\models\arch.py”, line 618, in init
I_N1 = torch.eye(out_features)[self.needed_output_dims]
IndexError: tensors used as indices must be long, byte or bool tensorsSeems theres something wrong with your bare metal installation. Please make sure all the required dependencies have been installed with the correct versions. I would then also try shutting off FuncTorch using following lines in your config.yaml for this problem:This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
34,is-it-possible-to-create-a-new-nn-for-the-next-time-window-based-on-checkpoints,"Let’s say that after completing the training in Taylor Green’s sample program, I want to create a new 10-11 second neural network based on the 9-10 second checkpoint.
How can I do this?Powered by Discourse, best viewed with JavaScript enabled"
35,cannot-call-validation-data-from-another-python-file,"Hello,I created a model from Nvidia Modulus based on a PDE. Now I want to validate my results with data that I imported from another Python file.This is the error message I am gettingc = c_A(to_absolute_path())
TypeError: ‘numpy.ndarray’ object is not callable""This is the extra lines of code I added for the validation data:from file_XX import c_A
c = c_A(to_absolute_path())
outvar_numpy = {“c”: c},
validator = PointwiseValidator(
nodes=nodes,
invar=invar_numpy,
true_outvar=c
plotter=ValidatorPlotter(),
)
domain.add_validator(validator, “val_data”)I don’t understand what is the error in my code. I’ve been looking at other examples and tried their methods too.Hi @nga77What is the type of c_A?to_absolute_path() is a function that will, given a directory, will prepend the run path. You can have a look at the code here.So I believeDear ngeneva,c_a are the concentration values that I am importing from another python file.
It is of a floating type.
This is the only validation data I am using.Previously, I modeled a PDE of how concentration varies with time and distance. That worked.
Now, I want to validate my results by importing already computed concentration data from another python file.I read about the use of the to_absolute_path function, and realized that was not needed for my case.
So, I changed my code to the following:#add validation data
cA = dict(enumerate(c_A.flatten(),1))
c = str(cA.values()) #convert dict values to string
#cA = dict(enumerate(c_A.flatten(),1))
#c = str(cA.values()) gave error ""invalid data type ‘str’. Without it, gave error “must be real number, not dict”
outvar_numpy = {“c”: c}
validator = PointwiseValidator(
nodes=nodes,
invar=invar_numpy,
true_outvar=outvar_numpy,
batch_size=10,
#100 floating elements in c_A array
plotter=ValidatorPlotter(),
)
domain.add_validator(validator, “val_data”)Now I get the following error message:[19:25:51] - JIT using the NVFuser TorchScript backend
[19:25:51] - JitManager: {‘_enabled’: True, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[19:25:51] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
Error executing job with overrides: 
Traceback (most recent call last):
File “PFR_Val.py”, line 189, in run
validator = PointwiseValidator(
File “/modulus/modulus/domain/validator/continuous.py”, line 52, in init
self.dataset = DictPointwiseDataset(invar=invar, outvar=true_outvar)
File “/modulus/modulus/dataset/continuous.py”, line 35, in init
super().init(invar=invar, outvar=outvar, lambda_weighting=lambda_weighting)
File “/modulus/modulus/dataset/dataset.py”, line 98, in init
self.outvar = Dataset._to_tensor_dict(outvar)
File “/modulus/modulus/dataset/dataset.py”, line 49, in _to_tensor_dict
tensor_dict = {
File “/modulus/modulus/dataset/dataset.py”, line 50, in 
key: torch.as_tensor(value, dtype=tf_dt, device=device)
TypeError: new(): invalid data type ‘str’Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.Hi @nga77The parameter true_outvar should be a dictionary of numpy arrays of size [N, 1] (seems your are feeding in a dictionary with a string value). Please refer to the API documentation here.Thank you so much! That helpedThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
36,transfer-learning,"Hello,I am trying to use transfer learning and just wanted to confirm that I am doing it correctly. I previously created a model and stored the weights in a folder. I then updated my new model and added to the configuration fileinitialization_network_dir : “outputs/previous_model”Are there anymore steps that are required? I asked because this model is taking the exact amount of time and epochs compared to previous model even given it the exact same results.Thank you for your help.Solved. The issue was that since the model is saved in the relative path of “outputs” it cannot see the other models in outputs. Using the to_absolute_path function helped or I could of put the absolute path in the network directory.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
37,inferences-in-real-time,"Hi, I would like to know about how to generate inferences in real time with nvidia modulus or if there is any document or example where inference is made in real time.Hi @matiyanezRight now we largely leave how to deploy the trained model up to the user. Its a PyTorch checkpoint so there are many ways to perform inference both inside and outside of the Modulus framework. What exactly is considered real time largely depends on the problem, the model and other factors. For a deployment example of real time inference, check out the Modulus Omniverse connector.Powered by Discourse, best viewed with JavaScript enabled"
38,conjugate-heat-transfer-issue,"I followed the three_fin_3d example and create my own heat transfer problem. I found that
the chip temperature goes up and I don’t know why it  drops down again.
Is this because that the training iterations is too long, should I terminate it when it reached the maximum value?Hi @cxi1Is a higher temperature expected? This is very problem dependent, but typically when I see something like this it indicates the model was unstable, jumped out of the local minima (i.e. almost diverged) then re-converged to the solution it was optimizing to originally.Check the output fields during this to see if there’s some fluctuations going on that are un-physical. Ideally these monitors should have smooth convergence over the training iteration (although this doesn’t always happen for tricky problems).I expected the temperature to be 70 degrees compared with fluid inlet temperature of 25 degrees.  But no matter
how much I increase the source term, heat sink temp will jump higher but always converge to the fluid temperature of 25 degrees. And the fluid temperature never increases, always keeps 25 degrees, which is strange.
Later I switched to Modified Fourier Network, so it seems to be that large conductivity difference between fluid and heat sink  is probably the cause to this.  Later I tried with different heat sink design parameters, and also fluid parameters and run parameterized simulation, I find the predicted temperature variations is small， which I think there may exists non-dimensionize geometry issues of my code, my inlet is a circle of radius 0.017 mm, I think I need to scale the geometry somehow to retrain the flow and then the heat solver.
And I find it a headache to follow the  documentation of limerock, anuresym, and chip2D example, because I don’t
know the logic what to set for scale and translate values.Powered by Discourse, best viewed with JavaScript enabled"
39,cant-run-simnet-image-with-gpu,"I’ve not been able to run SimNet with GPU on docker.When I try to run: sudo docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --runtime nvidia -v ${PWD}/examples:/examples -it simnet:21.06 bash
I get: docker: Error response from daemon: Unknown runtime specified nvidia.When I try to run: sudo docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --gpus all -v ${PWD}/examples:/examples -it simnet:21.06 bash
I get: docker: Error response from daemon: could not select device driver """" with capabilities: [[gpu]].In troubleshooting, I’ve tried:when I run: systemctl list-unit-files | grep enable | grep docker
the output is:I can run the SimNet Image just fine without GPU: sudo docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -v ${PWD}/examples:/examples -it simnet:21.06 bashI have driver version 465.27, CUDA version 11.3, docker version 20.10.2, and OS Ubuntu 20.04. Any help would be appreciated.Powered by Discourse, best viewed with JavaScript enabled"
40,docker-image-segmentation-fault-core-dumped,"I was trying to run Nvidia Modulus the way Nvidia recommends i.e. using Docker containers. However, I realised, I can’t run even a single example. I am getting Segmentation fault (core dumped) for every single example.I am using Jupyter lab terminal of a remote PC from paperspace.com (just like Google Colab) to run the example files (.py files).The remote computer has 30GB RAM (non ECC) and 16GB Quadro RTX 5000. Here is the output of Nvidia-smi.
image2732×2048 305 KB
I have attached the full error message.error.txt (13.7 KB)Looking at your logs, it seems like it’s a failure in NCCL that got caught by the UCX segfault handler. This is all running on a single node and with one GPU, correct? Can you confirm what version of the container are you using?Also, can you re-run with export NCCL_DEBUG=INFO so we get more verbose logs for the NCCL failures?Hi. Thanks for the reply. I am using version 21.06. Yes, this is on a single node with 1 GPU. Sorry, how to use export NCCL_DEBUG=INFO?As I mentioned in the first post I am inside an interactive session so can’t use docker run. Also, python ldc_2d.py export NCCL_DEBUG=INFO doesn’t work.Fortunately, the simulation is running for some reason without any error. Still, a solution would be helpful if I encounter the problem again.Glad it’s working for you now. For future reference, if you encounter this problem again, you can turn on the NCCL debug logs by running
NCCL_DEBUG=INFO python ldc_2d.pyThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
41,adding-a-constraint-for-speed-of-sound,"Hello,I’m trying to simulate waves in a domain with an obstacle. My model works fine without adding the obstacle constraint, however,  when I’m trying to add this “c” (speed of soundwave) map for the speed of sound as a constraint in my simulation,
I exported the values of x, y, and c_output to an NPZ file from my external script, and I’m trying to import them into my modulus code as such:I receive this error:For clarification, x is a dimension from 0 to 5 with 100 steps and y, t are the same. Also, the values of speed don’t change over time so the values I’m trying to import are constant throughout the time steps.How can I proceed with training my model while having these constant values of c (speed of soundwave) in my domain? Please advise.Hi @cpe.skFrom a first pass I think your code looks good. I dont see anything obvious. So let me just confirm some items here. First without this line of code:your training file runs fine. Please confirm this.The second thing I would verify is that all you numpy arrays are of the same dimension [N,1]:Let me know, and we can hopefully dig in more from here.Yes, it works fine without adding c_speed.I made some changes to this block:The error is no longer there, but the code gets stuck at this output:The sizes of the numpy arrays areAny suggestions on how to get around this?
Thanks for your patience and support @ngeneva !Hi @cpe.skI believe this issue here is that your x,y,t,c arrays all need to be the same size. For your output it also needs to be of the shape [N,1]. The last dimension is the dimension of the variable at a given point (it should also match the output dimension of your speed_net which is 1). In other words each element of your c array is a independent training point.This also means your input variables need to expand as well (the mesh grid approach you were using kinda works but remember your c_obs is not 3D [only 100x100]). So given the dimensions here you probably want:I removed the time dimension and flattened all the numpy arrays. It’s running now. Thank you @ngeneva ! Hopefully, it will produce the targeted results.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
42,the-results-of-turbulence-channel-flow-is-not-the-same-as-those-in-modulus-v22-03-1-user-guide,"Hi,I tried to run the turbulence channel example, testing both the Launder Spalding Wall Functions k_ep and k_om cases.
However, I didn’t get the results given in the user guide.  My case didn’t converge. The loss drops to ~ 10e-3 at around 3000 steps and then it increases, oscilating between 10e-1 and 10e1 till the end.
Moreover, my plof of TKE is simply a horizontal line, unlike the sloping line given in the guide.I didn’t change any parameter. May I know why this is happening?
Is there a bug or something wrong with the python code?Thanks.Hi,I rechecked and realised that I can get the graphs given in the TKE plot at the end of the training, which is 800000 steps. However, the loss is high at around 1e-1.But if I stop at 3000 steps where loss is 1e-3, I got a horizontal line in the TKE plot.I wonder why this is so.  Shouldn’t lower loss give better results?Thanks.No, it shouldn’t. I have included the same thing in my paper with proper reasoning. This is the disadvantage of Modulus. They don’t store the model with the least training loss. Sometimes, SiReNs decides to go crazy after some iterations.Powered by Discourse, best viewed with JavaScript enabled"
43,discretegeometry-sample-boundary-and-interior-with-parameter-subset,"Took me a bit to figure this out with my own code, but I replicated it with the ‘parameterized_tesselated_example.py’ file from the examples.When you try to sample with any a subset of parameters, similar to what is done in the three_fin example for monitors, you get the following error:Here is my modified version of the example file which replicates the problem:I tried this one, a version that makes a secondary parameter set based on the first:and multiple other versions to test how I structured the input, but I keep getting the same error.Let me know if you need any other information*Edit:  There is a workaround… it is to sample the entire discrete geometry range and then filter the returned valuesHi @pattersonThank you for the report as well as the minimal working example! We appreciate it! I’ll get this added to our back log. Another potential solution would be to create a separate geometry object for the subset that only has the files that you’re interested in.Thanks.Powered by Discourse, best viewed with JavaScript enabled"
44,using-bfgs-as-optimizer-and-receive-error-keyerror-max-iter,"Hello,I am trying to use the BFGS optimizer instead of ADAM. Each time I try to use this optimizer I get the following error“envs/modulus/lib/python3.9/site-packages/torch/optim/lbfgs.py”, line 298, in step
max_iter = group[‘max_iter’]
KeyError: ‘max_iter’""Currently my config file has the following entriesdefaults :#optimizer:
#max_iter: 20000scheduler:
decay_rate: 0.95
decay_steps: 5000save_filetypes : “vtk,npz”training:
rec_results_freq: 1000
max_steps : 500000      # Previous example required 500,000 epochs to runbatch_size:
upper_lower_BC: 400
Waveguide_port: 400
open_BC: 400
Interior: 4000
RHS: 400Per this forum post I have also tried putting self before the optimization errordefaults :#optimizer:
#max_iter: 20000scheduler:
decay_rate: 0.95
decay_steps: 5000save_filetypes : “vtk,npz”training:
rec_results_freq: 1000
max_steps : 500000      # Previous example required 500,000 epochs to runbatch_size:
upper_lower_BC: 400
Waveguide_port: 400
open_BC: 400
Interior: 4000
RHS: 400Currently I have max_iters commented out in the optimizer but I have also tried using it.Thank you for your help.Hi @tstonePlace the optimizer setting in your defaults list above self. This is a minor detail with Hydra Config.Some users have encountered a similar problem when this ordering is incorrect:Hello,Thank you for your response. In my original post I did link the bug report you referred to and I tried putting optimizer: bfgs above self. After playing around with the config file I found that if I use a fully connected NN then the optimizer bfgs works but with my setup I am using a modified fourier network which doesn’t seem to work with the BFGS optimizer.Hi @tstoneHmmm, that’s interesting. Does it give the same error you originally posted with the Modified Fourier network?Yes, my original network is modified fourier. The error that I listed is the same.Hi @tstoneWhat version of modulus sym are you using? I just tested the LDC example with the config:using a install of Modulus symbolic from the main branch of the Github repo and it was able to get into the training loop fine. Can you try LDC problem with this config and see if you get the same error?I am using modulus version 22.09Powered by Discourse, best viewed with JavaScript enabled"
45,monitor-the-continuity-and-momentum-residuals-in-sequential-solver,"Dear all, I did many trials to monitor the Continuity and momentum residuals for the Taylor Green Vortex problems but all trials failed.Can you please give a hint on how to do.ThanksHi @omarkhaledsallamThe annular ring problem has a point wise monitor implemented you can use for a reference implementation.Thanks for your reply,
Yes I am familiar on how to setup a monitor,
But this does not work with problems that has moving window architectures.This is my monitor part:This takes very long time then the kernel restarts.Also while the simulation proceeds without the monitor part, loss metric is printed on the screen, can you please advice how to save this loss data to a fileThanks in advancePowered by Discourse, best viewed with JavaScript enabled"
46,failed-unrolling-graph,"I am trying to solve a set of PDEs and algebraic equations with Modulus. Following is the class which defines the PDE node.The source code isRunning Battery.py results in the following errorFor instance, the second PDE (“Insertion_material_current”) expects ‘i_1’ as input. But ‘i_1’ is a dependent variable, the value of which is to be determined by solving the set of equations. Similar issue is observed for the “Material_balance” equation if the divergence term is made non-linear by multiplying variable ‘c’ to it.Is there a way to get around this problem in Modulus without creating additional PDE nodes for each of the equations.Hi @shubhamsp2195As you mentioned the issue is that you have no nodes that can compute many of the intermediate variables (i_1, i_2, and j_n) which causes the graph to fail. You need to create some node to compute these variables.You could do another PDE, although this is likely over kill. If its a neural network, you can use the make_node() function. If these are just some analytical function, the Node.from_sympy() function is a good option. There’s come example use cases of this function in the turbulent channel example.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
47,pytorch-inferencer-from-scratch-using-trained-weights-from-nvidia-modulus-wave-1d-example,"I am trying to create an inferencer that will initialize from a .pth trained model file. This is the wave_1d example from the NVidia Modulus examples. I trained it using the containerized modulus, but I want to use the trained model elsewhere.  I am early on in my learning here but I have this python code using pytorch. It loads the weights and biases as I expect, and I can see the values match what was in the file, which seems to be an OrderedDict. You can see how I set up my neural net class, and it runs, but I do not get the answers I would expect. Any help would be appreciated to let me know what I am missing.
==============================================>8==============================================OK, I think I have cracked the code. Here is my PyTorch-based code to read the .pth file and it looks like it produces the correct result. I am a bit new to Python, so it is really about figuring out the shapes and converting between data types. Python has soooooo much stuff in it, no matter what you want to do there is a function in python to do it, the trick is finding it and then understanding what it does under the hood.Powered by Discourse, best viewed with JavaScript enabled"
48,wave-simulation-giving-random-wrong-output,"I am currently writing a 3D wave equation simulator for electromagnetic waves. A few days ago, my main iteration kernel started behaving unpredictably - generating different results every time the simulation is run, with the same initial conditions. It is hard to provide a minimal example to reproduce the error, since the error is different every time the program is executed. Sometimes it fails at the first execution of the kernel, sometimes it manages to perform hundreds of steps flawlessly and then fail all of a sudden.To illustrate what “failure” means in this context, consider this image, or this one. The streaks coming from the bottom upwards in the Ey, Bx and Bz fields are obviously errors. The plots were generated using matplotlib in python, the kernel itself is written in C. Looking at the data dumps of the plots that exhibit the error shows that the values that are wrong are -nan(ind). I can be sure that the error occurs somewhere during the execution of the kernel, because the wrong values propagate outwards, i.e. they must be in device memory, and are used for the next iteration. The iteration kernel is the only kernel acting on the data in device memory.Further observations:If necessary, I can provide the full code of the kernel. The purpose of this post is to ask what such behaviour might be related to, as I would expect to get the same wrong plot every time the code is re-ran if it was a systematic error. My guess is that it is memory-related - looking at the PTX code generated using NVCC shows that the kernel uses 702 registers, more than half of which are 64-bit. I am running the code on two GTX 1080Ti’s, the error occurs on both of them; I have also asked a friend to run it on his GTX 1080, and he got the same faulty results as I did, with the same random behaviour. Otherwise, it would be possible that there is some sort of numerical instability, but as far as I know that would yield consistently wrong results. Are NVIDIA GPU’s arithmetics deterministic? I am not using any randomized input in the simulation.How does one debug code that does not exhibit consistent behaviour?Hi @slotboom.nI know this is perhaps a bit late, but my gut feeling is similar to what you have… this looks like either a memory problem, perhaps a driver related issue or perhaps an issue with the communication between the two GPUs you are running on. If you’re running the docker image you could try a bare metal install. We have not encountered an error like this when testing on V100/A100 GPUs.There is some driver information in our userguide related to what our docker image is built with. I would verify your versions match.Results should be deterministic with the same code (assuming you set all random seeds (torch, numpy, etc).Powered by Discourse, best viewed with JavaScript enabled"
49,error-in-installation-modulus-v22-03,"Hi:
I am trying to install Nvidia Modulus v22.03 on a cluster with a Conda environment. After installation, the job helmholtz.py cannot run with the following error, I wish to ask how to solve this:Traceback (most recent call last):
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 124, in initialize
DistributedManager.initialize_env()
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 67, in initialize_env
rank = int(os.environ.get(“RANK”))
TypeError: int() argument must be a string, a bytes-like object or a number, not ‘NoneType’During handling of the above exception, another exception occurred:Traceback (most recent call last):
File “/project/user/DL/modulus2203/examples/helmholtz/helmholtz.py”, line 95, in 
run()
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/hydra/utils.py”, line 58, in func_decorated
DistributedManager.initialize()
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 127, in initialize
DistributedManager.initialize_slurm(port)
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 108, in initialize_slurm
DistributedManager.setup(
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 150, in setup
os.environ[“MASTER_ADDR”] = addr
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/os.py”, line 684, in setitem
value = self.encodevalue(value)
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/os.py”, line 756, in encode
raise TypeError(“str expected, not %s” % type(value).name)
TypeError: str expected, not NoneTypePlz don’t use conda env. Use Python venv. I managed to run full Nvidia Modulus i.e. with tessellation library.I am also trying to install Modulus on my workstation. I am wondering does Modulus v22.03 support all NVIDIA GPUs including Ampere GPUs like A5000 and Turing GPUs like RTX 4000?yes I am using RTX A5000 on Modulus. There is no limitation on the GPU as long as the CUDA version of PyTorch is compatible with the GPU driver.Hi @yu_cheng ,Have a look at the install guide for the system/driver requirements. These newer GPUs should work fine (A5000), its older hardware that is typically the concern. I’ll make a note to get these GPUs officially tested and listed. Is there a reason for trying v22.03 versus 22.07?Sounds good. Sorry I didn’t mean to install v22.03. Will try the latest version.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
50,modules-not-found-nvidia-modulus,"Hi, I could run some of the examples within the Modulus Container (22.03.1)
I tried to write my own code, Iwas going to do it step by step, first by running an empty solver based on a custom pde class, that contains just a print(“test”)).
But I received a couple of errors: ModuleNotFoundError: …
after modifying some of the imports I still get the error for other module (geometry.primititves_1d)(
what I have modified and apparently worked:
from modulus.hydra import to_absolute_path, to_yaml, instantiate_arch, ModulusConfig
 → 
from modulus.hydra import to_absolute_path, to_yaml, instantiate_arch
from modulus.hydra.config import ModulusConfig
OR:
modulus.solver import Solver → modulus.continuous.solvers.solver import Solver
)I would like to ask where can one read about the () changes between versions?
There is a previous answer
But I am not able to acces the material in gitlab, I have already submitted the form , but is not possible to edit it in case I made some mistake.Thanks in advance.Hi @dan.m1We had a large restructure of imports in 22.07 release to hopefully make import statements a little more concise. Thus we recommend using the 22.07 container if possible.Is there a reason you’re using the 22.03.1 container? If you were having trouble with 22.07 we have reuploaded the 22.07 container to devzone image. Please give it another download if possible and let me know if it doesn’t work still.We also provide Modulus containers on NGC which can also be pulled as an alternative option: Modulus | NVIDIA NGCWe are looking into the permission issues regarding Gitlab.Hi @ngeneva ,Thanks.
I am using the 22.07 container and now the import is working. Also I’m able to read the material.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
51,tire-friction-has-no-effect-on-vehicle-motion,"I can run simulations with PxVehicleNoDrive and they work as expected. However, the terrain (ground plane) and tire friction attributes seem to not affect the vehicle’s motion.I thought it was a bug on my end until I tried running the example snippet SnippetVehicleNoDrive_64. Changing friction had no effect. Setting gravity to nearly zero yielded results consistent with physics i.e, the wheels spin without locomoting forward.Any help would be appreciated.Hello, I think you have the wrong forum for this question. This topic space is for questions related to Modulus.Powered by Discourse, best viewed with JavaScript enabled"
52,inverse-problem-with-openfoam-data-subnetworks,"Dear all,I am trying to run a similar case as the inverse problem to find PDE coefficients in the User Guide (here).In the example, subnets are used to assimilate OpenFoam data and another network is used to estimate the unknown parameters. My question is: Why sub-networks are needed to assimilate the data? Can’t we just simply provide the Openfoam data to the estimating network ?Are the two sub-networks mandatory? If yes, why?Thanks in advance!HI @lctlr ,Thanks for your interest. Naturally inverse modeling with DNN surrogates is an open research subject with a lot interesting directions. I can provide you some ideas here, but there are many DL and classical approaches that can be considered.This user guide problem has a couple of models: two for the inversion of the fluid flow and two for the inversion of the temperature field. Each has field has a model that learns the state field and another that learns the PDE coefficient.(In the case of the flow, same applies to thermal part)
Having a separate sub-network that learns the flow has a number of advantages.With enough observations over the domain, yes you can likely just have only one model that predicts the PDE coefficient solving the PDE residual using numerically approximated gradients. But this typically isn’t the case with inverse problems of interest. Hope this provides some insights.Thanks a lot for your clear explanation @ngeneva, now I see the point!Hi @lctlr,Hope the response was able to help you move forth with your use case. Would you be interested in speaking to the modulus team to share more details on the use case and we can try to share more insights on how to apply Modulus for you problem. You can reach out to us directly at modulus-team@exchange.nvidia.com.Thanks
RamHi @ramc, super nice!! Your technical support is awesome! However, the email cannot be sent to the following address with the following error message Recipient address rejected: Access denied.Sorry about that - yes there seems to be an issue with the email alias and we are trying to address it. In the mean time, you can reach out to ramc@nvidia.com or anshumanb@nvidia.com.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
53,datasets-for-operator-learning,"I had an issue in running some of the examples for operator learning. For example, the darcy flow example with FNO, (darcy/darcy_FNO.py), it requires the prepared datasets for training the FNO model. However, since I run the model in a server environment, it can not download the datasets there.
I try to download my laptop, but the following url:/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/haape8f9tanarbnit6p5v8tiq0tisevp/1669599975000/04742267196735254513/*/1ViDqN7nc_VCnMackiXv_d7CHZANAFKzV?uuid=8531e420-ca8c-44e8-bf6f-53193de06130seems not working.Do you have a working url for downloading the datasets ?Hi @li.zhang14Thanks for reporting this. The datasets can be found through the original Github repo for FNO:Use Fourier transform to learn operators in differential equations. - GitHub - zongyi-li/fourier_neural_operator: Use Fourier transform to learn operators in differential equations.Specifically, there will be a google drive folder with a Darcy_241 zip file which should be the default used in the example problem. Please be sure its added to the proper datasets folder where the example Python file is located.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
54,handling-an-integral-term-in-the-differential-equation,"Hello, I am trying to solve a PDE where one of the terms is an integral of the solution variable. What would be the best way to calculate it?Details:
We have multiple pdes of the form

$$ \frac{\partial^2 u_i}{\partial x^2} - u_i\int \frac{s(x’)}{\sqrt{(x-x’)^2+1}}dx’ = 0$$
Where $s$ is

$$ s(x) = \sum_i^n|u_i(x)|^2$$
The challenge here is that $s$ dependes on multiple $u_i$ and each solution $u_i$ depends on solving an integral of $s$ over the domain. What would be the best way to represent this in Modulus?Some things that I have tried:
I tried using the Integral function in sympy (Integrals - SymPy 1.11 documentation)Here, I get an error saying that Integral is not definedI checked the modulus sympy to torch converting functions and noticed that sympy.integrate is not in the list of functions that are converted to torch by modulus. This file is modulus/sympy_utils/torch_printer.py.  I tried writing my own convertor to calculate an integral in pytorch from sympy but can’t figure that out.I would be happy to explain this in more detail, and make necessary modifications in Modulus myself if you have some advice.Hi had the same issue. When you try to write a PDE where the inputs depend on the solution, the Modulus is unable to unroll the computational graph. I fixed this in my own implementation.Hi:Did you find a solution?
My equation is much simpler: u’’ + u + Integral_of_u(from -1, to 1) = 0
but I cannot find a condition or implementation inside MODULUS to solve this type of equation.RegardsHi @user39440Unfortunately we do not have native support integral terms inside of PDEs. The closest thing we have is the IntegralBoundaryConstraint but this is for cases where the entire equation is an integral.You would likely need to implement a custom constraint or perhaps a custom node, there are multiple paths. You will need to approximate the integral by sampling points between [-1,1] which could be independent from the ones used to calculate the derivatives.For the brute force custom constraint approach, I would suggest looking at the turbulent super resolution problem.Powered by Discourse, best viewed with JavaScript enabled"
55,parameterize-input-velocity-or-nu,"I’m still in the learning phase, but I have a working fluid flow simulation (currently zero equation turbulence) and I’d like to run it over a range of Reynolds number values.What would be the better/faster approach, parameterize my input velocity or parameterize my viscosity ‘nu’ value?  It seems like there are examples for parameterizing input boundary conditions and geometries, but I can’t find any for parameterization of nu (or similar).Maybe this is intentional? Or is it possible to evaluate a trained network for different nu values?Thanks in advance!Hi @pattersonTheoretically you could do both, but personally I use the different nu parameterization. nu would just be an additional input for your neural network model (e.g. for 2D steady state maybe you have (u,v,p) = NN(x,y,nu)). This would allow for the flow velocity to stay in the same approximate range between Reynolds numbers, likely making it a little easy for your model to converge.Remember to start with a smaller range (maybe even just having a constant Reynolds number) then increase the complexity to the range you desire. Parameterized problems are more tricky.Thanks @ngeneva , I’ll give it a try.If I specify nu as one of the input keys when instantiating the architecture, which I think is the right approach, would I still specify a single value when initializing the ZeroEquation (which then feeds into my NS)?Have a good weekend!Hi @pattersonYes you would want nu (or some scaled version of nu) to be an input key for the neural network. nu would then be provided through the parameterization parameter of a constraint. Any variables provided in the parameterization input are provided to all nodes inside a constraint (just like spatial coords from a geometry). So both your neural network and turbulence model nodes would have access to it.For more info, a good example of this is in the 3 fin example where complex parameterization are defined in the geometry file then used in the constraint.There is also some discussion regarding the parameterization use at the bottom of this post:Hi @ngenevaIt’s a bit sad, but it took me this long to get around to testing out parameterization.I did the following:
added “nu” as an input key for the constructed architecture (tried Fully Connected and Fourier Net)
set up parameterization using pr = Parameterization(Symbol(“nu”), (0.000003, 0.00005)) and use it as the parameterization arg for each of my constraintsIt runs without error!.. until I add a monitor or inferencer that needs velocity or pressure.  I run into the same type of issue that you included in your response, that it could not unroll graph.In looking at the errors, it shows that u, v, w, and p are no longer computable variables. As a straight forward physics problem, I understand how computing any of these without a given nu value would be impossible. Because of this I tried passing Symbol(“nu”) and, separately, a single number (0.000025) as the nu value to ZeroEquation.  Also, I tried changing the nu parameter range to a single value.Here’s a simplified version of my parameter and architecture construction:I feel like I’m close, but I also feel like I barely understand the parameterization component so I might not be close at all.I realize that I need to train the network initially and then can run it in eval run_mode to get results for the range of nu values. Because I am setting up nu as a parameter, do I wait to add any monitors/inferencers until I’m ready to run for evaluation?Any help is appreciated.Hello again,Responding to myself, but I think I misunderstood what to provide to the network.  I modified it so that I was still sending the parameterized nu to each of the constraints, but changed the actual ‘input_keys’ to only include x,y,z as I had for the single nu case.  This appears to be closer to what is discussed in the linked post which @ngeneva provided.It runs now, which gives me a small level of confidence that it is closer to correct.  I need to incorporate the evaluation portion to run post-training but I can post back when I have results.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
56,interpreting-batch-size-parameter-in-constraints,"Hi all,Regarding the batch size parameter that is used in Modulus constraints, I’ll use an example from the aneurysm tutorial:from the python script:and from the config file:
batch_size:
outlet: 650I understand (I think) that this batch size is the number of points sampled on the constraint (in this case the outlet boundary). The points are randomly sampled on the boundary. Are they randomly sampled once, and the same points used in all training epochs; or are they re-sampled periodically? If the former, is there a way to force resampling during training? This would allow greater coverage over the boundary while keeping the number of points (and memory usage) down.On a related note: if I want to sample a very large number of points in the volume (PointwiseInteriorConstraint) I’m likely to run out of memory if all the points are used at once. Is there a way to force mini-batch sampling of that large number of points?Likely the answer to one of these questions also answers the other. I couldn’t derive a satisfactory answer by perusing either the documentation or the source.Thanks.Hi @uribarriThanks for your interest in Modulus. The batch number is the number of points per iteration used for that particular constraint. There are actually two parameters in the constraints that govern the total number of points used in one epoch (side note, Modulus is centered around iterations not epochs):The second parameter listed tells modulus how many batches are in a epoch of this constraint. By default its 1000, so in the example you gave the total number of points used to train the model for the outlet is 650k (650*1000).The comment in the docstring answers the second part of your question. The fixed_dataset parameter, when set to False, will cause the constraint continuously sample points for training from a geometry object. This methodology isn’t used a lot since for most cases the entire training dataset can be stored in memory.Hi @ngeneva ,Thanks for your answer, which addressed all my questions. I was able to try out your suggestions and they seemed to work. I appreciate it.On a related note, when fixed_dataset=False, the resampling of the training points generates a lot of messages in the console, such as the below, which makes following the progress of the training very difficult. Is there a way of suppressing those status messages?Thanks.Hi @uribarriGreat, glad things are cleared up for you. Those messages are from PySDF for sampling points via OptiX. Presently there’s not a way to suppress those via Modulus at this time.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
57,error-in-the-middle-of-running-helmholtz-py,"Test running the helmholtz.py (bare installation) after a few iterations I get the following error. I am also running the same case on a different computer with a different gpu and that seems to be running fine.[22:32:48] - [step:       8900] loss:  5.814e-02, time/iteration:  1.051e+02 ms
[22:32:59] - [step:       9000] record validators time:  6.929e-01s
[22:32:59] - [step:       9000] saved checkpoint to outputs/helmholtz
[22:32:59] - [step:       9000] loss:  3.542e-02, time/iteration:  1.155e+02 ms
[22:33:10] - [step:       9100] loss:  2.047e-02, time/iteration:  1.055e+02 ms
[22:33:20] - [step:       9200] loss:  4.343e-02, time/iteration:  1.055e+02 ms
[22:33:31] - [step:       9300] loss:  2.113e-02, time/iteration:  1.052e+02 ms
[22:33:41] - [step:       9400] loss:  2.224e-02, time/iteration:  1.054e+02 ms
[22:39:15] - loss went to Nans
terminate called after throwing an instance of ‘c10::Error’
what():  CUDA error: the launch timed out and was terminated
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.Hi @mitanshtripUnfortunately its hard to tell what the cause is here. Did you try restarting the training from the latest checkpoint?Powered by Discourse, best viewed with JavaScript enabled"
58,how-do-i-configure-cylcic-learning-rates,"Hello,I’m currently running through the tutorials and I’m investigating ways to speed up convergence.Page 115 in the user guides states:The default is an exponential decay, but you can choose among exponential decay, polynomial decay, exponential decay with warm-up or cyclic schedules for the learning rates.I’ve checked learning_rate.py but I don’t recognise any cyclic learning rate class.
My question is what is the recommended way to implement cyclic learning rate?Hi, thank you for pointing this out. You are correct that we do not currently have the cyclical learning rate in SimNet. However, we have implemented a variant of cyclical learning rate for you and it will be included in the next SimNet release. In this variant, the maximum learning rate is reduced exponentially in each iteration. For now you can use the attached code. Simply replace the current learning_rate.py file with this one, and then run the installer:cd /simnet
python setup.py install
learning_rate.py (7.6 KB)This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
59,some-questions-about-sequentialsolver,"Hi,
i’m using Modulus for a problem similar to Conjugate Heat Transfer
example.
I want to include the temporal variable so i use the equations with time=True.
I decided to follow the Moving Time Window: Taylor Green Vortex Decay
example and manage the training involving time with SequentialSolver().
The overall time window of my problem is very large (about 8 hours).
My questions are:          and maybe go even further and decrease nr_time_windows and increase
          time_window_size?Thanks for your help.Hi @tom_02As a preface, transient problems are very hard for these type of physics-informed ML without data. You are likely beginning to enter current research areas that will be pushing what is possible with just physics constrained learning if the dynamics is complex. Thus take everything I suggest with a grain of salt.I like to think its not a matter of the length of time, but the complexity of the dynamics. If the system is pretty smooth/diffusive then the continuous wave approach can work. But for really complex dynamics we found this time moving window can provide a solution by breaking up the problem into smaller chunks. For example in TG, the length scales of the dynamics are dramatically different between start to end which is near impossible for a single network to learn in one go based on our experience.If you’re only using one time window for the entire t range of the problem then this essentially becomes similar to the wave 1D approach. If you have a set of smaller time windows, then you should also be able to train for a smaller number of iterations for each window since the domain is smaller.Think of this like a numerical solver with a residual criteria. For large timesteps you will need more numerical iterations to converge to a solution, while smaller time steps you may only require a few (granted the total number of iterations across the entire simulation is more for smaller timesteps)The initial condition in this problem is a known analytical field and is placed into its own domain for training (the sequential solver trains over a set of domains). Before we can train a network to learn the dynamics, we need to get it to just reproduce the initial state first. This is adding an inferencer to that domain to sample the prediction at t=0. You’re solution over time will only be as good as your learned initial state.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
60,modulus-extension-error-in-create-2022-1-5,"After enabling Modulus Core Extension and Modulus FPGA scenarios in the Create (2022.1.5) app, we found a triangle warning indicator as follows:

스크린샷_20230103_0929071416×882 184 KB
And I can’t check the FPGA scenario either. Attach the log as follows:Similarly, when Modulus Core Extension is enabled, a warning icon appears, and the log displays the following:Hi @seungha.leeCan you confirm that you launch omniverse using the following command:The FPGA error is likely stemming from the error in the core extension. Because the core extension cannot load, OV is not able to get access to the needed packages such as hydra.~/.local/share/ov/pkg/create-2022.2.0/omni.create.sh --enable modulus_ext.coreHello. Thank you for your kind reply.
When I ran as the guide you sent me, I found that Modulus Core Extension was enabled without warning icons in the Extensions window.
However, as soon as I activate the Modulus FPGA scenario, the Create app stops and shuts down, leaving the following log on the terminal:Powered by Discourse, best viewed with JavaScript enabled"
61,unable-to-run-on-more-than-1-gpu,"I am trying to run NVidia Modulus with FPGA laminar flow example and a personally created simulation.  Both will run and provide results, but I am unable to get either to use more than 1 GPU at a time.Launching using SLURM srun.
Using NVidia Modulus container, converted to Singularity.
Tested on nodes with T4 gpus and separately on nodes with V100 gpus.
I can run python sessions, import torch, and the device count will match however many GPUs I requested using srun.  (inside and outside the container)
nvidia-smi also shows correct gpu count/types. (inside and outside the container)I had to modify the srun command provided in the modulus documentation (Performance section), to set correct number of gpus.I’ve attempted to specify --mpi argument as none, pmi2, and pmix. None of them change the gpu usage.I’ve attempted to include mpirun (-np 4), but adding it prior to the singularity command just launches that many containers.  Adding it as an argument to run in the container returns that the specified number of resources are not available, which seems odd considering nvidia-smi and torch show that the gpus are available.Any help is appreciated!@patterson Looks like you don’t have the -n option in your srun command. This defaults to running a single task: Slurm Workload Manager - srun.That’s probably why you’re also not able to run with mpirun too since the hostfile probably only has one slot based on the SLURM command.If you instead run with srun -n 4 ..., that will launch 4 tasks and each task will target one GPU. Ensure that the following environment variables are set appropriately inside the container so that Modulus and PyTorch can pick those up to set up the distributed job: SLURM_PROCID, SLURM_NPROCS, SLURM_LOCALID and SLURM_LAUNCH_NODE_IPADDR.Thanks for the suggestions, they pointed us in the right direction.  Single node success with mpirun threw us off a bit, but we traced it back to the SLURM_ variables not showing up correctly inside the containers.Perhaps it is just our Slurm configuration, but to get the SLURM_ environment variables to show up correctly we need to allocate using an sbatch command and file:where the slurmGPU.sbatch file contents are:which actually uses srun to launch with the appropriate number of gpus.Hopefully this can help others. Thanks again.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
62,enabling-multiple-gpus,"I am using a system containing two A4000 GPUs, however when I run the modulus examples only one of these is being used at a time. running the line:torch.cuda.device_count()in python within the docker container generates the output “2”, indicating both GPUs can be seen by pytorch (as far as I understand), but only GPU 0 is actually used during the running of the examples.My question is what additional steps do I need to take to ensure that Modulus is able to run with both GPUs available on the system. The line I am using to start the container is:docker run --gpus all --runtime nvidia --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -it -p 8888:8888 modulus:22.09Hi @bmschoppYou should be able to run Modulus in parallel using MPI and other typical parallel launching tools. For some information and example, have to look at the performance section of the docs or some of our examples that use multiple GPUs (e.g. Turbulent super resolution)Powered by Discourse, best viewed with JavaScript enabled"
63,higher-order-derivatives-in-importance-sampling,"Hello,I am considering several functions to be used in the importance sampling scheme proposed by Modulus. In the lid driven cavity example, the 2-norm of the velocity derivative is used. In case higher-order derivatives are to be needed, how should one proceed? This might be of interest if one wanted to use the residual as a sampling measure (as it might be for the heat equation or Navier-Stokes where a second-order term is found).
In the list of required outputs of the graph, it is possible to specify which key (e.g., T in the heat equation) holds the derivative with respect to another key ( e.g., x ). How do you specify that you want a larger order derivative with respect to that key?Thanks,Hi @nripamontFor importance sampling in the LDC example, the first order derivatives are used. Changing to higher-order should be straight forward (assuming the gradients can be calculated in the graph). High-order diffs can be specified in the output keys which will then show up in the output dictionary.Keys that are derivatives are converted into Keys using the diff_str, so u__x is du/dx = Key('u', diff=[Key('x')]), u__x__x is d2u/dx2 = Key('u', diff=[Key('x'), Key('x')]), u__x__y is d2u/dxdy = Key('u', diff=[Key('x'), Key('y')]), etc.So if you want to importance sample in the LDC example with second order diffs:(You could try going higher to third order if you want, will be much slower but Modulus should do the autodiffs for you)Hello,
can we go up to fourth order, but for solving our equation we do not need first and third order, we only need second and fourth to solve equation.Powered by Discourse, best viewed with JavaScript enabled"
64,modulus-22-07-container-version-for-linux-issue,"My docker load failed trying to load Modulus 22.07. I looked at the tar.gz archive with tar ztf and got the following below error. Is there something wrong with modulus_image_v22.07.tar.gz ?f8a5c25010c4cc19ea8296cac8c204271966193c216d48eee4fcb28b91524018/json
f8a5c25010c4cc19ea8296cac8c204271966193c216d48eee4fcb28b91524018/layer.tar
fa61d082a571db03626aa8223571d65035298c6d8668db722420c678163e10b8/
fa61d082a571db03626aa8223571d65035298c6d8668db722420c678163e10b8/VERSION
fa61d082a571db03626aa8223571d65035298c6d8668db722420c678163e10b8/json
fa61d082a571db03626aa8223571d65035298c6d8668db722420c678163e10b8/layer.targzip: stdin: unexpected end of file
tar: Unexpected EOF in archive
tar: Error is not recoverable: exiting nowI also went to the other way to get the image, nVidia NGC, and got the pull command for the 22.07 image. I got this pulled:modulus:22.03 runs fine in docker. However, I get the following for 22.07:what is up with this image???I’m having the same issue - had to downgrade to the v22.03.1 image insteadI am using Windows 11, WSL2, Ubuntu 20.04.is what show up on the WSL2 Ubuntu terminal from nvidia-smi.
and even from within the container 22.03.1but when I run 22.07:Not really sure where to go, I have tried almost everything I can find to do, and nothing seems to break 22.03.1, nor fix 22.07.I also note the following nvidia-docker2 info from apt:I will also note that I can run the 22.07 image if I leave off the “–gpus all” so even though apt shows nvidia-docker2 installed, maybe it is not registering the environment the way 22.07 needs? Of course without --gpus all, it tells me “WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available. Use the NVIDIA Container Toolkit to start this container with GPU support; see Welcome — NVIDIA Cloud Native Technologies documentation .”Here is what happens when I try to run 22.07 on just cpus:But without gpus on 22.03.1 it runs fine, just slow…Something is wrong with the 22.07 container.I had the same error. Error processing tar file(exit status 1): unexpected EOFHi @imsiradws47004374 @gnieuwenhuis and @prakhar_sharmaThanks for reporting this. Is this the image on DevZone (modulus download page)? If so please try downloading it again, we uploaded an new image to hopefully resolve this issue.Note (for future reference) we also provide Modulus containers on NGC which can also be pulled as an alternative option: Modulus | NVIDIA NGCLet me know if the issue still persists.Thank you! Yes, I had issues (although slightly different, I think I put the output in the posts) that prevented each image from running. The NGC pull did create the image locally in my docker but failed to run, some dependency wasn’t there. The downloaded tar.gz image just would not even load, unexpected EOF.Thanks again for your help! That is much appreciated!
2FF09DD150944D29BE94E41A81B23CBE.png708×1 76 Bytes
I now get the same docker runtime error from both methods of getting the image:22.03.1 runs fine.Hi @imsiradws47004374 ,This looks more like a nvidia-docker issue. My suggestions would be to make sure your CUDA drivers are up to date with what is listed in the user-guide. Also to make sure your desktop docker is up to date.What hardware are you running on?Otherwise I would suggest looking on the nvidia container toolkit issues on Github for some solutions that may apply to your system.Hello again, thank you for your help!Here is some diagnostic info:

HardwareSpecs581×567 19.6 KB

NVidia-DockerInfo.txt (81 Bytes)
NVidia-SMI_Ubuntu.txt (1.4 KB)
NVidia-SMI_Windows.txt (2.7 KB)
WSL2Info.txt (541 Bytes)installed nvidia-docker: nvidia-docker2/bionic,now 2.11.0-1 all [installed]This covers my hardware (Alienware X17R2) in the larger PNG file, The windows NVidia driver info in the smaller PNG file. The text files show the output of nvidia-smi in windows powershell and ubuntu bash shell, and the version of nvidia-docker reported in the Ubuntu Linus. Also the WSL2 version.Under this setup, 22.03.1 runs well.22.07 seems to fail here: mount error: file creation failed: /var/lib/docker/overlay2/cbf295d0847a9ea1e856d012a9b2fb94781d2747095d870ac394abca5682339c/merged/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1: file exists: unknownIf I run the 22.07 container without GPU support, modulus starts and I get a bash root prompt. But when I try to run the wave_equation/wave_1d.py example (expecting it to be very slow but run), I get the following error:Thanks again!
ChrisHi @imsiradws47004374 ,Thanks for the system information. Unfortunately seems there’s an open issue with NVIDIA Container Toolkit on WSL2. I’ll have to point you to NVIDIA Docker Github for more information. Perhaps this is the reason. Sorry about this!Github issue:### 1. Issue or feature description
I prepare environment follow this [guide:](…https://docs.nvidia.com/cuda/wsl-user-guide/index.html) 
- Windows 11 build 22000 (Insider Preview Beta Channel)
- WSL2, ubuntu20.04 (Linux version is 5.10.16.3)
- [CUDA on WSL](https://developer.nvidia.com/cuda/wsl/download) 510.06
- CUDA Toolkit 11-4 (using [WSL-Ubuntu](https://docs.nvidia.com/cuda/wsl-user-guide/index.html#ch03a-setting-up-cuda))
- docker 20.10.8
- nvidia-docker2  2.6.0-1 (with libnvidia-container1_1.5.1-1, libnvidia-container-tools_1.5.1-1, nvidia-container-toolkit_1.5.1-1, nvidia-container-runtime_3.5.0-1)

When `sudo docker run --gpus all --runtime=nvidia -it --rm <my image name>`, there comes the issue

>docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: /var/lib/docker/overlay2/706b1d1b6de681b6daf1cab979336a9d465d9b333962cc17db663f2e334d5776/merged/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1: file exists: unknown.

Though encounter problems when run my own image, this sample just works fine:
`docker run --gpus all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark`
![image](https://user-images.githubusercontent.com/73638271/135861058-9c361324-04b8-49e8-877d-f6acdbd8bca0.png)

And I also checked that no nvidia driver installed in my image: 
`docker exec -it containerID /bin/bash`
`apt list --installed`
shows there isn't any nvidia* or libnvidia* package, only have some cuda related packages (cuda-compat-10-2, cuda-cudart-10-2, cuda-license-10-2)

### 2. Information

#### nvidia-container information from `nvidia-container-cli -k -d /dev/tty info`
-- WARNING, the following logs are for debugging purposes only --

I1004 13:41:19.446777 13740 nvc.c:372] initializing library context (version=1.5.1, build=4afad130c4c253abd3b2db563ffe9331594bda41)
I1004 13:41:19.447100 13740 nvc.c:346] using root /
I1004 13:41:19.447125 13740 nvc.c:347] using ldcache /etc/ld.so.cache
I1004 13:41:19.447183 13740 nvc.c:348] using unprivileged user 1000:1000
I1004 13:41:19.447196 13740 nvc.c:389] attempting to load dxcore to see if we are running under Windows Subsystem for Linux (WSL)
I1004 13:41:19.465867 13740 dxcore.c:227] Creating a new WDDM Adapter for hAdapter:40000000 luid:f95e09
I1004 13:41:19.478468 13740 dxcore.c:268] Adding new adapter via dxcore hAdapter:40000000 luid:f95e09 wddm version:3000
I1004 13:41:19.478495 13740 dxcore.c:326] dxcore layer initialized successfully
W1004 13:41:19.478894 13740 nvc.c:397] skipping kernel modules load on WSL
I1004 13:41:19.479135 13741 driver.c:101] starting driver service
I1004 13:41:19.537408 13740 nvc_info.c:758] requesting driver information with ''
I1004 13:41:19.551091 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.460.91.03
I1004 13:41:19.552122 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-opticalflow.so.1
I1004 13:41:19.552152 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.460.91.03
I1004 13:41:19.553231 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-ml.so.1
I1004 13:41:19.553264 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.460.91.03
I1004 13:41:19.553295 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.460.91.03
I1004 13:41:19.554246 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-encode.so.1
I1004 13:41:19.554278 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.460.91.03
I1004 13:41:19.555174 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvcuvid.so.1
I1004 13:41:19.555259 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libdxcore.so
I1004 13:41:19.556208 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libcuda.so.1
I1004 13:41:19.556240 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libcuda.so.460.91.03
I1004 13:41:19.556348 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libcuda.so.460.91.03
W1004 13:41:19.556404 13740 nvc_info.c:397] missing library libnvidia-cfg.so
W1004 13:41:19.556426 13740 nvc_info.c:397] missing library libnvidia-nscq.so
W1004 13:41:19.556429 13740 nvc_info.c:397] missing library libnvidia-fatbinaryloader.so
W1004 13:41:19.556431 13740 nvc_info.c:397] missing library libnvidia-allocator.so
W1004 13:41:19.556433 13740 nvc_info.c:397] missing library libnvidia-ngx.so
W1004 13:41:19.556434 13740 nvc_info.c:397] missing library libvdpau_nvidia.so
W1004 13:41:19.556453 13740 nvc_info.c:397] missing library libnvidia-eglcore.so
W1004 13:41:19.556456 13740 nvc_info.c:397] missing library libnvidia-glcore.so
W1004 13:41:19.556457 13740 nvc_info.c:397] missing library libnvidia-tls.so
W1004 13:41:19.556459 13740 nvc_info.c:397] missing library libnvidia-glsi.so
W1004 13:41:19.556460 13740 nvc_info.c:397] missing library libnvidia-fbc.so
W1004 13:41:19.556462 13740 nvc_info.c:397] missing library libnvidia-ifr.so
W1004 13:41:19.556500 13740 nvc_info.c:397] missing library libnvidia-rtcore.so
W1004 13:41:19.556506 13740 nvc_info.c:397] missing library libnvoptix.so
W1004 13:41:19.556512 13740 nvc_info.c:397] missing library libGLX_nvidia.so
W1004 13:41:19.556514 13740 nvc_info.c:397] missing library libEGL_nvidia.so
W1004 13:41:19.556521 13740 nvc_info.c:397] missing library libGLESv2_nvidia.so
W1004 13:41:19.556524 13740 nvc_info.c:397] missing library libGLESv1_CM_nvidia.so
W1004 13:41:19.556526 13740 nvc_info.c:397] missing library libnvidia-glvkspirv.so
W1004 13:41:19.556527 13740 nvc_info.c:397] missing library libnvidia-cbl.so
W1004 13:41:19.556547 13740 nvc_info.c:401] missing compat32 library libnvidia-ml.so
W1004 13:41:19.556555 13740 nvc_info.c:401] missing compat32 library libnvidia-cfg.so
W1004 13:41:19.556557 13740 nvc_info.c:401] missing compat32 library libnvidia-nscq.so
W1004 13:41:19.556562 13740 nvc_info.c:401] missing compat32 library libcuda.so
W1004 13:41:19.556564 13740 nvc_info.c:401] missing compat32 library libnvidia-opencl.so
W1004 13:41:19.556583 13740 nvc_info.c:401] missing compat32 library libnvidia-ptxjitcompiler.so
W1004 13:41:19.556586 13740 nvc_info.c:401] missing compat32 library libnvidia-fatbinaryloader.so
W1004 13:41:19.556587 13740 nvc_info.c:401] missing compat32 library libnvidia-allocator.so
W1004 13:41:19.556589 13740 nvc_info.c:401] missing compat32 library libnvidia-compiler.so
W1004 13:41:19.556625 13740 nvc_info.c:401] missing compat32 library libnvidia-ngx.so
W1004 13:41:19.556629 13740 nvc_info.c:401] missing compat32 library libvdpau_nvidia.so
W1004 13:41:19.556632 13740 nvc_info.c:401] missing compat32 library libnvidia-encode.so
W1004 13:41:19.556638 13740 nvc_info.c:401] missing compat32 library libnvidia-opticalflow.so
W1004 13:41:19.556640 13740 nvc_info.c:401] missing compat32 library libnvcuvid.so
W1004 13:41:19.556644 13740 nvc_info.c:401] missing compat32 library libnvidia-eglcore.so
W1004 13:41:19.556667 13740 nvc_info.c:401] missing compat32 library libnvidia-glcore.so
W1004 13:41:19.556670 13740 nvc_info.c:401] missing compat32 library libnvidia-tls.so
W1004 13:41:19.556676 13740 nvc_info.c:401] missing compat32 library libnvidia-glsi.so
W1004 13:41:19.556677 13740 nvc_info.c:401] missing compat32 library libnvidia-fbc.so
W1004 13:41:19.556679 13740 nvc_info.c:401] missing compat32 library libnvidia-ifr.so
W1004 13:41:19.556680 13740 nvc_info.c:401] missing compat32 library libnvidia-rtcore.so
W1004 13:41:19.556682 13740 nvc_info.c:401] missing compat32 library libnvoptix.so
W1004 13:41:19.556700 13740 nvc_info.c:401] missing compat32 library libGLX_nvidia.so
W1004 13:41:19.556703 13740 nvc_info.c:401] missing compat32 library libEGL_nvidia.so
W1004 13:41:19.556705 13740 nvc_info.c:401] missing compat32 library libGLESv2_nvidia.so
W1004 13:41:19.556740 13740 nvc_info.c:401] missing compat32 library libGLESv1_CM_nvidia.so
W1004 13:41:19.556745 13740 nvc_info.c:401] missing compat32 library libnvidia-glvkspirv.so
W1004 13:41:19.556746 13740 nvc_info.c:401] missing compat32 library libnvidia-cbl.so
W1004 13:41:19.556748 13740 nvc_info.c:401] missing compat32 library libdxcore.so
I1004 13:41:19.558106 13740 nvc_info.c:277] selecting /usr/lib/wsl/drivers/nv_dispi.inf_amd64_733101c735b9e264/nvidia-smi
W1004 13:41:19.884566 13740 nvc_info.c:423] missing binary nvidia-debugdump
W1004 13:41:19.884603 13740 nvc_info.c:423] missing binary nvidia-persistenced
W1004 13:41:19.884606 13740 nvc_info.c:423] missing binary nv-fabricmanager
W1004 13:41:19.884608 13740 nvc_info.c:423] missing binary nvidia-cuda-mps-control
W1004 13:41:19.884609 13740 nvc_info.c:423] missing binary nvidia-cuda-mps-server
I1004 13:41:19.884611 13740 nvc_info.c:437] skipping path lookup for dxcore
I1004 13:41:19.884617 13740 nvc_info.c:520] listing device /dev/dxg
W1004 13:41:19.884653 13740 nvc_info.c:347] missing ipc path /var/run/nvidia-persistenced/socket
W1004 13:41:19.884663 13740 nvc_info.c:347] missing ipc path /var/run/nvidia-fabricmanager/socket
W1004 13:41:19.884768 13740 nvc_info.c:347] missing ipc path /tmp/nvidia-mps
I1004 13:41:19.884791 13740 nvc_info.c:814] requesting device information with ''
I1004 13:41:19.896593 13740 nvc_info.c:686] listing dxcore adapter 0 (GPU-4949b172-957c-5479-5dc3-12e0ea688389 at 00000000:2d:00.0)
NVRM version:   510.06
CUDA version:   11.2

Device Index:   0
Device Minor:   0
Model:          NVIDIA GeForce RTX 2080 Ti
Brand:          GeForce
GPU UUID:       GPU-4949b172-957c-5479-5dc3-12e0ea688389
Bus Location:   00000000:2d:00.0
Architecture:   7.5
I1004 13:41:19.896655 13740 nvc.c:423] shutting down library context
I1004 13:41:19.897661 13741 driver.c:163] terminating driver service
I1004 13:41:19.898674 13740 driver.c:203] driver service terminated successfully

#### Kernel version from `uname -a`
Linux DESKTOP 5.10.16.3-microsoft-standard-WSL2 #1 SMP Fri Apr 2 22:23:49 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux

#### Any relevant kernel output lines from `dmesg`
[    0.000000] Linux version 5.10.16.3-microsoft-standard-WSL2 (oe-user@oe-host) (x86_64-msft-linux-gcc (GCC) 9.3.0, GNU ld (GNU Binutils) 2.34.0.20200220) #1 SMP Fri Apr 2 22:23:49 UTC 2021
[    0.000000] Command line: initrd=\initrd.img panic=-1 nr_cpus=16 swiotlb=force pty.legacy_count=0
[    0.000000] KERNEL supported cpus:
[    0.000000]   Intel GenuineIntel
[    0.000000]   AMD AuthenticAMD
[    0.000000]   Centaur CentaurHauls
[    0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
[    0.000000] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
[    0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format.
[    0.000000] BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009ffff] usable
[    0.000000] BIOS-e820: [mem 0x00000000000e0000-0x00000000000e0fff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000001fffff] ACPI data
[    0.000000] BIOS-e820: [mem 0x0000000000200000-0x00000000f7ffffff] usable
[    0.000000] BIOS-e820: [mem 0x0000000100000000-0x00000004057fffff] usable
[    0.000000] NX (Execute Disable) protection: active
[    0.000000] DMI not present or invalid.
[    0.000000] Hypervisor detected: Microsoft Hyper-V
[    0.000000] Hyper-V: features 0xae7f, privilege high: 0x3b8030, hints 0xc2c, misc 0xe0bed7b2
[    0.000000] Hyper-V Host Build:22000-10.0-0-0.194
[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480
[    0.000000] Hyper-V: Using hypercall for remote TLB flush
[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    0.000001] tsc: Detected 3899.997 MHz processor
[    0.000007] e820: update [mem 0x00000000-0x00000fff] usable ==> reserved
[    0.000008] e820: remove [mem 0x000a0000-0x000fffff] usable
[    0.000010] last_pfn = 0x405800 max_arch_pfn = 0x400000000
[    0.000033] MTRR default type: uncachable
[    0.000033] MTRR fixed ranges enabled:
[    0.000034]   00000-3FFFF write-back
[    0.000034]   40000-7FFFF uncachable
[    0.000035]   80000-8FFFF write-back
[    0.000035]   90000-FFFFF uncachable
[    0.000035] MTRR variable ranges enabled:
[    0.000036]   0 base 000000000000 mask FFFF00000000 write-back
[    0.000037]   1 base 000100000000 mask FFF000000000 write-back
[    0.000037]   2 disabled
[    0.000037]   3 disabled
[    0.000038]   4 disabled
[    0.000038]   5 disabled
[    0.000038]   6 disabled
[    0.000038]   7 disabled
[    0.000047] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT
[    0.000059] last_pfn = 0xf8000 max_arch_pfn = 0x400000000
[    0.000071] Using GB pages for direct mapping
[    0.000322] RAMDISK: [mem 0x03035000-0x03043fff]
[    0.000326] ACPI: Early table checksum verification disabled
[    0.000332] ACPI: RSDP 0x00000000000E0000 000024 (v02 VRTUAL)
[    0.000334] ACPI: XSDT 0x0000000000100000 000044 (v01 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000338] ACPI: FACP 0x0000000000101000 000114 (v06 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000341] ACPI: DSDT 0x00000000001011B8 01E184 (v02 MSFTVM DSDT01   00000001 MSFT 05000000)
[    0.000343] ACPI: FACS 0x0000000000101114 000040
[    0.000344] ACPI: OEM0 0x0000000000101154 000064 (v01 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000346] ACPI: SRAT 0x000000000011F33C 0003B0 (v02 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000347] ACPI: APIC 0x000000000011F6EC 0000C8 (v04 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000351] ACPI: Local APIC address 0xfee00000
[    0.000516] Zone ranges:
[    0.000517]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.000518]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff]
[    0.000519]   Normal   [mem 0x0000000100000000-0x00000004057fffff]
[    0.000519]   Device   empty
[    0.000520] Movable zone start for each node
[    0.000520] Early memory node ranges
[    0.000521]   node   0: [mem 0x0000000000001000-0x000000000009ffff]
[    0.000522]   node   0: [mem 0x0000000000200000-0x00000000f7ffffff]
[    0.000522]   node   0: [mem 0x0000000100000000-0x00000004057fffff]
[    0.000857] Zeroed struct page in unavailable ranges: 10593 pages
[    0.000859] Initmem setup node 0 [mem 0x0000000000001000-0x00000004057fffff]
[    0.000860] On node 0 totalpages: 4183711
[    0.000861]   DMA zone: 59 pages used for memmap
[    0.000862]   DMA zone: 22 pages reserved
[    0.000862]   DMA zone: 3743 pages, LIFO batch:0
[    0.000884]   DMA32 zone: 16320 pages used for memmap
[    0.000884]   DMA32 zone: 1011712 pages, LIFO batch:63
[    0.010695]   Normal zone: 49504 pages used for memmap
[    0.010698]   Normal zone: 3168256 pages, LIFO batch:63
[    0.011050] ACPI: Local APIC address 0xfee00000
[    0.011055] ACPI: LAPIC_NMI (acpi_id[0x01] dfl dfl lint[0x1])
[    0.011340] IOAPIC[0]: apic_id 16, version 17, address 0xfec00000, GSI 0-23
[    0.011344] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
[    0.011345] ACPI: IRQ9 used by override.
[    0.011346] Using ACPI (MADT) for SMP configuration information
[    0.011353] smpboot: Allowing 16 CPUs, 0 hotplug CPUs
[    0.011362] [mem 0xf8000000-0xffffffff] available for PCI devices
[    0.011363] Booting paravirtualized kernel on Hyper-V
[    0.011365] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.015482] setup_percpu: NR_CPUS:256 nr_cpumask_bits:256 nr_cpu_ids:16 nr_node_ids:1
[    0.016192] percpu: Embedded 52 pages/cpu s173272 r8192 d31528 u262144
[    0.016196] pcpu-alloc: s173272 r8192 d31528 u262144 alloc=1*2097152
[    0.016197] pcpu-alloc: [0] 00 01 02 03 04 05 06 07 [0] 08 09 10 11 12 13 14 15
[    0.016212] Built 1 zonelists, mobility grouping on.  Total pages: 4117806
[    0.016214] Kernel command line: initrd=\initrd.img panic=-1 nr_cpus=16 swiotlb=force pty.legacy_count=0
[    0.018810] Dentry cache hash table entries: 2097152 (order: 12, 16777216 bytes, linear)
[    0.019993] Inode-cache hash table entries: 1048576 (order: 11, 8388608 bytes, linear)
[    0.020038] mem auto-init: stack:off, heap alloc:off, heap free:off
[    0.036796] Memory: 4094128K/16734844K available (16403K kernel code, 2459K rwdata, 3464K rodata, 1444K init, 1164K bss, 388996K reserved, 0K cma-reserved)
[    0.036832] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=16, Nodes=1
[    0.036840] ftrace: allocating 49613 entries in 194 pages
[    0.048726] ftrace: allocated 194 pages with 3 groups
[    0.048929] rcu: Hierarchical RCU implementation.
[    0.048930] rcu:     RCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=16.
[    0.048931]  Rude variant of Tasks RCU enabled.
[    0.048931]  Tracing variant of Tasks RCU enabled.
[    0.048931] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.
[    0.048932] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=16
[    0.051184] Using NULL legacy PIC
[    0.051186] NR_IRQS: 16640, nr_irqs: 552, preallocated irqs: 0
[    0.051565] random: crng done (trusting CPU's manufacturer)
[    0.051585] Console: colour dummy device 80x25
[    0.051591] printk: console [tty0] enabled
[    0.051595] ACPI: Core revision 20200925
[    0.051693] Failed to register legacy timer interrupt
[    0.051694] APIC: Switch to symmetric I/O mode setup
[    0.051695] Switched APIC routing to physical flat.
[    0.051850] Hyper-V: Using IPI hypercalls
[    0.051851] Hyper-V: Using enlightened APIC (xapic mode)
[    0.051922] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x706eb0792cc, max_idle_ns: 881591209130 ns
[    0.051925] Calibrating delay loop (skipped), value calculated using timer frequency.. 7799.99 BogoMIPS (lpj=38999970)
[    0.051926] pid_max: default: 32768 minimum: 301
[    0.051936] LSM: Security Framework initializing
[    0.051958] Mount-cache hash table entries: 32768 (order: 6, 262144 bytes, linear)
[    0.051977] Mountpoint-cache hash table entries: 32768 (order: 6, 262144 bytes, linear)
[    0.052150] x86/cpu: User Mode Instruction Prevention (UMIP) activated
[    0.052167] Last level iTLB entries: 4KB 1024, 2MB 1024, 4MB 512
[    0.052168] Last level dTLB entries: 4KB 2048, 2MB 2048, 4MB 1024, 1GB 0
[    0.052170] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
[    0.052170] Spectre V2 : Mitigation: Full AMD retpoline
[    0.052171] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
[    0.052172] Spectre V2 : mitigation: Enabling conditional Indirect Branch Prediction Barrier
[    0.052172] Spectre V2 : User space: Mitigation: STIBP via seccomp and prctl
[    0.052173] Speculative Store Bypass: Mitigation: Speculative Store Bypass disabled via prctl and seccomp
[    0.052292] Freeing SMP alternatives memory: 52K
[    0.052344] smpboot: CPU0: AMD Ryzen 7 3800X 8-Core Processor (family: 0x17, model: 0x71, stepping: 0x0)
[    0.052403] Performance Events: PMU not available due to virtualization, using software events only.
[    0.052423] rcu: Hierarchical SRCU implementation.
[    0.052753] smp: Bringing up secondary CPUs ...
[    0.052800] x86: Booting SMP configuration:
[    0.052801] .... node  #0, CPUs:        #1  #2  #3  #4  #5  #6  #7  #8  #9 #10 #11 #12 #13 #14 #15
[    0.053300] smp: Brought up 1 node, 16 CPUs
[    0.053300] smpboot: Max logical packages: 1
[    0.053300] smpboot: Total of 16 processors activated (124799.90 BogoMIPS)
[    0.073395] node 0 deferred pages initialised in 10ms
[    0.075402] devtmpfs: initialized
[    0.075402] x86/mm: Memory block size: 128MB
[    0.075402] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.075402] futex hash table entries: 4096 (order: 6, 262144 bytes, linear)
[    0.075402] NET: Registered protocol family 16
[    0.075402] thermal_sys: Registered thermal governor 'step_wise'
[    0.075402] cpuidle: using governor menu
[    0.075402] ACPI: bus type PCI registered
[    0.075402] PCI: Fatal: No config space access function found
[    0.075402] HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages
[    0.075402] HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages
[    0.082164] raid6: skip pq benchmark and using algorithm avx2x4
[    0.082164] raid6: using avx2x2 recovery algorithm
[    0.082164] ACPI: Added _OSI(Module Device)
[    0.082164] ACPI: Added _OSI(Processor Device)
[    0.082164] ACPI: Added _OSI(3.0 _SCP Extensions)
[    0.082164] ACPI: Added _OSI(Processor Aggregator Device)
[    0.082164] ACPI: Added _OSI(Linux-Dell-Video)
[    0.082164] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)
[    0.082164] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)
[    0.085313] ACPI: 1 ACPI AML tables successfully acquired and loaded
[    0.086035] ACPI: Interpreter enabled
[    0.086038] ACPI: (supports S0 S5)
[    0.086039] ACPI: Using IOAPIC for interrupt routing
[    0.086046] PCI: Using host bridge windows from ACPI; if necessary, use ""pci=nocrs"" and report a bug
[    0.086138] ACPI: Enabled 1 GPEs in block 00 to 0F
[    0.086794] iommu: Default domain type: Translated
[    0.086851] SCSI subsystem initialized
[    0.086881] hv_vmbus: Vmbus version:5.2
[    0.086881] PCI: Using ACPI for IRQ routing
[    0.086881] PCI: System does not support PCI
[    0.086881] hv_vmbus: Unknown GUID: c376c1c3-d276-48d2-90a9-c04748072c60
[    0.086881] hv_vmbus: Unknown GUID: 6e382d18-3336-4f4b-acc4-2b7703d4df4a
[    0.086881] clocksource: Switched to clocksource tsc-early
[    0.086881] hv_vmbus: Unknown GUID: dde9cbc0-5060-4436-9448-ea1254a5d177
[    0.170448] VFS: Disk quotas dquot_6.6.0
[    0.170458] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
[    0.170473] FS-Cache: Loaded
[    0.170496] pnp: PnP ACPI init
[    0.170537] pnp 00:00: Plug and Play ACPI device, IDs PNP0b00 (active)
[    0.170571] pnp: PnP ACPI: found 1 devices
[    0.174903] NET: Registered protocol family 2
[    0.175138] tcp_listen_portaddr_hash hash table entries: 8192 (order: 5, 131072 bytes, linear)
[    0.175316] TCP established hash table entries: 131072 (order: 8, 1048576 bytes, linear)
[    0.175416] TCP bind hash table entries: 65536 (order: 8, 1048576 bytes, linear)
[    0.175625] TCP: Hash tables configured (established 131072 bind 65536)
[    0.175649] UDP hash table entries: 8192 (order: 6, 262144 bytes, linear)
[    0.175671] UDP-Lite hash table entries: 8192 (order: 6, 262144 bytes, linear)
[    0.175712] NET: Registered protocol family 1
[    0.176005] RPC: Registered named UNIX socket transport module.
[    0.176006] RPC: Registered udp transport module.
[    0.176007] RPC: Registered tcp transport module.
[    0.176007] RPC: Registered tcp NFSv4.1 backchannel transport module.
[    0.176009] PCI: CLS 0 bytes, default 64
[    0.176049] Trying to unpack rootfs image as initramfs...
[    0.176181] Freeing initrd memory: 60K
[    0.176183] PCI-DMA: Using software bounce buffering for IO (SWIOTLB)
[    0.176185] software IO TLB: mapped [mem 0x00000000f4000000-0x00000000f8000000] (64MB)
[    0.177614] kvm: no hardware support
[    0.178295] kvm: Nested Virtualization enabled
[    0.178301] SVM: kvm: Nested Paging enabled
[    0.178301] SVM: Virtual VMLOAD VMSAVE supported
[    0.181019] Initialise system trusted keyrings
[    0.181118] workingset: timestamp_bits=46 max_order=22 bucket_order=0
[    0.181643] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    0.182012] NFS: Registering the id_resolver key type
[    0.182019] Key type id_resolver registered
[    0.182019] Key type id_legacy registered
[    0.182021] Installing knfsd (copyright (C) 1996 okir@monad.swb.de).
[    0.182442] Key type cifs.idmap registered
[    0.182496] fuse: init (API version 7.32)
[    0.182618] SGI XFS with ACLs, security attributes, realtime, scrub, repair, quota, no debug enabled
[    0.182874] 9p: Installing v9fs 9p2000 file system support
[    0.182880] FS-Cache: Netfs '9p' registered for caching
[    0.182908] FS-Cache: Netfs 'ceph' registered for caching
[    0.182910] ceph: loaded (mds proto 32)
[    0.185420] NET: Registered protocol family 38
[    0.185422] xor: automatically using best checksumming function   avx
[    0.185423] Key type asymmetric registered
[    0.185424] Asymmetric key parser 'x509' registered
[    0.185429] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250)
[    0.186121] hv_vmbus: registering driver hv_pci
[    0.186439] hv_pci b85a1f33-3b6d-4a2b-982d-0ce62be71656: PCI VMBus probing: Using version 0x10003
[    0.187115] hv_pci b85a1f33-3b6d-4a2b-982d-0ce62be71656: PCI host bridge to bus 3b6d:00
[    0.187471] pci 3b6d:00:00.0: [1414:008e] type 00 class 0x030200
[    0.191995] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled
[    0.192317] Non-volatile memory driver v1.3
[    0.194890] brd: module loaded
[    0.195604] loop: module loaded
[    0.195630] hv_vmbus: registering driver hv_storvsc
[    0.195949] wireguard: WireGuard 1.0.0 loaded. See www.wireguard.com for information.
[    0.195950] wireguard: Copyright (C) 2015-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.
[    0.195962] tun: Universal TUN/TAP device driver, 1.6
[    0.196041] PPP generic driver version 2.4.2
[    0.196142] PPP BSD Compression module registered
[    0.196143] PPP Deflate Compression module registered
[    0.196144] PPP MPPE Compression module registered
[    0.196145] NET: Registered protocol family 24
[    0.196149] hv_vmbus: registering driver hv_netvsc
[    0.196242] VFIO - User Level meta-driver version: 0.3
[    0.196361] hv_vmbus: registering driver hyperv_keyboard
[    0.196496] rtc_cmos 00:00: RTC can wake from S4
[    0.196809] scsi host0: storvsc_host_t
[    0.197753] rtc_cmos 00:00: registered as rtc0
[    0.198038] rtc_cmos 00:00: setting system clock to 2021-10-03T15:03:26 UTC (1633273406)
[    0.198046] rtc_cmos 00:00: alarms up to one month, 114 bytes nvram
[    0.198221] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com
[    0.198335] device-mapper: raid: Loading target version 1.15.1
[    0.198404] hv_utils: Registering HyperV Utility Driver
[    0.198405] hv_vmbus: registering driver hv_utils
[    0.198429] hv_vmbus: registering driver hv_balloon
[    0.198437] hv_vmbus: registering driver dxgkrnl
[    0.198452] (NULL device *): dxgk: dxg_drv_init  Version: 2103
[    0.198453] hv_utils: cannot register PTP clock: 0
[    0.198736] hv_balloon: Using Dynamic Memory protocol version 2.0
[    0.198827] hv_utils: TimeSync IC version 4.0
[    0.199020] drop_monitor: Initializing network drop monitor service
[    0.199043] Mirror/redirect action on
[    0.199390] Free page reporting enabled
[    0.199392] hv_balloon: Cold memory discard hint enabled
[    0.199630] (NULL device *): dxgk: mmio allocated 9ffe00000  200000000 9ffe00000 bffdfffff
[    0.199802] IPVS: Registered protocols (TCP, UDP)
[    0.199813] IPVS: Connection hash table configured (size=4096, memory=64Kbytes)
[    0.199835] IPVS: ipvs loaded.
[    0.199836] IPVS: [rr] scheduler registered.
[    0.199836] IPVS: [wrr] scheduler registered.
[    0.199836] IPVS: [sh] scheduler registered.
[    0.199864] ipip: IPv4 and MPLS over IPv4 tunneling driver
[    0.201991] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully
[    0.202382] Initializing XFRM netlink socket
[    0.202426] NET: Registered protocol family 10
[    0.202648] Segment Routing with IPv6
[    0.203692] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver
[    0.203777] NET: Registered protocol family 17
[    0.203790] Bridge firewalling registered
[    0.203796] 8021q: 802.1Q VLAN Support v1.8
[    0.203808] sctp: Hash tables configured (bind 256/256)
[    0.203842] 9pnet: Installing 9P2000 support
[    0.203855] Key type dns_resolver registered
[    0.203863] Key type ceph registered
[    0.203976] libceph: loaded (mon/osd proto 15/24)
[    0.204044] NET: Registered protocol family 40
[    0.204045] hv_vmbus: registering driver hv_sock
[    0.204071] IPI shorthand broadcast: enabled
[    0.204077] sched_clock: Marking stable (203581151, 453300)->(215942200, -11907749)
[    0.204331] registered taskstats version 1
[    0.204338] Loading compiled-in X.509 certificates
[    0.204648] Btrfs loaded, crc32c=crc32c-generic
[    0.206255] Freeing unused kernel image (initmem) memory: 1444K
[    0.271961] Write protecting the kernel read-only data: 22528k
[    0.272551] Freeing unused kernel image (text/rodata gap) memory: 2028K
[    0.273043] Freeing unused kernel image (rodata/data gap) memory: 632K
[    0.273048] Run /init as init process
[    0.273048]   with arguments:
[    0.273048]     /init
[    0.273049]   with environment:
[    0.273049]     HOME=/
[    0.273049]     TERM=linux
[    0.829032] scsi 0:0:0:0: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[    0.829421] sd 0:0:0:0: Attached scsi generic sg0 type 0
[    0.830236] sd 0:0:0:0: [sda] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[    0.830238] sd 0:0:0:0: [sda] 4096-byte physical blocks
[    0.830362] sd 0:0:0:0: [sda] Write Protect is off
[    0.830364] sd 0:0:0:0: [sda] Mode Sense: 0f 00 00 00
[    0.830557] sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    0.874243] hv_pci bb4321df-980a-4d21-afdb-589c18527bf9: PCI VMBus probing: Using version 0x10003
[    0.915773] hv_pci bb4321df-980a-4d21-afdb-589c18527bf9: PCI host bridge to bus 980a:00
[    0.915775] pci_bus 980a:00: root bus resource [mem 0xbffe00000-0xbffe02fff window]
[    0.916751] pci 980a:00:00.0: [1af4:1049] type 00 class 0x010000
[    0.917716] pci 980a:00:00.0: reg 0x10: [mem 0xbffe00000-0xbffe00fff 64bit]
[    0.918396] pci 980a:00:00.0: reg 0x18: [mem 0xbffe01000-0xbffe01fff 64bit]
[    0.919017] pci 980a:00:00.0: reg 0x20: [mem 0xbffe02000-0xbffe02fff 64bit]
[    0.922797] pci 980a:00:00.0: BAR 0: assigned [mem 0xbffe00000-0xbffe00fff 64bit]
[    0.923220] pci 980a:00:00.0: BAR 2: assigned [mem 0xbffe01000-0xbffe01fff 64bit]
[    0.923644] pci 980a:00:00.0: BAR 4: assigned [mem 0xbffe02000-0xbffe02fff 64bit]
[    1.116874] EXT4-fs (sda): mounted filesystem with ordered data mode. Opts: (null)
[    1.202006] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
[    1.202180] sd 0:0:0:0: [sda] Attached SCSI disk
[    1.251980] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x706eb0792cc, max_idle_ns: 881591209130 ns
[    1.252943] clocksource: Switched to clocksource tsc
[    1.881960] Adding 4194304k swap on /swap/file.  Priority:-2 extents:3 across:4210688k
[    3.152119] scsi 0:0:0:1: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[    3.152455] sd 0:0:0:1: Attached scsi generic sg1 type 0
[    3.152998] sd 0:0:0:1: [sdb] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[    3.152999] sd 0:0:0:1: [sdb] 4096-byte physical blocks
[    3.153082] sd 0:0:0:1: [sdb] Write Protect is off
[    3.153083] sd 0:0:0:1: [sdb] Mode Sense: 0f 00 00 00
[    3.153213] sd 0:0:0:1: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    3.154369] sd 0:0:0:1: [sdb] Attached SCSI disk
[    3.160357] EXT4-fs (sdb): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[    3.215983] FS-Cache: Duplicate cookie detected
[    3.215986] FS-Cache: O-cookie c=00000000aa466783 [p=000000006f69fc41 fl=222 nc=0 na=1]
[    3.215987] FS-Cache: O-cookie d=0000000077b88f2e n=00000000cab53c7d
[    3.215987] FS-Cache: O-key=[10] '34323934393337363132'
[    3.215991] FS-Cache: N-cookie c=0000000061e3e253 [p=000000006f69fc41 fl=2 nc=0 na=1]
[    3.215991] FS-Cache: N-cookie d=0000000077b88f2e n=00000000485d5ccb
[    3.215992] FS-Cache: N-key=[10] '34323934393337363132'
[    3.285697] hv_pci d5ce7240-e76a-439c-ad60-bb77c783e7c5: PCI VMBus probing: Using version 0x10003
[    3.286638] 9pnet_virtio: no channels available for device drvfs
[    3.286641] WARNING: mount: waiting for virtio device...
[    3.325716] hv_pci d5ce7240-e76a-439c-ad60-bb77c783e7c5: PCI host bridge to bus e76a:00
[    3.325718] pci_bus e76a:00: root bus resource [mem 0xbffe04000-0xbffe06fff window]
[    3.326672] pci e76a:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.327614] pci e76a:00:00.0: reg 0x10: [mem 0xbffe04000-0xbffe04fff 64bit]
[    3.328222] pci e76a:00:00.0: reg 0x18: [mem 0xbffe05000-0xbffe05fff 64bit]
[    3.328821] pci e76a:00:00.0: reg 0x20: [mem 0xbffe06000-0xbffe06fff 64bit]
[    3.332517] pci e76a:00:00.0: BAR 0: assigned [mem 0xbffe04000-0xbffe04fff 64bit]
[    3.333024] pci e76a:00:00.0: BAR 2: assigned [mem 0xbffe05000-0xbffe05fff 64bit]
[    3.333449] pci e76a:00:00.0: BAR 4: assigned [mem 0xbffe06000-0xbffe06fff 64bit]
[    3.390415] hv_pci 3f8e3335-82c2-499f-8995-e1c33b9178df: PCI VMBus probing: Using version 0x10003
[    3.391719] 9pnet_virtio: no channels available for device drvfs
[    3.391721] WARNING: mount: waiting for virtio device...
[    3.430257] hv_pci 3f8e3335-82c2-499f-8995-e1c33b9178df: PCI host bridge to bus 82c2:00
[    3.430259] pci_bus 82c2:00: root bus resource [mem 0xbffe08000-0xbffe0afff window]
[    3.431241] pci 82c2:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.432187] pci 82c2:00:00.0: reg 0x10: [mem 0xbffe08000-0xbffe08fff 64bit]
[    3.432796] pci 82c2:00:00.0: reg 0x18: [mem 0xbffe09000-0xbffe09fff 64bit]
[    3.433396] pci 82c2:00:00.0: reg 0x20: [mem 0xbffe0a000-0xbffe0afff 64bit]
[    3.437087] pci 82c2:00:00.0: BAR 0: assigned [mem 0xbffe08000-0xbffe08fff 64bit]
[    3.437505] pci 82c2:00:00.0: BAR 2: assigned [mem 0xbffe09000-0xbffe09fff 64bit]
[    3.437940] pci 82c2:00:00.0: BAR 4: assigned [mem 0xbffe0a000-0xbffe0afff 64bit]
[    3.495623] hv_pci 1b1a11d5-ded9-4bdc-b728-16a6ce447102: PCI VMBus probing: Using version 0x10003
[    3.536074] hv_pci 1b1a11d5-ded9-4bdc-b728-16a6ce447102: PCI host bridge to bus ded9:00
[    3.536076] pci_bus ded9:00: root bus resource [mem 0xbffe0c000-0xbffe0efff window]
[    3.537089] pci ded9:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.537996] pci ded9:00:00.0: reg 0x10: [mem 0xbffe0c000-0xbffe0cfff 64bit]
[    3.538600] pci ded9:00:00.0: reg 0x18: [mem 0xbffe0d000-0xbffe0dfff 64bit]
[    3.539322] pci ded9:00:00.0: reg 0x20: [mem 0xbffe0e000-0xbffe0efff 64bit]
[    3.543300] pci ded9:00:00.0: BAR 0: assigned [mem 0xbffe0c000-0xbffe0cfff 64bit]
[    3.543740] pci ded9:00:00.0: BAR 2: assigned [mem 0xbffe0d000-0xbffe0dfff 64bit]
[    3.544177] pci ded9:00:00.0: BAR 4: assigned [mem 0xbffe0e000-0xbffe0efff 64bit]
[   49.061594] hv_balloon: Max. dynamic memory size: 16344 MB
[   71.292198] TCP: eth0: Driver has suspect GRO implementation, TCP performance may be compromised.
[ 8678.849099] docker0: port 1(veth07ad0a7) entered blocking state
[ 8678.849101] docker0: port 1(veth07ad0a7) entered disabled state
[ 8678.849121] device veth07ad0a7 entered promiscuous mode
[ 8678.849150] docker0: port 1(veth07ad0a7) entered blocking state
[ 8678.849151] docker0: port 1(veth07ad0a7) entered forwarding state
[ 8678.849472] docker0: port 1(veth07ad0a7) entered disabled state
[ 8678.990265] cgroup: runc (5415) created nested cgroup for controller ""memory"" which has incomplete hierarchy support. Nested cgroups may change behavior in the future.
[ 8678.990266] cgroup: ""memory"" requires setting use_hierarchy to 1 on the root
[ 8678.990549] cgroup: cgroup: disabling cgroup2 socket matching due to net_prio or net_cls activation
[ 8679.419693] eth0: renamed from veth984197c
[ 8679.459677] IPv6: ADDRCONF(NETDEV_CHANGE): veth07ad0a7: link becomes ready
[ 8679.459697] docker0: port 1(veth07ad0a7) entered blocking state
[ 8679.459697] docker0: port 1(veth07ad0a7) entered forwarding state
[ 8679.459722] IPv6: ADDRCONF(NETDEV_CHANGE): docker0: link becomes ready
[ 8680.288430] veth984197c: renamed from eth0
[ 8680.349650] docker0: port 1(veth07ad0a7) entered disabled state
[ 8680.445249] docker0: port 1(veth07ad0a7) entered disabled state
[ 8680.445930] device veth07ad0a7 left promiscuous mode
[ 8680.445948] docker0: port 1(veth07ad0a7) entered disabled state
[ 8871.582213] docker0: port 1(veth2124c65) entered blocking state
[ 8871.582215] docker0: port 1(veth2124c65) entered disabled state
[ 8871.582233] device veth2124c65 entered promiscuous mode
[ 8872.129587] eth0: renamed from veth99f60f2
[ 8872.189745] IPv6: ADDRCONF(NETDEV_CHANGE): veth2124c65: link becomes ready
[ 8872.189767] docker0: port 1(veth2124c65) entered blocking state
[ 8872.189768] docker0: port 1(veth2124c65) entered forwarding state
[ 9039.653247] process 'local/cuda-10.2/bin/ptxas' started with executable stack
[ 9387.169252] docker0: port 2(veth0ab1b19) entered blocking state
[ 9387.169254] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.169274] device veth0ab1b19 entered promiscuous mode
[ 9387.169302] docker0: port 2(veth0ab1b19) entered blocking state
[ 9387.169302] docker0: port 2(veth0ab1b19) entered forwarding state
[ 9387.169669] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.657707] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.657920] device veth0ab1b19 left promiscuous mode
[ 9387.657937] docker0: port 2(veth0ab1b19) entered disabled state
[ 9417.075476] nf_conntrack: default automatic helper assignment has been turned off for security reasons and CT-based  firewall rule not found. Use the iptables CT target to attach helpers instead.
[40931.406310] docker0: port 2(veth8968728) entered blocking state
[40931.406311] docker0: port 2(veth8968728) entered disabled state
[40931.406330] device veth8968728 entered promiscuous mode
[40931.780035] eth0: renamed from veth8b0ae09
[40931.840207] IPv6: ADDRCONF(NETDEV_CHANGE): veth8968728: link becomes ready
[40931.840231] docker0: port 2(veth8968728) entered blocking state
[40931.840232] docker0: port 2(veth8968728) entered forwarding state
[41888.847459] docker0: port 1(veth2124c65) entered disabled state
[41888.847547] veth99f60f2: renamed from eth0
[41888.994901] docker0: port 1(veth2124c65) entered disabled state
[41888.995012] device veth2124c65 left promiscuous mode
[41888.995014] docker0: port 1(veth2124c65) entered disabled state
[41899.075265] docker0: port 2(veth8968728) entered disabled state
[41899.075320] veth8b0ae09: renamed from eth0
[41899.195126] docker0: port 2(veth8968728) entered disabled state
[41899.195201] device veth8968728 left promiscuous mode
[41899.195202] docker0: port 2(veth8968728) entered disabled state
[44983.095711] docker0: port 1(veth579ec1c) entered blocking state
[44983.095713] docker0: port 1(veth579ec1c) entered disabled state
[44983.095767] device veth579ec1c entered promiscuous mode
[44983.095802] docker0: port 1(veth579ec1c) entered blocking state
[44983.095803] docker0: port 1(veth579ec1c) entered forwarding state
[44983.096169] docker0: port 1(veth579ec1c) entered disabled state
[44983.558932] eth0: renamed from vethe31675b
[44983.609007] IPv6: ADDRCONF(NETDEV_CHANGE): veth579ec1c: link becomes ready
[44983.609031] docker0: port 1(veth579ec1c) entered blocking state
[44983.609032] docker0: port 1(veth579ec1c) entered forwarding state
[48140.938717] docker0: port 2(vethe31a522) entered blocking state
[48140.938720] docker0: port 2(vethe31a522) entered disabled state
[48140.938783] device vethe31a522 entered promiscuous mode
[48140.938815] docker0: port 2(vethe31a522) entered blocking state
[48140.938815] docker0: port 2(vethe31a522) entered forwarding state
[48140.939141] docker0: port 2(vethe31a522) entered disabled state
[48140.953626] docker0: port 2(vethe31a522) entered disabled state
[48140.953890] device vethe31a522 left promiscuous mode
[48140.953910] docker0: port 2(vethe31a522) entered disabled state
[48163.430815] docker0: port 2(veth0cd2f65) entered blocking state
[48163.430817] docker0: port 2(veth0cd2f65) entered disabled state
[48163.430836] device veth0cd2f65 entered promiscuous mode
[48164.076307] docker0: port 2(veth0cd2f65) entered disabled state
[48164.076630] device veth0cd2f65 left promiscuous mode
[48164.076652] docker0: port 2(veth0cd2f65) entered disabled state
[48359.265419] docker0: port 2(veth87ce69e) entered blocking state
[48359.265420] docker0: port 2(veth87ce69e) entered disabled state
[48359.265439] device veth87ce69e entered promiscuous mode
[48359.265464] docker0: port 2(veth87ce69e) entered blocking state
[48359.265465] docker0: port 2(veth87ce69e) entered forwarding state
[48359.265939] docker0: port 2(veth87ce69e) entered disabled state
[48359.975849] docker0: port 2(veth87ce69e) entered disabled state
[48359.975930] device veth87ce69e left promiscuous mode
[48359.975932] docker0: port 2(veth87ce69e) entered disabled state
[63661.051609] docker0: port 2(veth2a489c7) entered blocking state
[63661.051611] docker0: port 2(veth2a489c7) entered disabled state
[63661.051692] device veth2a489c7 entered promiscuous mode
[63661.051745] docker0: port 2(veth2a489c7) entered blocking state
[63661.051747] docker0: port 2(veth2a489c7) entered forwarding state
[63661.052438] docker0: port 2(veth2a489c7) entered disabled state
[63661.065926] docker0: port 2(veth2a489c7) entered disabled state
[63661.065991] device veth2a489c7 left promiscuous mode
[63661.065992] docker0: port 2(veth2a489c7) entered disabled state
[63687.006899] docker0: port 2(veth2cbdb00) entered blocking state
[63687.006901] docker0: port 2(veth2cbdb00) entered disabled state
[63687.006921] device veth2cbdb00 entered promiscuous mode
[63687.533240] eth0: renamed from veth869fda5
[63687.613534] IPv6: ADDRCONF(NETDEV_CHANGE): veth2cbdb00: link becomes ready
[63687.613555] docker0: port 2(veth2cbdb00) entered blocking state
[63687.613556] docker0: port 2(veth2cbdb00) entered forwarding state
[63741.561335] docker0: port 3(veth4e13cbd) entered blocking state
[63741.561337] docker0: port 3(veth4e13cbd) entered disabled state
[63741.561359] device veth4e13cbd entered promiscuous mode
[63741.561385] docker0: port 3(veth4e13cbd) entered blocking state
[63741.561386] docker0: port 3(veth4e13cbd) entered forwarding state
[63741.561689] docker0: port 3(veth4e13cbd) entered disabled state
[63742.201594] docker0: port 3(veth4e13cbd) entered disabled state
[63742.201696] device veth4e13cbd left promiscuous mode
[63742.201697] docker0: port 3(veth4e13cbd) entered disabled state
[63945.395071] docker0: port 3(veth5172a71) entered blocking state
[63945.395073] docker0: port 3(veth5172a71) entered disabled state
[63945.395096] device veth5172a71 entered promiscuous mode
[63945.395127] docker0: port 3(veth5172a71) entered blocking state
[63945.395127] docker0: port 3(veth5172a71) entered forwarding state
[63945.395248] docker0: port 3(veth5172a71) entered disabled state
[63946.001462] docker0: port 3(veth5172a71) entered disabled state
[63946.001557] device veth5172a71 left promiscuous mode
[63946.001558] docker0: port 3(veth5172a71) entered disabled state
[63986.856749] docker0: port 2(veth2cbdb00) entered disabled state
[63986.856794] veth869fda5: renamed from eth0
[63986.998482] docker0: port 2(veth2cbdb00) entered disabled state
[63986.999130] device veth2cbdb00 left promiscuous mode
[63986.999133] docker0: port 2(veth2cbdb00) entered disabled state
[63987.085545] vethe31675b: renamed from eth0
[63987.213378] docker0: port 1(veth579ec1c) entered disabled state
[63987.218358] docker0: port 1(veth579ec1c) entered disabled state
[63987.218861] device veth579ec1c left promiscuous mode
[63987.218862] docker0: port 1(veth579ec1c) entered disabled state
[64786.418297] docker0: port 1(vethead51d5) entered blocking state
[64786.418299] docker0: port 1(vethead51d5) entered disabled state
[64786.418318] device vethead51d5 entered promiscuous mode
[64786.872856] eth0: renamed from veth99b057f
[64786.932949] IPv6: ADDRCONF(NETDEV_CHANGE): vethead51d5: link becomes ready
[64786.932966] docker0: port 1(vethead51d5) entered blocking state
[64786.932967] docker0: port 1(vethead51d5) entered forwarding state
[64787.786553] docker0: port 1(vethead51d5) entered disabled state
[64787.786605] veth99b057f: renamed from eth0
[64787.948146] docker0: port 1(vethead51d5) entered disabled state
[64787.948881] device vethead51d5 left promiscuous mode
[64787.948915] docker0: port 1(vethead51d5) entered disabled state
[64807.747511] docker0: port 1(vethb24ff9b) entered blocking state
[64807.747512] docker0: port 1(vethb24ff9b) entered disabled state
[64807.747531] device vethb24ff9b entered promiscuous mode
[64807.747561] docker0: port 1(vethb24ff9b) entered blocking state
[64807.747562] docker0: port 1(vethb24ff9b) entered forwarding state
[64807.747703] docker0: port 1(vethb24ff9b) entered disabled state
[64808.132878] eth0: renamed from vetha7cd44c
[64808.193099] IPv6: ADDRCONF(NETDEV_CHANGE): vethb24ff9b: link becomes ready
[64808.193123] docker0: port 1(vethb24ff9b) entered blocking state
[64808.193124] docker0: port 1(vethb24ff9b) entered forwarding state
[64809.023917] vetha7cd44c: renamed from eth0
[64809.183134] docker0: port 1(vethb24ff9b) entered disabled state
[64809.188226] docker0: port 1(vethb24ff9b) entered disabled state
[64809.188767] device vethb24ff9b left promiscuous mode
[64809.188769] docker0: port 1(vethb24ff9b) entered disabled state
[65194.352051] docker0: port 1(veth9b9311c) entered blocking state
[65194.352053] docker0: port 1(veth9b9311c) entered disabled state
[65194.352072] device veth9b9311c entered promiscuous mode
[65194.352101] docker0: port 1(veth9b9311c) entered blocking state
[65194.352102] docker0: port 1(veth9b9311c) entered forwarding state
[65194.352424] docker0: port 1(veth9b9311c) entered disabled state
[65194.792790] eth0: renamed from veth5d3475b
[65194.832884] IPv6: ADDRCONF(NETDEV_CHANGE): veth9b9311c: link becomes ready
[65194.832906] docker0: port 1(veth9b9311c) entered blocking state
[65194.832907] docker0: port 1(veth9b9311c) entered forwarding state
[65195.722684] veth5d3475b: renamed from eth0
[65195.792916] docker0: port 1(veth9b9311c) entered disabled state
[65195.878049] docker0: port 1(veth9b9311c) entered disabled state
[65195.878715] device veth9b9311c left promiscuous mode
[65195.878732] docker0: port 1(veth9b9311c) entered disabled state
[66182.663567] scsi 0:0:0:2: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[66182.664300] sd 0:0:0:2: Attached scsi generic sg2 type 0
[66182.664893] sd 0:0:0:2: [sdc] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[66182.664894] sd 0:0:0:2: [sdc] 4096-byte physical blocks
[66182.664973] sd 0:0:0:2: [sdc] Write Protect is off
[66182.664975] sd 0:0:0:2: [sdc] Mode Sense: 0f 00 00 00
[66182.665154] sd 0:0:0:2: [sdc] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[66182.666668] sd 0:0:0:2: [sdc] Attached SCSI disk
[66182.683579] EXT4-fs (sdc): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[66187.399545] EXT4-fs (sdc): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[66187.410623] FS-Cache: Duplicate cookie detected
[66187.410624] FS-Cache: O-cookie c=000000004e228525 [p=000000006f69fc41 fl=222 nc=0 na=1]
[66187.410625] FS-Cache: O-cookie d=0000000077b88f2e n=0000000013e7c87d
[66187.410625] FS-Cache: O-key=[10] '34333031353536303333'
[66187.410628] FS-Cache: N-cookie c=000000005b00e07c [p=000000006f69fc41 fl=2 nc=0 na=1]
[66187.410629] FS-Cache: N-cookie d=0000000077b88f2e n=00000000f3cfd1ce
[66187.410629] FS-Cache: N-key=[10] '34333031353536303333'
[66187.676655] hv_pci c689411f-e482-4a4b-b5ec-379303b0c4a9: PCI VMBus probing: Using version 0x10003
[66187.677922] 9pnet_virtio: no channels available for device drvfs
[66187.677925] WARNING: mount: waiting for virtio device...
[66187.718390] hv_pci c689411f-e482-4a4b-b5ec-379303b0c4a9: PCI host bridge to bus e482:00
[66187.718393] pci_bus e482:00: root bus resource [mem 0xbffe10000-0xbffe12fff window]
[66187.719402] pci e482:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.720467] pci e482:00:00.0: reg 0x10: [mem 0xbffe10000-0xbffe10fff 64bit]
[66187.721103] pci e482:00:00.0: reg 0x18: [mem 0xbffe11000-0xbffe11fff 64bit]
[66187.721739] pci e482:00:00.0: reg 0x20: [mem 0xbffe12000-0xbffe12fff 64bit]
[66187.725644] pci e482:00:00.0: BAR 0: assigned [mem 0xbffe10000-0xbffe10fff 64bit]
[66187.726097] pci e482:00:00.0: BAR 2: assigned [mem 0xbffe11000-0xbffe11fff 64bit]
[66187.726550] pci e482:00:00.0: BAR 4: assigned [mem 0xbffe12000-0xbffe12fff 64bit]
[66187.782347] hv_pci 5de0a50d-7985-4767-96bc-4a4a80b94674: PCI VMBus probing: Using version 0x10003
[66187.783556] 9pnet_virtio: no channels available for device drvfs
[66187.783561] WARNING: mount: waiting for virtio device...
[66187.823210] hv_pci 5de0a50d-7985-4767-96bc-4a4a80b94674: PCI host bridge to bus 7985:00
[66187.823212] pci_bus 7985:00: root bus resource [mem 0xbffe14000-0xbffe16fff window]
[66187.824217] pci 7985:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.825200] pci 7985:00:00.0: reg 0x10: [mem 0xbffe14000-0xbffe14fff 64bit]
[66187.825847] pci 7985:00:00.0: reg 0x18: [mem 0xbffe15000-0xbffe15fff 64bit]
[66187.826493] pci 7985:00:00.0: reg 0x20: [mem 0xbffe16000-0xbffe16fff 64bit]
[66187.830371] pci 7985:00:00.0: BAR 0: assigned [mem 0xbffe14000-0xbffe14fff 64bit]
[66187.830823] pci 7985:00:00.0: BAR 2: assigned [mem 0xbffe15000-0xbffe15fff 64bit]
[66187.831276] pci 7985:00:00.0: BAR 4: assigned [mem 0xbffe16000-0xbffe16fff 64bit]
[66187.887658] hv_pci 28ccd863-7f1b-48fb-a06c-14f1032961b1: PCI VMBus probing: Using version 0x10003
[66187.929043] hv_pci 28ccd863-7f1b-48fb-a06c-14f1032961b1: PCI host bridge to bus 7f1b:00
[66187.929046] pci_bus 7f1b:00: root bus resource [mem 0xbffe18000-0xbffe1afff window]
[66187.930038] pci 7f1b:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.930989] pci 7f1b:00:00.0: reg 0x10: [mem 0xbffe18000-0xbffe18fff 64bit]
[66187.931624] pci 7f1b:00:00.0: reg 0x18: [mem 0xbffe19000-0xbffe19fff 64bit]
[66187.932284] pci 7f1b:00:00.0: reg 0x20: [mem 0xbffe1a000-0xbffe1afff 64bit]
[66187.936143] pci 7f1b:00:00.0: BAR 0: assigned [mem 0xbffe18000-0xbffe18fff 64bit]
[66187.936627] pci 7f1b:00:00.0: BAR 2: assigned [mem 0xbffe19000-0xbffe19fff 64bit]
[66187.937076] pci 7f1b:00:00.0: BAR 4: assigned [mem 0xbffe1a000-0xbffe1afff 64bit]
[66977.281402] docker0: port 1(veth0d37bc8) entered blocking state
[66977.281404] docker0: port 1(veth0d37bc8) entered disabled state
[66977.281423] device veth0d37bc8 entered promiscuous mode
[66977.281453] docker0: port 1(veth0d37bc8) entered blocking state
[66977.281453] docker0: port 1(veth0d37bc8) entered forwarding state
[66977.281748] docker0: port 1(veth0d37bc8) entered disabled state
[66978.181803] docker0: port 1(veth0d37bc8) entered disabled state
[66978.181906] device veth0d37bc8 left promiscuous mode
[66978.181907] docker0: port 1(veth0d37bc8) entered disabled state
[67557.114920] docker0: port 1(veth9c4371d) entered blocking state
[67557.114921] docker0: port 1(veth9c4371d) entered disabled state
[67557.114944] device veth9c4371d entered promiscuous mode
[67557.652243] eth0: renamed from veth99c3a3f
[67557.802389] IPv6: ADDRCONF(NETDEV_CHANGE): veth9c4371d: link becomes ready
[67557.802412] docker0: port 1(veth9c4371d) entered blocking state
[67557.802413] docker0: port 1(veth9c4371d) entered forwarding state
[67558.185775] veth99c3a3f: renamed from eth0
[67558.302350] docker0: port 1(veth9c4371d) entered disabled state
[67558.307904] docker0: port 1(veth9c4371d) entered disabled state
[67558.308442] device veth9c4371d left promiscuous mode
[67558.308444] docker0: port 1(veth9c4371d) entered disabled state
[67593.210939] docker0: port 1(veth228dbe2) entered blocking state
[67593.210940] docker0: port 1(veth228dbe2) entered disabled state
[67593.210960] device veth228dbe2 entered promiscuous mode
[67593.210992] docker0: port 1(veth228dbe2) entered blocking state
[67593.210993] docker0: port 1(veth228dbe2) entered forwarding state
[67593.211282] docker0: port 1(veth228dbe2) entered disabled state
[67593.722096] eth0: renamed from veth20ca901
[67593.782236] IPv6: ADDRCONF(NETDEV_CHANGE): veth228dbe2: link becomes ready
[67593.782257] docker0: port 1(veth228dbe2) entered blocking state
[67593.782258] docker0: port 1(veth228dbe2) entered forwarding state
[68424.882867] init: (195) ERROR: operator():211: shutdown failed 107
[68424.884817] init: (195) ERROR: operator():211: shutdown failed 107
[68424.886584] init: (195) ERROR: operator():211: shutdown failed 107
[68424.888302] init: (195) ERROR: operator():211: shutdown failed 107
[68424.890043] init: (195) ERROR: operator():211: shutdown failed 107
[68424.891745] init: (195) ERROR: operator():211: shutdown failed 107
[68424.893473] init: (195) ERROR: operator():211: shutdown failed 107
[68424.896066] init: (195) ERROR: operator():211: shutdown failed 107
[68424.898353] init: (195) ERROR: operator():211: shutdown failed 107
[68424.900144] init: (195) ERROR: operator():211: shutdown failed 107
[68599.829580] init: (195) ERROR: operator():211: shutdown failed 107
[68599.832116] init: (195) ERROR: operator():211: shutdown failed 107
[68599.834452] init: (195) ERROR: operator():211: shutdown failed 107
[68599.836492] init: (195) ERROR: operator():211: shutdown failed 107
[68599.838390] init: (195) ERROR: operator():211: shutdown failed 107
[68599.840152] init: (195) ERROR: operator():211: shutdown failed 107
[68599.841806] init: (195) ERROR: operator():211: shutdown failed 107
[68599.843637] init: (195) ERROR: operator():211: shutdown failed 107
[68599.845480] init: (195) ERROR: operator():211: shutdown failed 107
[68599.847897] init: (195) ERROR: operator():211: shutdown failed 107

#### Driver information from `nvidia-smi -a`
==============NVSMI LOG==============

Timestamp                                 : Mon Oct  4 21:42:55 2021
Driver Version                            : 510.06
CUDA Version                              : 11.6

Attached GPUs                             : 1
GPU 00000000:2D:00.0
    Product Name                          : NVIDIA GeForce RTX 2080 Ti
    Product Brand                         : GeForce
    Product Architecture                  : Turing
    Display Mode                          : Enabled
    Display Active                        : Enabled
    Persistence Mode                      : Enabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : WDDM
        Pending                           : WDDM
    Serial Number                         : N/A
    GPU UUID                              : GPU-4949b172-957c-5479-5dc3-12e0ea688389
    Minor Number                          : N/A
    VBIOS Version                         : 90.02.30.00.b7
    MultiGPU Board                        : No
    Board ID                              : 0x2d00
    GPU Part Number                       : N/A
    Module ID                             : 0
    Inforom Version
        Image Version                     : G001.0000.02.04
        OEM Object                        : 1.1
        ECC Object                        : N/A
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : N/A
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x2D
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x1E0410DE
        Bus Id                            : 00000000:2D:00.0
        Sub System Id                     : 0x12AE10DE
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 3
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 7000 KB/s
        Rx Throughput                     : 221000 KB/s
    Fan Speed                             : 0 %
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 11264 MiB
        Used                              : 2840 MiB
        Free                              : 8424 MiB
    BAR1 Memory Usage
        Total                             : 256 MiB
        Used                              : 2 MiB
        Free                              : 254 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : N/A
        Memory                            : N/A
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Errors
        Volatile
            SRAM Correctable              : N/A
            SRAM Uncorrectable            : N/A
            DRAM Correctable              : N/A
            DRAM Uncorrectable            : N/A
        Aggregate
            SRAM Correctable              : N/A
            SRAM Uncorrectable            : N/A
            DRAM Correctable              : N/A
            DRAM Uncorrectable            : N/A
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 47 C
        GPU Shutdown Temp                 : 94 C
        GPU Slowdown Temp                 : 91 C
        GPU Max Operating Temp            : 89 C
        GPU Target Temperature            : 84 C
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 20.30 W
        Power Limit                       : 250.00 W
        Default Power Limit               : 250.00 W
        Enforced Power Limit              : 250.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 280.00 W
    Clocks
        Graphics                          : 387 MHz
        SM                                : 387 MHz
        Memory                            : 403 MHz
        Video                             : 539 MHz
    Applications Clocks
        Graphics                          : N/A
        Memory                            : N/A
    Default Applications Clocks
        Graphics                          : N/A
        Memory                            : N/A
    Max Clocks
        Graphics                          : 2100 MHz
        SM                                : 2100 MHz
        Memory                            : 7000 MHz
        Video                             : 1950 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : N/A
    Processes                             : None

#### Docker version from `docker version`
Client: Docker Engine - Community
 Version:           20.10.8
 API version:       1.41
 Go version:        go1.16.6
 Git commit:        3967b7d
 Built:             Fri Jul 30 19:54:27 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.8
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.16.6
  Git commit:       75249d8
  Built:            Fri Jul 30 19:52:33 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.10
  GitCommit:        8848fdb7c4ae3815afcc990a8a99d663dda1b590
 runc:
  Version:          1.0.2
  GitCommit:        v1.0.2-0-g52b36a2
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0

#### NVIDIA packages version from `dpkg -l '*nvidia*'` _or_ `rpm -qa '*nvidia*'`
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend
|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)
||/ Name                               Version                    Architecture Description
+++-==================================-==========================-============-================================================>
un  libgldispatch0-nvidia              <none>                     <none>       (no description available)
un  libnvidia-compute                  <none>                     <none>       (no description available)
ii  libnvidia-compute-460-server:amd64 460.91.03-0ubuntu0.20.04.1 amd64        NVIDIA libcompute package
ii  libnvidia-container-tools          1.5.1-1                    amd64        NVIDIA container runtime library (command-line t>
ii  libnvidia-container1:amd64         1.5.1-1                    amd64        NVIDIA container runtime library
ii  libnvidia-ml-dev                   10.1.243-3                 amd64        NVIDIA Management Library (NVML) development fil>
un  libnvidia-ml.so.1                  <none>                     <none>       (no description available)
un  libnvidia-ml1                      <none>                     <none>       (no description available)
un  libnvidia-tesla-418-ml1            <none>                     <none>       (no description available)
un  libnvidia-tesla-440-ml1            <none>                     <none>       (no description available)
un  libnvidia-tesla-cuda1              <none>                     <none>       (no description available)
ii  nvidia-container-runtime           3.5.0-1                    amd64        NVIDIA container runtime
un  nvidia-container-runtime-hook      <none>                     <none>       (no description available)
ii  nvidia-container-toolkit           1.5.1-1                    amd64        NVIDIA container runtime hook
ii  nvidia-cuda-dev                    10.1.243-3                 amd64        NVIDIA CUDA development files
ii  nvidia-cuda-doc                    10.1.243-3                 all          NVIDIA CUDA and OpenCL documentation
ii  nvidia-cuda-gdb                    10.1.243-3                 amd64        NVIDIA CUDA Debugger (GDB)
ii  nvidia-cuda-toolkit                10.1.243-3                 amd64        NVIDIA CUDA development toolkit
un  nvidia-docker                      <none>                     <none>       (no description available)
ii  nvidia-docker2                     2.6.0-1                    all          nvidia-docker CLI wrapper
un  nvidia-driver                      <none>                     <none>       (no description available)
un  nvidia-legacy-304xx-vdpau-driver   <none>                     <none>       (no description available)
un  nvidia-legacy-340xx-vdpau-driver   <none>                     <none>       (no description available)
un  nvidia-libopencl1                  <none>                     <none>       (no description available)
un  nvidia-libopencl1-dev              <none>                     <none>       (no description available)
ii  nvidia-opencl-dev:amd64            10.1.243-3                 amd64        NVIDIA OpenCL development files
un  nvidia-opencl-icd                  <none>                     <none>       (no description available)
ii  nvidia-profiler                    10.1.243-3                 amd64        NVIDIA Profiler for CUDA and OpenCL
un  nvidia-tesla-418-driver            <none>                     <none>       (no description available)
un  nvidia-tesla-440-driver            <none>                     <none>       (no description available)
un  nvidia-vdpau-driver                <none>                     <none>       (no description available)
ii  nvidia-visual-profiler             10.1.243-3                 amd64        NVIDIA Visual Profiler for CUDA and OpenCL

#### NVIDIA container library version from `nvidia-container-cli -V`
version: 1.5.1
build date: 2021-09-20T14:30+00:00
build revision: 4afad130c4c253abd3b2db563ffe9331594bda41
build compiler: gcc-5 5.4.0 20160609
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections

#### NVIDIA container library logs
2021/10/04 21:48:07 Using bundle directory: /var/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/43c805d8ac1895dc62353aa47b2ac77b5a6eb2d7af3a1441658e55abc97fae27
2021/10/04 21:48:07 Using OCI specification file path: /var/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/43c805d8ac1895dc62353aa47b2ac77b5a6eb2d7af3a1441658e55abc97fae27/config.json
2021/10/04 21:48:07 Looking for runtime binary 'docker-runc'
2021/10/04 21:48:07 Runtime binary 'docker-runc' not found: exec: ""docker-runc"": executable file not found in $PATH
2021/10/04 21:48:07 Looking for runtime binary 'runc'
2021/10/04 21:48:07 Found runtime binary '/bin/runc'
2021/10/04 21:48:07 Running nvidia-container-runtime

2021/10/04 21:48:07 'create' command detected; modification required
2021/10/04 21:48:07 prestart hook path: /bin/nvidia-container-runtime-hook

2021/10/04 21:48:07 existing nvidia prestart hook in OCI spec file
2021/10/04 21:48:07 Forwarding command to runtimePowered by Discourse, best viewed with JavaScript enabled"
65,nvidia-gtc-21-access-technical-training-and-sessions-built-for-developers,"Access technical training and sessions built for developers.
Register for Free - GTC 2022: #1 AI ConferencePowered by Discourse, best viewed with JavaScript enabled"
66,usd-composer-create-2022-2-0-beta-modulus-extension-issue,"Hi,
I installed Create 2022.2.0 beta and install modulus extension and got the error.
Please refer to the screenshot for details.
image2253×1213 309 KBPlease help with a resolution.Hi @ratan.s.muraliPlease try the manual download method towards the end of the install section of the docs. Please be mindful that the Modulus OV extension is presently on a development hiatus. Support will be very limited. Thanks!Thanks for the response.  USD Composer 2022.1.5 not opening on Ubuntu 22.04. here is the error, thus unable to test Modulus as this version nor 2022.2.0 beta not opening in Ubuntu ( error is the same). Please helpPowered by Discourse, best viewed with JavaScript enabled"
67,using-nvidia-modulus,"I am looking at the introductory example to test the use of Modulus here.Am I suppose to run anything else in the terminal before pasting the commands listed under “Creating Nodes”?Hi @nga77This example is showing code snippets from the LDC Python script in the examples repo. You should be running this python file using the command at the bottom of the webpage you linked.Understood. Thank you!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
68,basic-custom-pde-problem-with-boundary-conditions,"As a beginner in using the Modulus framework, I tried to follow the initial code given in the following link:https://docs.nvidia.com/deeplearning/modulus/user_guide/notebook/notebook.htmlIn order to learn, I tried to change the existing code in order to solve the equation of the form u__x__x = x with boundary conditions (BC):
u(0) = 0 and u(2)=1, where x in [0, 2]. Considering that the analytical solution of this equation is u = x*(x^2-1)/6, unfortunately, I did not get even an approximate result using Modulus.In order to set the appropriate BC, I made the following change:from modulus.domain.constraint import PointwiseBoundaryConstraint, PointwiseInteriorConstraintbc = PointwiseBoundaryConstraint(
nodes=nodes,
geometry=geo,
outvar={“in”: (0, 1)},
batch_size=2,
)
domain.add_constraint(bc, “bc”)Considering that I don’t have a good results, can the BC conditions: u(x=0) = 0 and u(x=2) = 1 be set with outvar={“u”: (0, 1)}?Result is shown below:Thanks in advance.Hi @senad.odzakFor two different boundary conditions I would suggest you create two different constraints. I.e. one on the left and right. You can use the criteria parameter of the boundary constraint to specify if its left or right. See the LDC script as an example. E.g.I think the issue you are seeing here is that your BC does not know what value is on the left or right boundary. Its just randomly sampling left / right boundary points and assigning 0/1. Hence why its converging to a value of 0.5 at the boundary (learns the average).This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
69,to-show-pde-loss-boundary-loss-and-aggregated-loss-in-a-single-plot,"In all the examples, the losses have been plotted separately. Is there a way to combine all of them in a single plot?Hi @id21resch11019If you want more custom plotting on top of what the default Tensorboard output provides, it’ll probably be easiest to save all loss values to a CSV then plot or perhaps export the data from Tensorboard.Powered by Discourse, best viewed with JavaScript enabled"
70,welcome-to-modulus-physics-ml-framework-news,"Watch this section for News about Modulus Physics-ML Model Framework.Powered by Discourse, best viewed with JavaScript enabled"
71,how-to-use-the-moving-time-window-method-when-solving-a-convective-heat-transfer-problem,"Hello,I need to solve a transient heat transfer problem in which the flow field and temperature field are coupled. In the Taylor-Green vortex decay example we have just Navier-Stokes eq. and a flow_net. How can I extend  the moving time window method for problems in which there is a heat_net as well as a flow_net?Hi @z.hashemi986Theoretically this is possible, but even taylor-green with this approach is not an easy problem. A transient coupled heat transfer problem is something that is even more complex than we have done, so unless you are very familiar with PINNs, I would recommend starting simple and building up. Its unknown how well the moving-time window approach generalizes to other problems / physics.A good research problem. Best of luck.Thanks for your reply.
By the way, I’m using GPU TRX4090 Ti, but I cannot run the “industrial heat sink” example and I get an “out of memory” runtime error.
Except for A100, which GPU cards do you recommend for PINN using Modulus (for a transient coupled heat and fluid flow may involve phase change)?
Do you recommend any item from these models: A6000 or A40 or A16?Hi @z.hashemi986For some of these more complex problems, GPUs with more VRAM are recommended (such as A100 or V100s). Generally with deep learning more VRAM you have the better. But for many PINNs problems , other GPUs will work just fine. A 4090 has quite a bit of VRAM so maybe adjusting some hyper-parameters may fix it:Thank you so much for the help.Powered by Discourse, best viewed with JavaScript enabled"
72,unable-to-sample-naca-0012-symmetrical-airfoil,"Hi,
I am trying to simulate flow across NACA 0012 airfoil. The formula for the shape of NACA 0012 is -
 yt = 5t(0.2969*sqrt(x) - 0.1260*x - 0.3516*x^2 +0.2843*x^3 - 0.1036*x^4) ,
where,
x is the position along the cord(0 to 1)
yt is the half thickness at a given value of x
t is the maximum thickness as a fraction of the chord, here t = 12% or 0.12The coordinates for upper and lower surface of the airfoil are (xu,yu) and (xl,yl), where,
xu = xl = x, yu = yt and yl = -ytCan someone please help me with the custom geometry class required to sample the airfoil? I am attaching an image of NACA 0012 for your reference.Thanks in advance

NACA00121081×179 25 KB
You may have solved this issue already, but the way I solved this problem was by producing the NACA wing as a list of points, and then I plugged the points into the modulus.geometry.primative_2d.Polygon object. A word of caution, however, while this produces the Wing, producing the Polygon object takes a considerable amount of CPU time. I did this all with Modulus 22.07.Here’s a sample of my code to hopefully help get started:Hope this helps.Hi mrunal.nasery, I tried in the old SimNet before but it was not easy using symbolic programming and I gave up. Wonder if it’s easier in Modulus now.Hi Markjonestx, you are creating a wing, right? So I guess there’s many pts. I guess it should be much faster if it’s just a 2D airfoil. I will take your code and give it a try. Thanks!Hi @tsltaywbIn the current Modulus version a polygon geometry class has been added to our CSG module to make things like 2D airfoils easier to work with. For 3D wings I would probably suggest making a discrete set of STL files and using our tessellated geometry functionality for these more complex cases.Hi ngeneva,Thanks for the tips. I’ll give it a try!Hi Markjonestx, you are creating a wing, right? So I guess there’s many pts. I guess it should be much faster if it’s just a 2D airfoil. I will take your code and give it a try. Thanks!Hello tsltaywb! As ngeneva has suggested, STL will likely be a better solution for 3D airfoils. If you’re working with 2D airfoils though, I have been attempting to explore better solutions than what I posted above. My latest attempt was to take a 2D cross-section of a NACA wing and load it as an STL file, but I suspect the classmethod that parses STL files was not written with 2D objects in mind. I’m exploring other solutions though.Hi @tsltaywbDid the suggested approach work for you? Would you be interested in speaking to the modulus team to share more details on the use case and we can try to share more insights on how to apply Modulus for you problem. You can reach out to us directly at modulus-team@exchange.nvidia.com.Thanks
RamHi markjonestx,Sure. I’ll talk to them. Thanks for the info!Hi ramc,I tried to email you ppl but the email bounced back:Recipient address rejected: Access denied. AS(201806281)Is this the correct email?Thanks.Sorry about that - yes there seems to be an issue with the email alias and we are trying to address it. In the mean time, you can reach out to ramc@nvidia.com or anshumanb@nvidia.com.Hi,I have successfully used the py file ( script at /examples/geometry/naca_airfoil.py) to construct a problem for flow past naca0012 airfoil. I have gotten some results. In the code:We can specify how many pieces of lines can be used to form the polygon airfoil. I realised that when I specify 50 for both airfoil_fore_pts and airfoil_aft_pts, it took a long time to set up, before the actual training starts, like 20 - 30mins. When I use 100, it took like around 1+ to 2 hrs on a V100.Is this normal? Am I using excessively a lot of points? Of course, I still need to do some convergent test but the initialization took really long. I wonder if I do things correctly.Hi @tsltaywbAs the number of elements increase in the CSG module the sample time does rapidly increase since interior points are sampled based on the analytical SDF’s of each element (so each element in the polynomial has its own SDF). Thus you are likely using too many elements in your polynomial for fast sampling. We have some improvements for the geometry module road-mapped.In the past with really complex geometry that takes a long time we have manually sampled points and saved them to file. Then we would load them into a dictionary in our training script and manually create a DictPointwiseDataset which can then be fed into a basic Constraint. The alternative would be to mesh your geometry then use PySDF for sampling.Hi @ngenevaThanks for the info. Will take note to reduce the no. of polygon elements.
Btw, is there an example with regard to the DictPointwiseDataset mtd? Seems like a good alternative.Kind of. This DictPointwiseDataset is used in quite a few spots under the hood. But probably the most convenient location of it being used is in the .from_numpy() class function of the PointwiseConstraint which is essentially an automated method of what I just described.A couple of examples use this: The anti-derivative example with DeepONet, wave inverse problem, etc. Typically shows up with problems involving some data or specific discretization.Hi,Now I need to add discrete pts to create an airfoil. There’s no formula to generate the airfoil. I believe I can still use the prev mtd which involves using polygon.I just saw this post:
https://forums.developer.nvidia.com/t/add-grid-points-manually/241039Will it be faster than using polygon?Using the above 2 approaches, is it also possible to do parameterization?Supposed I have a set of airfoil pts. I have a parameter t. I will multiply it with the y component of the airfoil pts to enable thickness parameterization. Is this workable?Thanks.Powered by Discourse, best viewed with JavaScript enabled"
73,how-do-you-access-a-trained-modulus-model-checkpoint,"Once I have trained the model, how do I access the model itself? So, once it has finished training, how would I plug in values for variables trained on into this model?Hi @isabella.hillmanYour model is saved in a model checkpoint file located in your outputs folder near your training script. With the model checkpoint you load it a python script and it can use it for what you would like. You could do this via the Modulus framework or fall back to a more native PyTorch route.The Link is not available. Is it still up to date?Updated link now on Github:You can also set run_mode: 'eval' in your config YAML.Powered by Discourse, best viewed with JavaScript enabled"
74,add-constraints-and-inferencers-for-navier-stokes-equations-time-true,"Hi,
i am using modulus for a problem similar to the “conjugate heat transfer” example.
First i started by setting the equations with time=False like in the example. Everything worked fine. For my problem i need to insert the time variable so i decided to switch to time=True.  This resulted in the following error:Below is my code:After this, like in “Conjugate heat transfer” example, i  define other constraints for the full geometry. Then i call the solve() function:Even if i change the line input_keys = [Key(""x""), Key(""y""), Key(""z""), Key(""t"")] in input_keys = [Key(""x""), Key(""y""), Key(""z"")] the inferencers and the constraints run but the solver have the following error:Since there are no examples in the guide with time=True i don’t understand where i went wrong.
I appreciate any suggestions.
ThanksHi @tom_02The reason you’re getting that graph error is that the transient N-S equations requires the additional input variable t, which isn’t provided by the geometry (only x,y,z) or your neural network (u,v,w,p). So we need to somehow provide that variable when creating that constraint.This is one of the purposes of the parameterization field in these point constraints that use the geometry module. This can be used in two ways: one is to control parameterized geometry, two is to provide additional variables in the inputs of constraints.Let say you want to solve between time [0,1] during training. You should be achieve this via:An example of this (granted for a specific time) is seen in the Taylor Green example. Using parameterization ranges is also demonstrated in several examples such as FPGA heat sink.Let me know if this doesn’t work.Hi @ngenevaI followed the instructions in the taylor_green example, I have included the time variable and added the “time_window_net” but it seems there are still problems, now with the “MovingTimeWindowArch” object.Error received:Below my code:Then i added inferencers and constraints to the domain.I don’t undertsand the reason of the error, because the code is copied from the example.Thanks for your help.Hi @tom_02If you’re deciding to try the moving time-window example I would suggest turning off JIT in your config and try again. Seems this error is torchscript related.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
75,unroll-graph-error-in-pointwisemonitor-of-2d-flow-over-airfoil-with-inlet-velocity-as-parameter,"Hi, I am using modulus 22.09 to train a model that provide flow field prediction for a 2D airfoil with changing angle of attack and inlet velocity.
However, I encountered a unroll graph error on the pointwisemonitor part, here is the error log:Here is how I set the flow nodes:Here is the PointwiseMonitor that have the unroll graph error:Can somebody kindly help me with this unroll graph error?Best regards.Hi @TinsenLYSeems that the graph is not able to get all of the needed inputs for the neural network to predict the velocity components. Is your model able to get access to vel_in in the monitor? I see you have it commented out, is it a parameterized variable in your geometry?In the error it says:invar: [x, y, sdf, area, aoa, x_pos]
requested var: [continuity, momentum_x, momentum_y]
computable var: [x, y, sdf, area, aoa, x_pos, continuity]which tells me that this vel_in variable is potentially missing from the input / cant be computed.Hi, @ngenevaThank you for your reply.I was trying to add the vel_in using the invar, but it comes out with the error that I have provide mutiple values for the invar. So how should I add the vel_in variable into the monitor?  It is not a parameterized variable in geometry, it is parameterized in flow.py.And then I tried to comment out the monitors and run the code, the loss was large, and the model failed to converge. Does the monitors have influence on the training of the model?Best regards.Hi @TinsenLYI was trying to add the vel_in using the invar , but it comes out with the error that I have provide mutiple values for the invar . So how should I add the vel_in variable into the monitor? It is not a parameterized variable in geometry, it is parameterized in flow.py.Yes, so in the invar parameter you need to provide a dictionary of numpy arrays that includes vel_in variable as well of the same size. So if your monitor will be using 1000 points, this will need to be an array of 1000 points added to the dictionary produced from the sample_interior method. E.g.:The alternative method is to add this variable as a parameterization into the geometry of the system. Basically the geometry model will then serve this variable with the x,y,z coords when building the dataset for the monitor. See the FPGA geometry for an example of this.And then I tried to comment out the monitors and run the code, the loss was large, and the model failed to converge. Does the monitors have influence on the training of the model?No something is wrong with your training.Powered by Discourse, best viewed with JavaScript enabled"
76,double-criteria-on-constraint-generation,"Hi,
i’m working on a problem similar to “conjugate heat transfer example”. I’d like to add double criteria condition in a constraint. So i try to add something like this:But this create the error below:Is it possible to add condition of this form in the same constraint?
ThanksHi @tom_02This should be achievable. At least if it can be compiled to a Sympy expression it should work. For example I can use the following in the LDC example with a double criteria:I can reproduce the error you’re seeing, it could be from the mixing of the custom function + sympy expression. But I am not 100% certain.One alternative you could try is to do both criteria in the wall_criteria function. I believe x and y should be available in your invar dictionary, so you could do this all in numpy using np.logical_and. E.g.Just as warning, this can be tricky for sampling these points. Particularly if you have an equals condition. This criteria is used to assess if randomly sampled points are valid or not, so having a condition that requires a point to exactly be on a certain boundary/constraint is impossible (random generation). You’d be better off defining a new boundary geometry for it if that’s needed.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
77,hanging-issue-of-modulus-v22-07-running-on-multi-node-gpus,"I want to run Modulus on two machines with each have 4 GPUs.
For now, I can run Modulus on each machine with 4 GPUs without any issues, as attached figure.

image1920×783 118 KB

However, when I use the two machines, it will hang as shown in the screen shot. It cannot initialized GPUs using openmpi as in the above worked simulation. It works for v21.06 but failed for v22.07.

image2386×210 95.5 KB

There is no mpi issues across the two machines and also no mpi incompatibility issue.
Does anyone meet similar issue or have any comments on this issue?
ThanksHi @Shen666 ,We don’t use singularity for running our image. I am somewhat suspecting that this may be an issue with that and the Modulus docker image (I am assuming the singularity container is built off the docker file?). I have not seen this issue before.After some Googling, there does seem to be some potentially relevant information here about using singularity with a nvidia-docker container (mention the cuda path you have here mid way down).https://www.nmr.mgh.harvard.edu/martinos/userInfo/computer/docker.phpIf this doesn’t work still you may want to try a bare-metal install (python install) which still has the majority Modulus’ features functional.I am able to train on multiple nodes using an Apptainer image.Thanks @ngenevaHi @prakhar_sharma , for Apptainer image, is it an image on AWS or other cloud provider? Where could I try?
Do you convert the Modulus to singularity container image .sif or sandbox?
ThanksI didn’t convert the image. I was learning Apptainer. So, out of interest I created my own Apptainer definition file to build an image from the base image.it works perfectly fine, with multiple GPUs, mpirun and with pysdf.Interesting. Since Modulus only release docker image, I am curious how you run it with Apptainer without convert it to .sif file. Would you mind sharing the cmd you run to launch Modulus with Apptainer? That will be very helpful for me to understand. Many thanks @prakhar_sharmasorry I can’ t share. I am looking to create an MR on their Gitlab repo if they allow me. But it is not too difficult. You just need the base image (find the link in the previous comment) and then apply everything which is required for the bare metal installation.I see. Thanks. I will try with ApptainerPowered by Discourse, best viewed with JavaScript enabled"
78,implementation-of-flux-continuity-across-interface-in-nvidia-modulus,"I am working on a physics problem which involves diffusive fluxes. At a certain location of defined geometry, flux continuity across interface must be imposed, i.e. the diffusive fluxes at the right and the left of interface must be the same. Following figure illustrates the problem that I am trying to handle.I tried using the parameterization option in PointwiseBoundaryConstraint() to specify the location of interface. But this option cannot be used for equating fluxes at two sides of an interface. Is there an elegant way to implement this constraint in Modulus?Hi @shubhamsp2195Is this interface aligned along an axis (say the normal of this interface is the x-axis as in the picture). Then does it make sense to impose u__x__x = 0 so pointwise the gradient of u_x is zero in the interface normal direction? Alternatively could you consider using a integral constraint to represent continuity here (we use this in incompressible problems)?Otherwise I think you would have to create a custom constraint to impose points on the left side of the line are equal to the right. This should not be too difficult, in fact we had tried something like that in the past. But go with the second-order gradient first if possible.Hi @ngeneva
My problem domain involves arbitrarily aligned interfaces. So I may need to specify a custom constraint. Thank you for suggesting possible solutions to my query.Powered by Discourse, best viewed with JavaScript enabled"
79,error-in-running-fourcastnet-github-code-pre-processing-stage,"Hi! I am going through the FourCastNet code inside GitHub (GitHub - NVlabs/FourCastNet: Initial public release of code, data, and model weights for FourCastNet) and at the pre-processing stage I have got an error which is:  KeyError: “Unable to open object (object ‘fields’ doesn’t exist)”
I have hdf5 parallel enabled and using the exact dataset which means the dates and the format inside the example code inside the rep, and still, get this error.
How can I solve this issue? thank you very much.Hi @afshin.shafeiUnfortunately we can’t provide direct support for the GitHub code since the team is not familiar with the pre-processing implemented here. I would say your best bet would be to open an issue on the Github repo page or reach out to the lead author.From what you described seems your H5 file is missing some data… perhaps use h5ls to see if the correct fields are in fact inside the file? (Just a guess)Thank you very much for the reply. I checked the files and they seem to be correct, they have all the parts required for running. but I can’t understand where is the problemHi @afshin.shafei @ngenevaDid you find a cause and a solution to this problem as I have encountered the same issue?Thank you for your help.hello @john.taylor1 ! :)
yeah I found the solution, you can check in this link: Pre-processing stage key error · Issue #6 · NVlabs/FourCastNet (github.com)They suggested me to pre-populating a h5 file:"" I would recommend pre-populating the empty hdf5 files. Before running the parallel_copy_small_set.py file. I will push a script to do that. It should just do the following:""time_steps = 52
with h5py.File(‘filename.h5’, ‘w’) as f:
f.create_dataset(‘fields’, shape = (time_steps, 20, 720, 1440), dtype=‘f’)Thank you - I created the h5 files and can now get the code running.Powered by Discourse, best viewed with JavaScript enabled"
80,simulation-killed-with-no-other-error-message,"I am running the Modulus v22.03.1 docker container on a Mac. In the past, it was working fine, but at present several of the examples are starting up, printing the training parameters, and then getting killed before the training can start. I have output like this:[00:55:36] - Jit compiling network arch
[00:55:37] - attempting to restore from: outputs/wave_1d
[00:55:37] - optimizer checkpoint not found
[00:55:37] - model wave_network.pth not found
KilledDo you know why the training process would be getting “Killed” like this?Hi @gemma.mason ,We don’t have a “Killed” exit message inside of Modulus, so I suspect this is coming for PyTorch side. Some suggestions would be to turn off JIT (add jit: false in your config.yaml). Also try lowering the batch size for these examples. Its hard to tell, but you could be running out of memory.If these do not work, do you have a list of examples that work vs. ones that don’t?You are correct, it was a memory issue! I found this page which talks about this issue in the PyTorch context: Code stopping with text ""Killed""? - PyTorch ForumsThank you very much for the advice.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
81,is-it-possible-to-include-training-data-within-modulus,"If someone could advise me on whether you can include training data within Modulus that would be most appreciated. I know you can use validation data, but I would like to include data to train on.I am using a linear elastic model. I have very low losses when training to model. However, the inference results for stresses and several orders of magnitude out.Hello, we are looking into including trained models for all of our examples so users can quickly see the results. We don’t have any definite plans on this yet.Powered by Discourse, best viewed with JavaScript enabled"
82,example-problem-t-junction,"@ngeneva I have reworked the bent pipe example to something that should both have valid geometries, and can be usable as an example problem if nvidia is interested. However, like the previous problem I am having some difficulties getting it solve the water flow and would appreciate some assistance if you have the bandwidth.This sample is emulating hot water flow in a T junction containing two inlets and one outlet. The pipe diameter is constant at ~5mm. The water relevant to my use case is 140f and so I’ve tried to select nu and rho values accordingly. This is not a space I’m experienced with however, and I may have selected these values poorly. I used this web app to aid me:This water viscosity will help you determine the viscosity of water at any temperature.
This example has been based on code from both the aneurysm and the 3D three fin samples.Scale is tied to velocity magnitude
Color is tied to pressure
image1301×580 93.2 KB
t_junc.zip (56.8 MB)In very early iterations (e.g. 1000-5000), Modulus produces output that appears close to the expected solution. This could just be a random coincidence given how few iterations have been ran, but it unfortunately fails to converge. As it continues to train, it will never solve the flow and continually diverge away from it. My current best guess is that this has something to do with scaling, as I’ve noticed that the modulus output produces velocities several magnitudes smaller than the CFD output. Unfortunately, I’m not sure how to troubleshoot that. I don’t believe it’s an over training issue because there’s no point in the middle at which it was producing good output either.I’m hoping that someone can help me identify some fundamental flaw in my approach that’s preventing me from convergence. Thanks :-).
image1374×654 131 KB

image1385×646 123 KB
Hi @npstrikeWow, thanks! I’ll do my best to take a look at this in the next week or two (will follow up). Really appreciate the effort here to set up a completely new system to share. Hopefully convergence can be improved as it would be an exciting edition to our examples.Thanks @ngeneva, I’ll appreciate whatever you can offer.Any chance you’ve had the opportunity to look into this @ngeneva ?Means of facilitating PINN convergence is of interest to me as well.I’ve bookmarked this problem, it may take me some time, but I will be examining other, related problems.Hi @npstrikeApologies for the delay. I did take a look at the problem and did notice pretty slow training progress, however the overall problem set up appears good.Regardless I have a few comments / suggestions I would eventually try on this type of problem which are below. Please correct me if something seems off:This is using the inlet mesh of the branch tube which results in an integral continuity plane just at the entrance of the mesh which isn’t actually that beneficial. Ideally we want these integral planes to be spaced out all along this inlet tube where we know the total flow rate. For example in the image below in paraview, the red points are the sampled current integral plane, the green are the volume and purple are where some good integral continuity could be placed.Ideally you want these to be random and a few per batch. I think you could create a 2D circle primitive with a symbol for its Y location, one can then parameterize the Y variable in the integral continuity to sample circles along the vertical (Y) axis. (I think, havent tried so dont quote me)image1760×1244 154 KBSame deal for the other inlet tube (and even the outlet). Setting this up correctly will be likely to make a large difference in convergence.What Reynolds number is this? I have not done the calculation myself, but if its quite high resolving the boundaries will be very challenging and I would probably recommend adding a zero equation turbulence model to the PDE (example). And also adjusting the sampling so you have a bulk flow constraint and then a near wall constraint. Can use the SDF as a criteria to accomplish this. We have used this in the past for some of the higher Re flows such as the FPGA problem.I would have to look at the scaling more, but I’m thinking maybe theres some adjustments that could be made there to make the inlet velocities / viscosity with slightly more normalized values while maintaining the Reynolds number. Perhaps its alright as is.Make sure you are not making the pipe diameter too small for the sake of decreasing the lengths of the tubes. If you know the inlet is likely laminar, you could decrease the length of the inlet pipes to make the diameter of the pipes larger since you know the flow profile (v(r) = v_0 (1 - r^2 / R^2) or something like that, cant recall exactly please check).Consider using a fourier net model (keyword fourier in the config for the model, docs are incorrect currently). They can work better for these problems with different length scales (in your case a long tube length but small diameter)Unfortunately, I dont have bandwidth at this very moment to dig into this problem more. Although I do intend to keep it on my radar for the future. Maybe trying out some of these suggestions. Naturally there’s a number of things that could be tinkered with but the first priority is to get the flow to converge consistency (even at a slightly different Reynolds number although your validation will be useless).Thanks for the feedback @ngeneva! I’ll definitely look into your suggestions. As for the integral planes, I don’t make the .stl files so to reduce how many new files I wait on I’m using the same mesh as the inlet/outlet, but then transforming it by an offset so that it’s somewhere along the length of the tube like you indicated. I believe the branch integral lands somewhere around the middle one you’ve marked. I hadn’t thought to parametrize the integral plane, but I can see how that’d be beneficial. Perhaps there’s a way I can parameterize the offset.I did find a minor bug after I posted that code where nu was getting multiplied by scale twice, but resolving that didn’t get me much further.I’ll have to follow up with more info about the Reynolds profile.One of our goals after this sample converges is to parameterize the inlet velocity/volume flow, so I’m not sure messing with that would help me in the long run.The pipe diameters are relatively fixed per the industry I work for, but there may be room to mess with changing the length.I’ll be sure to update this thread if/when I get this working :)For integral planes I would try to just use the CSG module! They are 2D circles so as long as you position it to be entered in the pipe it should be much easier than another STL file!I’ll check that out then, that could be a much nicer solution :)I tested the fourier network like you suggested and it made an immediate improvement. I recall testing all the different networks at one point, but perhaps there was another issue at the time that I’ve since resolved. At 15k iterations I can see the closest result I’ve seen so far to the truth. Pressure and scale are still pretty far off, but the fluid is flowing in a reasonable path now :D
One curious thing is that I’ve seen it’ll go from gradual progress to instantaneous insanity, which is coincidentally around the same iteration as specified under decay_steps. This is the first bit of significant progress I’ve made, and it’s a good boost for my moral :). Wish me luckimage1172×479 63.9 KBGreat news @npstrike ! Glad to see its making progress. : )Powered by Discourse, best viewed with JavaScript enabled"
83,is-my-computer-is-good-to-make-simnet-working,"Dear allI am absolutely new to SimNet
I have 2 computers with these GPU capabilities
1- Nividia Quadro K1000M
2-Nividia Quadro RTX 4000Can these capabilities run the SimNet
Thanks in advance
req747×622 105 KB

From the user guidePowered by Discourse, best viewed with JavaScript enabled"
84,how-to-make-nodes-for-geometrys-sdf,"I am referring to the Fully Developed Turbulent Channel in the tutorial. In ver 22.03, the distance from the wall could be referenced by making a node of the geometry’s sdf.In ver 22.09, however, the geometry’s sdf is not made and the distance from the wall is passed as a constant to argument ""parameter” of PointwiseBoundaryConstraint.In ver 22.09, when I tried to make a node of the geometry’s sdf as before, the following error occurred.
…
raceback (most recent call last):
File “mycode.py”, line 114, in run
+ [Node.from_sympy(geo.sdf, ‘normal_distance’)]
File “/modulus/modulus/node.py”, line 93, in from_sympy
evaluate = SympyToTorch(sub_eq, out_name, freeze_terms, detach_names)
File “/modulus/modulus/utils/sympy/torch_printer.py”, line 252, in init
self.keys = sorted([k.name for k in sympy_expr.free_symbols])
AttributeError: ‘function’ object has no attribute ‘free_symbols’
…Can you tell me how to generate a node of the geometry’s sdf?Hi @user106225The SDF of the geometry can be accessed using a SymPy symbol (seen here used for lambda weighting). Alternatively it can be accessed directing using the SDF attribute which will output a dictionary containing a SDF variable (example here).I would also suggest looking at the zero equation turbulence model which has the SDF in its equation for guidance.In the turbulent channel problem you reference, the 22.09 implementation is essentially training on a slightly smaller channel where the domain is between the edges of the wall-function. Hence the boundary is the value of the wall function at a fixed point (not no-slip).Hi, @ngenevaThank you for your response.
The use of sdf in the tutorial on zero equation turbulence model is what I was looking for.I have two additional problems.In ver. 22.09, I get the following error if I do not specify requires_grad=True in PoinrwiseInferencer etc. In ver. 22.03, there was no problem even if requires_grad=False.
…
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):File “/modulus/modulus/eq/derivatives.py”, line 24, in gradient
“”""
grad_outputs: List[Optional[torch.Tensor]] = [torch.ones_like(y, device=y.device)]
grad = torch.autograd.grad(
~~~~~~~~~~~~~ <— HERE
[
y,
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
…
In what case is requires_grad=True needed?I am using PointVYKInferencer for prediction. What should I do if there are sdf itself or quantities which has sdf in its equations in the output_names?
In the case of PointwiseInferencer, sdf is supposed to be calculated by passing geometory.sample_interior to invar. Likewise, should I pass the VTK lattice points containing the sdf to invar in some way?In what case is requires_grad=True needed?This is required when you want to save results that are gradients of the input. requires_grad turns on gradients for the model inputs. E.g. if I have a model that computes u = f(x), where f(.) is my NN, and I want to have an output value du/dx then requires_grad=True because I need gradients to be calculated on the input tensors. Without this grad variables will not be initialized and PyTorch will complain.Likewise, should I pass the VTK lattice points containing the sdf to invar in some way?Yes, basically the VTK inferencer is designed more for conducting inference on a predefined geometry as opposed to randomly sampling geometry with the regular PointwiseInferencer. This means you need to provide the SDF through the VTK object or as an additional input array of the appropriate size.Side note, the regular pointwise inferencer will still save the results in a Poly VTK file.  The downside is that you wont have any connectivity between these points for a mesh (although can could do this in post). Some more information on VTK utils is in our user-guide.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
85,about-modulus-multi-physics-coupling,"Hello, I would like to ask about how Modulus does the multi-physics simulation. Imagine we have temperature and flow fields, which interact strongly.  Is there one single NN trained for the two fields together or one NN for each field? If the latter case, how are the two NN coupled with each other? Thanks.Hi @hitustckitFor a purely physics-driven training we have some examples that solve one way coupled heat sink problems (so the flow impacts the thermal field). I would say the most basic example that demonstrates this is the Scalar Transport example which has two models training together for flow and thermal fields.Typically for more complex systems the flow field model is trained in isolation, fixed and then used to help train the model that solves the thermal field. An example of this is the FPGA example where we have both a flow and heat training script. Regardless we find having multiple models in mulit-physics systems is important for convergence since different physical quantities can have different structure and characteristics.Hi. Thanks a lot for the quick reply. I read the documents of some related cases. Still some confusion:This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
86,error-sampling-interior-of-geometry-from-stl-file,"Hi,
I have a .stl file and i want to use it for sample the interior of geometry. From the example STL Geometry: Blood Flow in Intracranial Aneurysm i understand that if i use a geometry to sample it only on the boundary i can write:Indeed if i want to print this geometry i can use:And i have this warning (even if i use the file contained in aneurysm example):But the problems begin when i want to use a geometry for sampling points on the interior (and for example adding constraint to them). In fact from the link i learn that in this case you must set airtight=True, and have a .stl file with a watertight geometry.
So i created a .stl file with this characteristic and try to do like the boundary geometry:Running this piece of code results in the following error (even if i use the file aneurysm_closed.stl from the directory of aneurysm example):If this can help in finding the solution running aneurysm.py results in the same errors just explained.Ps. i’m not worried about the warning received when i use the sample_boundary method because this warning doesn’t causes the program to fail, but i’m worried about the interior of the geometry that is extremely necessary in my case and the error causes the program to fail.Thanks for your help.Hi @tom_02This is likely an error between the compiled toolchain used for building PySDF versus the driver that is installed on your system. Remind me, are you using the docker container and what is your driver version (use nvidia-smi)?This version of Modulus/PySDF was built on 515 drivers. If you’re using a much older driver / cuda version than that, this could likely be the issue.Hi @ngeneva,
i’m using the docker container and this is the output of nvidia-smi command:So it is necessary to update the driver to a newer version?Thanks.Hi @tom_02That’s what I would try first if you have the ability to, particularly for PySDF. I have also personally tested Modulus on 510 drivers (CUDA 11.6).As a disclaimer, we do not currently test Modulus/PySDF on older CUDA versions such as 11.3, so I cannot confirm this is the source of the error. We are actively working on increasing our testing range including older drivers.Powered by Discourse, best viewed with JavaScript enabled"
87,how-to-combine-mfd-meshless-finite-difference-with-adf-exact-boundary-constraint,"Hi:
I am trying to combine MFD (meshless finite difference) with exact boundary condition (ADF) in a study.
MFD in Modulus v22.07 currently only accept single Node or model as input.
ADF (Exact boundary condition) requires a combination of two networks.
First network (Node): input x, output u_star
Second network (Node): input x and u_star, output u.
Therefore, I did not find any way to use MFD with exact boundary condition in Modulus v22.07.Hi @SpartacusGood question. This is correct that the finite derivative node does only accept a single model. However, you can pretty easily get around this limitation for instances where multiple models/nodes are needed using Modulus’ graph systems.To be fair this isn’t a documented solution, its essentially similar to how constraints build their graph. Creating a graph for the MFD node will chain multiple nodes together, which can then be provided as a single model. Here’s an example:Thank you so much for your help! It resolved my question.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
88,how-to-parameterize-coefficients-of-pdes,"Hello,
Does anyone know how to parameterize the coefficients of PDEs?
For example, I need to parameterize the vicosity or density of the fluid for Navier-Stokes equation?How to make changes to the NS node defined below or create the corresponding flow network?Hi @cxi1You can parameterize a PDE using a SymPy Symbol. While maybe not obvious, the 1D wave equation example can show how to go about this (here t is the parameterized variable). You can take these ideas and extend them to coefficients of other PDEs.Note inside the Wave equation we have:in the problem t is never predicted by the model but rather injected using the parameterization in the constraints. E.g.Thank you so much, Nicholas, that is very helpful to meThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
89,how-can-i-use-temperature-dependent-thermal-conductivity,"I want to solve a heat transfer problem, where the thermal conductivity changes with temperature. How should I achieve this?. I can’t find a similar example in examples.Hi @tao-zhan18We don’t have any specific examples of this, but we have many that involve heat transfer. I would suggest getting your system working with a constant heat conductivity. You can then look into replacing these constants with sympy variables and have separate nodes that can then calculate the thermal conductivity based on the temperature for you.Different PDE, but an example of using a predicted variable for a material property can be found in the inverse problem example with a model that predicts the fluid viscosity.Powered by Discourse, best viewed with JavaScript enabled"
90,print-output-for-troubleshooting-multinode-run,"Hi Dear Modulus devs,I am trying to troubleshoot an issue with multiprocessing with multi-Node using using slurm initlization. The GPU device id is not set correctly, for example using 2 DGX A100  nodes of total 16 GPUs, the device id ranges from 0 to 15, which produces CUDA error.I am trying to troubleshooting output an variable using the container. In the I am trying to export the local_rank variable in the initialize(), setup(), initialize_slurm() function of the DistributedManager class in $CONTAINER_HOME/modulus/modulus/distributed/manager.py.But the print() function in the file does not produce any output. Could you please help with how to output the local_rank variable?Thanks!Hi @yunchaoyangYou can get access to the parallel information that Modulus is using using the distributed manager. Its a singleton that gets initialized on the first construction.For example the following code can be used:Modulus relies on environment variables set by either Slurm or MPI to set up the ranks between processes. The device/cuda ID is either based on the assigned local rank of the process or, if no local rank is provided, calculated by rank % torch.cuda.device_count(). Additional info is in our user guide.Not entirely sure why your print statement is not working.Thank you @ngeneva for your kind response. I can print the the parallel attributes outside the container. It again shows that the wrong numbering of local rank.It is due to the fact that SLURM_LOCALID is not properly assigned by SLURM when requesting resources by requesting total number of tasks.Change #SBATCH --ntasks=16 to #SBATCH --ntasks_per_node=8, will set the SLURM_LOCALID correctly.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
91,vtk-writer-bug,"Hello, the VTK writer has some issues when running any example with Modulus 22.09 (bare metal installation). This is the error:2022-10-14 06:01:21.471160: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
Error executing job with overrides: 
Traceback (most recent call last):
File “helmholtz.py”, line 92, in run
slv.solve()
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 159, in solve
self._train_loop(sigterm_handler)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 593, in _train_loop
self._record_constraints()
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 275, in _record_constraints
self.record_constraints()
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 116, in record_constraints
self.domain.rec_constraints(self.network_dir)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/domain/domain.py”, line 45, in rec_constraints
constraint.save_batch(constraint_data_dir + key)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/domain/constraint/continuous.py”, line 77, in save_batch
var_to_polyvtk(save_var, filename)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/utils/io/vtk.py”, line 959, in var_to_polyvtk
vtk_obj.var_to_vtk(data_vars=var_dict)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/utils/io/vtk.py”, line 144, in var_to_vtk
self.save_vtk(file_name, file_dir)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/utils/io/vtk.py”, line 165, in save_vtk
self.writer.SetFileName(file_path)
TypeError: SetFileName argument 1: string or None requiredSet the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.Code for this is here: https://gitlab.com/nvidia/modulus/modulus/-/blob/release_22.09/modulus/utils/io/vtk.py#L165…and what I did to make this work is to manually edit it to be:self.writer.SetFileName(str(file_path))Is it possible to change this in Modulus source? This problem has persisted since 22.07.I have used 22.07 with bare metal. It works just fine. How did you install the dependencies?@michaltakacThanks for the report.Is there a chance you can print out what type of object file_path is when this is causing this error? Curious to know what it is other than a string. Have not seen this occur before.My only guess would be that somehow your constraint name is not a valid string somehow, but I am not sure how thats occurring (the filename is based on the name of the constraint you give when adding it to the domain).But not sure how thats possible here.Powered by Discourse, best viewed with JavaScript enabled"
92,how-to-model-multiple-inflow-outflow-fixed-locations-parameterize-inflow-velocities,"Hi, I am trying to train a steady-state scenario with obstacles and multiple inflow/outflow ‘windows’ at fixed locations. The inflow velocities through these ‘windows’ are to be a parameter. At all times, at least one ‘window’ is outlet (pressure = 0 imposed). As a start. we can assume the inflow velocity through each of the other window(s) to be either 1 m/s or 0 m/s (although eventually the inlet velocities are to modelled as in range(0.0 ,1.0) with spacing of 0.2 m/s).I have the following confusions:How to add ‘inflow’/‘outflow’ constraints to the domain in this case? I am not sure if I have to consider an approach where inflow/outflow locations are also a parameter. If yes, could you please guide a way to create and use such a (discrete?) (vector?) parameter that tells which of the 4 ‘windows’ are inlets and outlets? The velocities through each of the inlet windows is another parameter.Thank you for your excellent framework.Hi @hassan.iqbalThe inclusion of multiple inlet/outflow boundaries should be fairly easy to achieve using multiple boundary constraints. I would suggest having a look at the Annular Ring example where there is a simple inlet and outlet boundary condition. I would personally start with learning a problem where the inlet/outlet locations are fixed and constant.Such problems, where there are multiple constraints, is what the Modulus framework is designed for. Set up a geometry to represent the domain, then define your constraints using geometric criteria. As an example lets consider this domain is scaled to a unit square, your code may look something like this (the key here is the sympy criteria arguments):You could then go to more complicated boundaries where the velocity value is now a sympy expression.Powered by Discourse, best viewed with JavaScript enabled"
93,how-to-run-automl-in-nvidia-modulus,"Hi:
I am trying to use Nvidia Modulus v2209 and to find optimized hyper-parameters in my neural network architecture (i.e. number of layers or hidden neurons).
I wish to ask how to use AutoML in Nvidia Modulus and find the optimized model with minimum validation error.
Such as: ‘l2_relative_error_u’
Thanks!Hi @SpartacusUnfortunately I don’t think we have tried AutoML from the Modulus teams side, not sure if anyone in the community has either. Perhaps a primitive alternative is Hydra config multi-run which allows you to do easy hyper-parameter sweeps of different parameters controlled in your YAML file. An example in our docs.Dear @ngeneva , thank you for your notice, will try that!
BestPowered by Discourse, best viewed with JavaScript enabled"
94,how-to-make-the-modulus-stopping-criterion-more-sensitive,"Hi, previously, there was a bug which cause the stopping criterion not to work.It has now been fixed, as given in https://forums.developer.nvidia.com/t/problem-with-using-criterion-based-stopping/233377However, I found that using the stopping criterion cause Modulus to stop rather early. I need to compute and compare the wall shear stress with my OpenFOAM results. Hence, in Modulus, I’ll be computing du/dy (u__y) etc. To get accurate result, I need to run about 600,000 to 800,000 steps.My stopping criterion are:stop_criterion:
metric: ‘l2_relative_error_u’
min_delta: 0.1
patience: 10000
mode: ‘min’
freq: 2000
strict: trueI found that even if I reduce min_delta to 1e-5, Modulus stops at around 80,0000.  If I resume running, it goes for another 10,000 steps due to the patience parameters. But my wall shear stress results are still far from the ideal result. How should I tune to ensure that it will run till I reach my satisfied accurate wall shear stress?Thanks.Hi @tsltaywbFor your stopping criteria is the loss l2_relative_error_u based on the entire flow field you’re trying to solve? Perhaps mean flow is converging while the near-wall interaction takes longer to develop correctly. If so I would suggest trying to formulate a loss that is focused on the near wall region you’re interested in and use this for the metric. This can be achieved by using lambda_weighting in your constraint with the SDF function (or its inverse if you want near wall to be weighted higher).There are many examples that use the SDF function to spatially weight the loss. E.g. the annular ring problem.Ok sure. I’ll try it out. Thanks!Powered by Discourse, best viewed with JavaScript enabled"
95,parametrizing-constants-of-pdes,"In Lid Driven Cavity how can I parameterize the velocity of lid and complete training on various lid velocities in one training pass?
Can someone help me with the script?Powered by Discourse, best viewed with JavaScript enabled"
96,applying-slip-wall-conditions,"I’m trying to apply a slip wall condition to a wall but I’m not sure what’s the best way to go about this. My main issue is defining the tangential flow velocity on the wall boundary. For slip walls tangential velocity should be equal to the adjacent interior flow velocity, however, I’m unsure how to pass this information as input to top_wall.boundary_bc.My naive attempt so far:How should I configure the top_wall.boundary_bc to be a slip condition?Hi, it is easy to apply slip boundary conditions in SimNet. Please take a look at the attached example for 2D flow past a cylinder with slip channel walls.

cylinder_slip_wall_u715×382 20.3 KB


cylinder_slip_wall_v715×382 16.5 KB


cylinder_slip_wall_p715×382 18.6 KB

cylinder_2d_slip_walls.py (4.5 KB)So simple! I appreciate the response.Powered by Discourse, best viewed with JavaScript enabled"
97,testing-performance-on-multiple-gpus,"Hello all,We are testing the performance of modulus on our cluster with multiple GPUs. In this regard, we ran the basic wave_equation tutorial with 10000 batch points on one GPU and two GPUs. Surprisingly the time consumed by a single GPU is 45 min and on two GPUs it is 50 min. The GPUs are v100. please see the attachment with the GPU activity for two GPUs. The modulus is installed with docker. I don’t think this is supposed to happen. Can anyone give me any suggestions, please?  Thanks.

2gpus1165×755 351 KB
Hi @bvss891In Modulus the batch size defined in the config are by default the local (per GPU) batch size. What this means is that if you keep the batch size the same between 1 and 2 GPUs is that you’ve gone from a global batch size of 10000 → 20000.Thus this would be a weak scaling test and the best you could ask for is the same performance speed between 1->2 GPUs. This of course won’t happen because to the communication between the GPUs adding some overhead. The exact overhead depends on how the hardware you have and how its configured, the size of the model, etc…For strong scaling tests, Reduce your batch size when running on 2 GPUs to 5000. But keep in mind that if your GPUs are fully saturated with the smaller batch size you’re not going to see ideal scaling.There are some scaling stats in our user-guide for weak scaling.I was initially confused by the same sort of tests, until I understood the scaling system, as @ngeneva explained it.Other things I noticed is that we weren’t using anywhere close to the total ram available on a single GPU yet.
So increasing batch-size(s), and decreasing # of iterations, was the first step to training a solution to the same accuracy in less time.After that, increasing GPU # increased accuracy for the same configuration, such that we could lower the # of iterations again for the same accuracy, but I haven’t found the sweet-spot yetThanks, @ngeneva and @bsarkar for the inputs. It gives clarity on how parallelization works.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
98,implementing-learningrateannealing-in-loss-aggregator,"Hello all,I am struggling with implementing LearningRate Annealing algorithm during the training.I founded that modulus.loss.aggregator has LRAnnealing class so that we can implement Learning rate annealing for loss aggregation, but how can I use this LRAnnealing class in Constraint class?For example, if I have two constraints,
BC = PointwiseBoundaryConstraint(…)
interior = PointwiseInteriorConstraint(…)
and want to balance the loss between BC and interior with learning rate annealing algorithm, how do I implement it?I also founded custom_aggregator.py at modulus.examples.turbulent_channel directory, but this aggregator class was not used in example code.Any suggestions, links, or advice(any sample code for loss aggregation) would be highly appreciated.Thanks.Hi @heechangkim , yes the LR Annealing algorithm is already implemented in Modulus. To use this, all you need to do is to set the loss entry in your .yaml config file to lr_annealing. For example, for the Helmholtz example:Powered by Discourse, best viewed with JavaScript enabled"
99,news-modulus-deep-dive-webinar,"Deep Dive into NVIDIA’s Physics-ML Framework, ModulusOn Demand WebinarRegister Now!Date: Wednesday, April 26, 2023
Time: 8:00am - 9:00am PT
Duration: 1 hourAbstract:Physics ML is the term that we use at NVIDIA to talk about solving hard engineering problems using AI: problems like optimizing engineering designs, developing virtual sensors, and building digital twins. Until recently, some of these problems were only attempted using sophisticated numerical tools, while others were considered impossible due to the great computational requirements of traditional methods. In this talk, we will discuss how Physics ML is changing what is possible. We’ll share some examples, introduce three different types of Physics ML techniques, the skills required to use them, and discuss what NVIDIA is doing to help reduce the barrier to develop and deploy Physics ML solutions.Reminder to Register Now!Powered by Discourse, best viewed with JavaScript enabled"
100,parametrization-of-an-ode-coefficient,"Hi, I’m trying to solve a system of two coupled equations. The system (the Hopf oscillator), has two coefficients: a and w. I have succesfully trained a model capable of solve the system for a=0.6 and w=1, but now I want to parameterize it with respect to a in the range (-1,1).
Following a tutorial (Parameterized 3D Heat Sink - NVIDIA Docs), I’ve modified my scripts to add the parameterization but it seem like I’m not getting the desired output.
Can someone tell me what I’m doing wrong? And also, how can I plot the results?Thank you!Hi @facundoroffetThanks for trying out Modulus. Glad you’ve got the non-parameterized version working! Parameterized solutions can be a lot more tricky but much more useful in the end.I’ve modified my scripts to add the parameterization but it seem like I’m not getting the desired output. Can someone tell me what I’m doing wrong?Can you elaborate by what you mean here? For example, Is the convergence bad? Is it unstable? Just not running?And also, how can I plot the results?Add a inferencer or validator (for example in the annular ring problem). Additional post processing information in the Modulus-Sym docs!Hi, thank you for your answer!I wasn’t sure what the problem was, but then I realized that the parameterization wasn’t doing anything (the model was still being trained for one value of ‘a’).But luckily, I was able to fix the code, so now everything is working as intended. Below I show the full code in case anyone finds it useful.I think now I’m having another problem.I trained a model for ‘a’ in the range [-0.1, 0.1], and got a small loss (≈2e-5). But the results differ a lot from the reference solutions.For a=0.1:
Is there something that I’m still doing wrong?Hi @facundoroffetThis looks like a convergence problem. Its likely the (wrong) prediction does satisfy the PDE loss in some loose form so the error appears small. Consider trying weighting your ODE loss constraint more via the lambda weighting parameter, modifying your network, train more on the earlier time steps than the later or some of the tricks we mention in our user guide.Personally I would start training a smaller time range (say 0 - 10) and see if it can converge there. If so you know your loss is working, its a matter of how you train it for longer roll outs.Thank you a lot for the help!! I tried what you suggested: I got the same loss (≈2e-5), but now the results are very good. For a=0.1:Any tips regarding how to train the model for longer? Because the results are already starting to get worse when I train it for the range 0-20.Hi @facundoroffetLong time predictions is where a lot of experimentation is often required.Also have a browse of the Recommended Practices section of the docs for some tricks to consider. Good luck!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
101,modifying-the-iteration-number-of-bfgs-after-using-adam,"Hi,We are trying to use ADAM 1st and then switch to BFGS for the optimizer, as suggested here:We tried and it work but it seems that BFGS is hard-coded to run only 1000 iterations.
May I know how can we change it?Thanks.Hi @tsltaywbYou should be able to update the iterations BFGS uses via the max_iter config option in your config. See Hydra options here. So you should have something like the following in your config.yaml:Powered by Discourse, best viewed with JavaScript enabled"
102,docker-compose-yml-for-portainer-stack,"Edit: I am looking for a docker-compose.yml for a Portainer Stack to be able to add a bind mount to an external drive. Thus, if the container gets updated, the data persists. Thanks a lot!The command to translate to compose yml for Portainer is:Here is the solution. Note that only absolute paths including symlinks (here: BLOCK) work unless connected to a git repository.This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
103,architectures-on-nvidia-modulus-for-data-based-model-and-evaluation-of-the-trained-neural-network,"I want to train a neural network with only data, the data I want to use for training correspond to solutions obtained from CFD simulations in ansys fluent in a 3d domain. What model should I use for this purpose? Fourier neural operator is the indicated option? Are there other architectures in nvidia modulus that can be useful for training only based on data? And finally, after training, using the modulus extension for Omniverse, is it possible to evaluate this already trained neural network with new input parameters?@matiyanezThanks for your interest in Modulus, some responses to your questions are below:What model should I use for this purpose? Fourier neural operator is the indicated option?Many models can be used. If you want a continuous function then a fully connected, Fourier neural network would work. If your data is on a structured grid then FNO, AFNO or convolutional (pix2pix, super-res) models can work.Are there other architectures in nvidia modulus that can be useful for training only based on data?FNO / pix2pix / super-res can all work well for structured data. The fully-connected models can work well too if your data is unstructured. Its very problem dependent (based on data, system complexity, etc.).And finally, after training, using the modulus extension for Omniverse, is it possible to evaluate this already trained neural network with new input parameters?Yes but the OV extension is in a beta state with limited support and documentation. This code can be quite challenging to develop inside omniverse. However, there are several examples that you can build off of if desired.Powered by Discourse, best viewed with JavaScript enabled"
104,using-multi-scale-fourier-neural-networks,"I previously had trouble implementing my code with multiscale_fourier networks.
after looking at Modulus Models - NVIDIA Docs by the advice in my previous post (Thanks!):
Could not unroll graph! - #11 by cpe.skI added frequencies and frequencies_param variables in my arch instantiation as such:I got this error;Any suggestions on how to use this type of PINNs correctly?Hi @cpe.skSeems theres two issues here:This is problem only for this model it seems, so other networks like Modified Fourier Net should work with out this fix. Thanks for reporting this.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
105,no-result-when-using-pointwiseconstraint-from-numpy-for-1d-problem,"I have loaded my 1D data using the following lines:
def read_eta_data(time, Nx):
eta_filename = to_absolute_path(f""data_ppt1D512/eta.{int(time):03d}.npz"")
data= np.load(eta_filename)[“arr_0”].astype(np.float32)
x = np.expand_dims(np.linspace(0, Nx, 512), axis=-1)
invar={}
invar[“x”]=x
invar[“t”] = np.full_like(invar[“x”], time * 0.005)
outvar = {}
outvar[“eta”]=np.expand_dims(data, axis=-1)
return invar, outvarAnd I used the above data for  initial timestep  constraint,
for i, ms in enumerate(np.linspace(101, 200, 10)):
timestep_invar, timestep_outvar = read_eta_data(ms, Nx)
timestep = PointwiseConstraint.from_numpy(
nodes,
timestep_invar,
timestep_outvar,
batch_size,
)
domain.add_constraint(timestep, f""BC{i:03d}"")But when I run my code, it doesn’t move forward and doesn’t show any error message as well. This is what is shown in log file.
[05:22:37] - Jit compiling network arch
[05:22:37] - Jit compiling network arch
[05:22:39] - attempting to restore from: outputs/PF1D_data_512
[05:22:39] - optimizer checkpoint not found
[05:22:39] - model c_network.pth not found
[05:22:39] - model eta_network.pth not foundCan someone let me know what is the issue?Hi @gaijinliugangmeiWell no errors probably means that you are setting up your constraints correctly (hopefully!). Could you potentially be adding a large number of training points?For example, this bit is creating 10 different contraints:What hardware are you running on? I would try reducing the number of constraints and/or training points to see if it get through a few iterations.Thank you for your suggestion.  It is working now.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
106,modulus-bare-metal-installation-not-working,"I tried to follow the instructions on Modulus Installation guide/Modulus Bare Metal Installation:Installation Guidelines
Release v21.06 | November 9, 2021After running:
tar -xvzf ./modulus_image_v21.06.tar.gzI cannot:cd ./Modulus/
python setup.py installbecause setup.py is not in the list of uncompressed files, or install, or even a Modulus folder, just a long list of folders.What am I missing?Hi, for bare metal installation of Modulus, please use the “Download Modulus 21.06 Archive for Linux” tab under “Compressed Tar Archive”. You have downloaded the Modulus docker image and that is why you are not able to see the setup file.Hi! Thanks for the help. I was able to install it following your suggestion, but now TensorFlow is complaining. It looks like an intermediate option will be to downgrade TensorFlow installation to 1.15 as it is suggested on the manual:AttributeError                            Traceback (most recent call last)
 in 
----> 1 from modulus.solver import Solver~/Modulus/modulus/init.py in 
9 from . import graph
10 from . import learning_rate
—> 11 from . import optimizer
12 from .node import Node
13 from .arch import Arch~/Modulus/modulus/optimizer.py in 
351     return loss
352
 → 353 class AdamOptimizerWrapper(tf.train.AdamOptimizer):
354   def init(self, learning_rate, beta1, beta2, epsilon, alpha, num_terms, local_annealing):
355       self.alpha = alphaAttributeError: module ‘tensorflow._api.v2.train’ has no attribute ‘AdamOptimizer’It looks like you are using TensorFlow 2. Modulus is currently based on TensorFlow 1.15, so please downgrade your TensorFlow version.Thank you for your response. Correct. I am trying to install Modulus and then launch Jupyter Notebook, so downgrading TensorFlow may cause other problems (Linux OS). I am currently evaluating creating a virtual environment and other alternatives.Hey @mnabian,I can’t seem to see how to start a new discussion post. If you could point me in the right direction that would be much appreciated.I am having problems with installing the  PySDF library with the bare metal installation. It seems to install but when I very the installation it says that there is an import error.ImportError: libsdf.so: cannot open shared object file: No such file or directoryHave posted a new topic about my issue here: Problems installing the PySDF library with the bare metal installationPowered by Discourse, best viewed with JavaScript enabled"
107,problem-with-boundary-conditions-that-change-over-time-or-other-factors,"Hello,I am confused about setting constraints, particularly when it comes to problems where boundary conditions change over time or other factors. What would be a smart way to write the code for such problems?Here’s an example (omitting part of the equation for brevity):I want to solve the following problem:Input: x, z, t
Output: η, φEquations (where h is an arbitrary constant):
φ__z = 0 ; z = -h
φ__z - η__t - φ__x * η__x ; z = ηAs mentioned earlier, the output (η) is used as a boundary condition for the input variable (z).(Just to clarify, since I haven’t provided all the equations, it’s not possible to solve the problem with just this information. The example you provided is used for solving problems related to Stokes wave theory.)Thank you in advance.Hi @masuda-kazukiThanks for your interest in Modulus!
If I understood your problem correctly, I would parameterize the time dimension. We have an example of a 1D wave equation that may help with this. (see the forum post also for some info)Powered by Discourse, best viewed with JavaScript enabled"
108,fundamental-understanding-linear-elasticity,"Hello everyone,
I have a fundamental understanding problem here. In the linear elasticity example with the bracket, one defines the geometry of the bracket with computational geometry and then learn the physics using the Linear Elasticity module and their inherent equations.
I am confused to what has the model learned?  Has it learned the linear elasticity physics for that specific geometry or has it learned to generalize the physics on the bracket for different geometry ie If the length of the bracket is 2x times longer than the one we used for training? Since the physics for different bracket geometry for the same load and material is the same, can the model generalize them all? If not, how can this be done in Modulus?
ThanksThe way this problem is set up in the UG, it has only learnt for that geometry. In some cases, if the new configuration is not too far off, transfer learning could work (e.g. aneurysm) but in other cases it’ll need to be parameterized (e.g. 3-fin or the industrial heat sinks). There are neural operators that can learn the parameterization implicitly with some data which is the current focus of Modulus in terms of further developmentThank you. That is exactly what I was looking for in the examples.Powered by Discourse, best viewed with JavaScript enabled"
109,angle-parameterization,"Hi!In my work, I want to try to parameterize the model due to the angle of rotation of a certain cutout in my design. But I ran into a problem that I cannot comprehend. There were no problems with parameterizations, but the rotation did not give in (I attach the logs and code)
problem (2.4 KB)
my_checkerEllipse.py (9.6 KB)Hey, sorry for the late reply to this. I looked into this and I think I see the issue now. When we create the ElliCylinder we parameterized the SDF with a value named theta and this was causing an issue when you parameterized with the same variable name. We will look into a permanent solution for this but for now I renamed your parameter theta and it runs fine.
my_checkerEllipse.py (9.6 KB)Powered by Discourse, best viewed with JavaScript enabled"
110,error-when-applying-exact-continuity-feature-for-solving-the-heat-variable,"I’m having an issue with applying exact continuity feature to solve the heat variables in the FPGA case.  (FPGA Heat Sink with Laminar Flow — Modulus 22.09 documentation)For solving flow variables, the exact continuity feature was successfully implemented after disabling the FuncTorch function. (without using symmetry trick)However, on the same case, the exact continuity feature can’t be applied successfully when solving the heat variable.  The error msg is:Error executing job with overrides: []
Traceback (most recent call last):
**  File “fpga_heat.py”, line 368, in run**
**    thermal_slv.solve()**
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 159, in solve**
**    self._train_loop(sigterm_handler)**
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 599, in _train_loop**
**    self._record_validators(step)**
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 289, in _record_validators**
**    self.validator_outvar = self.record_validators(step)**
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 119, in record_validators**
**    return self.domain.rec_validators(**
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/domain/domain.py”, line 57, in rec_validators**
**    valid_losses = validator.save_results(**
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/domain/validator/continuous.py”, line 94, in save_results**
**    pred_outvar = self.forward(invar)**
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/domain/validator/validator.py”, line 15, in forward_nograd**
**    pred_outvar = self.model(invar)**
**  File “/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py”, line 1194, in _call_impl**
**    return forward_call(input, kwargs)
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/graph.py”, line 220, in forward*
**    outvar.update(e(outvar))**
**  File “/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py”, line 1194, in _call_impl**
**    return forward_call(input, kwargs)
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/eq/derivatives.py”, line 85, in forward*
**    grad = gradient(var, grad_var)**
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
**  File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/eq/derivatives.py”, line 24, in gradient**
**    “”""**
**    grad_outputs: List[Optional[torch.Tensor]] = [torch.ones_like(y, device=y.device)]**
**    grad = torch.autograd.grad(**
**           ~~~~~~~~~~~~~~~~~~~ <— HERE**
**        [**
**            y,**
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.In order to apply the exact continuity feature for solving the heat variable, some changes of the code were mad as shown below:

code_change_highlights_1961×622 39.9 KB


code_change_highlights_2782×813 40.3 KB
The system information is listed below:
Linux Version: Win11 WSL-Ubuntu 20.04 LTS
Driver Version: 522.30
CUDA Version: 11.8
GPU: RTX3090
Modulus Version: Modulus Bare Metal Install - 22.09Are there any suggestion for this issue?Hi @johnlaideThanks for the detailed report and code snippets. Try adding the requires_grad = True to the validator. This needs to be set to tell the validator to track the gradients which are required in the exact continuity setup. Seems we forgot to add this for this part of the problem.An example of this being turned on is in the flow script where it set to the continuity param in the config file.Hi @ngenevaAppreciate for your kindly reply.The exact continuity feature has success fully implemented with the case after makes the requires_grad = True to the [validator].Thanks & RegardsThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
111,corner-point-constraint-in-stress-analysis-for-aircraft-fuselage-panel,"In Stress analysis for aircraft fuselage panel.
image1802×3439 226 KB
One particular BC is going over my head.Why do we need this BC and only at the bottom left corner?Probably to avoid rigid body motion in the horizontal direction. A singular node is sufficient in order to avoid stresses due to contraction at the bottom row.Powered by Discourse, best viewed with JavaScript enabled"
112,how-can-i-apply-the-techniques-such-as-temporal-loss-weighting-and-time-marching,"I want to try the tricks written in the document below, but they seem not used
in the sample code of 1d wave equation.<1D Wave Equation>
https://docs.nvidia.com/deeplearning/modulus/user_guide/foundational/1d_wave_equation.htmlFor temporal-loss weighting, maybe, I can handle it by rewriting the lambda_weighting as follows;But, for time marching trick, I have no idea how to use this because I need to use the current iteration number during training but
I don’t know how to reference it.
If you have a sample code, it would be much appreciated.Thanks in advance.Hi @yusuke.takara Have you managed to implement this?
thank youHi there,
We dont have an example for this, but this is common trick used in many papers.This isnt a tested solution, but one way you could try is by writing a custom Node that has input keys t_0 (say this is parameterized between 0-1 for the scaled time range and is in your constraint parameterization) and an output key t.The evaluate function can be a small torch.nn.Module that maybe looks something like this:Just an idea, good luck with your experimenting. There is also a moving time window approach we have an example on for an alternative method of temporal learning.Powered by Discourse, best viewed with JavaScript enabled"
113,time-and-space-dependent-material-constants,"Hello all,First of all thanks for the wonderful framework. I am able to run the material constants (such as elastic modulus, thermal conductivity, etc) as a function of space and time only in the functional form (sympy expression). Can you please provide any suggestion on whether can we give this data in a discrete form or some tabular format? Thanks.Regards,
BharatHi @bvss891For discrete data I think the easiest route is to define another constraint from numpy dictionaries that would contain the discrete inputs and outputs. Most of the constraints you’re using are usually designed for a continuous representation via SymPy (which is what you have).This is a pretty useful utility to build constraints from a fixed dataset. Some of the wave examples use this function. You will need to create an input/target dataset of sampled boundary points but this should be achievable manually or using the geometry module.Powered by Discourse, best viewed with JavaScript enabled"
114,taking-a-lot-of-time-while-running-a-lid-driven-cavity-simulation,"Hello all,
I am new to SimNet and have installed it using docker on the ubuntu machine. When I tried to run the first tutorial, lid-driven cavity, it is taking a huge time to run, around more than 10 hrs.
When I installed SimNet, it gave me the warning that MOFED is not installed, it may slow down multi-node performance. Is this creating an issue or there might be any other problem?Please help me.Hey,
what hardware are you running? You need pretty good specs…
Iv got a 3090 and a Ryzen 9 3900X and the LDC took me about 4 hours.Hi,
Thank you so much for your reply.
I am using Tesla V 100 graphics card. I have not installed NVIDIA drivers by the method given in the guide. Instead, I directly downloaded it from the site and then installed it. Also, I am using CUDA 11.2 version. Does this will create any problems?
Also, the MOFED driver is not installed and I am not able to install it by following the given method. Can this create any issues?Even though if it is taking 4 hrs to solve the LDC problem, isn’t it too slow? because the same problem can be solved using CFD software in 20 seconds only.Powered by Discourse, best viewed with JavaScript enabled"
115,installation-on-a100-cluster,"Does NVIDIA have recommendations for best practice when installing Modulus on an HPC cluster with A100s to get optimal performance?The cluster does not support Docker; I have tried converting the Docker image to Singularity, but it fails to run.I’ve also tried the bare metal installation, using a Conda environment, but it seems that Tensorflow 1.15 (at least the version available through Conda) doesn’t support the A100, so would be using generic kernels that don’t take advantage of all the features of the A100 to give maximal performance.Many thanksHere’s the steps I took to get Modulus working on a HPC cluster using V100s. The steps also worked for a machine using a singular A100 last time I checked a few months ago.conda create --name SimNetv21 python=3.7conda activate SimNetv21pip install cmakeconda install -c anaconda gxx_linux- 64pip install horovod== 0.21conda install -c conda-forge tensorflow-gpu= 1.15Now that the environment has been set up with the required prerequisites, you can follow the Bare metal installation instructions found within the SimNet user guide:pip install matplotlib transforms3d future typing numpy quadpy\  numpy-stl== 2.11 . 2 h5py sympy== 1.5 . 1 termcolor\  psutil symengine== 0.6 . 1 numba Cython chaospypip install -U https: //github.com/paulo-herrera/PyEVTK/archive/v1.1.2.tar.gztar -xvzf ./SimNet_source.tar.gzcd ./SimNet/python setup.py installTo run examples using the STL point cloud generation you will need to put libsdf.so in your library path and install the accompanying PySDF library. This can be done bycd..export LD_LIBRARY_PATH=$(pwd)/SimNet/external/pysdf/build/:${LD_LIBRARY_PATH}cd ./SimNet/external/pysdf/ python setup.py installTo edit SimNet code, navigate to SimNet directory, /SimNet/simnet/, then edit or replace the desired files. Then update the SimNet package with setup.py just as beforecd ./SimNet/python setup.py installWhen installing SimNet to the hpc you may encounter some CUDA library issues. To resolve this, a system link can be created pointing Tensorflow to the correct location where CUDA is installed.First create a sandbox from the container, this sandbox allows you to access all the files needed to run SimNet.singularity build --sandbox SimNetv21_sandbox  docker-archive: //simnet_image_v21.06.tar.gzYou can then upload the required CUDA files to your hpc space and then subsequently create a system link pointing to the needed CUDA library.The system link needs to be created in each SimNet case you want to run. For example, to run the Helmholtz example you have to create a system link in that directory. To create the system link.cd ./examples/Helmholtzln -s /u/… /SimNet_sandboxv21/usr/local/cuda ./cuda_sdk_libWith the system link you can now execute training as usual.Hi Nason, thanks for your reply.I’m performing the installation directly on the HPC cluster using Conda, so I’m not sure why building a Singularity image would help here. (I’m also using a Mac as my desktop, so can’t easily get a working CUDA version to test locally and then package with Singularity to put on the cluster.)The instructions you gave closely match what I tried, but I did try them again just in case I’d missed something. I believe at least part of the problem is specific to A100s—Tensorflow 1.15 doesn’t explicitly support compute capability 8, so when it sees the A100 report its compute capability, it falls back to compute capability 3.5.Running the Helmholtz example, after a long period of seemingly doing nothing (and not using the GPU, presumably while kernels are compiled), I get the message:Presumably this means that significant amounts of possible performance are being left on the table, due to the improvements in later compute capabilities that are being ignored.However, then Tensorflow reports that the results from different GEMM implementations are different (by three orders of magnitude). I believe that in general running code compiled for a low compute capability on a higher one shouldn’t give different results, so I don’t know what is causing this issue. An example of the lines I see—I see dozens like the second line, and hundreds like the first.Presumably due to this failure, I then get a series of errors from layers of Tensorflow and Modulus, which are in the attached output file.Do you/does anyone else know what specifically could cause these errors, how to get Modulus to get the full performance from the A100, and how to get it to run correctly on this example?Many thanksEdslurm-7129520.out (58.3 KB)Powered by Discourse, best viewed with JavaScript enabled"
116,how-to-make-nodes-with-nondimensionalizer,"Hi, I am trying training using the NonDimensionalizer. I am using a pre-trained network with dimensional variables, so I prepare variables in the nodes that have been converted back to dimensional ones by the NonDimensionalizer, but I get a “Failed unrolling graph” error.
Since I cannot provide the code I am using, I have attached a sample code that reproduces the same error.
“Failed unrolling graph” occurs for the variable ‘dummy_eq’, and the following is the flow of the requested variables in the sample.‘dummt_eq’ in dummy_const
→ ‘dummy’ in DummyPDE
→ ‘dummy_output_scaled’ in nodes using NonDimensionalizer
→ ‘dummy_input_scaled’ in dummy_net
→ (*) ‘temp_scaled’ in nodes using NonDimensionalizer
→ ‘temp’ in nodes 1.
→ ‘u’ and ‘v’ in nodes
→ ‘x’ and ‘y’ in flow_netHere, using L.81 instead of L.82 in the sample code (‘dummy_input_scaled’ is calculated from ‘temp’ without via ‘temp_scaled’, i.e., skipping the * part of the above flow), the error will not occur.I assume that the variables converted by NonDimensionalizer cannot be used as inputs to the network.
How can I work around this error?ldc_2d.py (5.9 KB)Hi @user106225For future reference pasting the graph error:Is very insightful, but thanks for posting your script with a minimal working example. From looking at your code I think the problem is you have a cyclic dependency in your graph when using you use the non-dim node (swapping out for line 81 removed the non-dim node from your graph). This type of error is a little more tricky to spot than other graph issues.I think the issue is with these three nodes:In short:The result is a cyclic graph which cannot be executed. Removing dummy_output_scaled from the input of the Scaler node allows the script to build the graph since this makes the symbolic graph a DAG. (Granted this now means dummy variable is now not produced so I would create a separate Scalar node to go from dummy_output_scaled to dummy).Hi, ngeneva.Thank you for your reply.I think it is not a cyclic graph.
My example means as followsHi @user106225The problem is that when you create the Scaler node, it sees all of the listed inputs (['u', 'v', 'p', 'temp', 'dummy_output_scaled'],) as the input to the node of the symbolic graph. It does not do one-by-one inputs. It creates one node.So it is a cyclic graph because dummy_output_scaled is a required input to the same node that computes temp_scaled. Did you try my solution of removing dummy_output_scaled and running the code?I could understand why this is a cyclic graph.
I tried your solution and was able to run the code without errors.I appreciate your kind support.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
117,news-nvidia-simnet-v21-06-released-for-general-availability,"Today, NVIDIA announces the release of SimNet v21.06 for general availability, enabling physics simulations across a variety of use cases. This GA release builds on a successful early access program of baseline features, and layers on additional new capabilities.This GA release introduces:
•	New physics such as Electromagnetics and 2D wave propagation.
•	A new algorithm that enables a wider number of use cases for simulating more complex Fluid-Thermal systems.
•	New time stepping schemes implemented for solving temporal problems, treating time as both discrete and continuous.
•	Transfer learning to help reduce the time to convergence for neural network solvers.Read about this on our DevNews post here : https://developer.nvidia.com/blog/nvidia-simnet-v21-06-released-for-general-availabilityGive SimNet v21.06 a try today by downloading it here : https://developer.nvidia.com/nvidia-simnet-downloadsPowered by Discourse, best viewed with JavaScript enabled"
118,modulus-22-03-bare-metal-installation-no-module-named-easy-install,"I am trying to use the bare metal installation of Nvidia Modulus 22.03 on my PC. I followed the instructions from Nvidia Documentation. Modulus installation was successful using the python setup.py install. However, the PySDF is problematic. I can’t use easy_install tried pip as well, turned out egg files is depreciated stuff and does not work with pip.I upgraded the pip to 22.0.4 and setuptools to 62.1.0, still things are same. I am experiencing the same in my university PC as well. Both of them run Ubuntu LTS 20.04.
Here is some useful information.Hi I also encountered the same issue,  I worked around it by copying the pysdf folder found in./Modulus/external/pysf  from the previous releases into ./Modulus/external/
From there I installed pysdf just as with previous releases of Modulus - Imgur: The magic of the InternetThanks a lot. You copied this before installing Modulus or after installing Modulus. Because after installing Modulus we install PySDF.I did this after executing python setup.py install, if pysdf isn’t working then check the directory you set the library path.
The image I used above is from the documentation of Modulus v21 which requires you to be a level above the ./Modulus folder when exporting the library path. For this work around to work, after executing python setup.py install  you need to run the following:This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Hello, unfortunately we decided to pull the pysdf support for the bare metal installation because it became too cumbersome to maintain. This is reflected in the installation instructions. If the tessellated geometry module is required then we suggest using the Docker image. We are pushing now to have pysdf released as a separate library but don’t have any release date for this. In the mean time we are looking into a slower fallback option when pysdf is not installed.Powered by Discourse, best viewed with JavaScript enabled"
119,2d-seismic-wave-propagation-where-is-ricker-source,"Hello,I’ve just checked the example code of 2D seismic wave propagtion,
but I couldn’t figure out which part of the code actually considers Ricker source.
Could you tell me where it is so that I can modify it for my own case?best regards,Powered by Discourse, best viewed with JavaScript enabled"
120,implementing-graph-neural-networks-in-modulus,"Hello, I’d love to ask a bit open-ended question, but do you think that one can write a custom code to extend Modulus to support also graph neural networks? In particular, GNNs that can be used for simulating physics?I was implementing a custom framework before stumbling on Modulus that followed a work done in this area from DeepMind (Learning to simulate). Afterwards we switched to Modulus since it has lot of stuff for solving practical problems in physics, but I just wonder if it’s possible to implement something like MeshGraphNets mentioned in DeepMind’s work in Modulus.You’ll be happy to know that Graph Networks will be in Dec release of Modulus (22.12) and the DeepMind paper is one of the networks among some others that would be available.Very interesting! Looking forward!Hi, When is 22.12 expected to be released?Powered by Discourse, best viewed with JavaScript enabled"
121,deploying-using-a-trained-model-post-training,"I’m currently trying to familiarize myself with the modulus platform (v22.09) and am a little confused as to how I am supposed to utilize the final models. Let’s say I’ve got a good model that I trained (foo.pth), and I now want to use it for generating predictions. The suggested modulus workflow documentation ends on the “training begins” step:https://docs.nvidia.com/deeplearning/modulus/modulus-v2209/user_guide/basics/modulus_overview.htmlHow can I run the finalized model? E.g. is it the same as running a PyTorch save (i.e. predictions are not implemented via the modulus package), if so how do I know how to structure the inputs given that the definition was handled by modulus? I couldn’t find an example the demonstrates how to use the outputted models, e.g. via a model.predict([inputs]) function.Thank you.Hi @npstrikeThere’s a few threads in the forums with some discussions on this. The summary of it i,s its up to the user. We have some built in methods that allow users to perform inference inside the the symbolic ecosystem (E.g. you need gradient calculations). We have also had users that just take the model, load the architecture manually then just treat it like a PyTorch model.There is some nuance with manually running a Modulus-Symbolic network like a PyTorch model (the _impl property can be userful here). The reason for this additional step is that Modulus architectures are set up to work with dictionaries for the symbolic graph that gets build during training.Thank you for the followup. I think it would be beneficial for the samples to include running solver.eval() as  a final step as I did eventually find this by looking through the source code, but it wasn’t clear to me if it’s something I’m intended to be using.
I think I have what I need in order to move forward with my projects though, thanks :)Powered by Discourse, best viewed with JavaScript enabled"
122,can-i-use-rtx8000,"I want to use NVIDIA Modulus 22.09 with docker, on Ubuntu22.04,  but I get an error.root@50a7161248f2:/examples/examples/three_fin_2d# python heat_sink.py
/opt/conda/lib/python3.8/site-packages/hydra/_internal/callbacks.py:26: UserWarning: Callback ModulusCallback.on_job_start raised RuntimeError: Running CUDA fuser is only supported on CUDA builds.
warnings.warn(
[02:57:43] - Arch Node: heat_network has been converted to a FuncArch node.
[02:57:49] - Arch Node: flow_network has been converted to a FuncArch node.
[02:57:50] - Arch Node: heat_network has been converted to a FuncArch node.
[02:57:51] - Arch Node: flow_network has been converted to a FuncArch node.
[02:57:51] - attempting to restore from: outputs/heat_sink [02:57:51] - optimizer checkpoint not found [02:57:51] - model flow_network.0.pth not found [02:57:51] - model heat_network.0.pth not found Error executing job with overrides:  Traceback (most recent call last):
File “heat_sink.py”, line 275, in run
slv.solve()
File “/modulus/modulus/solver/solver.py”, line 159, in solve
self._train_loop(sigterm_handler)
File “/modulus/modulus/trainer.py”, line 521, in _train_loop
loss, losses = self._cuda_graph_training_step(step)
File “/modulus/modulus/trainer.py”, line 694, in _cuda_graph_training_step
self.warmup_stream = torch.cuda.Stream()
File “/opt/conda/lib/python3.8/site-packages/torch/cuda/streams.py”, line 34, in new
return super(Stream, cls).new(cls, priority=priority, **kwargs)
RuntimeError: CUDA error: no CUDA-capable device is detected CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.Driver is >515, but  I can’t.$ nvidia-smi
Sat Dec 17 12:00:12 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     Off  | 00000000:D8:00.0 Off |                  Off |
| 33%   31C    P8    11W / 260W |      5MiB / 49152MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1857      G   /usr/lib/xorg/Xorg                  4MiB |
±----------------------------------------------------------------------------+
WARNING: infoROM is corrupted at gpu 0000:D8:00.0Can Modulus use RTX8000?Hi @con2Seems this is some error that’s occurring with cuda graphs. We don’t currently test Modulus on RTX8000 so unfortunately I cannot have a complete solution (however we have tested it fine on other Quadros).
I would try shutting off cuda graphs in your config.yaml file:Does the base line Helmholtz example work for you?Thanks for the advice.
Results are as follows.helmholts.py: Workheat_sink.py: Not work
heat_sink.py -cuda_graphs:False: Work, but too Slow2nd
heat_sink.py -cuda_graphs:False:
Compared to the first, the second calculation is faster.But it doesn’t converge.Powered by Discourse, best viewed with JavaScript enabled"
123,modulus-sym-ldc-example-runtimeerror-cuda-error-no-cuda-capable-device-is-detected,"After I installed all modules, I tried to run an example case in modulus sym: ldc. I run python ldc_2d.py and got following error. I did this on my laptop with onboard graphic card. I assume the issue is with “RuntimeError: CUDA error: no CUDA-capable device is detected” and somehow I cannot tell the software to use CPU:…
Traceback (most recent call last):File “ldc_2d.py”, line 136, in runFile “/home/pasha/.local/lib/python3.8/site-packages/modulus/sym/solver/solver.py”, line 173, in solveFile “/home/pasha/.local/lib/python3.8/site-packages/modulus/sym/trainer.py”, line 535, in _train_loopFile “/home/pasha/.local/lib/python3.8/site-packages/modulus/sym/trainer.py”, line 708, in _cuda_graph_training_stepFile “/home/pasha/.local/lib/python3.8/site-packages/torch/cuda/streams.py”, line 34, in newRuntimeError: CUDA error: no CUDA-capable device is detectedCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.For debugging consider passing CUDA_LAUNCH_BLOCKING=1.Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.Thank you very much for your help,
PashaHi @pasha.piroozmandI would highly recommend finding a machine with a GPU. Many of these problems are not able to run on a CPU with out being extremely slow and power hungry. However for LDC it should work. Try adding the following to your config YAML:That will eliminate the error given here.Powered by Discourse, best viewed with JavaScript enabled"
124,sympy-size-error-and-setting-2d-point-constraints,"I’m trying to implement this PDE class and I’m having some difficulties, am I doing something wrong?

eiko754×405 37 KB
At the PointwiseInteriorConstraint I get the error: ValueError: C order implies last dim (1) == len(args) (2)error:
error1084×354 42.2 KB
I need the initial condition T(4,1) = 0 and I am not successfulhow the network was setI would be grateful if someone could help me.Hi @caio.leaoI’m not sure what is causing that error you’re getting. I was not able to reproduce it on my end. However there are a few issues. The first is that the Rectangle geometry object returns x,y, so your ‘z’ variable in your PDE and model won’t be provided. This would cause a graph unrolling error. The fix is simply changing z to y.The second issue is that in your PointwiseInteriorConstraint you don’t provide a v variable which will also cause a graph unrolling error. Your PDE can’t be calculated without it. To fix this I added v as a parameterized variable.I created a simple script to test on my end and seems it works fine on my end:@ngenevaDear @ngenevam I’m really grateful for help me with the code, now it is working. However, I would like to ask for another question. Looking in the documentation, I can’t find a good way to make a point restriction on data in two dimensions of two dimensions. I mean, in this case I need T(x,y) to be like this T(4,1) = (0,0). I looked at the criteria but it refers to boundary conditions my problem has no border. I tried this way but I was not successful,or more easy  T = 0 for v = 0 using PointwiseConstraint.from_numpy
Could you help me with this?Hi @caio.leaoYes, unfortunately we don’t have a 2D point primitive as far as I know. You could try a few things.Define the input/ output training points for this constraint manually via numpy dictionaries. (See this thread and embedded links). This is probably what I would recommend the most.Use the criteria to create a small bounding box around the point of interest.A hacky approach would be to use a 1D point geometry for the x dimension and then parameterize the y variable like what you have here.Another option I would try is to create a 2D circle geometry with a really small radius so its approximately a point.@ngenevaThanks. I was able to run successfully after the previous suggestion using PointwiseConstraint.from_numpy. I’ll try the other two suggestions as I need to vary this initial condition. A suggestion for Nvidia is to generate the direct possibility of entering these point restriction conditionsThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
125,for-importance-sampling-example-increasing-batch-size-to-50-000-make-memory-outage,"For annular_ring_importance sampling example, I changed Interior batch_size to 50,000 and it returned error in allocating GPU memory (RTX3080 laptop 16GB). I also tried on V100-32GB GPU and it also showed out of memory warning. T
annular_ring_importance_sampling.py (11.6 KB)
he python file is as attached.Hello @Spartacus , A batch size of 50,000 will not run on with that amount of memory. For the importance sampled constraint you are computing the Navier Stokes momentum and continuity equations. These require doing several second order gradient calls each of which is very memory intensive. If you would like to run with larger batch sizes you can use multiple GPUs. I will note that the importance sampling functionality has been refactored in the 22.03 release and is now much simpler. You can find this in the ldc example.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
126,unclear-units-for-electromagnetic-field-simulation,"I am working with a simulation of electromagnetic fields. After reading the modulus user guide, I have some doubts about the units used in the modulus samples, especially the wavenumber (frequency divided by the speed of light). When we usually simulate the electromagnetic field in Matlab, the unit of length, width and height of the electrolyte space is nm or micrometer, and the unit of transmitted wavelength is also nm.
In my simulation, the space unit is microns, and the wavelength of electromagnetic waves is 500 nm. The results simulated by modulus are different from those of matlab. I am sure that other settings are no problem, mainly the problem of units.
In Chapter 10 of the User Guide, all the examples are unitless, with wave numbers of 16 or 32, as shown in the figure below.

{{@VEP_1(OHRTO@DQ8A_401071×301 33.1 KB

I want to know what are the spatial units used in the modulus and also what are the frequency units of the electromagnetic wave.Thanks and regards,ZhouHi @ZMartialFor all problems using Modulus we typically suggest users scale/nondimensionalize the problem to be centered around 0 and has a reasonable domain range. This practice is essential for successful deep learning of physical systems, akin to scaling training data. Thus in this example, think of the domain length of having a nondimensionalize unit (say m*) and the wave number also being applied in that nondimensionalize space (1/m*).So for your particularly problem where the space unit is micron, you would want to scale/nondimensionalize the system to get the best results from physics-informed deep learning.We have some information/resources on this process in the docs here:
https://docs.nvidia.com/deeplearning/modulus/user_guide/theory/recommended_practices.html#scaling-the-problemPowered by Discourse, best viewed with JavaScript enabled"
127,recurrent-network-in-modulus,"Hello.You have mentioned about RNN and GRU for transient problem in Simnet document.Would you let me know if  you have any plans to develop such a recurrent network architecture for modulus?Thanks,Yes, Modulus 22.12 release will have the RNNsHi schoudhry,Thank you for your answer.Can we use the RNN for 3D transient CFD problem?Regards,Hi @yokoi.toshiakiThis is a pretty broad question as this largely depends on the complexity of the 3D fluid flow. However, we have been testing a data-driven RNN model for 3D transient fluid flow with some promising results. 3D fluid systems add a lot of additional challenges in addition to the more complex physics regarding training time, data-loading, etc.Hi ngenevaThank you for your reply.As you mention the RNNs are promising for data-driven surrogate model.However we are interested in RNNs for PINNs.
Will the RNNs in Modulus22.12 be available for for PINNs?For example, unsteady vortex around a cylinder.Thanks,Powered by Discourse, best viewed with JavaScript enabled"
128,help-with-calculation-of-wall-velocity-gradients,"Hi,I’m trying to get the wall velocity gradients for the three_fin_3d example. In the user guide for 2106, in page 131, we were given the code to add into the three_fin_flow_solver.py.I modified and ran the code.
I got the WallGradients.vtu file in the inference dir. When I opened it using Paraview, I saw the variables like, normal x/y/z, u/v/w etc. However there is no du/dx (u__x) etc.Did I make a mistake somewhere? Can someone help?Powered by Discourse, best viewed with JavaScript enabled"
129,welcome-to-the-modulus-physics-ml-model-framework-forum,"Whether you’re looking to get started with AI-driven physics simulations or working on complex nonlinear physics problems, come engage us on how the Modulus Physics-ML Model Framework  can help you solve your forward, inverse, or data assimilation problems. Learn about the innovative capabilities of our latest release here :https://developer.nvidia.com/blog/nvidia-announces-modulus--a-framework-for-developing-physics-ml-models-for-digital-twins/Powered by Discourse, best viewed with JavaScript enabled"
130,how-to-train-dynamical-pde-system-in-pino,"In the example documentation of PINO, it uses stationary PDE(input tensor shape: 1024,1,421,421). But my PDE depends on time, so my input tensor shape is (1024,100,421,421).
Can you kindly guide me how to solve dynamical PDE in PINO?Hi @id21resch11019We presently do not have an example of PINO for a transient problem, just 2D steady state. You could predict all time-steps at once with a 4D output and approximate time derivatives using finite difference, Fourier derivatives, etc. in that dimension.One approach I would consider is an auto-regressive approach which can work well for physical systems with physics based loss functions. For data-driven this is how models like FourCastNet (Adaptive FNO under the hood) operate.Powered by Discourse, best viewed with JavaScript enabled"
131,alpha-build-100-physx-motorcycle,"Hey Guys,I would like to give a shout out to all the amazing PhysX developers, I love working with your physics engine and find it to be awesome!  Also a big thanks to the people from Nvidia Physics support for answering questions I had when I first started this project.  Thank you!PS: Here is a short alpha video clip of a motorcycle and rider made 100% with Nvidia PhysX Physics.
Thank you very much for the kind feedback and the wonderful video @john242 !!Powered by Discourse, best viewed with JavaScript enabled"
132,news-simnet-gtc-21,"SimNet On-Demand Technical Sessions from GTC '21“Physics-Informed Neural Networks for Mechanics of Heterogenous Media” – IIT-Bombay presented a session on Physics-Informed Neural Networks for Mechanics of Heterogeneous Media. The PINN-based NVIDIA SimNet toolkit is used to develop a framework for the simulation of damage in elastic and elastoplastic materials. For verification, SimNet results are found in good agreement with the analytical solution based on Haghighat et al, 2020.“Using Physics-Informed Neural Networks and SimNet to Accelerate Product Development” – Kinetic Vision presented a session on using Physics Informed Neural Networks and SimNet to accelerate product development where the Coanda effect, encountered in aerospace and several industrial applications, is simulated using SimNet. Both 2D and 3D geometries are constructed using SimNet’s internal Geometry module and simulated using modified Fourier Network Architecture. The results showed that qualitatively, the velocity flow field predicted by the commercial CFD code, Ansys Fluent and the trained SimNet PINN are very similar. Furthermore, Kinetic Vision did parametric simulations with SimNet and went a step further by taking these results and integrating them into CAD with SolidWorks for automated inference as well as providing a way for users to interact with SimNet from within Solidworks UI.“Hybrid Physics-Informed Neural Networks for Digital Twin in Prognosis and Health Management” – University of Central Florida presented a session on Hybrid Physics-Informed Neural Networks for Digital Twin in Prognosis and Health Management where a Digital twin model is built to predict damage and fatigue crack growth in aircraft window panels. SimNet models are based in physics and this ensures accuracy needed for prognosis and health management of structural materials. Once SimNet models are trained, they can be used to perform fast and accurate computations as a function of different input conditions. SimNet also achieves good accuracy that the commercial solvers achieve with high degree of mesh refinement. With SimNet, they can scale the predictive model to a fleet of 500 aircraft and get predictions in less than 10 seconds as opposed to taking a few days to weeks if they were to perform the same computations using high-fidelity finite element models.“Physics-Informed Neural Network for Flow and Transport in Porous Media” – Stanford University presented a session on Physics-Informed Deep Learning for Flow and Transport in Porous Media where a methodology is used to simulate a 2-phase immiscible transport problem (Buckley-Leverett). The model can produce an accurate physical solution both in terms of shock and rarefaction and honors the governing partial differential equation along with initial and boundary conditions. Read more about this on our NVIDIA blog here.“AI-Accelerated Computational Science and Engineering Using Physics-Based Neural Networks” – NVIDIA presented a session on AI-Accelerated Computational Science and Engineering Using Physics-Based Neural Networks that covers state-of-the-art AI for addressing diverse areas of applications ranging from real-time simulation (e.g., digital twin and autonomous machines) to design space exploration (generative design and product design optimization), inverse problems (e.g., medical imaging, full wave inversion in oil and gas exploration) and improved science (e.g., micromechanics, turbulence) that are difficult to solve because of various gradients and discontinuities, due to physics laws and complex shapes.Powered by Discourse, best viewed with JavaScript enabled"
133,solving-multidimensional-pdes-more-than-3d,"Hello,is it possible to solve high dimensional PDEs with Moduls, for example 6 dimensions, defining hypercubes geometry?Thanks.I’m not with nvidia, so take what I say with a grain of salt.
Technologically speaking, I don’t see a reason why it fundamentally wouldn’t work so long as your PDE’s support the added dimensionality. However, the included code and PDE’s (e.g. Navier Stokes) appear to be capped at 3 dimensions, so you would likely need to implement the functionality yourself. Once that’s done though, I would imagine it works.Thank you for your reply.The reason why I am asking is that it seems from the documentation that in the geometry classes only 1D, 2D, and 3D geometries can be defined (Modulus Geometry - NVIDIA Docs), with output being only [‘x’], [‘x’,’y’], or [‘x’,’y’,’z’].For example, how would I define a custom 4D hypercube geometry class to be used in PointwiseInteriorConstraint and PointwiseBoundaryConstraint?Thanks.@uarizonassel4D geometry is not possible in the geometry module. You can always generate a input variable dataset ahead of time that reflects your higher-dimensional system you are interested in. This should be pretty easy to achieve if you can get your inputs to be numpy dictionary:Alternatively, if you want to a custom geometry object that is possible like you mention. It can be used in the current constraints given it has the proper functionality (typically this is boundary shapes, sdf function, etc).Powered by Discourse, best viewed with JavaScript enabled"
134,how-to-apply-a-different-geometry-to-a-trained-model,"Hi there,I’d like to use my trained neural network to apply it to a similar but different geometry. I’ve read about the eval() mode, but I need more information.I know there are already few basic topics in this forum as well as the three fin example, but which instances does my skript need if I want to use a different geometry instead of another parameterset?
Do I need to define all my Constraints just like when training a model? What do I need to change apart from my geometry?
Basically how should my basic script look like? Which instances are mandatory? Or is this even possible?A fast forward help would be much appreciated.Many thanks in advance.Hi @jflatterIf you want to change the geometry, then its just updating the geometry object that is fed into the constraints/inferencers/monitors. E.g. The (point wise) constraints view the geometry as this point generator, thats it. For example, you could define a circle for the heat_sink geometry used here and the solver should then just sample training points based on this new shape.Its the same deal for pointwise inferencers. For inference (with a trained model), just define your new geometry (assuming its of the same dimension as your previous geometry) and provide it to a pointwise inferencer thats added to a solver. Assuming all other input variables are provided and the symbolic graph can unroll you should be good to go to call solver.eval().Hi @ngenevaThank you for your reply.I tried applying a trained model to a different geometry (different size and less obstacles in the channel). All I used was the pointwise validator (for openfoam reference) and I changed my mode to eval(), just like you said. I defined the new geometry including all boundary conditions just like the one I trained on.However, Modulus just seems to resample the trained interior onto the new domain, without “calculating” any different behavior. I attached a picture for better understanding. There you can see that Modulus doesn’t take the new obstacle into account at all. Where is my mistake?
validator_p1476×389 51.6 KB
Many thanks in advance.Hi @jflatterHmmm,I’m assuming your model has some sort of parameter / input that would reflect the new geometry (i.e. its not just x or y) otherwise your network will have no idea if anything has changed since its point wise.Consider generating a VTK point cloud output by changing the ouput format in the config (example here). Then display that VTP file in Paraview to see what points were actually sampled and if that reflects your geometry.Its hard to tell from these matplotlib plots since it actually interpolates the unstructured points onto a grid under the hood for these images.Hi @ngenevaThank you for your help.I applied a totally different geometry with different shape, which wasn’t parameterized which will be the problem I guess.I’ve now defined a new geometry with a parameter range for a cylinder radius. How can I change the radius for evaluation? Just change the range parameter to a fixed value and run on eval() mode?This is my code snippet:Thanks in advance.Hi @jflatterCorrect, on the construction of the constraints/inferencers/validators/monitors the (modified) geometry is sampled to generate the point cloud. So in your inference script just change your parameterization from a range to a number. Have a look at this sample script:The parameterized sample uses points between radius 0.01 to 0.06.

image1052×926 179 KB
The fixed one has all samples uniformly in a radius of 0.02

image1055×932 66.6 KB
Powered by Discourse, best viewed with JavaScript enabled"
135,help-with-creating-3d-wing-geometry,"Hi, I have successfully create 2D NACA airfoils using the help given below:https://forums.developer.nvidia.com/t/unable-to-sample-naca-0012-symmetrical-airfoil/190259Now, I’m thinking of creating a 3D wing. For a start, I just want to do a simple wing with NACA profile. Also, the objective is to be able to do parametric analysis similar to the 3D fin case.So if I’m importing STL thru pySDF, it may not be easy to parameterize later on.For the 3D fin, it is using the box function to create the 3D fin. Is it feasible to create a new function for the 3D wing based on the box function? Or can the polygon function using in the 2D airfoil be used in a modified function to create a 3D wing?Hope someone can help. Thanks!Hi @tsltaywbCreating a parameterized CSG can be pretty challenging if the geometry strays far from the built in primitives. It’s theoretically possible yes, but can be very challenging to set up for shapes that stray aware from the built in primitives. Additionally, the polygon primitive has some limitations in terms of scaling to finer resolutions (sampling becomes slow).Thus typically we suggest people use parameterization based a discrete set of STL files. The idea here is to create a set of STL files each representing a sample in your parameterization range. You can then import them all and set up the respective parameters for sampling. An example of this is found our examples repo.Hi ngeneva,Thanks for the tips. Btw, I found some equations for airfoils, defined parametrically. I understand that besides the parametric eqns, I have to provide the normal x/y, area, sdf and bounds. When you mention “challenging”, do you mean that it’s difficult to obtain the corresponding eqns? Or that it will be slow like the polygon primitive? Are normal  x/y, area, sdf compulsory?Nevertheless, I’ll check out the repo. Strange that I’m getting block at the moment:Your account is blockedWe’ve detected suspicious activity on your account.I will check again in the next few days.Hi @tsltaywbWhen you mention “challenging”, do you mean that it’s difficult to obtain the corresponding eqns? Or that it will be slow like the polygon primitive? Are normal x/y, area, sdf compulsory?If you can construct the geometry from a set of primitives (like spheres, rectangles, etc.) then CSG is a great approach, but this is the challenging part if you do not know this. But most 3D objects people tend want to try are complex in geometry. Even if it can be reconstructed with CSG but requires a lot of primitives, it can take a long time to sample training points. Additionally because its up to the user to essentially build the geometry in a python script (not a 3D Cad software) complex CSG can take a long time to setup/debug.But it is possible. We have done it before. So its really depends on your priorities.Nevertheless, I’ll check out the repo. Strange that I’m getting block at the momentHmmm, okay. If its specific to the Modulus repo let us know. If its related to your entire Gitlab account, I would seek help from Gitlab’s side of things.Hi ngeneva,I have managed to get the code thru Gitlab. Can I check if this code require pysdf? I have a hard time trying to get pysdf to work on the systems I use - school clusters, saturn cloud.Most don’t allow the use of docker directly. And it seems that converting to singularity prevents pysdf from running correctly.In this case, is there any other alternatives to import stl files?Thanks and Merry Christmas!Hi @tsltaywbUnfortunately that’s the only method we offer STL support right now for training points. There is some VTK support but we dont support creating training points from a VTK file like we do with STL files via pysdf.Powered by Discourse, best viewed with JavaScript enabled"
136,zerodivisionerror-float-division-by-zero-when-using-parameterized-tesselated-geometry,"Hello,I want to make a parameterized discrete geometry out of tesselated geometries. When I execute the code I get a strange error:This error occures only when I try to make a discrete geometry out of tesselated geometries, I can sample points on each tesselated geometry that I use without any problem. Here is a code that produces an error:I would be great if you could help me resolve this issue.Thank youHi @gorpinich4This typically happens when the geometry module samples 0 points (somethings up with the sampling bounds, geometry itself, etc). Does a single tessellated geometry from the parse_file sample alright?E.g.Powered by Discourse, best viewed with JavaScript enabled"
137,news-simnet-in-springers-lecture-notes-in-computer-science,"Our SimNet paper has now been published in Springer’s Lecture Notes in Computer Science: NVIDIA SimNet™: An AI-Accelerated Multi-Physics Simulation Framework | SpringerLinkPowered by Discourse, best viewed with JavaScript enabled"
138,how-to-set-a-global-seed-to-repeat-the-result,"Hello, I am wondering how to set a global seed to repeat the results? Or how to set seeds separatly? Thanks!Hi @zhangzhenthuPresently you need to set the random seed yourself to have an exact repeat. Some parts of Modulus-Sym have fixed seeds for reproducibility already (data loaders), but not all of it. Have a look at the PyTorch docs on this matter for what seeds to set.Hi,
Thank you for your reply. I will try to set the seed myself.  :)This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
139,problem-using-modulus-22-07-in-wsl2,"Hi,I tried to upgrade modulus from 2203 to 2207. 2203 worked, however, 2207 didn’t work. I’m using WSL2.Anyway, I downloaded *.tar image file and load it successfully.
However, running the command
docker run --gpus all --ipc=host --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 7007:7007 -v /home/user/Modulus_2207/myprojects_2207:/myprojects_2207 -it modulus:22.07 bash
gave the error:docker: Error response from daemon: failed to create shim: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: /var/lib/docker/overlay2/8802aa6c9c154dbba3d8fdefbae602451e75390392b3070f01303a2083c0f85e/merged/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1: file exists: unknown.
ERRO[0001] error waiting for container: context canceledThe error comes from “–gpus all”.If I remove it, it loads ok but it fails when I tried to run an example, complaining that there’s no GPU present.If I use:
docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 
–runtime nvidia -v ${PWD}/examples:/examples 
-it modulus:22.07 bashI got the err:
Docker: Eorror response from daemon: Unknown runtime specified nvidia
Btw, I already installed the nvidia-docker2 lib.
In pure linux ubuntu, the 2nd docker command works though.
Any one can help?Thanks.Hi @tsltaywbUnfortunately we updated the nvidia-docker version used in 22.07 and presently there seems to be a bug with it running on WSL. This GitHub issue has the precise error message that I believe you are seeing. Perhaps you can get some information there (seems some have figured out a work around):### 1. Issue or feature description
I prepare environment follow this [guide:](…https://docs.nvidia.com/cuda/wsl-user-guide/index.html) 
- Windows 11 build 22000 (Insider Preview Beta Channel)
- WSL2, ubuntu20.04 (Linux version is 5.10.16.3)
- [CUDA on WSL](https://developer.nvidia.com/cuda/wsl/download) 510.06
- CUDA Toolkit 11-4 (using [WSL-Ubuntu](https://docs.nvidia.com/cuda/wsl-user-guide/index.html#ch03a-setting-up-cuda))
- docker 20.10.8
- nvidia-docker2  2.6.0-1 (with libnvidia-container1_1.5.1-1, libnvidia-container-tools_1.5.1-1, nvidia-container-toolkit_1.5.1-1, nvidia-container-runtime_3.5.0-1)

When `sudo docker run --gpus all --runtime=nvidia -it --rm <my image name>`, there comes the issue

>docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: /var/lib/docker/overlay2/706b1d1b6de681b6daf1cab979336a9d465d9b333962cc17db663f2e334d5776/merged/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1: file exists: unknown.

Though encounter problems when run my own image, this sample just works fine:
`docker run --gpus all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark`
![image](https://user-images.githubusercontent.com/73638271/135861058-9c361324-04b8-49e8-877d-f6acdbd8bca0.png)

And I also checked that no nvidia driver installed in my image: 
`docker exec -it containerID /bin/bash`
`apt list --installed`
shows there isn't any nvidia* or libnvidia* package, only have some cuda related packages (cuda-compat-10-2, cuda-cudart-10-2, cuda-license-10-2)

### 2. Information

#### nvidia-container information from `nvidia-container-cli -k -d /dev/tty info`
-- WARNING, the following logs are for debugging purposes only --

I1004 13:41:19.446777 13740 nvc.c:372] initializing library context (version=1.5.1, build=4afad130c4c253abd3b2db563ffe9331594bda41)
I1004 13:41:19.447100 13740 nvc.c:346] using root /
I1004 13:41:19.447125 13740 nvc.c:347] using ldcache /etc/ld.so.cache
I1004 13:41:19.447183 13740 nvc.c:348] using unprivileged user 1000:1000
I1004 13:41:19.447196 13740 nvc.c:389] attempting to load dxcore to see if we are running under Windows Subsystem for Linux (WSL)
I1004 13:41:19.465867 13740 dxcore.c:227] Creating a new WDDM Adapter for hAdapter:40000000 luid:f95e09
I1004 13:41:19.478468 13740 dxcore.c:268] Adding new adapter via dxcore hAdapter:40000000 luid:f95e09 wddm version:3000
I1004 13:41:19.478495 13740 dxcore.c:326] dxcore layer initialized successfully
W1004 13:41:19.478894 13740 nvc.c:397] skipping kernel modules load on WSL
I1004 13:41:19.479135 13741 driver.c:101] starting driver service
I1004 13:41:19.537408 13740 nvc_info.c:758] requesting driver information with ''
I1004 13:41:19.551091 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.460.91.03
I1004 13:41:19.552122 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-opticalflow.so.1
I1004 13:41:19.552152 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.460.91.03
I1004 13:41:19.553231 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-ml.so.1
I1004 13:41:19.553264 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.460.91.03
I1004 13:41:19.553295 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.460.91.03
I1004 13:41:19.554246 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-encode.so.1
I1004 13:41:19.554278 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.460.91.03
I1004 13:41:19.555174 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvcuvid.so.1
I1004 13:41:19.555259 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libdxcore.so
I1004 13:41:19.556208 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libcuda.so.1
I1004 13:41:19.556240 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libcuda.so.460.91.03
I1004 13:41:19.556348 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libcuda.so.460.91.03
W1004 13:41:19.556404 13740 nvc_info.c:397] missing library libnvidia-cfg.so
W1004 13:41:19.556426 13740 nvc_info.c:397] missing library libnvidia-nscq.so
W1004 13:41:19.556429 13740 nvc_info.c:397] missing library libnvidia-fatbinaryloader.so
W1004 13:41:19.556431 13740 nvc_info.c:397] missing library libnvidia-allocator.so
W1004 13:41:19.556433 13740 nvc_info.c:397] missing library libnvidia-ngx.so
W1004 13:41:19.556434 13740 nvc_info.c:397] missing library libvdpau_nvidia.so
W1004 13:41:19.556453 13740 nvc_info.c:397] missing library libnvidia-eglcore.so
W1004 13:41:19.556456 13740 nvc_info.c:397] missing library libnvidia-glcore.so
W1004 13:41:19.556457 13740 nvc_info.c:397] missing library libnvidia-tls.so
W1004 13:41:19.556459 13740 nvc_info.c:397] missing library libnvidia-glsi.so
W1004 13:41:19.556460 13740 nvc_info.c:397] missing library libnvidia-fbc.so
W1004 13:41:19.556462 13740 nvc_info.c:397] missing library libnvidia-ifr.so
W1004 13:41:19.556500 13740 nvc_info.c:397] missing library libnvidia-rtcore.so
W1004 13:41:19.556506 13740 nvc_info.c:397] missing library libnvoptix.so
W1004 13:41:19.556512 13740 nvc_info.c:397] missing library libGLX_nvidia.so
W1004 13:41:19.556514 13740 nvc_info.c:397] missing library libEGL_nvidia.so
W1004 13:41:19.556521 13740 nvc_info.c:397] missing library libGLESv2_nvidia.so
W1004 13:41:19.556524 13740 nvc_info.c:397] missing library libGLESv1_CM_nvidia.so
W1004 13:41:19.556526 13740 nvc_info.c:397] missing library libnvidia-glvkspirv.so
W1004 13:41:19.556527 13740 nvc_info.c:397] missing library libnvidia-cbl.so
W1004 13:41:19.556547 13740 nvc_info.c:401] missing compat32 library libnvidia-ml.so
W1004 13:41:19.556555 13740 nvc_info.c:401] missing compat32 library libnvidia-cfg.so
W1004 13:41:19.556557 13740 nvc_info.c:401] missing compat32 library libnvidia-nscq.so
W1004 13:41:19.556562 13740 nvc_info.c:401] missing compat32 library libcuda.so
W1004 13:41:19.556564 13740 nvc_info.c:401] missing compat32 library libnvidia-opencl.so
W1004 13:41:19.556583 13740 nvc_info.c:401] missing compat32 library libnvidia-ptxjitcompiler.so
W1004 13:41:19.556586 13740 nvc_info.c:401] missing compat32 library libnvidia-fatbinaryloader.so
W1004 13:41:19.556587 13740 nvc_info.c:401] missing compat32 library libnvidia-allocator.so
W1004 13:41:19.556589 13740 nvc_info.c:401] missing compat32 library libnvidia-compiler.so
W1004 13:41:19.556625 13740 nvc_info.c:401] missing compat32 library libnvidia-ngx.so
W1004 13:41:19.556629 13740 nvc_info.c:401] missing compat32 library libvdpau_nvidia.so
W1004 13:41:19.556632 13740 nvc_info.c:401] missing compat32 library libnvidia-encode.so
W1004 13:41:19.556638 13740 nvc_info.c:401] missing compat32 library libnvidia-opticalflow.so
W1004 13:41:19.556640 13740 nvc_info.c:401] missing compat32 library libnvcuvid.so
W1004 13:41:19.556644 13740 nvc_info.c:401] missing compat32 library libnvidia-eglcore.so
W1004 13:41:19.556667 13740 nvc_info.c:401] missing compat32 library libnvidia-glcore.so
W1004 13:41:19.556670 13740 nvc_info.c:401] missing compat32 library libnvidia-tls.so
W1004 13:41:19.556676 13740 nvc_info.c:401] missing compat32 library libnvidia-glsi.so
W1004 13:41:19.556677 13740 nvc_info.c:401] missing compat32 library libnvidia-fbc.so
W1004 13:41:19.556679 13740 nvc_info.c:401] missing compat32 library libnvidia-ifr.so
W1004 13:41:19.556680 13740 nvc_info.c:401] missing compat32 library libnvidia-rtcore.so
W1004 13:41:19.556682 13740 nvc_info.c:401] missing compat32 library libnvoptix.so
W1004 13:41:19.556700 13740 nvc_info.c:401] missing compat32 library libGLX_nvidia.so
W1004 13:41:19.556703 13740 nvc_info.c:401] missing compat32 library libEGL_nvidia.so
W1004 13:41:19.556705 13740 nvc_info.c:401] missing compat32 library libGLESv2_nvidia.so
W1004 13:41:19.556740 13740 nvc_info.c:401] missing compat32 library libGLESv1_CM_nvidia.so
W1004 13:41:19.556745 13740 nvc_info.c:401] missing compat32 library libnvidia-glvkspirv.so
W1004 13:41:19.556746 13740 nvc_info.c:401] missing compat32 library libnvidia-cbl.so
W1004 13:41:19.556748 13740 nvc_info.c:401] missing compat32 library libdxcore.so
I1004 13:41:19.558106 13740 nvc_info.c:277] selecting /usr/lib/wsl/drivers/nv_dispi.inf_amd64_733101c735b9e264/nvidia-smi
W1004 13:41:19.884566 13740 nvc_info.c:423] missing binary nvidia-debugdump
W1004 13:41:19.884603 13740 nvc_info.c:423] missing binary nvidia-persistenced
W1004 13:41:19.884606 13740 nvc_info.c:423] missing binary nv-fabricmanager
W1004 13:41:19.884608 13740 nvc_info.c:423] missing binary nvidia-cuda-mps-control
W1004 13:41:19.884609 13740 nvc_info.c:423] missing binary nvidia-cuda-mps-server
I1004 13:41:19.884611 13740 nvc_info.c:437] skipping path lookup for dxcore
I1004 13:41:19.884617 13740 nvc_info.c:520] listing device /dev/dxg
W1004 13:41:19.884653 13740 nvc_info.c:347] missing ipc path /var/run/nvidia-persistenced/socket
W1004 13:41:19.884663 13740 nvc_info.c:347] missing ipc path /var/run/nvidia-fabricmanager/socket
W1004 13:41:19.884768 13740 nvc_info.c:347] missing ipc path /tmp/nvidia-mps
I1004 13:41:19.884791 13740 nvc_info.c:814] requesting device information with ''
I1004 13:41:19.896593 13740 nvc_info.c:686] listing dxcore adapter 0 (GPU-4949b172-957c-5479-5dc3-12e0ea688389 at 00000000:2d:00.0)
NVRM version:   510.06
CUDA version:   11.2

Device Index:   0
Device Minor:   0
Model:          NVIDIA GeForce RTX 2080 Ti
Brand:          GeForce
GPU UUID:       GPU-4949b172-957c-5479-5dc3-12e0ea688389
Bus Location:   00000000:2d:00.0
Architecture:   7.5
I1004 13:41:19.896655 13740 nvc.c:423] shutting down library context
I1004 13:41:19.897661 13741 driver.c:163] terminating driver service
I1004 13:41:19.898674 13740 driver.c:203] driver service terminated successfully

#### Kernel version from `uname -a`
Linux DESKTOP 5.10.16.3-microsoft-standard-WSL2 #1 SMP Fri Apr 2 22:23:49 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux

#### Any relevant kernel output lines from `dmesg`
[    0.000000] Linux version 5.10.16.3-microsoft-standard-WSL2 (oe-user@oe-host) (x86_64-msft-linux-gcc (GCC) 9.3.0, GNU ld (GNU Binutils) 2.34.0.20200220) #1 SMP Fri Apr 2 22:23:49 UTC 2021
[    0.000000] Command line: initrd=\initrd.img panic=-1 nr_cpus=16 swiotlb=force pty.legacy_count=0
[    0.000000] KERNEL supported cpus:
[    0.000000]   Intel GenuineIntel
[    0.000000]   AMD AuthenticAMD
[    0.000000]   Centaur CentaurHauls
[    0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
[    0.000000] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
[    0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format.
[    0.000000] BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009ffff] usable
[    0.000000] BIOS-e820: [mem 0x00000000000e0000-0x00000000000e0fff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000001fffff] ACPI data
[    0.000000] BIOS-e820: [mem 0x0000000000200000-0x00000000f7ffffff] usable
[    0.000000] BIOS-e820: [mem 0x0000000100000000-0x00000004057fffff] usable
[    0.000000] NX (Execute Disable) protection: active
[    0.000000] DMI not present or invalid.
[    0.000000] Hypervisor detected: Microsoft Hyper-V
[    0.000000] Hyper-V: features 0xae7f, privilege high: 0x3b8030, hints 0xc2c, misc 0xe0bed7b2
[    0.000000] Hyper-V Host Build:22000-10.0-0-0.194
[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480
[    0.000000] Hyper-V: Using hypercall for remote TLB flush
[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    0.000001] tsc: Detected 3899.997 MHz processor
[    0.000007] e820: update [mem 0x00000000-0x00000fff] usable ==> reserved
[    0.000008] e820: remove [mem 0x000a0000-0x000fffff] usable
[    0.000010] last_pfn = 0x405800 max_arch_pfn = 0x400000000
[    0.000033] MTRR default type: uncachable
[    0.000033] MTRR fixed ranges enabled:
[    0.000034]   00000-3FFFF write-back
[    0.000034]   40000-7FFFF uncachable
[    0.000035]   80000-8FFFF write-back
[    0.000035]   90000-FFFFF uncachable
[    0.000035] MTRR variable ranges enabled:
[    0.000036]   0 base 000000000000 mask FFFF00000000 write-back
[    0.000037]   1 base 000100000000 mask FFF000000000 write-back
[    0.000037]   2 disabled
[    0.000037]   3 disabled
[    0.000038]   4 disabled
[    0.000038]   5 disabled
[    0.000038]   6 disabled
[    0.000038]   7 disabled
[    0.000047] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT
[    0.000059] last_pfn = 0xf8000 max_arch_pfn = 0x400000000
[    0.000071] Using GB pages for direct mapping
[    0.000322] RAMDISK: [mem 0x03035000-0x03043fff]
[    0.000326] ACPI: Early table checksum verification disabled
[    0.000332] ACPI: RSDP 0x00000000000E0000 000024 (v02 VRTUAL)
[    0.000334] ACPI: XSDT 0x0000000000100000 000044 (v01 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000338] ACPI: FACP 0x0000000000101000 000114 (v06 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000341] ACPI: DSDT 0x00000000001011B8 01E184 (v02 MSFTVM DSDT01   00000001 MSFT 05000000)
[    0.000343] ACPI: FACS 0x0000000000101114 000040
[    0.000344] ACPI: OEM0 0x0000000000101154 000064 (v01 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000346] ACPI: SRAT 0x000000000011F33C 0003B0 (v02 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000347] ACPI: APIC 0x000000000011F6EC 0000C8 (v04 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000351] ACPI: Local APIC address 0xfee00000
[    0.000516] Zone ranges:
[    0.000517]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.000518]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff]
[    0.000519]   Normal   [mem 0x0000000100000000-0x00000004057fffff]
[    0.000519]   Device   empty
[    0.000520] Movable zone start for each node
[    0.000520] Early memory node ranges
[    0.000521]   node   0: [mem 0x0000000000001000-0x000000000009ffff]
[    0.000522]   node   0: [mem 0x0000000000200000-0x00000000f7ffffff]
[    0.000522]   node   0: [mem 0x0000000100000000-0x00000004057fffff]
[    0.000857] Zeroed struct page in unavailable ranges: 10593 pages
[    0.000859] Initmem setup node 0 [mem 0x0000000000001000-0x00000004057fffff]
[    0.000860] On node 0 totalpages: 4183711
[    0.000861]   DMA zone: 59 pages used for memmap
[    0.000862]   DMA zone: 22 pages reserved
[    0.000862]   DMA zone: 3743 pages, LIFO batch:0
[    0.000884]   DMA32 zone: 16320 pages used for memmap
[    0.000884]   DMA32 zone: 1011712 pages, LIFO batch:63
[    0.010695]   Normal zone: 49504 pages used for memmap
[    0.010698]   Normal zone: 3168256 pages, LIFO batch:63
[    0.011050] ACPI: Local APIC address 0xfee00000
[    0.011055] ACPI: LAPIC_NMI (acpi_id[0x01] dfl dfl lint[0x1])
[    0.011340] IOAPIC[0]: apic_id 16, version 17, address 0xfec00000, GSI 0-23
[    0.011344] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
[    0.011345] ACPI: IRQ9 used by override.
[    0.011346] Using ACPI (MADT) for SMP configuration information
[    0.011353] smpboot: Allowing 16 CPUs, 0 hotplug CPUs
[    0.011362] [mem 0xf8000000-0xffffffff] available for PCI devices
[    0.011363] Booting paravirtualized kernel on Hyper-V
[    0.011365] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.015482] setup_percpu: NR_CPUS:256 nr_cpumask_bits:256 nr_cpu_ids:16 nr_node_ids:1
[    0.016192] percpu: Embedded 52 pages/cpu s173272 r8192 d31528 u262144
[    0.016196] pcpu-alloc: s173272 r8192 d31528 u262144 alloc=1*2097152
[    0.016197] pcpu-alloc: [0] 00 01 02 03 04 05 06 07 [0] 08 09 10 11 12 13 14 15
[    0.016212] Built 1 zonelists, mobility grouping on.  Total pages: 4117806
[    0.016214] Kernel command line: initrd=\initrd.img panic=-1 nr_cpus=16 swiotlb=force pty.legacy_count=0
[    0.018810] Dentry cache hash table entries: 2097152 (order: 12, 16777216 bytes, linear)
[    0.019993] Inode-cache hash table entries: 1048576 (order: 11, 8388608 bytes, linear)
[    0.020038] mem auto-init: stack:off, heap alloc:off, heap free:off
[    0.036796] Memory: 4094128K/16734844K available (16403K kernel code, 2459K rwdata, 3464K rodata, 1444K init, 1164K bss, 388996K reserved, 0K cma-reserved)
[    0.036832] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=16, Nodes=1
[    0.036840] ftrace: allocating 49613 entries in 194 pages
[    0.048726] ftrace: allocated 194 pages with 3 groups
[    0.048929] rcu: Hierarchical RCU implementation.
[    0.048930] rcu:     RCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=16.
[    0.048931]  Rude variant of Tasks RCU enabled.
[    0.048931]  Tracing variant of Tasks RCU enabled.
[    0.048931] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.
[    0.048932] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=16
[    0.051184] Using NULL legacy PIC
[    0.051186] NR_IRQS: 16640, nr_irqs: 552, preallocated irqs: 0
[    0.051565] random: crng done (trusting CPU's manufacturer)
[    0.051585] Console: colour dummy device 80x25
[    0.051591] printk: console [tty0] enabled
[    0.051595] ACPI: Core revision 20200925
[    0.051693] Failed to register legacy timer interrupt
[    0.051694] APIC: Switch to symmetric I/O mode setup
[    0.051695] Switched APIC routing to physical flat.
[    0.051850] Hyper-V: Using IPI hypercalls
[    0.051851] Hyper-V: Using enlightened APIC (xapic mode)
[    0.051922] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x706eb0792cc, max_idle_ns: 881591209130 ns
[    0.051925] Calibrating delay loop (skipped), value calculated using timer frequency.. 7799.99 BogoMIPS (lpj=38999970)
[    0.051926] pid_max: default: 32768 minimum: 301
[    0.051936] LSM: Security Framework initializing
[    0.051958] Mount-cache hash table entries: 32768 (order: 6, 262144 bytes, linear)
[    0.051977] Mountpoint-cache hash table entries: 32768 (order: 6, 262144 bytes, linear)
[    0.052150] x86/cpu: User Mode Instruction Prevention (UMIP) activated
[    0.052167] Last level iTLB entries: 4KB 1024, 2MB 1024, 4MB 512
[    0.052168] Last level dTLB entries: 4KB 2048, 2MB 2048, 4MB 1024, 1GB 0
[    0.052170] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
[    0.052170] Spectre V2 : Mitigation: Full AMD retpoline
[    0.052171] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
[    0.052172] Spectre V2 : mitigation: Enabling conditional Indirect Branch Prediction Barrier
[    0.052172] Spectre V2 : User space: Mitigation: STIBP via seccomp and prctl
[    0.052173] Speculative Store Bypass: Mitigation: Speculative Store Bypass disabled via prctl and seccomp
[    0.052292] Freeing SMP alternatives memory: 52K
[    0.052344] smpboot: CPU0: AMD Ryzen 7 3800X 8-Core Processor (family: 0x17, model: 0x71, stepping: 0x0)
[    0.052403] Performance Events: PMU not available due to virtualization, using software events only.
[    0.052423] rcu: Hierarchical SRCU implementation.
[    0.052753] smp: Bringing up secondary CPUs ...
[    0.052800] x86: Booting SMP configuration:
[    0.052801] .... node  #0, CPUs:        #1  #2  #3  #4  #5  #6  #7  #8  #9 #10 #11 #12 #13 #14 #15
[    0.053300] smp: Brought up 1 node, 16 CPUs
[    0.053300] smpboot: Max logical packages: 1
[    0.053300] smpboot: Total of 16 processors activated (124799.90 BogoMIPS)
[    0.073395] node 0 deferred pages initialised in 10ms
[    0.075402] devtmpfs: initialized
[    0.075402] x86/mm: Memory block size: 128MB
[    0.075402] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.075402] futex hash table entries: 4096 (order: 6, 262144 bytes, linear)
[    0.075402] NET: Registered protocol family 16
[    0.075402] thermal_sys: Registered thermal governor 'step_wise'
[    0.075402] cpuidle: using governor menu
[    0.075402] ACPI: bus type PCI registered
[    0.075402] PCI: Fatal: No config space access function found
[    0.075402] HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages
[    0.075402] HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages
[    0.082164] raid6: skip pq benchmark and using algorithm avx2x4
[    0.082164] raid6: using avx2x2 recovery algorithm
[    0.082164] ACPI: Added _OSI(Module Device)
[    0.082164] ACPI: Added _OSI(Processor Device)
[    0.082164] ACPI: Added _OSI(3.0 _SCP Extensions)
[    0.082164] ACPI: Added _OSI(Processor Aggregator Device)
[    0.082164] ACPI: Added _OSI(Linux-Dell-Video)
[    0.082164] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)
[    0.082164] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)
[    0.085313] ACPI: 1 ACPI AML tables successfully acquired and loaded
[    0.086035] ACPI: Interpreter enabled
[    0.086038] ACPI: (supports S0 S5)
[    0.086039] ACPI: Using IOAPIC for interrupt routing
[    0.086046] PCI: Using host bridge windows from ACPI; if necessary, use ""pci=nocrs"" and report a bug
[    0.086138] ACPI: Enabled 1 GPEs in block 00 to 0F
[    0.086794] iommu: Default domain type: Translated
[    0.086851] SCSI subsystem initialized
[    0.086881] hv_vmbus: Vmbus version:5.2
[    0.086881] PCI: Using ACPI for IRQ routing
[    0.086881] PCI: System does not support PCI
[    0.086881] hv_vmbus: Unknown GUID: c376c1c3-d276-48d2-90a9-c04748072c60
[    0.086881] hv_vmbus: Unknown GUID: 6e382d18-3336-4f4b-acc4-2b7703d4df4a
[    0.086881] clocksource: Switched to clocksource tsc-early
[    0.086881] hv_vmbus: Unknown GUID: dde9cbc0-5060-4436-9448-ea1254a5d177
[    0.170448] VFS: Disk quotas dquot_6.6.0
[    0.170458] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
[    0.170473] FS-Cache: Loaded
[    0.170496] pnp: PnP ACPI init
[    0.170537] pnp 00:00: Plug and Play ACPI device, IDs PNP0b00 (active)
[    0.170571] pnp: PnP ACPI: found 1 devices
[    0.174903] NET: Registered protocol family 2
[    0.175138] tcp_listen_portaddr_hash hash table entries: 8192 (order: 5, 131072 bytes, linear)
[    0.175316] TCP established hash table entries: 131072 (order: 8, 1048576 bytes, linear)
[    0.175416] TCP bind hash table entries: 65536 (order: 8, 1048576 bytes, linear)
[    0.175625] TCP: Hash tables configured (established 131072 bind 65536)
[    0.175649] UDP hash table entries: 8192 (order: 6, 262144 bytes, linear)
[    0.175671] UDP-Lite hash table entries: 8192 (order: 6, 262144 bytes, linear)
[    0.175712] NET: Registered protocol family 1
[    0.176005] RPC: Registered named UNIX socket transport module.
[    0.176006] RPC: Registered udp transport module.
[    0.176007] RPC: Registered tcp transport module.
[    0.176007] RPC: Registered tcp NFSv4.1 backchannel transport module.
[    0.176009] PCI: CLS 0 bytes, default 64
[    0.176049] Trying to unpack rootfs image as initramfs...
[    0.176181] Freeing initrd memory: 60K
[    0.176183] PCI-DMA: Using software bounce buffering for IO (SWIOTLB)
[    0.176185] software IO TLB: mapped [mem 0x00000000f4000000-0x00000000f8000000] (64MB)
[    0.177614] kvm: no hardware support
[    0.178295] kvm: Nested Virtualization enabled
[    0.178301] SVM: kvm: Nested Paging enabled
[    0.178301] SVM: Virtual VMLOAD VMSAVE supported
[    0.181019] Initialise system trusted keyrings
[    0.181118] workingset: timestamp_bits=46 max_order=22 bucket_order=0
[    0.181643] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    0.182012] NFS: Registering the id_resolver key type
[    0.182019] Key type id_resolver registered
[    0.182019] Key type id_legacy registered
[    0.182021] Installing knfsd (copyright (C) 1996 okir@monad.swb.de).
[    0.182442] Key type cifs.idmap registered
[    0.182496] fuse: init (API version 7.32)
[    0.182618] SGI XFS with ACLs, security attributes, realtime, scrub, repair, quota, no debug enabled
[    0.182874] 9p: Installing v9fs 9p2000 file system support
[    0.182880] FS-Cache: Netfs '9p' registered for caching
[    0.182908] FS-Cache: Netfs 'ceph' registered for caching
[    0.182910] ceph: loaded (mds proto 32)
[    0.185420] NET: Registered protocol family 38
[    0.185422] xor: automatically using best checksumming function   avx
[    0.185423] Key type asymmetric registered
[    0.185424] Asymmetric key parser 'x509' registered
[    0.185429] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250)
[    0.186121] hv_vmbus: registering driver hv_pci
[    0.186439] hv_pci b85a1f33-3b6d-4a2b-982d-0ce62be71656: PCI VMBus probing: Using version 0x10003
[    0.187115] hv_pci b85a1f33-3b6d-4a2b-982d-0ce62be71656: PCI host bridge to bus 3b6d:00
[    0.187471] pci 3b6d:00:00.0: [1414:008e] type 00 class 0x030200
[    0.191995] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled
[    0.192317] Non-volatile memory driver v1.3
[    0.194890] brd: module loaded
[    0.195604] loop: module loaded
[    0.195630] hv_vmbus: registering driver hv_storvsc
[    0.195949] wireguard: WireGuard 1.0.0 loaded. See www.wireguard.com for information.
[    0.195950] wireguard: Copyright (C) 2015-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.
[    0.195962] tun: Universal TUN/TAP device driver, 1.6
[    0.196041] PPP generic driver version 2.4.2
[    0.196142] PPP BSD Compression module registered
[    0.196143] PPP Deflate Compression module registered
[    0.196144] PPP MPPE Compression module registered
[    0.196145] NET: Registered protocol family 24
[    0.196149] hv_vmbus: registering driver hv_netvsc
[    0.196242] VFIO - User Level meta-driver version: 0.3
[    0.196361] hv_vmbus: registering driver hyperv_keyboard
[    0.196496] rtc_cmos 00:00: RTC can wake from S4
[    0.196809] scsi host0: storvsc_host_t
[    0.197753] rtc_cmos 00:00: registered as rtc0
[    0.198038] rtc_cmos 00:00: setting system clock to 2021-10-03T15:03:26 UTC (1633273406)
[    0.198046] rtc_cmos 00:00: alarms up to one month, 114 bytes nvram
[    0.198221] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com
[    0.198335] device-mapper: raid: Loading target version 1.15.1
[    0.198404] hv_utils: Registering HyperV Utility Driver
[    0.198405] hv_vmbus: registering driver hv_utils
[    0.198429] hv_vmbus: registering driver hv_balloon
[    0.198437] hv_vmbus: registering driver dxgkrnl
[    0.198452] (NULL device *): dxgk: dxg_drv_init  Version: 2103
[    0.198453] hv_utils: cannot register PTP clock: 0
[    0.198736] hv_balloon: Using Dynamic Memory protocol version 2.0
[    0.198827] hv_utils: TimeSync IC version 4.0
[    0.199020] drop_monitor: Initializing network drop monitor service
[    0.199043] Mirror/redirect action on
[    0.199390] Free page reporting enabled
[    0.199392] hv_balloon: Cold memory discard hint enabled
[    0.199630] (NULL device *): dxgk: mmio allocated 9ffe00000  200000000 9ffe00000 bffdfffff
[    0.199802] IPVS: Registered protocols (TCP, UDP)
[    0.199813] IPVS: Connection hash table configured (size=4096, memory=64Kbytes)
[    0.199835] IPVS: ipvs loaded.
[    0.199836] IPVS: [rr] scheduler registered.
[    0.199836] IPVS: [wrr] scheduler registered.
[    0.199836] IPVS: [sh] scheduler registered.
[    0.199864] ipip: IPv4 and MPLS over IPv4 tunneling driver
[    0.201991] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully
[    0.202382] Initializing XFRM netlink socket
[    0.202426] NET: Registered protocol family 10
[    0.202648] Segment Routing with IPv6
[    0.203692] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver
[    0.203777] NET: Registered protocol family 17
[    0.203790] Bridge firewalling registered
[    0.203796] 8021q: 802.1Q VLAN Support v1.8
[    0.203808] sctp: Hash tables configured (bind 256/256)
[    0.203842] 9pnet: Installing 9P2000 support
[    0.203855] Key type dns_resolver registered
[    0.203863] Key type ceph registered
[    0.203976] libceph: loaded (mon/osd proto 15/24)
[    0.204044] NET: Registered protocol family 40
[    0.204045] hv_vmbus: registering driver hv_sock
[    0.204071] IPI shorthand broadcast: enabled
[    0.204077] sched_clock: Marking stable (203581151, 453300)->(215942200, -11907749)
[    0.204331] registered taskstats version 1
[    0.204338] Loading compiled-in X.509 certificates
[    0.204648] Btrfs loaded, crc32c=crc32c-generic
[    0.206255] Freeing unused kernel image (initmem) memory: 1444K
[    0.271961] Write protecting the kernel read-only data: 22528k
[    0.272551] Freeing unused kernel image (text/rodata gap) memory: 2028K
[    0.273043] Freeing unused kernel image (rodata/data gap) memory: 632K
[    0.273048] Run /init as init process
[    0.273048]   with arguments:
[    0.273048]     /init
[    0.273049]   with environment:
[    0.273049]     HOME=/
[    0.273049]     TERM=linux
[    0.829032] scsi 0:0:0:0: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[    0.829421] sd 0:0:0:0: Attached scsi generic sg0 type 0
[    0.830236] sd 0:0:0:0: [sda] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[    0.830238] sd 0:0:0:0: [sda] 4096-byte physical blocks
[    0.830362] sd 0:0:0:0: [sda] Write Protect is off
[    0.830364] sd 0:0:0:0: [sda] Mode Sense: 0f 00 00 00
[    0.830557] sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    0.874243] hv_pci bb4321df-980a-4d21-afdb-589c18527bf9: PCI VMBus probing: Using version 0x10003
[    0.915773] hv_pci bb4321df-980a-4d21-afdb-589c18527bf9: PCI host bridge to bus 980a:00
[    0.915775] pci_bus 980a:00: root bus resource [mem 0xbffe00000-0xbffe02fff window]
[    0.916751] pci 980a:00:00.0: [1af4:1049] type 00 class 0x010000
[    0.917716] pci 980a:00:00.0: reg 0x10: [mem 0xbffe00000-0xbffe00fff 64bit]
[    0.918396] pci 980a:00:00.0: reg 0x18: [mem 0xbffe01000-0xbffe01fff 64bit]
[    0.919017] pci 980a:00:00.0: reg 0x20: [mem 0xbffe02000-0xbffe02fff 64bit]
[    0.922797] pci 980a:00:00.0: BAR 0: assigned [mem 0xbffe00000-0xbffe00fff 64bit]
[    0.923220] pci 980a:00:00.0: BAR 2: assigned [mem 0xbffe01000-0xbffe01fff 64bit]
[    0.923644] pci 980a:00:00.0: BAR 4: assigned [mem 0xbffe02000-0xbffe02fff 64bit]
[    1.116874] EXT4-fs (sda): mounted filesystem with ordered data mode. Opts: (null)
[    1.202006] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
[    1.202180] sd 0:0:0:0: [sda] Attached SCSI disk
[    1.251980] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x706eb0792cc, max_idle_ns: 881591209130 ns
[    1.252943] clocksource: Switched to clocksource tsc
[    1.881960] Adding 4194304k swap on /swap/file.  Priority:-2 extents:3 across:4210688k
[    3.152119] scsi 0:0:0:1: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[    3.152455] sd 0:0:0:1: Attached scsi generic sg1 type 0
[    3.152998] sd 0:0:0:1: [sdb] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[    3.152999] sd 0:0:0:1: [sdb] 4096-byte physical blocks
[    3.153082] sd 0:0:0:1: [sdb] Write Protect is off
[    3.153083] sd 0:0:0:1: [sdb] Mode Sense: 0f 00 00 00
[    3.153213] sd 0:0:0:1: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    3.154369] sd 0:0:0:1: [sdb] Attached SCSI disk
[    3.160357] EXT4-fs (sdb): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[    3.215983] FS-Cache: Duplicate cookie detected
[    3.215986] FS-Cache: O-cookie c=00000000aa466783 [p=000000006f69fc41 fl=222 nc=0 na=1]
[    3.215987] FS-Cache: O-cookie d=0000000077b88f2e n=00000000cab53c7d
[    3.215987] FS-Cache: O-key=[10] '34323934393337363132'
[    3.215991] FS-Cache: N-cookie c=0000000061e3e253 [p=000000006f69fc41 fl=2 nc=0 na=1]
[    3.215991] FS-Cache: N-cookie d=0000000077b88f2e n=00000000485d5ccb
[    3.215992] FS-Cache: N-key=[10] '34323934393337363132'
[    3.285697] hv_pci d5ce7240-e76a-439c-ad60-bb77c783e7c5: PCI VMBus probing: Using version 0x10003
[    3.286638] 9pnet_virtio: no channels available for device drvfs
[    3.286641] WARNING: mount: waiting for virtio device...
[    3.325716] hv_pci d5ce7240-e76a-439c-ad60-bb77c783e7c5: PCI host bridge to bus e76a:00
[    3.325718] pci_bus e76a:00: root bus resource [mem 0xbffe04000-0xbffe06fff window]
[    3.326672] pci e76a:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.327614] pci e76a:00:00.0: reg 0x10: [mem 0xbffe04000-0xbffe04fff 64bit]
[    3.328222] pci e76a:00:00.0: reg 0x18: [mem 0xbffe05000-0xbffe05fff 64bit]
[    3.328821] pci e76a:00:00.0: reg 0x20: [mem 0xbffe06000-0xbffe06fff 64bit]
[    3.332517] pci e76a:00:00.0: BAR 0: assigned [mem 0xbffe04000-0xbffe04fff 64bit]
[    3.333024] pci e76a:00:00.0: BAR 2: assigned [mem 0xbffe05000-0xbffe05fff 64bit]
[    3.333449] pci e76a:00:00.0: BAR 4: assigned [mem 0xbffe06000-0xbffe06fff 64bit]
[    3.390415] hv_pci 3f8e3335-82c2-499f-8995-e1c33b9178df: PCI VMBus probing: Using version 0x10003
[    3.391719] 9pnet_virtio: no channels available for device drvfs
[    3.391721] WARNING: mount: waiting for virtio device...
[    3.430257] hv_pci 3f8e3335-82c2-499f-8995-e1c33b9178df: PCI host bridge to bus 82c2:00
[    3.430259] pci_bus 82c2:00: root bus resource [mem 0xbffe08000-0xbffe0afff window]
[    3.431241] pci 82c2:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.432187] pci 82c2:00:00.0: reg 0x10: [mem 0xbffe08000-0xbffe08fff 64bit]
[    3.432796] pci 82c2:00:00.0: reg 0x18: [mem 0xbffe09000-0xbffe09fff 64bit]
[    3.433396] pci 82c2:00:00.0: reg 0x20: [mem 0xbffe0a000-0xbffe0afff 64bit]
[    3.437087] pci 82c2:00:00.0: BAR 0: assigned [mem 0xbffe08000-0xbffe08fff 64bit]
[    3.437505] pci 82c2:00:00.0: BAR 2: assigned [mem 0xbffe09000-0xbffe09fff 64bit]
[    3.437940] pci 82c2:00:00.0: BAR 4: assigned [mem 0xbffe0a000-0xbffe0afff 64bit]
[    3.495623] hv_pci 1b1a11d5-ded9-4bdc-b728-16a6ce447102: PCI VMBus probing: Using version 0x10003
[    3.536074] hv_pci 1b1a11d5-ded9-4bdc-b728-16a6ce447102: PCI host bridge to bus ded9:00
[    3.536076] pci_bus ded9:00: root bus resource [mem 0xbffe0c000-0xbffe0efff window]
[    3.537089] pci ded9:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.537996] pci ded9:00:00.0: reg 0x10: [mem 0xbffe0c000-0xbffe0cfff 64bit]
[    3.538600] pci ded9:00:00.0: reg 0x18: [mem 0xbffe0d000-0xbffe0dfff 64bit]
[    3.539322] pci ded9:00:00.0: reg 0x20: [mem 0xbffe0e000-0xbffe0efff 64bit]
[    3.543300] pci ded9:00:00.0: BAR 0: assigned [mem 0xbffe0c000-0xbffe0cfff 64bit]
[    3.543740] pci ded9:00:00.0: BAR 2: assigned [mem 0xbffe0d000-0xbffe0dfff 64bit]
[    3.544177] pci ded9:00:00.0: BAR 4: assigned [mem 0xbffe0e000-0xbffe0efff 64bit]
[   49.061594] hv_balloon: Max. dynamic memory size: 16344 MB
[   71.292198] TCP: eth0: Driver has suspect GRO implementation, TCP performance may be compromised.
[ 8678.849099] docker0: port 1(veth07ad0a7) entered blocking state
[ 8678.849101] docker0: port 1(veth07ad0a7) entered disabled state
[ 8678.849121] device veth07ad0a7 entered promiscuous mode
[ 8678.849150] docker0: port 1(veth07ad0a7) entered blocking state
[ 8678.849151] docker0: port 1(veth07ad0a7) entered forwarding state
[ 8678.849472] docker0: port 1(veth07ad0a7) entered disabled state
[ 8678.990265] cgroup: runc (5415) created nested cgroup for controller ""memory"" which has incomplete hierarchy support. Nested cgroups may change behavior in the future.
[ 8678.990266] cgroup: ""memory"" requires setting use_hierarchy to 1 on the root
[ 8678.990549] cgroup: cgroup: disabling cgroup2 socket matching due to net_prio or net_cls activation
[ 8679.419693] eth0: renamed from veth984197c
[ 8679.459677] IPv6: ADDRCONF(NETDEV_CHANGE): veth07ad0a7: link becomes ready
[ 8679.459697] docker0: port 1(veth07ad0a7) entered blocking state
[ 8679.459697] docker0: port 1(veth07ad0a7) entered forwarding state
[ 8679.459722] IPv6: ADDRCONF(NETDEV_CHANGE): docker0: link becomes ready
[ 8680.288430] veth984197c: renamed from eth0
[ 8680.349650] docker0: port 1(veth07ad0a7) entered disabled state
[ 8680.445249] docker0: port 1(veth07ad0a7) entered disabled state
[ 8680.445930] device veth07ad0a7 left promiscuous mode
[ 8680.445948] docker0: port 1(veth07ad0a7) entered disabled state
[ 8871.582213] docker0: port 1(veth2124c65) entered blocking state
[ 8871.582215] docker0: port 1(veth2124c65) entered disabled state
[ 8871.582233] device veth2124c65 entered promiscuous mode
[ 8872.129587] eth0: renamed from veth99f60f2
[ 8872.189745] IPv6: ADDRCONF(NETDEV_CHANGE): veth2124c65: link becomes ready
[ 8872.189767] docker0: port 1(veth2124c65) entered blocking state
[ 8872.189768] docker0: port 1(veth2124c65) entered forwarding state
[ 9039.653247] process 'local/cuda-10.2/bin/ptxas' started with executable stack
[ 9387.169252] docker0: port 2(veth0ab1b19) entered blocking state
[ 9387.169254] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.169274] device veth0ab1b19 entered promiscuous mode
[ 9387.169302] docker0: port 2(veth0ab1b19) entered blocking state
[ 9387.169302] docker0: port 2(veth0ab1b19) entered forwarding state
[ 9387.169669] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.657707] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.657920] device veth0ab1b19 left promiscuous mode
[ 9387.657937] docker0: port 2(veth0ab1b19) entered disabled state
[ 9417.075476] nf_conntrack: default automatic helper assignment has been turned off for security reasons and CT-based  firewall rule not found. Use the iptables CT target to attach helpers instead.
[40931.406310] docker0: port 2(veth8968728) entered blocking state
[40931.406311] docker0: port 2(veth8968728) entered disabled state
[40931.406330] device veth8968728 entered promiscuous mode
[40931.780035] eth0: renamed from veth8b0ae09
[40931.840207] IPv6: ADDRCONF(NETDEV_CHANGE): veth8968728: link becomes ready
[40931.840231] docker0: port 2(veth8968728) entered blocking state
[40931.840232] docker0: port 2(veth8968728) entered forwarding state
[41888.847459] docker0: port 1(veth2124c65) entered disabled state
[41888.847547] veth99f60f2: renamed from eth0
[41888.994901] docker0: port 1(veth2124c65) entered disabled state
[41888.995012] device veth2124c65 left promiscuous mode
[41888.995014] docker0: port 1(veth2124c65) entered disabled state
[41899.075265] docker0: port 2(veth8968728) entered disabled state
[41899.075320] veth8b0ae09: renamed from eth0
[41899.195126] docker0: port 2(veth8968728) entered disabled state
[41899.195201] device veth8968728 left promiscuous mode
[41899.195202] docker0: port 2(veth8968728) entered disabled state
[44983.095711] docker0: port 1(veth579ec1c) entered blocking state
[44983.095713] docker0: port 1(veth579ec1c) entered disabled state
[44983.095767] device veth579ec1c entered promiscuous mode
[44983.095802] docker0: port 1(veth579ec1c) entered blocking state
[44983.095803] docker0: port 1(veth579ec1c) entered forwarding state
[44983.096169] docker0: port 1(veth579ec1c) entered disabled state
[44983.558932] eth0: renamed from vethe31675b
[44983.609007] IPv6: ADDRCONF(NETDEV_CHANGE): veth579ec1c: link becomes ready
[44983.609031] docker0: port 1(veth579ec1c) entered blocking state
[44983.609032] docker0: port 1(veth579ec1c) entered forwarding state
[48140.938717] docker0: port 2(vethe31a522) entered blocking state
[48140.938720] docker0: port 2(vethe31a522) entered disabled state
[48140.938783] device vethe31a522 entered promiscuous mode
[48140.938815] docker0: port 2(vethe31a522) entered blocking state
[48140.938815] docker0: port 2(vethe31a522) entered forwarding state
[48140.939141] docker0: port 2(vethe31a522) entered disabled state
[48140.953626] docker0: port 2(vethe31a522) entered disabled state
[48140.953890] device vethe31a522 left promiscuous mode
[48140.953910] docker0: port 2(vethe31a522) entered disabled state
[48163.430815] docker0: port 2(veth0cd2f65) entered blocking state
[48163.430817] docker0: port 2(veth0cd2f65) entered disabled state
[48163.430836] device veth0cd2f65 entered promiscuous mode
[48164.076307] docker0: port 2(veth0cd2f65) entered disabled state
[48164.076630] device veth0cd2f65 left promiscuous mode
[48164.076652] docker0: port 2(veth0cd2f65) entered disabled state
[48359.265419] docker0: port 2(veth87ce69e) entered blocking state
[48359.265420] docker0: port 2(veth87ce69e) entered disabled state
[48359.265439] device veth87ce69e entered promiscuous mode
[48359.265464] docker0: port 2(veth87ce69e) entered blocking state
[48359.265465] docker0: port 2(veth87ce69e) entered forwarding state
[48359.265939] docker0: port 2(veth87ce69e) entered disabled state
[48359.975849] docker0: port 2(veth87ce69e) entered disabled state
[48359.975930] device veth87ce69e left promiscuous mode
[48359.975932] docker0: port 2(veth87ce69e) entered disabled state
[63661.051609] docker0: port 2(veth2a489c7) entered blocking state
[63661.051611] docker0: port 2(veth2a489c7) entered disabled state
[63661.051692] device veth2a489c7 entered promiscuous mode
[63661.051745] docker0: port 2(veth2a489c7) entered blocking state
[63661.051747] docker0: port 2(veth2a489c7) entered forwarding state
[63661.052438] docker0: port 2(veth2a489c7) entered disabled state
[63661.065926] docker0: port 2(veth2a489c7) entered disabled state
[63661.065991] device veth2a489c7 left promiscuous mode
[63661.065992] docker0: port 2(veth2a489c7) entered disabled state
[63687.006899] docker0: port 2(veth2cbdb00) entered blocking state
[63687.006901] docker0: port 2(veth2cbdb00) entered disabled state
[63687.006921] device veth2cbdb00 entered promiscuous mode
[63687.533240] eth0: renamed from veth869fda5
[63687.613534] IPv6: ADDRCONF(NETDEV_CHANGE): veth2cbdb00: link becomes ready
[63687.613555] docker0: port 2(veth2cbdb00) entered blocking state
[63687.613556] docker0: port 2(veth2cbdb00) entered forwarding state
[63741.561335] docker0: port 3(veth4e13cbd) entered blocking state
[63741.561337] docker0: port 3(veth4e13cbd) entered disabled state
[63741.561359] device veth4e13cbd entered promiscuous mode
[63741.561385] docker0: port 3(veth4e13cbd) entered blocking state
[63741.561386] docker0: port 3(veth4e13cbd) entered forwarding state
[63741.561689] docker0: port 3(veth4e13cbd) entered disabled state
[63742.201594] docker0: port 3(veth4e13cbd) entered disabled state
[63742.201696] device veth4e13cbd left promiscuous mode
[63742.201697] docker0: port 3(veth4e13cbd) entered disabled state
[63945.395071] docker0: port 3(veth5172a71) entered blocking state
[63945.395073] docker0: port 3(veth5172a71) entered disabled state
[63945.395096] device veth5172a71 entered promiscuous mode
[63945.395127] docker0: port 3(veth5172a71) entered blocking state
[63945.395127] docker0: port 3(veth5172a71) entered forwarding state
[63945.395248] docker0: port 3(veth5172a71) entered disabled state
[63946.001462] docker0: port 3(veth5172a71) entered disabled state
[63946.001557] device veth5172a71 left promiscuous mode
[63946.001558] docker0: port 3(veth5172a71) entered disabled state
[63986.856749] docker0: port 2(veth2cbdb00) entered disabled state
[63986.856794] veth869fda5: renamed from eth0
[63986.998482] docker0: port 2(veth2cbdb00) entered disabled state
[63986.999130] device veth2cbdb00 left promiscuous mode
[63986.999133] docker0: port 2(veth2cbdb00) entered disabled state
[63987.085545] vethe31675b: renamed from eth0
[63987.213378] docker0: port 1(veth579ec1c) entered disabled state
[63987.218358] docker0: port 1(veth579ec1c) entered disabled state
[63987.218861] device veth579ec1c left promiscuous mode
[63987.218862] docker0: port 1(veth579ec1c) entered disabled state
[64786.418297] docker0: port 1(vethead51d5) entered blocking state
[64786.418299] docker0: port 1(vethead51d5) entered disabled state
[64786.418318] device vethead51d5 entered promiscuous mode
[64786.872856] eth0: renamed from veth99b057f
[64786.932949] IPv6: ADDRCONF(NETDEV_CHANGE): vethead51d5: link becomes ready
[64786.932966] docker0: port 1(vethead51d5) entered blocking state
[64786.932967] docker0: port 1(vethead51d5) entered forwarding state
[64787.786553] docker0: port 1(vethead51d5) entered disabled state
[64787.786605] veth99b057f: renamed from eth0
[64787.948146] docker0: port 1(vethead51d5) entered disabled state
[64787.948881] device vethead51d5 left promiscuous mode
[64787.948915] docker0: port 1(vethead51d5) entered disabled state
[64807.747511] docker0: port 1(vethb24ff9b) entered blocking state
[64807.747512] docker0: port 1(vethb24ff9b) entered disabled state
[64807.747531] device vethb24ff9b entered promiscuous mode
[64807.747561] docker0: port 1(vethb24ff9b) entered blocking state
[64807.747562] docker0: port 1(vethb24ff9b) entered forwarding state
[64807.747703] docker0: port 1(vethb24ff9b) entered disabled state
[64808.132878] eth0: renamed from vetha7cd44c
[64808.193099] IPv6: ADDRCONF(NETDEV_CHANGE): vethb24ff9b: link becomes ready
[64808.193123] docker0: port 1(vethb24ff9b) entered blocking state
[64808.193124] docker0: port 1(vethb24ff9b) entered forwarding state
[64809.023917] vetha7cd44c: renamed from eth0
[64809.183134] docker0: port 1(vethb24ff9b) entered disabled state
[64809.188226] docker0: port 1(vethb24ff9b) entered disabled state
[64809.188767] device vethb24ff9b left promiscuous mode
[64809.188769] docker0: port 1(vethb24ff9b) entered disabled state
[65194.352051] docker0: port 1(veth9b9311c) entered blocking state
[65194.352053] docker0: port 1(veth9b9311c) entered disabled state
[65194.352072] device veth9b9311c entered promiscuous mode
[65194.352101] docker0: port 1(veth9b9311c) entered blocking state
[65194.352102] docker0: port 1(veth9b9311c) entered forwarding state
[65194.352424] docker0: port 1(veth9b9311c) entered disabled state
[65194.792790] eth0: renamed from veth5d3475b
[65194.832884] IPv6: ADDRCONF(NETDEV_CHANGE): veth9b9311c: link becomes ready
[65194.832906] docker0: port 1(veth9b9311c) entered blocking state
[65194.832907] docker0: port 1(veth9b9311c) entered forwarding state
[65195.722684] veth5d3475b: renamed from eth0
[65195.792916] docker0: port 1(veth9b9311c) entered disabled state
[65195.878049] docker0: port 1(veth9b9311c) entered disabled state
[65195.878715] device veth9b9311c left promiscuous mode
[65195.878732] docker0: port 1(veth9b9311c) entered disabled state
[66182.663567] scsi 0:0:0:2: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[66182.664300] sd 0:0:0:2: Attached scsi generic sg2 type 0
[66182.664893] sd 0:0:0:2: [sdc] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[66182.664894] sd 0:0:0:2: [sdc] 4096-byte physical blocks
[66182.664973] sd 0:0:0:2: [sdc] Write Protect is off
[66182.664975] sd 0:0:0:2: [sdc] Mode Sense: 0f 00 00 00
[66182.665154] sd 0:0:0:2: [sdc] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[66182.666668] sd 0:0:0:2: [sdc] Attached SCSI disk
[66182.683579] EXT4-fs (sdc): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[66187.399545] EXT4-fs (sdc): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[66187.410623] FS-Cache: Duplicate cookie detected
[66187.410624] FS-Cache: O-cookie c=000000004e228525 [p=000000006f69fc41 fl=222 nc=0 na=1]
[66187.410625] FS-Cache: O-cookie d=0000000077b88f2e n=0000000013e7c87d
[66187.410625] FS-Cache: O-key=[10] '34333031353536303333'
[66187.410628] FS-Cache: N-cookie c=000000005b00e07c [p=000000006f69fc41 fl=2 nc=0 na=1]
[66187.410629] FS-Cache: N-cookie d=0000000077b88f2e n=00000000f3cfd1ce
[66187.410629] FS-Cache: N-key=[10] '34333031353536303333'
[66187.676655] hv_pci c689411f-e482-4a4b-b5ec-379303b0c4a9: PCI VMBus probing: Using version 0x10003
[66187.677922] 9pnet_virtio: no channels available for device drvfs
[66187.677925] WARNING: mount: waiting for virtio device...
[66187.718390] hv_pci c689411f-e482-4a4b-b5ec-379303b0c4a9: PCI host bridge to bus e482:00
[66187.718393] pci_bus e482:00: root bus resource [mem 0xbffe10000-0xbffe12fff window]
[66187.719402] pci e482:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.720467] pci e482:00:00.0: reg 0x10: [mem 0xbffe10000-0xbffe10fff 64bit]
[66187.721103] pci e482:00:00.0: reg 0x18: [mem 0xbffe11000-0xbffe11fff 64bit]
[66187.721739] pci e482:00:00.0: reg 0x20: [mem 0xbffe12000-0xbffe12fff 64bit]
[66187.725644] pci e482:00:00.0: BAR 0: assigned [mem 0xbffe10000-0xbffe10fff 64bit]
[66187.726097] pci e482:00:00.0: BAR 2: assigned [mem 0xbffe11000-0xbffe11fff 64bit]
[66187.726550] pci e482:00:00.0: BAR 4: assigned [mem 0xbffe12000-0xbffe12fff 64bit]
[66187.782347] hv_pci 5de0a50d-7985-4767-96bc-4a4a80b94674: PCI VMBus probing: Using version 0x10003
[66187.783556] 9pnet_virtio: no channels available for device drvfs
[66187.783561] WARNING: mount: waiting for virtio device...
[66187.823210] hv_pci 5de0a50d-7985-4767-96bc-4a4a80b94674: PCI host bridge to bus 7985:00
[66187.823212] pci_bus 7985:00: root bus resource [mem 0xbffe14000-0xbffe16fff window]
[66187.824217] pci 7985:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.825200] pci 7985:00:00.0: reg 0x10: [mem 0xbffe14000-0xbffe14fff 64bit]
[66187.825847] pci 7985:00:00.0: reg 0x18: [mem 0xbffe15000-0xbffe15fff 64bit]
[66187.826493] pci 7985:00:00.0: reg 0x20: [mem 0xbffe16000-0xbffe16fff 64bit]
[66187.830371] pci 7985:00:00.0: BAR 0: assigned [mem 0xbffe14000-0xbffe14fff 64bit]
[66187.830823] pci 7985:00:00.0: BAR 2: assigned [mem 0xbffe15000-0xbffe15fff 64bit]
[66187.831276] pci 7985:00:00.0: BAR 4: assigned [mem 0xbffe16000-0xbffe16fff 64bit]
[66187.887658] hv_pci 28ccd863-7f1b-48fb-a06c-14f1032961b1: PCI VMBus probing: Using version 0x10003
[66187.929043] hv_pci 28ccd863-7f1b-48fb-a06c-14f1032961b1: PCI host bridge to bus 7f1b:00
[66187.929046] pci_bus 7f1b:00: root bus resource [mem 0xbffe18000-0xbffe1afff window]
[66187.930038] pci 7f1b:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.930989] pci 7f1b:00:00.0: reg 0x10: [mem 0xbffe18000-0xbffe18fff 64bit]
[66187.931624] pci 7f1b:00:00.0: reg 0x18: [mem 0xbffe19000-0xbffe19fff 64bit]
[66187.932284] pci 7f1b:00:00.0: reg 0x20: [mem 0xbffe1a000-0xbffe1afff 64bit]
[66187.936143] pci 7f1b:00:00.0: BAR 0: assigned [mem 0xbffe18000-0xbffe18fff 64bit]
[66187.936627] pci 7f1b:00:00.0: BAR 2: assigned [mem 0xbffe19000-0xbffe19fff 64bit]
[66187.937076] pci 7f1b:00:00.0: BAR 4: assigned [mem 0xbffe1a000-0xbffe1afff 64bit]
[66977.281402] docker0: port 1(veth0d37bc8) entered blocking state
[66977.281404] docker0: port 1(veth0d37bc8) entered disabled state
[66977.281423] device veth0d37bc8 entered promiscuous mode
[66977.281453] docker0: port 1(veth0d37bc8) entered blocking state
[66977.281453] docker0: port 1(veth0d37bc8) entered forwarding state
[66977.281748] docker0: port 1(veth0d37bc8) entered disabled state
[66978.181803] docker0: port 1(veth0d37bc8) entered disabled state
[66978.181906] device veth0d37bc8 left promiscuous mode
[66978.181907] docker0: port 1(veth0d37bc8) entered disabled state
[67557.114920] docker0: port 1(veth9c4371d) entered blocking state
[67557.114921] docker0: port 1(veth9c4371d) entered disabled state
[67557.114944] device veth9c4371d entered promiscuous mode
[67557.652243] eth0: renamed from veth99c3a3f
[67557.802389] IPv6: ADDRCONF(NETDEV_CHANGE): veth9c4371d: link becomes ready
[67557.802412] docker0: port 1(veth9c4371d) entered blocking state
[67557.802413] docker0: port 1(veth9c4371d) entered forwarding state
[67558.185775] veth99c3a3f: renamed from eth0
[67558.302350] docker0: port 1(veth9c4371d) entered disabled state
[67558.307904] docker0: port 1(veth9c4371d) entered disabled state
[67558.308442] device veth9c4371d left promiscuous mode
[67558.308444] docker0: port 1(veth9c4371d) entered disabled state
[67593.210939] docker0: port 1(veth228dbe2) entered blocking state
[67593.210940] docker0: port 1(veth228dbe2) entered disabled state
[67593.210960] device veth228dbe2 entered promiscuous mode
[67593.210992] docker0: port 1(veth228dbe2) entered blocking state
[67593.210993] docker0: port 1(veth228dbe2) entered forwarding state
[67593.211282] docker0: port 1(veth228dbe2) entered disabled state
[67593.722096] eth0: renamed from veth20ca901
[67593.782236] IPv6: ADDRCONF(NETDEV_CHANGE): veth228dbe2: link becomes ready
[67593.782257] docker0: port 1(veth228dbe2) entered blocking state
[67593.782258] docker0: port 1(veth228dbe2) entered forwarding state
[68424.882867] init: (195) ERROR: operator():211: shutdown failed 107
[68424.884817] init: (195) ERROR: operator():211: shutdown failed 107
[68424.886584] init: (195) ERROR: operator():211: shutdown failed 107
[68424.888302] init: (195) ERROR: operator():211: shutdown failed 107
[68424.890043] init: (195) ERROR: operator():211: shutdown failed 107
[68424.891745] init: (195) ERROR: operator():211: shutdown failed 107
[68424.893473] init: (195) ERROR: operator():211: shutdown failed 107
[68424.896066] init: (195) ERROR: operator():211: shutdown failed 107
[68424.898353] init: (195) ERROR: operator():211: shutdown failed 107
[68424.900144] init: (195) ERROR: operator():211: shutdown failed 107
[68599.829580] init: (195) ERROR: operator():211: shutdown failed 107
[68599.832116] init: (195) ERROR: operator():211: shutdown failed 107
[68599.834452] init: (195) ERROR: operator():211: shutdown failed 107
[68599.836492] init: (195) ERROR: operator():211: shutdown failed 107
[68599.838390] init: (195) ERROR: operator():211: shutdown failed 107
[68599.840152] init: (195) ERROR: operator():211: shutdown failed 107
[68599.841806] init: (195) ERROR: operator():211: shutdown failed 107
[68599.843637] init: (195) ERROR: operator():211: shutdown failed 107
[68599.845480] init: (195) ERROR: operator():211: shutdown failed 107
[68599.847897] init: (195) ERROR: operator():211: shutdown failed 107

#### Driver information from `nvidia-smi -a`
==============NVSMI LOG==============

Timestamp                                 : Mon Oct  4 21:42:55 2021
Driver Version                            : 510.06
CUDA Version                              : 11.6

Attached GPUs                             : 1
GPU 00000000:2D:00.0
    Product Name                          : NVIDIA GeForce RTX 2080 Ti
    Product Brand                         : GeForce
    Product Architecture                  : Turing
    Display Mode                          : Enabled
    Display Active                        : Enabled
    Persistence Mode                      : Enabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : WDDM
        Pending                           : WDDM
    Serial Number                         : N/A
    GPU UUID                              : GPU-4949b172-957c-5479-5dc3-12e0ea688389
    Minor Number                          : N/A
    VBIOS Version                         : 90.02.30.00.b7
    MultiGPU Board                        : No
    Board ID                              : 0x2d00
    GPU Part Number                       : N/A
    Module ID                             : 0
    Inforom Version
        Image Version                     : G001.0000.02.04
        OEM Object                        : 1.1
        ECC Object                        : N/A
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : N/A
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x2D
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x1E0410DE
        Bus Id                            : 00000000:2D:00.0
        Sub System Id                     : 0x12AE10DE
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 3
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 7000 KB/s
        Rx Throughput                     : 221000 KB/s
    Fan Speed                             : 0 %
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 11264 MiB
        Used                              : 2840 MiB
        Free                              : 8424 MiB
    BAR1 Memory Usage
        Total                             : 256 MiB
        Used                              : 2 MiB
        Free                              : 254 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : N/A
        Memory                            : N/A
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Errors
        Volatile
            SRAM Correctable              : N/A
            SRAM Uncorrectable            : N/A
            DRAM Correctable              : N/A
            DRAM Uncorrectable            : N/A
        Aggregate
            SRAM Correctable              : N/A
            SRAM Uncorrectable            : N/A
            DRAM Correctable              : N/A
            DRAM Uncorrectable            : N/A
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 47 C
        GPU Shutdown Temp                 : 94 C
        GPU Slowdown Temp                 : 91 C
        GPU Max Operating Temp            : 89 C
        GPU Target Temperature            : 84 C
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 20.30 W
        Power Limit                       : 250.00 W
        Default Power Limit               : 250.00 W
        Enforced Power Limit              : 250.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 280.00 W
    Clocks
        Graphics                          : 387 MHz
        SM                                : 387 MHz
        Memory                            : 403 MHz
        Video                             : 539 MHz
    Applications Clocks
        Graphics                          : N/A
        Memory                            : N/A
    Default Applications Clocks
        Graphics                          : N/A
        Memory                            : N/A
    Max Clocks
        Graphics                          : 2100 MHz
        SM                                : 2100 MHz
        Memory                            : 7000 MHz
        Video                             : 1950 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : N/A
    Processes                             : None

#### Docker version from `docker version`
Client: Docker Engine - Community
 Version:           20.10.8
 API version:       1.41
 Go version:        go1.16.6
 Git commit:        3967b7d
 Built:             Fri Jul 30 19:54:27 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.8
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.16.6
  Git commit:       75249d8
  Built:            Fri Jul 30 19:52:33 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.10
  GitCommit:        8848fdb7c4ae3815afcc990a8a99d663dda1b590
 runc:
  Version:          1.0.2
  GitCommit:        v1.0.2-0-g52b36a2
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0

#### NVIDIA packages version from `dpkg -l '*nvidia*'` _or_ `rpm -qa '*nvidia*'`
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend
|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)
||/ Name                               Version                    Architecture Description
+++-==================================-==========================-============-================================================>
un  libgldispatch0-nvidia              <none>                     <none>       (no description available)
un  libnvidia-compute                  <none>                     <none>       (no description available)
ii  libnvidia-compute-460-server:amd64 460.91.03-0ubuntu0.20.04.1 amd64        NVIDIA libcompute package
ii  libnvidia-container-tools          1.5.1-1                    amd64        NVIDIA container runtime library (command-line t>
ii  libnvidia-container1:amd64         1.5.1-1                    amd64        NVIDIA container runtime library
ii  libnvidia-ml-dev                   10.1.243-3                 amd64        NVIDIA Management Library (NVML) development fil>
un  libnvidia-ml.so.1                  <none>                     <none>       (no description available)
un  libnvidia-ml1                      <none>                     <none>       (no description available)
un  libnvidia-tesla-418-ml1            <none>                     <none>       (no description available)
un  libnvidia-tesla-440-ml1            <none>                     <none>       (no description available)
un  libnvidia-tesla-cuda1              <none>                     <none>       (no description available)
ii  nvidia-container-runtime           3.5.0-1                    amd64        NVIDIA container runtime
un  nvidia-container-runtime-hook      <none>                     <none>       (no description available)
ii  nvidia-container-toolkit           1.5.1-1                    amd64        NVIDIA container runtime hook
ii  nvidia-cuda-dev                    10.1.243-3                 amd64        NVIDIA CUDA development files
ii  nvidia-cuda-doc                    10.1.243-3                 all          NVIDIA CUDA and OpenCL documentation
ii  nvidia-cuda-gdb                    10.1.243-3                 amd64        NVIDIA CUDA Debugger (GDB)
ii  nvidia-cuda-toolkit                10.1.243-3                 amd64        NVIDIA CUDA development toolkit
un  nvidia-docker                      <none>                     <none>       (no description available)
ii  nvidia-docker2                     2.6.0-1                    all          nvidia-docker CLI wrapper
un  nvidia-driver                      <none>                     <none>       (no description available)
un  nvidia-legacy-304xx-vdpau-driver   <none>                     <none>       (no description available)
un  nvidia-legacy-340xx-vdpau-driver   <none>                     <none>       (no description available)
un  nvidia-libopencl1                  <none>                     <none>       (no description available)
un  nvidia-libopencl1-dev              <none>                     <none>       (no description available)
ii  nvidia-opencl-dev:amd64            10.1.243-3                 amd64        NVIDIA OpenCL development files
un  nvidia-opencl-icd                  <none>                     <none>       (no description available)
ii  nvidia-profiler                    10.1.243-3                 amd64        NVIDIA Profiler for CUDA and OpenCL
un  nvidia-tesla-418-driver            <none>                     <none>       (no description available)
un  nvidia-tesla-440-driver            <none>                     <none>       (no description available)
un  nvidia-vdpau-driver                <none>                     <none>       (no description available)
ii  nvidia-visual-profiler             10.1.243-3                 amd64        NVIDIA Visual Profiler for CUDA and OpenCL

#### NVIDIA container library version from `nvidia-container-cli -V`
version: 1.5.1
build date: 2021-09-20T14:30+00:00
build revision: 4afad130c4c253abd3b2db563ffe9331594bda41
build compiler: gcc-5 5.4.0 20160609
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections

#### NVIDIA container library logs
2021/10/04 21:48:07 Using bundle directory: /var/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/43c805d8ac1895dc62353aa47b2ac77b5a6eb2d7af3a1441658e55abc97fae27
2021/10/04 21:48:07 Using OCI specification file path: /var/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/43c805d8ac1895dc62353aa47b2ac77b5a6eb2d7af3a1441658e55abc97fae27/config.json
2021/10/04 21:48:07 Looking for runtime binary 'docker-runc'
2021/10/04 21:48:07 Runtime binary 'docker-runc' not found: exec: ""docker-runc"": executable file not found in $PATH
2021/10/04 21:48:07 Looking for runtime binary 'runc'
2021/10/04 21:48:07 Found runtime binary '/bin/runc'
2021/10/04 21:48:07 Running nvidia-container-runtime

2021/10/04 21:48:07 'create' command detected; modification required
2021/10/04 21:48:07 prestart hook path: /bin/nvidia-container-runtime-hook

2021/10/04 21:48:07 existing nvidia prestart hook in OCI spec file
2021/10/04 21:48:07 Forwarding command to runtimeSome users have also seen this issue as well. Sorry about this!Hi ngeneva,Thanks for the tips. I will give it a try!Hi, I have found a solution. The steps are as follows:DO NOT INSTALL functorch since you will be forced to uninstall the current pytorch and install 1.12
Go to source dir and install:Then it should work. You can update the image:docker ps -aCheck the image id of the one you just modified and run:docker commit d8cf130b5f37 modulus_2209Note that I haven’t been able to get pysdf working. If anyone manages to get it working, please let me know how.
Thanks.Powered by Discourse, best viewed with JavaScript enabled"
140,issues-with-parameterized-3d-fin-example,"In three fin_3d example, the fin are defined in a particular (x, y, z) directions.  However, after I switched the direction definition,
I found that the fin.repeat method doesn’t work anymore?
So should I define all the geometry in the same directions as the fin examples?Hi @cxi1If you want to rotate the fins of the heat sink, you’ll also likely need to adjust the repeat method as well which requires you to specify the number of copies in a given direction. Using simple scripts like in the geometry section of the user guide and var_to_polyvtk is a good way to rapidly debug geometry objects.Hi @ngeneva ,
I noticed an issue with the geometry module.  Previously I define the heat sink dims using units of mm (scale = 1000), and the below code works well with heat sink creation and also heat sink bottom surface sampling for heat source location.  However, after change geometry to SI units of meter (scale = 1),  the codes below doesn’t work anymore, it can’t sample the bottom surface and it gives me the error message :
""   File “test_geometry.py”, line 48, in 
sample= heat_sink.sample_boundary(nr_points=4000, criteria=Eq(z, heat_sink_base_origin1[2]))
File “/home/cexi1992/anaconda3/envs/modulus_22.09/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/geometry/geometry.py”, line 479, in sample_boundary
assert np.sum(curve_areas) > 0, “Geometry has no surface”
AssertionError: Geometry has no surface
""Code:from sympy import Symbol, Eq,  tanh, And
import numpy as np
from modulus.geometry.primitives_3d import Box, Channel, Plane,  Cylinder
from modulus.utils.io.vtk import var_to_polyvtkx, y, z = Symbol(“x”), Symbol(“y”), Symbol(“z”)scale = 1000
heat_sink_base_origin1 = np.array((-0.098, -0.065, 0.018))*scale
heat_sink_base_dim1 = np.array((0.076, 0.060, 0.005))*scale
fin_origin1 = heat_sink_base_origin1 #np.array((-0.098, -0.065, 0.0226))*scale  # base=4.6 mm
fin_dim = np.array((0.002, 0.06, 0.0174))*scale
total_fins = 10heat_sink_base = Box(
heat_sink_base_origin1,
(
heat_sink_base_origin1[0] + heat_sink_base_dim1[0],  # base of left heat sink
heat_sink_base_origin1[1] + heat_sink_base_dim1[1],
heat_sink_base_origin1[2] + heat_sink_base_dim1[2],
),
)fin = Box(
fin_origin1,
(
fin_origin1[0] + fin_dim[0],
fin_origin1[1] + fin_dim[1],
fin_origin1[2] + fin_dim[2],
),
)
gap = (heat_sink_base_dim1[0] - fin_dim[0]) / (total_fins - 1)  # gap between finsfin_original = fin
for i in range(total_fins - 1):
fin = fin.translate([gap, 0, 0])
fin_original = fin_original + finheat_sink = heat_sink_base + fin_originalsample= heat_sink.sample_boundary(nr_points=4000)
var_to_polyvtk(sample, “./heat_sink”)bottom= heat_sink.sample_boundary(nr_points=4000, criteria=Eq(z, heat_sink_base_origin1[2]))
var_to_polyvtk(bottom, “./heat_sink_bottom”)""
Do you know why it happens? Is this because that geometry module only accept floating point values up to a certain degree?
If this is the case,  what should I do now? Defining all the geometry in unit of “mm” ? But what am I supposed to do with the corresponding changes with the unit of fluid density, velocity, etc to make them consistent?Thank you again for your support,CeFile “test_geometry.py”, line 48, in
sample= heat_sink.sample_boundary(nr_points=4000, criteria=Eq(z, heat_sink_base_origin1[2]))
File “/home/cexi1992/anaconda3/envs/modulus_22.09/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/geometry/geometry.py”, line 479, in sample_boundary
assert np.sum(curve_areas) > 0, “Geometry has no surface”
AssertionError: Geometry has no surfaceThis error typically arises when you’re trying to sample geometry that  has some sort of criteria or form that has no volume / area (e.g. I have a box that’s has points [(0,0), (0,1), (1,0), (1,1)] and a criteria of x > 1.5). The geometry for this example was specifically build for this and I would treat it as pretty rigid. It’s likely there’s some hard coded values that are conflicting with the scale parameter somewhere.@ngeneva
I did some debugging yesterday, it seems there exist rounding errors associated with the coordinates definition.
If I set heat_sink_base_origin1 = (-0.098, -0.065, 0.018) to be  (-0.098, -0.065, 0.0182). The error message is gone.
Pretty strange but it works anyway.Powered by Discourse, best viewed with JavaScript enabled"
141,integralboundaryconstraint-leads-to-constant-loss,"Hello, I’m currently trying to learn modulus. My experience with neural networks is admittedly rusty and I have no prior experience with CFDs.The Problem:
If I include the following code for an IntegralBoundaryConstraint, which represents the inlet and outlet of a system containing water flow I notice that my loss value becomes constant, which would obviously make it impossible for it to converge. Anyone have tips on how I should troubleshoot this? This code is modifed from the Aneurysm case.Note that gpm is currently set to a value of 2 and the coordinate system is in mm (coords are normalized to fit within a unit cube).Here’s a sample of the training log outputUpdate: if I change the lambda_weighting={""normal_dot_vel"": 1e-8} parameter to a closer to the same scale as the loss value without the IntegralBoundaryConstraint then I can begin to see changes to the loss value. This leads me to believe one of the following may be true:Log output with adjusted lambda_weightingHi @npstrikeFor many problems, balancing the different constraints is often a very tricky and empirical process. Typically, its not that the model is bad at satisfying one constraint or the other, but rather both of them. Tuning is essential to balance these objectives.Also be aware that the Aneurysm takes a very long time to fully converge.In summary, I think your take aways are all correct based on my personal experience.Thanks for the input. I’m going to continue messing with it, but it sounds like I’m at least thinking about it in the right way. I’ll mark your response as a solution.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
142,validation-data-creation,"Hello,I wanted to ask Modulus users/developers how they generate ground truth data for comparison of the prediction results. I’ve been using Modulus for a while now, and I’m currently using a script I developed myself to achieve the FDTD solution of the PDE I’m interested in. I then export the solution to my Modulus code to perform validation.Are there any other tools that are flexible and user-friendly to perform FDM or FEM for certain PDEs? Does modulus support such functionality (creating ground-truth data for validation/comparison)?Please share your thoughts about this.Thanks!Powered by Discourse, best viewed with JavaScript enabled"
143,modulus-sdf-usage,"Hello,
I have some questions related to the SDF usage in setting up constraints in Modulus.
Take the fpga codes as example:
""""
What does  "" np.less(sdf[“sdf”], -1e-5)"" in "" channel_walls_criteria"" and “np.greater(sdf[“sdf”], 0)” in  “fpga_criteria”
mean to set up these constraints? Can anyone tell me how to relate the criteria with the constraints here?
Or Any reference on the sdf library and how it’s used?Thank you,
CeHi @cxi1What does "" np.less(sdf[“sdf”], -1e-5)"" in "" channel_walls_criteria"" and “np.greater(sdf[“sdf”], 0)” in “fpga_criteria” mean to set up these constraints?  Can anyone tell me how to relate the criteria with the constraints here?The criteria is defined in the API doc of constaints. Here we are sampling the boundary of a given geometry but want to consider multiple geometry objects when sampling and the criteria parameter allows us to do this.The channel_walls constriant is imposing the boundary condition that channel walls are insulating. So the  np.less(sdf[""sdf""], -1e-5) is forcing the sampling to occur on the channels walls but not inside the FGPA which is attached to the wall.The fluid_solid_interface constraint is imposing the boundary condition of the FPGA interface with the fluid. Thus we want to sample points from the boundary of the fpga geometry object but exclude any points that are on the bottom of the FPGA which intersect the channel (outside the flow). This is what np.greater(sdf[""sdf""], 0), makes sure our points are inside the channel walls / in the flow volume.The geometry image in the user guide can help clear up what the domain looks like.Or Any reference on the sdf library and how it’s used?Signed distance function (SDF) is a property of geometry, used in many of our examples for criteria functions but also spatial weighting of the loss (E.g. LDC example). I would recommend just looking through the different examples to see how its typically used.Hi @ngeneva ,If I understand correctly, the points with negative sdf values indicate the points outside the geometry in modulus. Regarding the channel_wall constraint, it could be considered that we are sampling the boundary of the channel wall, but only utilizing points outside the FPGA geometry with sdf values smaller than “-1e-5”.Yes! You are correct @johnlaide, I got switched up. Thanks for the correction! Updated my response.@ngeneva @johnlaideThank you both for the great explanations.  If I got the message, regarding the “fluid solid interface” constraint,
it could be considered that we are sampling the boundary of the fpga surface, but only utilizing points inside of the channel wall with sdf values greater than 0.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
144,can-you-suggest-how-to-simulate-a-conveyor-roller-that-works-on-an-assembly-line,"Is there a way we could simulate rollers on a conveyor using any extensions? I assumed there is force field and joint extension that possibly make it work, but seems like @force extension is still not implemented in the current version. Is there any other way that we can work around this problem? Please help. Thanks.Hello @tshaik2, currently we don’t have anything like this implemented in Modulus. The closes examples we have are for some linear elasticity problems. Perhaps this question is in the wrong topic though.Powered by Discourse, best viewed with JavaScript enabled"
145,fluctuating-loss-function,"Hi,
I would like to have some insights on the optimizers compatible with modulus-sym and CUDA constraintsThe loss is quite oscilating and not decreasing muchCUDA shows out of memory but gpu has memeory vacanterror:Scripts:Could anyone please explain these issues, and how can i correct them? please let me know if you need complete successful training output as wellThank youHi @nihalpushkar11Your loss here is really large, if its oscillating consider increasing batch size or lowering your learning rate.PyTorch drives the memory allocation which can be a little challenging to track. You can either lower your batch size or even decrease the size of your model architecture.Powered by Discourse, best viewed with JavaScript enabled"
146,modulus-hyperparameter-tuning,"I am planning to do a hyperparameter tuning using hydra’s optuna plugin and mlflow logging. Instead of using hydra I generally use Hydra-zen to define and manipulate the config file within the python file as a string. Do i need to rebuild the docker container to install these packages?Hi @prakhar_sharmaIf you want to use another package with Modulus, I see a couple options one could try:Hopefully one of these works for you.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
147,what-is-signed-distance-function-sdf-doing-in-integral-continuity-planes,"In the Scalar Transport: 2D Advection Diffusion example, I am confused with how the integral continuity planes have been implemented.Here, I understand that batch_size denotes the number of integral continuity planes and integral_batch_size denotes the number of points to be sampled in each integral continuity plane. These things can be changed in the config file.I also understand that a very low priority has been given to the targeted mass flow rate with a lambda_weighting of 0.1.However, I am confused with what criteria=geo.sdf > 0 is doing.
image1571×430 32.3 KB
Here geo = channel section - 3 rectangular finsIs there a way to plot the sdf values, as an example plt.scatter(x,y,c=geo.sdf) to see where it goes negative.I pulled out the definition of Line as integral continuity planes are Line object, but could not get any strong conclusion.Hello, so one tip is to visualize the integral constraint in paraview. When you run this it will make a file in the network directory call constraints. This will have vtp files for a single batch of all the constraints. You can load these into Paraview to see them. The reason we have that criteria=geo.sdf > 0 is we don’t want to integrate points that are inside those 3 fins. When you plot them you will see that if the integral line intersects the fins then it will not sample points there. This allows the integral to properly be computed.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
148,help-for-the-use-of-supervisedgridconstraint,"I am use modulus to solve a 3D PDE equation. Just PINN, not DeepONet.
The boundary conditional of my PDE equation is not just a value, and is not easy to write as a sympy funtion.
So I have generated a dataset of points, which contains 10000 boundary coordinate points (x,y,z) and the corrosponding true value for the pde (u).I looked at Constraints and found it seems that I should use SupervisedGridConstraint to add those boundary points as a Boundary Condition.So I write the code as:where the grid_r_is_1.txt is:Unfortunatly, it crashes and says:I totally have no idea about how to debug it.
Could anyone give me some suggestion?Thanks in advance!Hi @Zhao-ZCIts a little hard to tell what your doing since the Constraint you have doesn’t use x_bc,y_bc,z_bc,u_bc. Its a CSG constraint using a geometry object.The error you have is from your input not being of the correct size. This could be from declaring the network incorrectly, adding the data in correctly or defining your variables with incorrect dimensions.Without knowing too much of the nature of your problem, for adding boundary points though I would suggest just using dictionaries and PointwiseConstraint.from_numpy() function. SupervisedGridConstraint is for image like data. These forum threads may provide some insight:Powered by Discourse, best viewed with JavaScript enabled"
149,2d-geometry-from-file,"The Modulus user guide suggests two different ways to define the geometry. We can either use the Geometry module, or we can import from an STL file. I haven’t worked with STL files much, but it seems like they are all 3D. Is there any way to use a file to define all or part of a 2D geometry, or are 2D simulations only possible with shapes in the Geometry module?Hi @gemma.masonRight now the tessellated geometry support (STL files) in Modulus only supports 3D objects. It relies on 3D ray tracing to determine interior points, so an enclosed volume is needed.There is arbitrary polygon support in the geometry module for 2D, but it can be a bit slow for complex shapes with lots of lines (see airfoil example).Thank you for the response! Might I inquire as to the location of the arbitrary polygon support? I am using version 22.3 and would have expected to find it in modulus.geometry.csg.csg_2d, but it doesn’t seem to be there. Are you sure it’s still supported?Hi @gemma.masonThis was a feature that was added in later versions of Modulus. You’ll need to use Modulus version 22.07 or 22.09 to have access to this feature. Here is its location in the current source code and example file for reference.Ah, I see I am behind the times! Thank you very much for your help.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
150,fourcastnet-implementation-different-from-paper,"Hi,I am interested in using FourCastNet, and I’m going through the source code on github GitHub - NVlabs/FourCastNet: Initial public release of code, data, and model weights for FourCastNet , assuming it’s the same implementation in Modulus.In the paper, the AFNO layer is defined such thatbias = x
x = RFFT2(x)
x = x.reshape(b, h, w//2+1, k, d/k)
x = BlockMLP(x)
x = x.reshape(b, h, w//2+1, d)
x = SoftShrink(x)
x = IRFFT2(x)
return x + biassuch that the MLP happens between the FFT and IFFT.
However, in the codebase, it’sSuch that the MLP happens after the IFFT. This seems like a pretty important difference. Am I missing something?Hi @alexandre.szenicerThanks for your interest. The section of code you’re looking at is a block of AFNO inside FourcastNet which is what is implemented inside of Modulus as well as the FCN repo you linked.To see the Fourier convolution, we need to look at the AFNO2D module. Inside the forward of this torch module, you will see the FFT transforms. In between the rfft2 and irfft2 theres some reshapes as well as einsum ops which look like the following:There’s four of then (one for each corner of the spectral coefficient matrix). These are explicitly performing a single MLP layer on the spectral coefficients (both the real and imaginary parts), note the self.w2 and self.b2 terms.Does this clear things up?Hi @ngeneva,Thanks for your quick response!So as I understand it, the operations with einsum only perform linear operations, as there is no nonlinearity in between the matrix multiplications.  The AFNO paper however, proposes to use an MLP, such thatdef BlockMLP(x):
x = MatMul(x, W_1) + b_1
x = ReLU(x)
return MatMul(x, W_2) + b_2As you can see however, in the code snippet from my first message, the AFNO implementation uses the MLP only after the inverse fourier transform. Therefore I feel like there is a missing non-linearity in the AFNO2D module in the computation of the o2 quantities. What’s more, there shouldn’t be the MLP applied after the AFNO2D module.Oh I’m sorry I realised I just missed the Relu after the computation of the o1 quantities. It’s my bad!@alexandre.szenicer Thanks for looking into this. There are a couple of figures in the paper. Attaching the most relevant part here. There is the MLP between the FFT and IFFT which is the block diagonal matrix multiply as you have in the first code snipper of your original post. However, there is also another MLP after the IFFT that is not block diagonal and that’s what is in self.mlp in the second code snippet that you have. Hope this helps clear up some of the confusion.

image1440×890 69.5 KB
Hi @alexandre.szenicerWould you be interested in speaking to the modulus team to share more details on your use case. You can reach out to us directly at modulus-team@exchange.nvidia.com.Thanks
RamPowered by Discourse, best viewed with JavaScript enabled"
151,simnet-20-06-kepsilon-class-name,"Hi,
First, i would like to thank you for this great work.
There is a error in the class definition of KEpsilon (the name still ZeroEquation). And, if it possible to add an example of the use of KEpsilon because I’ve a lot of errors when I use it.
Thank you !Powered by Discourse, best viewed with JavaScript enabled"
152,applying-multiple-optimizers-in-modulus,"I have a question about using multiple optimizers when training my neural network: Is it possible to train the model for 15,000 steps with adam and then continue training for 10,000 steps with BFGS for instance?
How can this be implemented in the config file or the python file?Please assist.Hi @cpe.skPlease see the following thread for information on this. The short answer is you will need to stop training, then start again with the other optimizer / different config. Should be cleanly achievable using Hydra config.Thanks for the prompt reply and great support!
I tried training my model for 50,000 steps using adam:Then I changed the file to:however, no additional steps of training were performed. Running the code only restores adam training and then prints out that the training is done.Please advise if I’m doing something wrong.Hi @cpe.skWe didn’t anticipate many people would be interested in trying multiple optimizers so the checkpointed optimizer state is always loaded if present. Try renaming that file, some info later in that thread (towards the end of the post is the relevant part):Thanks a lot, @ngeneva!I tried renaming the optim_checkpoint.pth file, I also set max_steps to 15,000 (adam performed 50,000 before) however, this was the output:Why does it say that the max number of steps is 0 while it was set to 15,000 in the config file?
I also tried creating two different config files with different names. The output was still the same.Please help me set up this problem.Hi @cpe.skThis is because L-BFGS does not run more than 1 training iteration. Rather a single training iteration, L-BFGS has multiple optimization iterations. You can control how many optimization iterations BFGS uses via the Hydra configs / looking at the PyTorch API.Thank you @ngeneva for the suggestion. I tried changing max_iter by adding this to the config file:but it had the same result as finishing the training after one step.I tried another optimizer like sgd, and it worked and continued the training steps. Unfortunately, it did not for bfgs.
Please assist.Hi, @ngenevaI met the same problem.In my model, I’m trying to use ADAM 1st and then switch to BFGS for the optimizer. I tried to train my model using ADAM for 30000 steps. I renamed my optim_checkpoint.pth file as you mentioned. Then I tried to change max_iter = 15000 in the config.yaml. But it seems that it only run 957 iterations and then finished. May I know where the problem is.
Here is the config:Here is the log record:Thank you!Powered by Discourse, best viewed with JavaScript enabled"
153,different-layer-numbers-and-sizes-for-multiple-networks,"Hi,I am trying to construct multiple networks for my model, just like the one in the 2D seismic wave propagation example where two separate nets were constructed for the wave u and wave speed c.I would like them to have different network structures, for example, different layer numbers and sizes, but I am having trouble finding how to configure these for each network separately.Chapter 12 of the user guide says that it is possible to tune these properties by defining update_defaults method in the Solver class but it seems that this applies to all of the networks defined in the class.I looked into the source code, and found that Solver.arch has the nr_layers and layer_size attributes. So would following (in the initialization method of the Solver class) work?Or is there any other ‘proper’ way to do this?Thanks in advance!Powered by Discourse, best viewed with JavaScript enabled"
154,ellipse2d,"Hello!In the latest release, there was an ElliCylinder class, but sometimes an ellipse is required for 2d tasks, how can I get it?Unfortunately SimNet’s constructive solid geometry module does not currently support 2D elliptical geometries.Hi, we have implemented the 2D ellipse class for you and this will be available in the next SimNet release. For now you can use the attached code.

image889×650 71.2 KB

ellipse_2d.py (1.2 KB)Hi, I just added the ellipse2d code. I modified the clyinder2d code and replaced it with the ellipse. I got a reasonable result but the sampling points are lesser than before.I checked the code:area=pimajorminorHowever, in the circle class, it is:area=2piradiusDoes the area actually mean perimeter here? In this case, the area for the ellipse should be the perimeter, instead of the actual area.Hope the developer can clarify. Thanks.Powered by Discourse, best viewed with JavaScript enabled"
155,unclear-viscosity-and-density-units,"I’m working with a similar use case to the aneurysm example in the left atria. I am pretty confused with the viscosity and density units employed. The meshes of the aneurysm are defined in mm, but the density appears to be in g/cm3. The aneurysm meshes are defined in mm, but the density seems to be in g/cm3. According to literature, blood viscosity should be between 3 × 10-3 to 4 × 10-3 Pa*s or 3 - 4 centipoise (cP). Given the kinematic viscosity, the dynamic viscosity does not seem defined in any of these units. Am I missing something or is the rheolifferent in aneurysms?In fact I have conducted some tests using CFD data for training purposes and the values of density and viscosity at which the predicted velocity field and the continuity and momentum equations do not conflict are 1.06 and 0.00035. My meshes are defined in meters. These are some weird values and I’m quite sure that the CFD data from Ansys is correct.Kind regards,
XabierI am also interested in this question. I understand that the values input into a ML tool like this are more or less unitless in terms of how the NN processes it, but what’s not clear to me is whether the inputs to Navier Stokes (nu and rho) need to be in the same units as the meshes. Is there benefit (e.g. convergence time, accuracy, etc.) in putting these into the same units even if they’re not convenient to read, or are they relatively independant?Additionally, if I’m working with in non compressible fluid and I want to substitute volumetric values (which is documented as acceptable) for the following parameter from the aneurysm sample
outvar={""normal_dot_vel"": 2.540},
my meshes are in terms of mm, and my flow rate is 2 gpm, can I use a value of 2? I.e
outvar={""normal_dot_vel"": 2},I’m sure this question seems basic, but it helps me grow my understanding.Hi @npstrikeI understand that the values input into a ML tool like this are more or less unitless in terms of how the NN processes itThe key here is scaling, just like how your normalize data for data-driven problems. Feeding numbers that are either super small or super large will produce undesirable results. It just so happens non-dimensionalizing is a pretty good physically based normalization that works which keeps your PDE loss calculable with model outputs. I’m probably over simplifying, there may be some nuance here to why non-dimensionalization is good such as say auto-grad / higher-order gradient stability…but what’s not clear to me is whether the inputs to Navier Stokes (nu and rho) need to be in the same units as the meshesThe important part is what is being evaluated in the PDE is consistent and makes sense. For example, if my PDE needs Kelvin units, I could predict Celsius in my neural network, then feed it through a converter node where it just adds 273.15 to it before the loss calc.my meshes are in terms of mm, and my flow rate is 2 gpm, can I use a value of 2If you have defined the state variable of the network to be in GPM, then this works. If this unit works in your PDE loss (units are consistent) then you should be good.@ngeneva thanks for the reply. I think you’ve helped me identify a difference between how I’m trying to use the tool, and how nvidia intends me to use it. In the examples I’ve investigated so far, none of them have expanded upon the provided modulus code. Is the user (e.g. me) encouraged to be creating additional files within the modulus directory? E.g. to create custom architectures, aggregators, loss functions, etc?I’m currently trying to get a simple pipe+flow to work in modulus, and despite being simpler than the Aneurysm sample am having difficulties getting it to converge correctly. It’ll give output that looks close, and then shoot past it and garble it up, oscillating between these outputs until it eventually settles on erroneous solution. In my previous work with neural networks, this type of overshoot was often reflective of a loss function issue, but I didn’t see those kinds of modifications to be within scope of this tool. After all, if the given sample can solve an aneurysm, it should be able to solve a pipe with a couple bends in it. Should I be investigating custom loss funcs, aggregators, and such?For example, if my PDE needs Kelvin units, I could predict Celsius in my neural network, then feed it through a converter node where it just adds 273.15 to it before the loss calc.Is there an example that demonstrates this? I searched all examples containing the word “custom” but didn’t find anything regarding nodes.Hey @npstrikeI believe I was mainly thinking of the from_sympy function. There’s quite a few examples that use this that can be used to move from one variable to another. E.g. turbulent examples have quite a few of these.Powered by Discourse, best viewed with JavaScript enabled"
156,customers-using-simnet-or-modulus,"Any information would be appreciatedHello!
Modulus was previously known as SimNet - customers are using it in their workflow. Please visit our customer stories section to learn about different applications.Powered by Discourse, best viewed with JavaScript enabled"
157,can-modulus-be-used-to-make-an-ai-openfoam-module,"OpenFoam is an important Computation Fluid Dynamics application. There are projects to take advantage of deep learning, such as :A Case Study on Coupling OpenFOAM with Different Machine Learning FrameworksDeploying deep learning in OpenFOAM with TensorFlowIn the second paper 'the DL module  is constructed with the TensorFlow C API and is integrated into OpenFOAM as an application that may be linked at run time. ’Is Nvidia Modulus useful for such purposes? Are there any experiments?Hi @joepareti54Yes Modulus is a training platform for physics-informed neural networks which can be trained to predict various fluid quantities such as the flow field, closure models, boundary layer, etc. Once the PyTorch model is trained, the deployment is up to the user, just like any PyTorch model. We don’t have any specific examples with a direct OpenFOAM integration at the moment, however we have tested internally solver integration of neural networks with solvers with success.You may be interested in the following examples which involve fluid systems:Powered by Discourse, best viewed with JavaScript enabled"
158,lbfgs-optimizer-set-the-initial-state-as-the-final-state,"Hi, report a bug about the L-BFGS optimizer.
I added the training loss log during the BFGS train and found that the BFGS optimizer used the initial loss (1.361e-02) as the final loss. The same value is shown in the TensorBoard. It is not clear on which state is the inference based.[14:08:36] - attempting to restore from: outputs/NS_inverse
[14:08:36] - Success loading optimizer: outputs/NS_inverse/optim_checkpoint.0.pth
[14:08:36] - Success loading model: outputs/NS_inverse/uvp_network.0.pth
[14:08:40] - lbfgs optimizer selected. Setting max_steps to 0
[14:08:43] - [step:          0] lbfgs optimization in running
[14:08:52] - [iter:          0] loss:  1.361e-02
[14:09:07] - [iter:        200] loss:  1.342e-02
[14:09:20] - [iter:        400] loss:  1.326e-02
[14:09:34] - [iter:        600] loss:  1.316e-02
[14:09:48] - [iter:        800] loss:  1.306e-02
[14:10:02] - [iter:       1000] loss:  1.293e-02
[14:10:16] - [iter:       1200] loss:  1.282e-02
[14:10:29] - [iter:       1400] loss:  1.272e-02
[14:10:43] - [iter:       1600] loss:  1.261e-02
[14:10:57] - [iter:       1800] loss:  1.254e-02
[14:11:11] - [iter:       2000] loss:  1.244e-02
[14:11:25] - [iter:       2200] loss:  1.235e-02
[14:11:38] - [iter:       2400] loss:  1.226e-02
[14:11:52] - [iter:       2600] loss:  1.219e-02
[14:12:06] - [iter:       2800] loss:  1.211e-02
[14:12:20] - lbfgs optimization completed after 3000 steps
[14:12:20] - [step:          0] record constraint batch time:  5.271e-01s
[14:12:33] - [step:          0] record inferencers time:  1.297e+01s
[14:12:33] - [step:          0] saved checkpoint to outputs/NS_inverse
[14:12:33] - [step:          0] loss:  1.361e-02
[14:12:33] - [step:          0] reached maximum training steps, finished training!Hi @zhangzhenthuThanks for the report, is this just a reporting error (I.e. the model appears to be optimized okay)?Can you please report this on the Github repo for better visibility and triage from the team:An abstracted framework for training AI surrogates of physical systems using physics-based symbolic loss functions - Issues · NVIDIA/modulus-symMany thanks!Powered by Discourse, best viewed with JavaScript enabled"
159,implementing-boundary-conditions-on-a-moving-boundary,"Hi there,I am trying to solve a 1D, two-phase Stefan problem on Modulus 21.06 and implement the Stefan conditions on a moving boundary. I am solving the 1D, unsteady heat equation with different conductivities on either side of the free boundary as the PDE. For the interface, I implemented a class similar to the DiffusionInterface class as in chapter 9 of the User’s Guide. However, I need to give the Stefan conditions on the moving boundary and cannot implement them because the free boundary changes with time. Can you give me an idea to implement conditions for variable coordinates? Can we use the same approach as the parametric PINN but solve for the coordinate parameter?Powered by Discourse, best viewed with JavaScript enabled"
160,url-in-command-prompt-does-not-work-for-lcd-example-modulus,"The lcd example successfully ran after decreasing the batch size, but the output URL to display the results does not work.

IMG_29311920×1441 260 KB
Hi @nga77If you are running a local machine, you should go to the local url that Tensorboard prints at the bottom. If your’re running on a remote machine, you will need to set up a port forward. Alternatively you could download the Tensorboard file to your local machine and serve it there.I was running it on a local machine, and the local URL for the tensorboard that is listed next to “Tensorboard 2.9.1” did not workPowered by Discourse, best viewed with JavaScript enabled"
161,aneurysm-do-not-work,"Hi!With a version update, the aneurysm module stopped working.
problem.txt (14.7 KB)In the old version everything was fine, but to guarantee I will load the module with the installation that I use in google colabHello, can you send your driver version? In this version we had to upgrade the optix version and because of this it needs a driver update to 465. That might be your issue.Hey,I’m encountering a similar issue with  optix.I’ve managed to get SimNet working on my local machine with a BareMetal installation through anaconda. I’m running driver 460.56, with this setup the optix and the aneurysm case work just fine.Repeating the exact same installation steps on on a hpc cluster then running  $python aneurysm.py I get a similar error to @bim159.Checking the driver on the HPC:The HPC I’m using is a shared resource so it will be difficult to change the driver, do you have any other suggestions I could ask the cluster manager to implement?Powered by Discourse, best viewed with JavaScript enabled"
162,export-trained-models-as-onnx-but-can-i-then-use-it-outside-of-modulus,"Hello, I’m wondering if the models trained with Modulus can be exported into ONNX format, and if yes, can they be used outside of Modulus in the context of external C++ application?Reason I’m asking this: I’d like to integrate trained models with Modulus into Unreal Engine 5 by using their NeuralNetworkInterface which can run inference on ONNX models. Example UE5 project showcasing this: GitHub - cassiebreviu/unreal-onnxruntime-nni-exampleI guess in theory it should not be hard to export ONNX model, but will it be “standalone”? I mean, is it possible to use it for inference from other applications (like UE5) outside Modulus context of boundary constraints, interior constraints, or whole network’s knowledge about the boundaries we’ve been using through Tessellation module when working with STL geometries?Hi @michaltakacThanks for your interest. Inference is a major effort we are currently working on in Modulus right now which includes much of what you’re asking. More specifically, as of Modulus version 22.09 there is no explicit inference export functionality written into Modulus (although this is changing very soon with ONNX/TRT functions). However since Modulus is built on PyTorch one could set up a manual export script themselves for most of the models (Models like FNO/PINO/AFNO will not work).The stand alone aspect is a more challenging problem which we have on our radar but will take some more time. Essentially we are looking at the possibilities of bundling these data/inference pipelines in an easy to deploy package. In the mean time users will need to set up their own PyTorch inference script.Much of this is being actively developed, first set of inference export features should be arriving next release. So please let us know of any specific inference features you may be interested in for your application!Powered by Discourse, best viewed with JavaScript enabled"
163,how-to-use-a-trained-model-for-optimization-thru-a-function,"Hi, I have trained a flow past airfoil problem with parameterization for the angle of attack AoA.Supposed I want to find the AoA which gives the highest lift within the range which I did the training.Thru the PointwiseMonitor, I can compute the lift force using this:However it is given as an output after every 1000 steps in a csv file during training.Is there anyway I can create a function in Modulus which gives me the lift given my inputs such as AoA? In this way, I can use many different types of optimizers to get my AoA for max lift.Of course, I think I can also read from the csv file to get the lift but it will be very slow with all the i/o.Thanks.Any one have experience in this area?Thanks.Hi @tsltaywbIf you’re model is already trained and you just want to run a forward pass you could use the point monitor you have with the trainer solver.eval() function (can use this instead for the solver.solve() function).This is a bit of a hidden API of the solver/trainer class that can be used to perform just one pass of the validators / inferencers / monitors you’ve added.There is also the more manual pure PyTorch approach of writing an inference script from scratch, but if your output quantity relies on some gradient calculations then its best you stick with running a monitor / inferencer in Modulus.Powered by Discourse, best viewed with JavaScript enabled"
164,unable-to-import-stl-geometry-on-hpc-provided-ptx-was-compiled-with-an-unsupported-toolchain,"I managed to get SimNet working on my local machine through a conda env. However setting up the same conda env on a cluster, I get the following error:Full trace:
stl library error.txt (7.9 KB)The first command shows how libsdf.so was added to the library path as instructed in the installation guide.The conda environment and HPC are listed here:
Conda env and GPU config.txt (9.6 KB)The main significant difference between the local installation and the HPC installation was the need to add a Symbolic link to the correct cuda location on the HPC. I used @martiningram 's answer to fix this cuda library path issue.$ ln -s /u/usr/Physics_informed_nueral_network/SimNet_sandboxv21/usr/local/cuda ./cuda_sdk_lib
Where SimNet_sandboxv21 is a singularity sandbox of the SimNet container.  As mentioned this is the only significant difference between the local installation where anuerysm.py and its dependent stl libraries worked,  and the HPC installation where I’m encountering the mentioned error.My question is how do I resolve the PTX error? Any advice would be appreciated.Hi I have the same error. It is because the CUDA and GPU version is not compatible. Simply use older version of TensorFlow or PyTorch. For me, it is working now.Powered by Discourse, best viewed with JavaScript enabled"
165,error-with-accessing-validation-data-csv-to-dict,"I am new to modulus and am running the ldc case. I am able to create an outputs folder, however, when compiling I run into the issue related to validation data as posted below[00:48:58] - JIT using the NVFuser TorchScript backend
[00:48:58] - JitManager: {‘_enabled’: True, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[00:48:58] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
Error executing job with overrides: 
ValueError: could not convert string to float: ‘oid sha256:4c68adf2b0a04c53f0abd4d3920f3fec618669399638dd5ece84785f474d1fa6’The above exception was the direct cause of the following exception:Traceback (most recent call last):
File “ldc_2d.py”, line 82, in run
openfoam_var = csv_to_dict(Hi @mitanshtripThis error is typically because you do not have Git LFS installed:Please see our install notes regarding this.Hello, So I had previously installed git-lfs (git-lfs/3.2.0 (GitHub; linux amd64; go 1.18.2)). I recloned the examples directory, this time I am getting a different error as stated below. Is this mainly because of the installed pytorch version?/examples/ldc# python3 ldc_2d.py
[12:24:27] - JIT using the NVFuser TorchScript backend
[12:24:27] - Disabling JIT because functorch does not work with it.
[12:24:27] - JitManager: {‘_enabled’: False, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[12:24:27] - GraphManager: {‘_func_arch’: True, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
[12:24:31] - Arch Node: flow_network has been converted to a FuncArch node.
[12:24:31] - Installed PyTorch version 1.13.0+cu116 is not TorchScript supported in Modulus. Version 1.13.0a0+d321be6 is officially supported.
[12:24:31] - attempting to restore from: outputs/ldc_2d
[12:24:31] - optimizer checkpoint not found
[12:24:31] - model flow_network.0.pth not found
Error executing job with overrides: Hi @mitanshtripIs there an error message below Error executing job with overrides: ? Its a bit difficult to tell what happening from the console log here.It is actually a very long long message, I have copy pasted some from there below:Error executing job with overrides: 
Traceback (most recent call last):
File “ldc_2d.py”, line 116, in run
slv.solve()
File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 159, in solve
self._train_loop(sigterm_handler)
File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 593, in _train_loop
self._record_constraints()
File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/trainer.py”, line 275, in _record_constraints
self.record_constraints()
File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py”, line 116, in record_constraints
self.domain.rec_constraints(self.network_dir)
File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/domain/domain.py”, line 45, in rec_constraints
constraint.save_batch(constraint_data_dir + key)
File “/usr/local/lib/python3.8/dist-packages/modulus-22.9-py3.8.egg/modulus/domain/constraint/continuous.py”, line 60, in save_batch
pred_outvar = modl(invar)
File “/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py”, line 1190, in _call_impl
return forward_call(*input, **kwargs)File “/usr/local/lib/python3.8/dist-packages/functorch/_src/eager_transforms.py”, line 113, in _autograd_grad
grad_inputs = torch.autograd.grad(diff_outputs, inputs, grad_outputs,
File “/usr/local/lib/python3.8/dist-packages/torch/autograd/init.py”, line 300, in grad
return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.Hi @mitanshtripThanks. This seems to be some issue with the gradient calculations. Please try turning off functorch for gradient calculations by putting the following in your config.yaml file for this problem:If that does not work then I would try shutting off CUDA graphs with cuda_graphs: falseHello, I tried those options but, I am getting the same error. Would this line be the cause?Installed PyTorch version 1.13.0+cu116 is not TorchScript supported in Modulus. Version 1.13.0a0+d321be6 is officially supported.Hi @mitanshtripIs this an error or just a warning? Typically this message is just from a warning that JIT is not being used which has little to no performance gain most of the time. You can also turn this off by shutting off JIT in your config using jit: false.Powered by Discourse, best viewed with JavaScript enabled"
166,spatial-weighting-of-losses-with-stl-geometries,"Hello,I’m trying to implement the spatial weighting loss for the nonslip boundary condition in a Navier-Stokes problem. This is the code I’m using, interior_mesh represents the surface of the domain of interest, which is a closed .stl mesh similar to the one in the aneurysm task.I keep getting the following error.Hi @xtaltecIs this with Modulus version 22.07? If so please try:The heat sink examples typically have this such as FPGA and three fin.Powered by Discourse, best viewed with JavaScript enabled"
167,error-occurred-during-hydras-exception-formatting,"Hi,I try to run the examples, all of them give an error relates to Hydra.
The error were shown as follows. Please advise thank you.[16:22:34] - JitManager: {‘_enabled’: False, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[16:22:34] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
Error executing job with overrides: 
An error occurred during Hydra’s exception formatting:
TypeError(“print_exception() got an unexpected keyword argument ‘etype’”)
ValueError: could not convert string to float: ‘oid sha256:7d5a53b87b5a4446023965b6e0ead4d5fca8fd8cb1f40316336d65dad5e466e6’The above exception was the direct cause of the following exception:Traceback (most recent call last):
File “/home/uos/MODULUS/examples/three_fin_2d/heat_sink.py”, line 277, in 
run()
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/modulus-22.9-py3.10.egg/modulus/hydra/utils.py”, line 91, in func_decorated
_run_hydra(
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 377, in _run_hydra
run_and_report(
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 294, in run_and_report
raise ex
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 211, in run_and_report
return func()
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 378, in 
lambda: hydra.run(
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/hydra.py”, line 111, in run
_ = ret.return_value
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/core/utils.py”, line 233, in return_value
raise self._return_value
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/core/utils.py”, line 160, in run_job
ret.return_value = task_function(task_cfg)
File “/home/uos/MODULUS/examples/three_fin_2d/heat_sink.py”, line 211, in run
openfoam_var = csv_to_dict(
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/modulus-22.9-py3.10.egg/modulus/utils/io/csv_rw.py”, line 33, in csv_to_dict
values = np.loadtxt(filename, skiprows=1, delimiter=delimiter, unpack=False)
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/numpy/lib/npyio.py”, line 1356, in loadtxt
arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/numpy/lib/npyio.py”, line 999, in _read
arr = _load_from_filelike(
ValueError: could not convert string ‘oid sha256:7d5a53b87b5a4446023965b6e0ead4d5fca8fd8cb1f40316336d65dad5e466e6’ to float64 at row 0, column 1.Process finished with exit code 1Hi @nuraliya.sheffieldThis looks like a Git LFS issue. Make sure you have Git LFS installed and re-pull the repo.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
168,how-to-handle-near-wall-flow-behavior-for-turbulent-flow,"I was looking through the fpga and limerock cases. I noticed that for both cases use the zero equation formulation to handle the turbulence modelling, the zero equation model incorporates wall effects by damping the mixing length close to the wall.For the other turbulence model defined, the  k - epsilon model I don’t see the the equivalent damping terms used to handle near wall behavior.My question is if its possible to handle no slip wall cases such as fpga with alternative turbulence models such as k - epsilon? If so, what’s the recommended way of doing so.The k-epsilon equations that are currently in the source code are under development. Hence they do not have any special treatment to handle the near wall behavior as you pointed out. Among the two ways of handling them (low Re models and wall functions), we recently have seen better success using the wall functions approach. Resolving the near wall variation using a Low-Re model might require very high point cloud densities and hence wall functions seem to be an attractive alternative. We are working more towards it and hopefully we can have a few examples showing its use in upcoming releases.Thanks for the response. I have also been working on a low Re formulation of the K-e model as it seemed like it was more straightforward to implement within the SimNet framework despite the mesh/sampling penalty, its interesting to hear that the wall function approach has been more effective.I have 2 further questions regarding your wall treatment function:Are you able to share  your wall function in it current state? I have a few 2D and 3D cases I would like to try, I’d be happy to share them with you.Additionally, are there any resources that detail the release schedule? This would help decide whether its worth waiting for your release or implementing our own.Powered by Discourse, best viewed with JavaScript enabled"
169,time-resolved-boundary-conditions-from-mesh-data,"Hi,I want to impose boundary conditions based on our fluid dynamic simulations. The data is 3D + time and stored as tetrahedral meshes. I have been reading how to import the geometry from .stl files, but I’m not sure how to import the time-resolved velocity as boundary conditions. I have separated the inlet and outlet surfaces and extracted the velocity data as flattened numpy arrays. Then, I have been trying to load the velocity data through PointwiseBoundaryConstraint.from_numpy(), but I keep getting the following error:I’m sure I’m missing something important. I have attached a sample inlet surface if it may be of help.prueba.vtu (45.9 KB)Powered by Discourse, best viewed with JavaScript enabled"
170,how-is-the-parametric-pinn-applied,"I am trying to implement a problem linear elasticity problem with modulus. I want to parameterise my geometry. I am following the example given in chapter 16 from the user guide. And chapter 1.3.3 (see image)
image1291×632 84.4 KB
I want to know where in the source code I can find out how the geometry parameters are incorporated within the network?I know that they are added as inputs to the network but I want to see how they are sampled within the loss functions. Where is the code for equations 10 and 11?If someone could point me in the right directionHello @mn17b2m , when you construct your geometry you can parameterize it with SymPy Symbols as shown in the three_fin_3d example. Then when you make the actual constraints to train your problem you can give a param_ranges.  This is a dictionary of the following form, param_ranges={sympy_symbol: (lower_bound, upper_bound)} where sympy_symbol is your SymPy Symbol you used in the geometric parameterization. The lower_bound and upper_bound are floats that define the range you want to sample the parameter in. When Modulus is sampling these parameters it will sample uniformly randomly in this given range.The source code for this is found in sympy_utils/geometry.py and sympy_utils/curves.py in the Modulus release prior to our new 22.03 release. In the new 22.03 release this has moved to geometry/csg/csg.py. You can interpret the geometric parameterization as adding an extra dimension to the geometry. For example, if you parameterized the radius of a 2D circle and sampled the boundary in effect you would sample a cone in 3D where the 3rd dimension is the radius parameter. You can experiment with this by using the sample_boundary method of the geometry and plotting it in paraview like the following snippet,Hi! I want to add another twist to this parametrized problem. What if you have not just one dimension that is a parameter, but a whole function? Simple example: f(x)_xx + k(x)*f(x) = 0, but there are many possible functions k(x) and you want the network to learn the output f(x) under many different k(x), so in the future you have a new k(x) as an input, and want the network to output f(x). Any ideas? Thx.Adding this for reference.As you said, one solution was to parametrize k(x) and I was thinking about a Fourier Transform parametrized version of the input function, but I knew that it won’t work for larger dimensions, so I gave up on the idea. Literature search brought me to DeepONets by Karniadiakis and other versions by Caltech groups and I was preparing my code to use their libraries but it is great to know that the last release of Modulus 22.03 included this really important extension. Thanks for the help.Sorry, but after more than a month trying to figure out how to setup a simple equation F_x + k(x)*F = 0 on the new Physics-Based DeepOnet framework in Modulus 22.03, I give up. Because of the lack of manuals/explanations it took me a while to see how the new Branch-net <input_key> size was connected with the ‘x’_data sampling size in the Boundary and Interior constraints. It was also not easy to see how the deeponet <output_key> size must be the same as the interior and boundary constraints  column size, something that is obvious from the papers but has no explanation in any of the Modulus examples. Unfortunately I still have no idea why the <input_key> on the Trunk-net has size 1, and more importantly, I am completely clueless on how to impose a simple equation like the one described before as an Interior constraint. I mean, in the “manual” there is an overly simplistic anti-derivative example where the Interior  parameter is only a simple derivative “u__s”. The way to impose a new equation like ""F_x + k(x)*F=0 should be through the PDES class, but I have tried that and I keep getting errors like matrix size mismatch, or something more complex than that. Besides, the Darcy PINO example doesn’t help much as it redefines the symbolic equation on 3 different types of numerical derivatives. It would have been much simpler to state basic examples like the one I am describing and people can grow from there.Powered by Discourse, best viewed with JavaScript enabled"
171,magneto-dynamics-i-e-electromagnet,"Hi All!
I was wandering if anybody had any luck using  Modulus to solve simple electro(magneto) dynamics problems. I have tried applying Modulus to a simple set-up of an electro-magnet (c-shaped iron core with copper windings on one side through which current j is applied all in 2D). In this setting Maxwell equations can be reduced to a Poisson equation with the current j being a “force” term. The trick is that the difference in magnetic permeability material properties between iron and air have to be encoded as a Neumann boundary condition to the border between air and iron. Of course we can add those to our loss, however I’m having problems getting the correct solution out. I think it is due to the fact that the magnetic permeability of iron is about 7000 more than that of air, so the boundary condition wants to enforce a normal gradient of the function to be about 7000 more steep on the iron side than on the air side and it fails.
Anyway I was just curious if anybody had any luck using Modulus for electromagnetics (special domain, not frequency domain)?
Thanks,
JarekHello @jaroslaw.rz, The only thing we have tried related to this is solving some Maxwell-Vlasov equations. We were able to get pretty good results with this but have not released them. We have solved some coupled fluid solid thermal problems though. In these cases we are similarly solving the Poisson equation. For the boundary conditions between the two we have a Neumann for the flux and Dirichlet for temp. The ratios of permeability are going to be tough to deal with though. In our thermal problems the ratios of diffusivity are on the order of 3-6 magnitudes. The only wave we have managed to handle these is to use a complex iterative method call hFTB (https://www.researchgate.net/publication/269134416_A_NOVEL_METHOD_FOR_THE_COMPUTATION_OF_CONJUGATE_HEAT_TRANSFER_WITH_COUPLED_SOLVERS). We were using this for the limerock example where the heat sink material is copper and the fluid is air.Powered by Discourse, best viewed with JavaScript enabled"
172,what-is-the-recommend-hardware-gpu-for-modulus,"Hi,
I’m new to Nvidia Modulus and I have some questions:HI @elin.hm20Thanks for your interest in Modulus:Does Modulus automatically run on GPU?If PyTorch see’s GPUs, Modulus will use themCan Modulus run on CPU? How?Some parts will work with CPU. If theres no GPU present, packages like Modulus Sym should default to CPU. In Modulus-Launch you may need to change the example script.What are the limitations for choosing a GPU for Modulus? Only the amount of VRAM?Typically VRAM is the critical spec, more is better for all deep learning. But of course also speed / flops of the GPU. Newer Nvidia GPUs will run faster naturally and maybe have some improved / different features (E.g. tensor cores). But many problems will still work just fine and converge in a timely manner on many GPU models. For development we use A100 and V100 GPUs.In general, if a GPU is good for deep learning / PyTorch. It will be good for Modulus.Thanks for your quick and complete response.
In the website there are some recommendations for GPUs such as A100, A30, A4000, V100, RTX 30xx.
What about A6000 model? Can this model support Modulus?Hi @elin.hm20The listed GPUs are ones we have officially tested ourselves and verified the examples work on. Multiple other users have been successful on GPUs outside this list, some times with a few modifications.Thank you very much for the help.Powered by Discourse, best viewed with JavaScript enabled"
173,does-anyone-have-an-inference-of-simnet-prediction-example,"As for examples of inference scripts using learned SimNet neural nets. I would like to know how fast it is!It self-cured from our collegue’s suggestion.
The option run_mode=eval was worked.
Thanks all!Thank you for sharing the tip.Powered by Discourse, best viewed with JavaScript enabled"
174,recurrent-neutral-with-a-bi-lstm-in-nvidia-modulus,"I am interested in applying recurrent neutral with a bi-LSTM network for time series data. I believe that
Moving Time Window: Taylor Green Vortex Decay example can be useful for this purpose. it is possible to use Moving Time Window front and back in time to achieve the behavior of bi-LSTM. or there is any other way to achieve it, thank youHi @rahul.kum.varshneyWe currently do not natively support RNNs inside Modulus-Sym, but we encourage our users to customize and experiment since this is an active topic of research after all. Good luck!Powered by Discourse, best viewed with JavaScript enabled"
175,2d-flow-over-airfoil-with-aoa-as-parameter,"Hi, I am using modulus 22.09 to train a model that provide flow field prediction for a 2D airfoil with changing angle of attack from 0deg to 10deg. However, the results is bad compared to the fixed aoa of 0deg and 10deg. The main error happens on the pressure on y diction. I tried to add the batch sizes of airfoil boundaries and interior points. it don’t work.
can someone give some advice to solve it?Hi @uniquezedpgI can’t promise that I know what I’m doing, but could you post some more information about the problem? What type of error are you seeing?  Did you parameterize the geometry? Or are you using transfer learning and retraining?Turbulence models each have strengths and weaknesses.  When used to simulate flow around an airfoil some will predict separation early, some late, and some never at all.  For an airfoil in an otherwise open flow I’d start with k-w:k-w and k-e examples in GitlabHi @uniquezedpgHave a look at the recommended practices section of the documentation for some idea on how to improve your convergence.Powered by Discourse, best viewed with JavaScript enabled"
176,how-to-use-dockers-to-associate-a-modular-container-with-a-jupter-notebook,"Hello, I’m a newcomer to dockers and modulus. I’m trying to load the modulus image through dockers. I have successfully established a container for modulus, but how do I load a jumper notebook on the module container to implement the running of the case?Hi @shimanukilagrantql7846You can do this by running a Jupyter notebook in the docker container. There’s information about this online, here’s a stack overflow post that concisely goes over the steps. Also the notebook tutorial in our docs was created from a Jupyter notebook, so you should be able to follow along there once your notebook is running.Powered by Discourse, best viewed with JavaScript enabled"
177,cuda-out-of-memory-error-when-running-helmholtz-example-in-modulus,"
Screenshot from 2023-02-08 15-44-071920×1108 183 KB
Hi, I’m new to Modulus and I get the following error whenever I run their Helmholtz python scripts example. How do I solve this issue?Hi @nga77 ,Thanks for trying out Modulus. This is a general deep learning problem not just Modulus. Unfortunately, PINNs training can take up quite a bit of memory compared to data-driven problems since additional gradients need to be stored. We develop on V100 and A100 gpus so the GPU memory we work with is larger than 4Gb. Fortunately there’s some simple solutions you can try:Can this problem also be solved if I used Modulus on public cloud instances like AWS?Yes, given that your remote instance has a GPU available with sufficient memory. In development we may test things by running on smaller sizes on test machines then scale to larger systems for bigger problems. It greatly depends on what the problem you’re working on.Alternatively you could try running in CPU mode, but this will be much slower.Alright, thank you so much for the help :)This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
178,problem-getting-wall-gradients-in-modulus-v22-09-works-in-v22-03,"Hi, I am trying to get wall velocity gradients for my problem. However, it doesn’t seem to work.Previously, I followed the example in the conjugate heat transfer problem for v22.03. I insert:into the orginial code and it worked.However, now using v22.09, it doesn’t work anymore. The error is:Is there a bug somewhere?Thanks.After some checking, it seems that syntax in the new v22.09 is different from v22.03.By adding:andMoreover, in the conf_flow.yaml:add:One should be able to get the gradients.Hi @tsltaywbThat’s correct. We had a large API change between 22.03 and 22.06 (and thus 22.09) related to imports. Please check out the examples for updated imports and implementations.Powered by Discourse, best viewed with JavaScript enabled"
179,resource-exhausted-oom-when-allocating-tensor-with-shape-181202-512,"Hello,I am having trouble with my GPU memory when running the example “Turbulent physics: Zero Equation Turbulance model”, i.e. ldc_2d_zeroEq.py.When running the example code, everything works perfectly fine for about 5 time steps . During this stage around 2.2 Gb of the GPU memory is used. Then all the sudden, a spike occurs where the simulation start occupying the entire memory (3.7 Gb) and the run fails.
image720×415 44.9 KB
Can’t really see any reason for why the memory usages should increase so drastically and is wondering whether it is a bug or just lack of hardware capacity.I’ve tried running the example “Lid Driven Cavity Flow”, and it works without any problems.2021-11-01 17:04:49.237170: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 353.91MiB (rounded to 371101696).  Current allocation summary follows.
2021-11-01 17:04:49.237316: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (256): 	Total Chunks: 128, Chunks in use: 128. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 553B client-requested in use in bin.
2021-11-01 17:04:49.237360: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (512): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.237405: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1024): 	Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.
2021-11-01 17:04:49.237451: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2048): 	Total Chunks: 54, Chunks in use: 54. 108.0KiB allocated for chunks. 108.0KiB in use in bin. 108.0KiB client-requested in use in bin.
2021-11-01 17:04:49.237497: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4096): 	Total Chunks: 14, Chunks in use: 13. 64.0KiB allocated for chunks. 60.0KiB in use in bin. 59.5KiB client-requested in use in bin.
2021-11-01 17:04:49.237526: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8192): 	Total Chunks: 53, Chunks in use: 51. 814.8KiB allocated for chunks. 783.2KiB in use in bin. 777.2KiB client-requested in use in bin.
2021-11-01 17:04:49.237567: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16384): 	Total Chunks: 9, Chunks in use: 7. 257.0KiB allocated for chunks. 203.5KiB in use in bin. 203.1KiB client-requested in use in bin.
2021-11-01 17:04:49.237610: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (32768): 	Total Chunks: 1, Chunks in use: 0. 47.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.237651: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.237692: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.237732: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.237777: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (524288): 	Total Chunks: 10, Chunks in use: 5. 6.94MiB allocated for chunks. 3.46MiB in use in bin. 3.46MiB client-requested in use in bin.
2021-11-01 17:04:49.237822: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1048576): 	Total Chunks: 30, Chunks in use: 29. 33.05MiB allocated for chunks. 31.67MiB in use in bin. 31.67MiB client-requested in use in bin.
2021-11-01 17:04:49.237864: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.237914: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4194304): 	Total Chunks: 52, Chunks in use: 51. 402.29MiB allocated for chunks. 396.43MiB in use in bin. 396.43MiB client-requested in use in bin.
2021-11-01 17:04:49.237966: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8388608): 	Total Chunks: 3, Chunks in use: 3. 28.71MiB allocated for chunks. 28.71MiB in use in bin. 23.43MiB client-requested in use in bin.
2021-11-01 17:04:49.238010: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.238056: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (33554432): 	Total Chunks: 1, Chunks in use: 0. 38.71MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.238100: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.238146: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (134217728): 	Total Chunks: 1, Chunks in use: 0. 158.09MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-11-01 17:04:49.238196: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (268435456): 	Total Chunks: 7, Chunks in use: 6. 2.45GiB allocated for chunks. 2.14GiB in use in bin. 2.07GiB client-requested in use in bin.
2021-11-01 17:04:49.238244: I tensorflow/core/common_runtime/bfc_allocator.cc:885] Bin for 353.91MiB was 256.00MiB, Chunk State:
2021-11-01 17:04:49.238305: I tensorflow/core/common_runtime/bfc_allocator.cc:891]   Size: 316.18MiB | Requested Size: 7.81MiB | in_use: 0 | bin_num: 20, prev:   Size: 353.91MiB | Requested Size: 353.91MiB | in_use: 1 | bin_num: -1
2021-11-01 17:04:49.238345: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1180827648
2021-11-01 17:04:49.238386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f15e2000000 next 245 of size 371101696
2021-11-01 17:04:49.238423: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f15f81e9000 next 342 of size 371101696
2021-11-01 17:04:49.238459: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f160e3d2000 next 18446744073709551615 of size 438624256
2021-11-01 17:04:49.238493: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1073741824
2021-11-01 17:04:49.238528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f162e000000 next 472 of size 371101696
2021-11-01 17:04:49.238566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16441e9000 next 298 of size 371101696
2021-11-01 17:04:49.238599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f165a3d2000 next 18446744073709551615 of size 331538432
2021-11-01 17:04:49.238632: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 536870912
2021-11-01 17:04:49.238665: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f166e000000 next 469 of size 371101696
2021-11-01 17:04:49.238695: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16841e9000 next 18446744073709551615 of size 165769216
2021-11-01 17:04:49.238727: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 268435456
2021-11-01 17:04:49.238754: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f168e000000 next 247 of size 8192000
2021-11-01 17:04:49.238773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f168e7d0000 next 484 of size 8192000
2021-11-01 17:04:49.238793: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f168efa0000 next 454 of size 8192000
2021-11-01 17:04:49.238820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f168f770000 next 363 of size 8192000
2021-11-01 17:04:49.238854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f168ff40000 next 476 of size 8189952
2021-11-01 17:04:49.238890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169070f800 next 440 of size 8189952
2021-11-01 17:04:49.238925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1690edf000 next 441 of size 8189952
2021-11-01 17:04:49.238959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16916ae800 next 240 of size 8189952
2021-11-01 17:04:49.238991: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1691e7e000 next 213 of size 8192000
2021-11-01 17:04:49.239025: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169264e000 next 219 of size 8192000
2021-11-01 17:04:49.239050: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1692e1e000 next 457 of size 8192000
2021-11-01 17:04:49.239065: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16935ee000 next 401 of size 8192000
2021-11-01 17:04:49.239085: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f1693dbe000 next 324 of size 1449728
2021-11-01 17:04:49.239115: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1693f1ff00 next 301 of size 1048576
2021-11-01 17:04:49.239149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169401ff00 next 380 of size 1048576
2021-11-01 17:04:49.239170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169411ff00 next 221 of size 1048576
2021-11-01 17:04:49.239186: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169421ff00 next 253 of size 1048576
2021-11-01 17:04:49.239206: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169431ff00 next 433 of size 1048576
2021-11-01 17:04:49.239233: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f169441ff00 next 426 of size 6144000
2021-11-01 17:04:49.239265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16949fbf00 next 473 of size 8189952
2021-11-01 17:04:49.239299: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16951cb700 next 366 of size 8192000
2021-11-01 17:04:49.239331: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169599b700 next 229 of size 8192000
2021-11-01 17:04:49.239364: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169616b700 next 450 of size 8192000
2021-11-01 17:04:49.239396: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169693b700 next 420 of size 8189952
2021-11-01 17:04:49.239428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169710af00 next 353 of size 8189952
2021-11-01 17:04:49.239455: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16978da700 next 361 of size 2048000
2021-11-01 17:04:49.239473: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1697ace700 next 280 of size 6144000
2021-11-01 17:04:49.239494: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16980aa700 next 260 of size 8189952
2021-11-01 17:04:49.239524: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1698879f00 next 442 of size 8192000
2021-11-01 17:04:49.239557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1699049f00 next 428 of size 2048000
2021-11-01 17:04:49.239590: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169923df00 next 443 of size 8189952
2021-11-01 17:04:49.239616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f1699a0d700 next 288 of size 8189952
2021-11-01 17:04:49.239632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169a1dcf00 next 311 of size 8189952
2021-11-01 17:04:49.239647: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169a9ac700 next 220 of size 8189952
2021-11-01 17:04:49.239668: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169b17bf00 next 302 of size 8189952
2021-11-01 17:04:49.239698: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f169b94b700 next 18446744073709551615 of size 40585472
2021-11-01 17:04:49.239730: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 134217728
2021-11-01 17:04:49.239764: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169e000000 next 194 of size 8192000
2021-11-01 17:04:49.239798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169e7d0000 next 295 of size 8192000
2021-11-01 17:04:49.239832: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169efa0000 next 336 of size 8192000
2021-11-01 17:04:49.239869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169f770000 next 389 of size 8192000
2021-11-01 17:04:49.239904: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f169ff40000 next 382 of size 8189952
2021-11-01 17:04:49.239940: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a070f800 next 316 of size 8189952
2021-11-01 17:04:49.239973: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a0edf000 next 215 of size 8189952
2021-11-01 17:04:49.240008: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a16ae800 next 416 of size 8189952
2021-11-01 17:04:49.240042: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a1e7e000 next 445 of size 8192000
2021-11-01 17:04:49.240077: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a264e000 next 258 of size 8192000
2021-11-01 17:04:49.240110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a2e1e000 next 230 of size 8192000
2021-11-01 17:04:49.240146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a35ee000 next 368 of size 8192000
2021-11-01 17:04:49.240170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a3dbe000 next 281 of size 8189952
2021-11-01 17:04:49.240186: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a458d800 next 371 of size 8189952
2021-11-01 17:04:49.240208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a4d5d000 next 319 of size 8189952
2021-11-01 17:04:49.240241: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a552c800 next 18446744073709551615 of size 11352064
2021-11-01 17:04:49.240302: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 67108864
2021-11-01 17:04:49.240336: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a6000000 next 436 of size 8192000
2021-11-01 17:04:49.240371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a67d0000 next 452 of size 8192000
2021-11-01 17:04:49.240406: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a6fa0000 next 327 of size 8192000
2021-11-01 17:04:49.240440: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a7770000 next 386 of size 8192000
2021-11-01 17:04:49.240473: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a7f40000 next 210 of size 8189952
2021-11-01 17:04:49.240507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a870f800 next 405 of size 8189952
2021-11-01 17:04:49.240543: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a8edf000 next 400 of size 8189952
2021-11-01 17:04:49.240580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16a96ae800 next 18446744073709551615 of size 9771008
2021-11-01 17:04:49.240614: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 33554432
2021-11-01 17:04:49.240646: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16aa000000 next 398 of size 8189952
2021-11-01 17:04:49.240659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16aa7cf800 next 478 of size 8189952
2021-11-01 17:04:49.240670: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16aaf9f000 next 315 of size 8189952
2021-11-01 17:04:49.240682: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16ab76e800 next 18446744073709551615 of size 8984576
2021-11-01 17:04:49.240693: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 8388608
2021-11-01 17:04:49.240704: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2000000 next 43 of size 1048576
2021-11-01 17:04:49.240716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2100000 next 45 of size 1048576
2021-11-01 17:04:49.240728: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2200000 next 46 of size 1048576
2021-11-01 17:04:49.240739: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2300000 next 47 of size 1048576
2021-11-01 17:04:49.240750: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2400000 next 58 of size 1048576
2021-11-01 17:04:49.240761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2500000 next 69 of size 1048576
2021-11-01 17:04:49.240773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2600000 next 73 of size 1048576
2021-11-01 17:04:49.240784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2700000 next 18446744073709551615 of size 1048576
2021-11-01 17:04:49.240795: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 16777216
2021-11-01 17:04:49.240806: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2800000 next 95 of size 1048576
2021-11-01 17:04:49.240817: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2900000 next 96 of size 1048576
2021-11-01 17:04:49.240828: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2a00000 next 99 of size 1048576
2021-11-01 17:04:49.240839: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2b00000 next 100 of size 1048576
2021-11-01 17:04:49.240851: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2c00000 next 101 of size 1048576
2021-11-01 17:04:49.240862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2d00000 next 102 of size 1048576
2021-11-01 17:04:49.240873: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2e00000 next 259 of size 724992
2021-11-01 17:04:49.240885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d2eb1000 next 286 of size 1449728
2021-11-01 17:04:49.240896: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3012f00 next 344 of size 1449728
2021-11-01 17:04:49.240908: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d3174e00 next 232 of size 741120
2021-11-01 17:04:49.240919: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3229d00 next 241 of size 16128
2021-11-01 17:04:49.240931: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d322dc00 next 196 of size 12032
2021-11-01 17:04:49.240942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d3230b00 next 370 of size 737024
2021-11-01 17:04:49.240951: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d32e4a00 next 379 of size 16128
2021-11-01 17:04:49.240959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d32e8900 next 388 of size 16128
2021-11-01 17:04:49.240967: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d32ec800 next 209 of size 16128
2021-11-01 17:04:49.240975: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d32f0700 next 303 of size 4096
2021-11-01 17:04:49.240984: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d32f1700 next 343 of size 729088
2021-11-01 17:04:49.240992: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d33a3700 next 326 of size 724992
2021-11-01 17:04:49.241000: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d3454700 next 238 of size 724992
2021-11-01 17:04:49.241008: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3505700 next 294 of size 724992
2021-11-01 17:04:49.241016: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d35b6700 next 404 of size 724992
2021-11-01 17:04:49.241024: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3667700 next 270 of size 4096
2021-11-01 17:04:49.241033: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3668700 next 206 of size 256
2021-11-01 17:04:49.241041: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3668800 next 474 of size 256
2021-11-01 17:04:49.241049: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3668900 next 332 of size 724992
2021-11-01 17:04:49.241057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3719900 next 475 of size 12032
2021-11-01 17:04:49.241065: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d371c800 next 195 of size 16128
2021-11-01 17:04:49.241073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d3720700 next 214 of size 16128
2021-11-01 17:04:49.241081: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3724600 next 237 of size 12032
2021-11-01 17:04:49.241089: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3727500 next 470 of size 16128
2021-11-01 17:04:49.241097: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d372b400 next 340 of size 16128
2021-11-01 17:04:49.241105: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d372f300 next 464 of size 4096
2021-11-01 17:04:49.241113: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3730300 next 273 of size 16128
2021-11-01 17:04:49.241121: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3734200 next 274 of size 16128
2021-11-01 17:04:49.241129: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3738100 next 418 of size 256
2021-11-01 17:04:49.241137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d3738200 next 226 of size 16384
2021-11-01 17:04:49.241145: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d373c200 next 268 of size 16128
2021-11-01 17:04:49.241153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d3740100 next 279 of size 48128
2021-11-01 17:04:49.241161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f16d374bd00 next 378 of size 16128
2021-11-01 17:04:49.241169: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f16d374fc00 next 18446744073709551615 of size 721920
2021-11-01 17:04:49.241177: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1048576
2021-11-01 17:04:49.241185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd600000 next 1 of size 256
2021-11-01 17:04:49.241193: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd600100 next 2 of size 2048
2021-11-01 17:04:49.241201: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd600900 next 3 of size 2048
2021-11-01 17:04:49.241209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd601100 next 4 of size 2048
2021-11-01 17:04:49.241217: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd601900 next 5 of size 256
2021-11-01 17:04:49.241225: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd601a00 next 6 of size 2048
2021-11-01 17:04:49.241233: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd602200 next 7 of size 256
2021-11-01 17:04:49.241241: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd602300 next 8 of size 256
2021-11-01 17:04:49.241249: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd602400 next 9 of size 2048
2021-11-01 17:04:49.241257: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd602c00 next 10 of size 2048
2021-11-01 17:04:49.241265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd603400 next 11 of size 2048
2021-11-01 17:04:49.241273: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd603c00 next 12 of size 256
2021-11-01 17:04:49.241281: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd603d00 next 13 of size 256
2021-11-01 17:04:49.241289: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd603e00 next 14 of size 2048
2021-11-01 17:04:49.241297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd604600 next 15 of size 2048
2021-11-01 17:04:49.241305: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd604e00 next 16 of size 256
2021-11-01 17:04:49.241313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd604f00 next 17 of size 2048
2021-11-01 17:04:49.241321: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd605700 next 18 of size 2048
2021-11-01 17:04:49.241329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd605f00 next 19 of size 2048
2021-11-01 17:04:49.241337: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd606700 next 20 of size 256
2021-11-01 17:04:49.241345: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd606800 next 21 of size 2048
2021-11-01 17:04:49.241353: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd607000 next 22 of size 256
2021-11-01 17:04:49.241361: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd607100 next 23 of size 256
2021-11-01 17:04:49.241369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd607200 next 24 of size 256
2021-11-01 17:04:49.241377: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd607300 next 25 of size 2048
2021-11-01 17:04:49.241385: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd607b00 next 26 of size 256
2021-11-01 17:04:49.241393: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd607c00 next 27 of size 2048
2021-11-01 17:04:49.241401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd608400 next 28 of size 2048
2021-11-01 17:04:49.241409: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd608c00 next 29 of size 2048
2021-11-01 17:04:49.241417: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd609400 next 30 of size 256
2021-11-01 17:04:49.241425: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd609500 next 31 of size 256
2021-11-01 17:04:49.241433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd609600 next 32 of size 2048
2021-11-01 17:04:49.241441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd609e00 next 35 of size 6144
2021-11-01 17:04:49.241449: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60b600 next 38 of size 4096
2021-11-01 17:04:49.241457: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60c600 next 41 of size 1280
2021-11-01 17:04:49.241466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60cb00 next 44 of size 2048
2021-11-01 17:04:49.241473: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60d300 next 48 of size 2048
2021-11-01 17:04:49.241481: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60db00 next 49 of size 2048
2021-11-01 17:04:49.241490: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60e300 next 50 of size 4096
2021-11-01 17:04:49.241497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60f300 next 51 of size 2048
2021-11-01 17:04:49.241505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd60fb00 next 52 of size 2048
2021-11-01 17:04:49.241513: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd610300 next 53 of size 2048
2021-11-01 17:04:49.241521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd610b00 next 54 of size 2048
2021-11-01 17:04:49.241530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd611300 next 55 of size 256
2021-11-01 17:04:49.241537: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd611400 next 56 of size 256
2021-11-01 17:04:49.241546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd611500 next 57 of size 2048
2021-11-01 17:04:49.241568: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd611d00 next 59 of size 2048
2021-11-01 17:04:49.241575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd612500 next 60 of size 4096
2021-11-01 17:04:49.241583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd613500 next 61 of size 2048
2021-11-01 17:04:49.241591: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd613d00 next 62 of size 2048
2021-11-01 17:04:49.241598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd614500 next 63 of size 2048
2021-11-01 17:04:49.241606: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd614d00 next 64 of size 2048
2021-11-01 17:04:49.241613: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd615500 next 65 of size 2048
2021-11-01 17:04:49.241621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd615d00 next 66 of size 2048
2021-11-01 17:04:49.241628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd616500 next 67 of size 4096
2021-11-01 17:04:49.241636: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd617500 next 68 of size 2048
2021-11-01 17:04:49.241644: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd617d00 next 70 of size 2048
2021-11-01 17:04:49.241651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd618500 next 71 of size 2048
2021-11-01 17:04:49.241659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd618d00 next 72 of size 2048
2021-11-01 17:04:49.241667: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd619500 next 74 of size 2048
2021-11-01 17:04:49.241675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd619d00 next 75 of size 2048
2021-11-01 17:04:49.241683: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61a500 next 76 of size 256
2021-11-01 17:04:49.241690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61a600 next 77 of size 256
2021-11-01 17:04:49.241698: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61a700 next 78 of size 2048
2021-11-01 17:04:49.241706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61af00 next 79 of size 256
2021-11-01 17:04:49.241713: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61b000 next 80 of size 2048
2021-11-01 17:04:49.241722: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61b800 next 81 of size 2048
2021-11-01 17:04:49.241729: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61c000 next 82 of size 2048
2021-11-01 17:04:49.241737: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61c800 next 83 of size 2048
2021-11-01 17:04:49.241744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61d000 next 84 of size 2048
2021-11-01 17:04:49.241752: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61d800 next 85 of size 2048
2021-11-01 17:04:49.241760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61e000 next 86 of size 2048
2021-11-01 17:04:49.241767: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61e800 next 87 of size 2048
2021-11-01 17:04:49.241775: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61f000 next 88 of size 256
2021-11-01 17:04:49.241782: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61f100 next 89 of size 2048
2021-11-01 17:04:49.241790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd61f900 next 90 of size 6144
2021-11-01 17:04:49.241798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd621100 next 91 of size 2048
2021-11-01 17:04:49.241806: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd621900 next 92 of size 2048
2021-11-01 17:04:49.241813: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd622100 next 93 of size 2048
2021-11-01 17:04:49.241821: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd622900 next 97 of size 2048
2021-11-01 17:04:49.241828: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd623100 next 98 of size 2048
2021-11-01 17:04:49.241836: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd623900 next 103 of size 6144
2021-11-01 17:04:49.241844: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd625100 next 104 of size 6144
2021-11-01 17:04:49.241851: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd626900 next 118 of size 256
2021-11-01 17:04:49.241859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd626a00 next 115 of size 256
2021-11-01 17:04:49.241867: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd626b00 next 119 of size 256
2021-11-01 17:04:49.241874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd626c00 next 117 of size 256
2021-11-01 17:04:49.241882: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd626d00 next 124 of size 256
2021-11-01 17:04:49.241890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd626e00 next 106 of size 256
2021-11-01 17:04:49.241898: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd626f00 next 107 of size 256
2021-11-01 17:04:49.241905: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627000 next 113 of size 256
2021-11-01 17:04:49.241913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627100 next 131 of size 256
2021-11-01 17:04:49.241920: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627200 next 123 of size 256
2021-11-01 17:04:49.241928: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627300 next 112 of size 256
2021-11-01 17:04:49.241935: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627400 next 114 of size 256
2021-11-01 17:04:49.241943: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627500 next 105 of size 256
2021-11-01 17:04:49.241950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627600 next 137 of size 256
2021-11-01 17:04:49.241958: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627700 next 138 of size 256
2021-11-01 17:04:49.252116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627800 next 135 of size 256
2021-11-01 17:04:49.252135: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd627900 next 136 of size 16128
2021-11-01 17:04:49.252143: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd62b800 next 109 of size 32000
2021-11-01 17:04:49.252150: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd633500 next 126 of size 32000
2021-11-01 17:04:49.252156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd63b200 next 132 of size 16128
2021-11-01 17:04:49.252162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd63f100 next 133 of size 16128
2021-11-01 17:04:49.252169: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd643000 next 110 of size 16128
2021-11-01 17:04:49.252175: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd646f00 next 111 of size 16128
2021-11-01 17:04:49.252181: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd64ae00 next 120 of size 16128
2021-11-01 17:04:49.252188: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd64ed00 next 122 of size 16128
2021-11-01 17:04:49.252194: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd652c00 next 134 of size 16128
2021-11-01 17:04:49.252200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd656b00 next 139 of size 16128
2021-11-01 17:04:49.252207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd65aa00 next 108 of size 16128
2021-11-01 17:04:49.252213: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd65e900 next 129 of size 16128
2021-11-01 17:04:49.252219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd662800 next 130 of size 256
2021-11-01 17:04:49.252226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd662900 next 128 of size 4096
2021-11-01 17:04:49.252232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd663900 next 127 of size 12032
2021-11-01 17:04:49.252238: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd666800 next 121 of size 256
2021-11-01 17:04:49.252244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd666900 next 125 of size 256
2021-11-01 17:04:49.252260: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd666a00 next 116 of size 16128
2021-11-01 17:04:49.252267: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66a900 next 140 of size 256
2021-11-01 17:04:49.252273: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66aa00 next 141 of size 256
2021-11-01 17:04:49.252279: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ab00 next 142 of size 256
2021-11-01 17:04:49.252286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ac00 next 143 of size 256
2021-11-01 17:04:49.252292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ad00 next 144 of size 256
2021-11-01 17:04:49.252298: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ae00 next 145 of size 256
2021-11-01 17:04:49.252304: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66af00 next 146 of size 256
2021-11-01 17:04:49.252311: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b000 next 147 of size 256
2021-11-01 17:04:49.252317: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b100 next 148 of size 256
2021-11-01 17:04:49.252323: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b200 next 149 of size 256
2021-11-01 17:04:49.252329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b300 next 150 of size 256
2021-11-01 17:04:49.252336: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b400 next 151 of size 256
2021-11-01 17:04:49.252342: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b500 next 152 of size 256
2021-11-01 17:04:49.252348: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b600 next 153 of size 256
2021-11-01 17:04:49.252355: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b700 next 154 of size 256
2021-11-01 17:04:49.252361: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b800 next 155 of size 256
2021-11-01 17:04:49.252367: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66b900 next 156 of size 256
2021-11-01 17:04:49.252373: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ba00 next 157 of size 256
2021-11-01 17:04:49.252379: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66bb00 next 158 of size 256
2021-11-01 17:04:49.252386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66bc00 next 159 of size 256
2021-11-01 17:04:49.252392: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66bd00 next 160 of size 256
2021-11-01 17:04:49.252398: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66be00 next 161 of size 256
2021-11-01 17:04:49.252404: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66bf00 next 162 of size 256
2021-11-01 17:04:49.252410: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c000 next 163 of size 256
2021-11-01 17:04:49.252416: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c100 next 164 of size 256
2021-11-01 17:04:49.252422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c200 next 165 of size 256
2021-11-01 17:04:49.252428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c300 next 166 of size 256
2021-11-01 17:04:49.252435: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c400 next 167 of size 256
2021-11-01 17:04:49.252441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c500 next 168 of size 256
2021-11-01 17:04:49.252447: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c600 next 169 of size 256
2021-11-01 17:04:49.252453: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c700 next 170 of size 256
2021-11-01 17:04:49.252459: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c800 next 171 of size 256
2021-11-01 17:04:49.252465: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66c900 next 172 of size 256
2021-11-01 17:04:49.252472: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ca00 next 173 of size 256
2021-11-01 17:04:49.252478: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66cb00 next 174 of size 256
2021-11-01 17:04:49.252484: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66cc00 next 175 of size 256
2021-11-01 17:04:49.252490: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66cd00 next 176 of size 256
2021-11-01 17:04:49.252496: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ce00 next 177 of size 256
2021-11-01 17:04:49.252502: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66cf00 next 178 of size 256
2021-11-01 17:04:49.252508: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d000 next 179 of size 256
2021-11-01 17:04:49.252515: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d100 next 180 of size 256
2021-11-01 17:04:49.252521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d200 next 181 of size 256
2021-11-01 17:04:49.252527: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d300 next 182 of size 256
2021-11-01 17:04:49.252533: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d400 next 183 of size 256
2021-11-01 17:04:49.252540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d500 next 184 of size 256
2021-11-01 17:04:49.252546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d600 next 185 of size 256
2021-11-01 17:04:49.252553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d700 next 186 of size 256
2021-11-01 17:04:49.252559: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d800 next 187 of size 256
2021-11-01 17:04:49.252565: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66d900 next 188 of size 256
2021-11-01 17:04:49.252571: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66da00 next 189 of size 256
2021-11-01 17:04:49.252577: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66db00 next 190 of size 256
2021-11-01 17:04:49.252584: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66dc00 next 191 of size 256
2021-11-01 17:04:49.252590: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66dd00 next 192 of size 256
2021-11-01 17:04:49.252596: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66de00 next 369 of size 256
2021-11-01 17:04:49.252602: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66df00 next 365 of size 256
2021-11-01 17:04:49.252609: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e000 next 487 of size 256
2021-11-01 17:04:49.252615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e100 next 422 of size 256
2021-11-01 17:04:49.252621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e200 next 423 of size 256
2021-11-01 17:04:49.252628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e300 next 334 of size 256
2021-11-01 17:04:49.252634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e400 next 468 of size 256
2021-11-01 17:04:49.252640: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e500 next 318 of size 256
2021-11-01 17:04:49.252646: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e600 next 267 of size 256
2021-11-01 17:04:49.252653: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e700 next 425 of size 256
2021-11-01 17:04:49.252659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e800 next 216 of size 256
2021-11-01 17:04:49.252666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66e900 next 349 of size 256
2021-11-01 17:04:49.252672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66ea00 next 287 of size 256
2021-11-01 17:04:49.252678: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd66eb00 next 481 of size 16128
2021-11-01 17:04:49.252684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd672a00 next 290 of size 16128
2021-11-01 17:04:49.252691: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd676900 next 390 of size 32000
2021-11-01 17:04:49.252697: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd67e600 next 323 of size 32000
2021-11-01 17:04:49.252704: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd686300 next 309 of size 32000
2021-11-01 17:04:49.252710: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd68e000 next 364 of size 32000
2021-11-01 17:04:49.252717: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd695d00 next 227 of size 16128
2021-11-01 17:04:49.252723: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd699c00 next 373 of size 16128
2021-11-01 17:04:49.252729: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd69db00 next 278 of size 16128
2021-11-01 17:04:49.252735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6a1a00 next 360 of size 16128
2021-11-01 17:04:49.252742: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6a5900 next 346 of size 16128
2021-11-01 17:04:49.252748: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6a9800 next 449 of size 16128
2021-11-01 17:04:49.252755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6ad700 next 233 of size 16128
2021-11-01 17:04:49.252761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6b1600 next 341 of size 16128
2021-11-01 17:04:49.252767: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6b5500 next 284 of size 16128
2021-11-01 17:04:49.252773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6b9400 next 211 of size 16128
2021-11-01 17:04:49.252780: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6bd300 next 471 of size 16128
2021-11-01 17:04:49.252786: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6c1200 next 201 of size 16128
2021-11-01 17:04:49.252793: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6c5100 next 419 of size 16128
2021-11-01 17:04:49.252799: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6c9000 next 458 of size 16128
2021-11-01 17:04:49.252805: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6ccf00 next 299 of size 16128
2021-11-01 17:04:49.252811: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6d0e00 next 251 of size 16128
2021-11-01 17:04:49.252818: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6d4d00 next 465 of size 16128
2021-11-01 17:04:49.252824: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6d8c00 next 312 of size 16128
2021-11-01 17:04:49.252831: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dcb00 next 339 of size 256
2021-11-01 17:04:49.252837: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dcc00 next 427 of size 256
2021-11-01 17:04:49.252843: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dcd00 next 197 of size 256
2021-11-01 17:04:49.252849: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dce00 next 335 of size 256
2021-11-01 17:04:49.252856: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dcf00 next 461 of size 256
2021-11-01 17:04:49.252862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd000 next 432 of size 256
2021-11-01 17:04:49.252868: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd100 next 444 of size 256
2021-11-01 17:04:49.252874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd200 next 477 of size 256
2021-11-01 17:04:49.252881: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd300 next 212 of size 256
2021-11-01 17:04:49.252887: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd400 next 377 of size 256
2021-11-01 17:04:49.252893: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd500 next 243 of size 256
2021-11-01 17:04:49.252899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd600 next 337 of size 256
2021-11-01 17:04:49.252905: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd700 next 394 of size 256
2021-11-01 17:04:49.252911: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd800 next 223 of size 256
2021-11-01 17:04:49.252917: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dd900 next 385 of size 256
2021-11-01 17:04:49.252924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dda00 next 310 of size 256
2021-11-01 17:04:49.252930: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6ddb00 next 421 of size 256
2021-11-01 17:04:49.252936: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6ddc00 next 218 of size 256
2021-11-01 17:04:49.252942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6ddd00 next 396 of size 256
2021-11-01 17:04:49.252948: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6dde00 next 397 of size 256
2021-11-01 17:04:49.252954: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6ddf00 next 322 of size 4096
2021-11-01 17:04:49.252961: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6def00 next 297 of size 16128
2021-11-01 17:04:49.252967: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6e2e00 next 222 of size 16128
2021-11-01 17:04:49.252974: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6e6d00 next 362 of size 4096
2021-11-01 17:04:49.252980: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6e7d00 next 482 of size 12032
2021-11-01 17:04:49.252986: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6eac00 next 261 of size 16128
2021-11-01 17:04:49.252992: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f17cd6eeb00 next 271 of size 28160
2021-11-01 17:04:49.252999: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cd6f5900 next 409 of size 16128
2021-11-01 17:04:49.253005: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0x7f17cd6f9800 next 18446744073709551615 of size 26624
2021-11-01 17:04:49.253011: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 2097152
2021-11-01 17:04:49.253018: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cda00000 next 34 of size 1048576
2021-11-01 17:04:49.253025: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cdb00000 next 18446744073709551615 of size 1048576
2021-11-01 17:04:49.253031: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 4194304
2021-11-01 17:04:49.253038: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cdc00000 next 37 of size 1048576
2021-11-01 17:04:49.253044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cdd00000 next 39 of size 1048576
2021-11-01 17:04:49.253051: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cde00000 next 40 of size 1048576
2021-11-01 17:04:49.253057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0x7f17cdf00000 next 18446744073709551615 of size 1048576
2021-11-01 17:04:49.253063: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size:
2021-11-01 17:04:49.253074: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 128 Chunks of size 256 totalling 32.0KiB
2021-11-01 17:04:49.253081: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1280 totalling 1.2KiB
2021-11-01 17:04:49.253089: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 54 Chunks of size 2048 totalling 108.0KiB
2021-11-01 17:04:49.253096: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 9 Chunks of size 4096 totalling 36.0KiB
2021-11-01 17:04:49.253103: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 6144 totalling 24.0KiB
2021-11-01 17:04:49.253111: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 12032 totalling 58.8KiB
2021-11-01 17:04:49.253118: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 46 Chunks of size 16128 totalling 724.5KiB
2021-11-01 17:04:49.253125: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 16384 totalling 16.0KiB
2021-11-01 17:04:49.253132: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 6 Chunks of size 32000 totalling 187.5KiB
2021-11-01 17:04:49.253139: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 724992 totalling 2.77MiB
2021-11-01 17:04:49.253147: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 729088 totalling 712.0KiB
2021-11-01 17:04:49.253154: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 25 Chunks of size 1048576 totalling 25.00MiB
2021-11-01 17:04:49.253161: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 1449728 totalling 2.76MiB
2021-11-01 17:04:49.253168: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2048000 totalling 3.91MiB
2021-11-01 17:04:49.253175: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6144000 totalling 5.86MiB
2021-11-01 17:04:49.253182: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 26 Chunks of size 8189952 totalling 203.07MiB
2021-11-01 17:04:49.253190: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 24 Chunks of size 8192000 totalling 187.50MiB
2021-11-01 17:04:49.253197: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 8984576 totalling 8.57MiB
2021-11-01 17:04:49.253204: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 9771008 totalling 9.32MiB
2021-11-01 17:04:49.253211: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 11352064 totalling 10.83MiB
2021-11-01 17:04:49.253218: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 371101696 totalling 1.73GiB
2021-11-01 17:04:49.253225: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 438624256 totalling 418.30MiB
2021-11-01 17:04:49.253231: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 2.59GiB
2021-11-01 17:04:49.253238: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 3327262720 memory_limit_: 3327262720 available bytes: 0 curr_region_allocation_bytes_: 4294967296
2021-11-01 17:04:49.253248: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats:
Limit:                  3327262720
InUse:                  2777986560
MaxInUse:               2777986560
NumAllocs:                  604462
MaxAllocSize:            4386242562021-11-01 17:04:49.253278: W tensorflow/core/common_runtime/bfc_allocator.cc:424] x_____________****************
2021-11-01 17:04:49.253307: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cwise_ops_common.cc:82 : Resource exhausted: OOM when allocating tensor with shape[181202,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
*** Process received signal ***
Signal: Segmentation fault (11)
Signal code: Address not mapped (1)
Failing at address: 0x10
[ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x153c0)[0x7f1901b7b3c0]
[ 2] /home/apollo/miniconda3/envs/SimNet_conda/lib/python3.6/site-packages/tensorflow_core/python/…/libtensorflow_framework.so.1(_ZN10tensorflow13BaseGPUDevice7ComputeEPNS_8OpKernelEPNS_15OpKernelContextE+0x512)[0x7f18c4b64ef2]
[ 3] /home/apollo/miniconda3/envs/SimNet_conda/lib/python3.6/site-packages/tensorflow_core/python/…/libtensorflow_framework.so.1(+0xfaf19e)[0x7f18c4bbf19e]
[ 4] /home/apollo/miniconda3/envs/SimNet_conda/lib/python3.6/site-packages/tensorflow_core/python/…/libtensorflow_framework.so.1(+0xfaf64f)[0x7f18c4bbf64f]
[ 5] /home/apollo/miniconda3/envs/SimNet_conda/lib/python3.6/site-packages/tensorflow_core/python/…/libtensorflow_framework.so.1(_ZN5Eigen15ThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x291)[0x7f18c4c64e21]
[ 6] /home/apollo/miniconda3/envs/SimNet_conda/lib/python3.6/site-packages/tensorflow_core/python/…/libtensorflow_framework.so.1(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x48)[0x7f18c4c624b8]
[ 7] /home/apollo/miniconda3/envs/SimNet_conda/lib/python3.6/site-packages/tensorflow_core/python/…/…/…/…/libstdc++.so.6(+0xc819d)[0x7f18bd14119d]
[ 8] /lib/x86_64-linux-gnu/libpthread.so.0(+0x9609)[0x7f1901b6f609]
[ 9] /lib/x86_64-linux-gnu/libc.so.6(clone+0x43)[0x7f1901a96293]
*** End of error message ***
Segmentation fault (core dumped)Even I have RTX 5000 16GB with 32GB RAM, I get the same error when I run any example. Looks like Nvidia Modulus needs a HPC cluster. I am using their dockers image. The CUDA version is 11.0. I am getting the same error.One more thing, their example code doesn’t work on Jupyter notebooks.I found a potential solution. The Segmentation fault (core dumped) is encountered when you try to access memory that you do not have access to probably due to some memory error. Remember we are using Tf 1.15.So, the solution is to use an ECC RAM, which corrects the errors in the memory.Hello @prakhar_sharma, It looks like your are running out of memory when evaluating the results on the validation data. This can be fixed by adding the config option, rec_results_cpu: True like bellow. This will make the evaluation running on CPU instead of your GPU. This issue will be addressed in future releases by batching the evaluation.For the Jypyter notebook, the reason it doesn’t work is becuase of issues feeding in command line arguments. This can be fixed to a certain degree by setting the sys.argv manually like the following,This issue will also be addressed in the upcoming release.Powered by Discourse, best viewed with JavaScript enabled"
180,modulus-with-2022-3-3-version,"I’m using version 2022.3.3 and MODULUS doesn’t work, I can’t find it in WINDOW>EXTENSION.Could you please help me with this?Or should I use version 2022.2.0 or earlier? (Modulus Extension — Omniverse Extensions documentation)If so, where can I find the download link for previous versions?Thank you very much!Hi @contato48Yes, as mentioned in the docs “Currently the extension works with Omniverse USD Composer 2022.2.0 or older”. You should be able to select older version of Omniverse in the launcher.Disclaimer: The Modulus OV extension is presently paused for development. If you are interested in visualization I would suggest using Modulus to output VTK files then using the Paraview connector to render.Hi @ngeneva
Thanks for the feedbackMy goal is to generate CFD (Computational fluid dynamics) type physics simulations using Omniverse tools.Question: Would the only way be to use CREATE together with MODULUS or is there another APP that would allow me to do CFD simulations?Thank you very much for your attention.Powered by Discourse, best viewed with JavaScript enabled"
181,nvidia-modulus-failed-to-run-cublas-routine-cublas-status-execution-failed,"I was running Nvidia Modulus with bare-metal installation in a conda environment.I am getting this error failed to run cuBLAS routine: CUBLAS_STATUS_EXECUTION_FAILED. No idea how to fix this.Here is the whole error.Hello, we have release a new version of Modulus that uses PyTorch so this problem should be resolved now.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
182,periodic-boundary-conditions,"how can we create periodic boundary Condition in modulusHi @big4085bossThe best way is to force the inputs to be periodic. With MLP models, there is a periodicity parameter that can be used to periodic inputs for a given axis. This is done by applying a sine/cosine function on the input coordinates which then forces the prediction to be periodic. An example of this being used is in the Taylor Green Example.If this doesn’t work and you need to use a loss function, there’s multiple ways to approach this such as using a custom node to compute the values on each boundary for the loss or even a completely custom constraint. This is a bit more involved.how can we define boundary condition for a line (0 , 2Pi) and we want go give initial condition at 0 its is 0 and from Pi/4 to 3Pi/4 is 1 and then till 2Pi is 0.Powered by Discourse, best viewed with JavaScript enabled"
183,could-not-unroll-graph,"I created my PDE and nodes like:But adding my constraints fail with error:Any suggestions on how to fix this?Hi @cpe.skThanks for your interest in Modulus.
Let me see if I can help you better understand this error:####################################
could not unroll graph!
This is probably because you are asking to compute a value that is not an output of any node
####################################
invar: [x, y, sdf, area, t]
requested var: [wave_PDE]
computable var: [x, y, sdf, area, t, u]
####################################The symbolic graph failed to unroll (for PointwiseInteriorConstraint as we see right under this print out); this tells you high level info here. What the input variables are, the ones that need to be computed, and the intermediate ones that can currently be computed…So we know that we want wave_PDE but we only have the quantities x, y, sdf, area, t, u (u is from your NN which is revealed below:Nodes in graph:
node: Sympy Node: wave_PDE
evaluate: SympyToTorch
inputs: [S, c]
derivatives: [u__t__t, u__x__x, u__y__y]
outputs: [wave_PDE]
optimize: False
node: Arch Node: wave_network
evaluate: FullyConnectedArch
inputs: [x, y, t]
derivatives: 
outputs: [u]
optimize: True
####################################Here we see 2 nodes: wave_PDE and wave_network. The wave PDE we want to execute to get output residual but can’t, so we take a look at the inputs / derivatives:
inputs: [S, c]
derivatives: [u__t__t, u__x__x, u__y__y]Okay, so we can likely compute those derivatives because we have u from wave_network with inputs t,x,y. The problem here is that S,c don’t exist, so the computation isn’t possible.Now that we know what the issue is, we can work on a solution.  In your PointwiseInteriorConstraint the geometry is providing x and y. And the parameterization=time_range, is providing the t. So what you should do is add the missing variables S, c to your parameterization dictionary. E.g.
parameterization={Symbol(""t""): (0.0,1.0),  Symbol(""S""): 1.0,  Symbol(""c""):1.0}For more info, a good example of this is in the 3 fin example where complex parameterization are defined in the geometry file then used in the constraint.Thank you very much for the professional and detailed explanation. I sincerely appreciate it. It helped me understand a lot.
I have a follow-up question in this case:
“S” is the Source function (five points producing a signal from the specified locations) in my case which is supposed to be:and “c” is also a function like:How can I correctly implement them? Please advise. Thanks again!If your S and C are functions that depend on x,y,t then you need to provide Modulus a node to connect between x,y,t and s,c.One option is to use the Node.from_sympy function. Theres a few example of this in the provided examples such as the turbulent channel problem.Thanks. What if I wanted to solve the 2D wave equation with a point source placed at coordinates (x,y), what is the best way to define the source point?The case I’m trying to solve is a 2D wave equation with a source point function that looks something like this:
f(x=xs, y=ys) = sin (4 pi f t)The difficulties I’m facing:At this point I tried solving a 1D wave equation with a time dependent source point placed at one of the boundaries and it was successful. However, with the difficulties I mentioned, I do not know how to proceed to parameterizing the frequency f or expanding to 2D with source points within the domain.
validator_u1481×412 45.5 KB
I hope I explained my problem well. Please assist. Also, please ask me for further explanation if I missed something.Update: I have looked at the example in Interface Problem by Variational Method — Modulus 22.09 documentation about using a Dirac function for creating a point source, but I don’t fully understand how to apply it to the wave equation class.Hi @cpe.skIf you want to add a source to the 2D wave equation / change the PDE, you’ll need to create a custom PDE class for your problem. This should be simple enough for the wave equations because you can copy the existing class and add your forcing equation into the definition of that equation. The DiracDelta function can work for a point source, although this may require having a constraint specifically to train on the source point.The 1D wave equation example in our user guide, you’ve been working with creates a custom PDE.so is it still possible to add another parameterization for frequency f in addition to time t ?Yep, should be possible from my understanding here. Granted training will most likely take longer to converge and you may need a larger model. Just add it as another input to your network and define a range to sample f from in your parameterizationThank you for your reply!
I haven’t tried parameterization for this example yet, but I’m trying to implement the source points and I got the the following error:My original attempt code is :I’m suspecting it has to do with sympy. Any suggestions on how to fix this?Hi @cpe.skYes, this is a sympy error at the light where you’re defining wave_source_outvar[""s_func""]. Is there are reason you’re using sympy math operations here, could you change things to numpy operations like np.sin(*)? I’m assuming you’re calculating an array of target values here. Best to avoid mixing numpy and sympy together when possible, as they can lead to complications.It worked! Thank you!
The 2D validator plots have a significant error value. I’m trying to change the loss function type and the learning rate to fix this. Do you have any suggestions for that?As for the parameterization I was trying to attempt, I thought about testing it for 1D first. As I added the parameterization for frequency. I got this error:Here’s my trial code:Any ideas on how to get around this?UPDATE: I managed to run the code successfully by changing the parameterization definition to:And then using parameterization in the interior and boundary constraints. This got the code running without errors, however, I’m facing two other challenges:Please advise.@cpe.skGreat glad you’ve got things running.The results got a lot worse. So, I’m not sure if I’m implementing the parameterization correctly.Yes, looks like the model is really having a tough time learning. Start with lowering your parameterization range and increasing the size of your model / training points. Get the training working for this simpler set up then start increasing your parameterization range.How to plot the results for different parameterization values separately? Is there a good example that I can start from?I’m not sure off the top of my head. If you want to plot more results during training consider adding a plotter object for your validation or inference constraint. The default plotter classes can be found here. This should allow you to create multiple plots to your tensorboard report. Worse case you can create multiple constraints for evaluation each with a fixed parameterization.Start with lowering your parameterization range and increasing the size of your model / training points. Get the training working for this simpler set up then start increasing your parameterization range.I lowered the freq_range from (4,16) to (4,5) and increased the training points. Unfortunately, the results did not improve. I tried other solutions like testing another architecture model, fused_fully_connected and I got:So I used this command from Issues · NVlabs/nvdiffrec · GitHubpip install --global-option=""--no-networks"" git+https://github.com/NVlabs/tiny-cuda-nn#subdirectory=bindings/torchand tried running again:UPDATE:
I also tried using another arch model, the multiscale_fourier and got this error:Can you help me get around this?
Thank you so much for your support.Hi @cpe.skThe Fused Neural networks are highly optimized but not as robust (from an installation stand point) as the other Pytorch models. It will require TinyCUDADNN to be built on your machine for your specific CUDA version. I would advise against using this if possible when just prototyping / testing.For multiscale_fourier error, what does your code look like for constructing the model? Seems its complaining about the frequencies parameter being an interger when it needs to be something like a list or tuple. Please have a look at the API documentation for guidance on model parameters.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
184,variable-kinematic-viscosity-and-density-in-conjugate-heat-transfer,"Hi,i would ask how is it possible to add kinematic viscosity and density based on the equations that allow to calculate their value.
In Conjugate Heat Transfer example these quantities are constant. But if i want to get variable quantities based on their equations?
What the idea of the solutions can be? Because these equations involved also the temperature of the flow so, i think, that is not possible to solve flow net first and then thermal net as in the example.Thanks for your help!Hi @tom_02Making these variables a function should be possible. Note that when defining a PDE, many constants in the constructor allow for either a numeric, sympy expression or a string (kinematic viscosity in the N-S equations included).E.g. in the sympy case: the idea would be to define a sympy expression for your viscosity, feed this expression into the N-S PDE, and then create an additional Node for calculating the viscosity (the from_sympy() function is designed for this. )What the idea of the solutions can be? Because these equations involved also the temperature of the flow so, i think, that is not possible to solve flow net first and then thermal net as in the example.I think here you are thinking of having a fully coupled system here (flow depends on thermals, we can avoid this due to the properties of the problem). If thats the case, I would expect the training of the thermal/flow model would have to alternate (train one NN for X iterations then train the other NN for Y iterations and repeat). This is more of a research topic, that would require some experimenting.
The initial state may be tricky.Powered by Discourse, best viewed with JavaScript enabled"
185,error-when-applying-k-e-model-to-flow-over-airfoil-problem,"Hello, I am trying to apply k-e model to flow over 2D airfoil problem with Re = 1e5.
I have encountered a error when setting up the wall function constraint.
I generated a geometry that is a little bit thicker than the original airfoil, trying to make the y+ = 30. Then I use this as the geometry in the wall function constraint definition, as shown in the following:Then I got the error report on this constraint, it is:I have tried changing the geometry I provided to this constraint but it didn’t work. Can anyone help me with this problem?Thank you very muchHi @TinsenLYIts a little difficult to tell the exact problem here, but from I can tell its most likely because the geometry module is failing to sample the boundary of this geometry.Perhaps you can try to isolate the boundary to verify and just call:And see if that works, if it does try adding the parameterization:If the first fails theres a problem with your geometry, if the second fails its the parameterization.Hi @ngeneva ,Thanks for your advice, I tried to comment the parameterization line and the code comes up with an fail unroll graph error. I checked the log and find that “normal_distance” is required for the nodes to calculate variables like “velocity_wall_parallel_wf”, “ep_wf”, “k_wf”, “wall_shear_stress_x_wf”, “wall_shear_stress_y_wf”.Then I provided the paratmer “normal_distance” with the parameterization.In my case, I don’t need the normal_distance to calculate the geometry for wall function, I read in airfoil points and use the polygon method to generate the airfoil geometry. I read in the airfoil boundary geometries that I to apply wall function directly. Yet I still import the normal_distance  with the resolved_y_start value, which is a constant.Could you please help me figure out how the parameterization result in an error shown above?Hi @TinsenLYSo both of the code samples I gave work?What is resolved_y_start here? Again its hard to debug this with the limited code snippet here. These numpy printer problems typically occur when some node/variable is not returning data. But its hard to say.In my case, I don’t need the normal_distance to calculate the geometry for wall functionYes this is correct. Its just that parameters are sampled with geometry which is why I wanted to verify the geometry was first functioning.Powered by Discourse, best viewed with JavaScript enabled"
186,cannot-run-the-example-in-bare-metal-22-09-no-module-named-modulus-hydra,"Hello,I am a beginner in deep learning and PINNs, and I have enjoyed using Modulus in the container. However, I would like to try it on the bare metal as well, so I can use jupyter notebook.I followed the tutorial to install Modulus on Ubuntu 22.04, but I encountered an error when I ran the helmholtz.py example:from modulus.hydra import to_absolute_path, instantiate_arch, ModulusConfig ModuleNotFoundError: No module named ‘modulus.hydra’I tried to change the version of hydra.core==1.1.1, but it did not help. I am not sure what went wrong during the installation process. Could you please give me some advice or guidance on how to fix this issue?Thank you very much.Hi @gptkzmThis looks like Modulus was not properly installed fully. modulus.hydra lives in the Modulus package. So I would double check your Modulus install.Hello,I have a similar issue using Google Collab. When the code is inside a python file and executed by command:!python example.pythen it works. When I put the code directly into the notebook, then I have the error:ModuleNotFoundError: No module named 'modulus.hydra'There is no error during modulus installation.Hi @mateusz10Where did you install from (what repo did you clone)?I cloned the official repo (I guess):@gitlab.com/nvidia/modulus/modulus.gitIt is the same version number as OP’s.Finished processing dependencies for modulus==22.9@mateusz10This error is because it seems Modulus the package is not completely installed for some reason (not necessarily related to the dependencies). I would check the installation location of the modulus package to see if all the files are there.Can also check other imports such as from modulus.key import Key works. If this also fails, Modulus is not installed.Other imports also fail. But what is strange for me is that Modulus works when I execute it from a python file.I checked the installation location:/content/modulus/build/lib/modulus - correct me if I am wrongand get the following structure. Looks like Hydra is in there.I found the solution, which is restart the Runtime :-)I have the same issue here.File “helmholtz.py”, line 4, in 
from modulus.hydra import to_absolute_path, instantiate_arch, ModulusConfig
ModuleNotFoundError: No module named ‘modulus.hydra’However, when I run python 3.8 and runfrom modulus.key import Keyit works.Any ideas?@wolkerstorfergloria whats your environment and what version of Modulus are you using?Powered by Discourse, best viewed with JavaScript enabled"
187,parameterization-with-many-stl-files,"Is there any way to use different .stl files for different geometries during the training process and as a result have a network that can accept some discrete value that represents each geometry as an input? I have seen all the tutorials in the Modulus documentation but they either use a geometry built from CSG primitives only or a gPC approach without the parameterization.I don’t know for sure as I haven’t messed with it myself yet, but this is something I’m interested in as well. Looking at tesselation.py leads me to believe it’s possible via the parameterization input. How that’s used and what it’s used for I’m not certain on. I find the documentation and search to be difficult to navigate and find what I’m looking for, but here’s the option as seen in the source code.
https://docs.nvidia.com/deeplearning/modulus/modulus-v2209/api/modulus.geometry.html#modulus.geometry.parameterization.ParameterizationHi @gorpinich4Have a look at the parameterized tessellated geometry example here. If you can represent the different STL files as some sort of parameterization (that would perhaps be an input to a neural network) this should be possible.Hey @npstrikeI find the documentation and search to be difficult to navigate and find what I’m looking for.Thanks for the feedback, this is very useful. We are presently evaluating the documentation (we’ve just recently moved to this new system) to look for parts where we can improve. If you have any particular pain points (e.g. search doesn’t work well, structure is cumbersome) or any ideas for improvements we are always open to input from our users. Thanks!My apologies for being non-constructively critical, I appreciate your professionalism. There is one thing in particular that I seem to be struggling with regularly. I know there are documents that cover and explain the various classes and components of Modulus (e.g. tessellation.py), and I tend to look for those under the Modulus API portion of the side bar.
For example, if I’m looking for what loss values are available for the hydra configurator out of the box, I may find my way to this file via clicking through the Modulus API docs,
https://docs.nvidia.com/deeplearning/modulus/modulus-v2209/api/modulus.loss.html
However, what I’m really looking for is this, which is more difficult for me to navigate to, part because the search function seems to apply to all nvidia products (until the modulus filter is applied) and even then doesn’t seem to always get me to this page.
https://docs.nvidia.com/deeplearning/modulus/modulus-v2209/user_guide/features/configuration.htmlAs I’ve been writing this response, I’ve edited this last section many times. It took me a minute or two to find the second link, but I think I’ve identified my source of confusion. The documentation I’m often looking for appears to be under “Modulus Features” rather than “Modulus API.” To me, ‘Features’ makes it sound like it would contain marketing material rather than technical use documentation and so I don’t naturally check there. As a user, I don’t fully understand that title, or how it’s contents are intended to be different from the “Modulus API” section, but I think if the relevant docs were cross linked between the two different sources, or the naming was tweaked it may be more intuitive to me.When I skim the side bar I categorize the sections under two categories: topics intended to help me learn the platform, and secondly, reference docs (i.e. Modulus API). Perhaps this was a bad assumption on my part.No worries, this is very useful for us. Thank you. I agree the search currently leaves much to be desired. I’ll re-initiate talks with our docs team to see if it can get fixed. I’ll forward the rest of these comments to our team for review.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
188,how-to-create-a-digital-twin-with-only-data-driven,"I have made a set of simulations in ansys fluent where I parameterize two boundary conditions (entry and exit velocity)
of a 3d case. How can I make it so that with this set of simulations I can train a neural network (only data driven) on Nvidia modulus to be able to generate new solutions from the training data?
My goal is to create a digital twin from only data obtained from simulation and/or experiments.Hi @matiyanezYes, Modulus does allow for physic-driven, hybrid, and data-driven training. An example of a pure data-driven problem is the Darcy problem which has image like data.
For point wise data you can use the PointwiseConstraint.from_numpy() where you can feed in a set of numpy dictionaries to train from. This is used in a couple spots of our examples such as the three fin heat sink which can combined with other physics-based training constraints.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
189,automatic-differentiation-in-pino,"I was going through the documentation of Physics Informed Neural Operator (PINO) on Modulus Sym Guide page
https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/neural_operators/darcy_pino.htmlThe following block explains approaches for evaluating differential operators for residual computation in PINO.Defining PDE LossFor this example, a custom PDE residual calculation is defined using the various approaches proposed above. Defining a custom PDE residual using sympy and automatic differentiation is discussed in 1D Wave Equation, but in this problem you will not be relying on standard automatic differentiation for calculating the derivatives. Rather, you will explicitly define how the residual is calculated using a custom torch.nn.Module called Darcy. The purpose of this module is to compute and return the Darcy PDE residual given the input and output tensors of the FNO model, which is done via its .forward(...) method:Is there a way to implement automatic differentiation (AD) in PINO with modulus? Or do I need to write a custom “if-block” inside “forward” function of “Darcy” class defined in
https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/neural_operators/darcy_pino.html  to incorporate AD in PINO?Hi @shubhamsp2195The exact method built into Modulus uses partial AD with Fourier derivatives in the latent variables (this is the method proposed in the original paper). FNO / PINO is not like a point-wise model like many of the other PINNs models in modulus. So full AD does not work the same here. Could be possible however, we have not tried.Thank you @ngeneva for the information.Hi @ngeneva
Can we run PINO without data in modulus? The “Fourier gradient method” has been implemented in the following manner for Darcy problem in “darcy_PINO.py” file.This code includes “u” which I believe is being read from the dataset using the following code snippet.Is there a way to train PINO without data in Modulus Sym?Good question @shubhamsp2195Yes and no.From our testing, we found PINO did not have very good performance without data. Hybrid learning worked the best. But you could certainly try. There are many papers in the literature that achieve this.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
190,super-res-net-does-it-include-generator-and-discriminator-or-only-generator,"Dear all,In the documentation of the super_res_net, it is written that the code is based on the implementation of this github page (GitHub - sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution: Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network | a PyTorch Tutorial to Super-Resolution).
This github page has two architectures SRResNet and SRGAN.
The SRResNet  has only generator and the SRGAN has generator and discriminator.I am not sure of the super_res_net in Nvidia Modulus included the discriminator as well in the architecture or not.Thanks in advanceHi @omarkhaledsallamSRResNet inside of modulus is just the generator (convolutional decoder) architecture designed to bring a low resolution image to a higher-fidelity one. Some documentation on it can be found here and an example that can use it can be found here.Thanks for your reply,Does the Pix2Pix include both generator and discriminator?ThanksThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
191,problems-installing-the-pysdf-library-with-the-bare-metal-installation,"I am having problems with installing the PySDF library with the bare metal installation. It seems to install but when I very the installation it says that there is an import error.ImportError: libsdf.so: cannot open shared object file: No such file or directoryFor example when I install the PySDF library I get this output which suggests it was successful:

image1156×703 40.3 KB
But when I test if the library is installed correctly by running the aneurysm example I get this error:

image1422×445 29.4 KB
Or if I try and run the PINN that I built that uses STL file import

image1422×445 29.4 KB
If anyone has any idea how to help that would be much appreciated. I feel like I’ve maybe made a simple mistake somewhere.Thanks,
BenHave just seen that if using the SDF library with the bare metal version a Nvidia driver of 465.19 is required.
I am using google colab with a driver of 460.32.03. So I am assuming that this is the root of my issue.I had an error that pointed out to a bad gcc command. Installed gcc in the environment and it didn’t work. Installed cxx-container and it pysdf install was successful.Hello, unfortunately we decided to pull the pysdf support for the bare metal installation because it became too cumbersome to maintain. This is reflected in the installation instructions. If the tessellated geometry module is required then we suggest using the Docker image. We are pushing now to have pysdf released as a separate library but don’t have any release date for this. In the mean time we are looking into a slower fallback option when pysdf is not installed.Hi cabj, can you tell us how you did it?I tried to install pysdf in my own docker Modulus 22.09 using the prev 21.06 version and egg mtd according to:https://forums.developer.nvidia.com/t/pysdf-error-in-modulus-22-03/211327/6andhttps://forums.developer.nvidia.com/t/modulus-22-03-bare-metal-installation-no-module-named-easy-install/210970The 2nd mtd seems to work but I still get errors:Maybe your mtd can work.don’t know what you did. But if you can import pysdf.sdf there should be no problem. We were running the bare metal with tessellation for 6-7 months. Now we have switched to Apptainer.Powered by Discourse, best viewed with JavaScript enabled"
192,modulus-v22-03-docker-container-mpirun-issue,"Hi, thanks for your attention!
When I load the Modulus v22.03 docker container and want to run with multiple GPUs by mpirun -np 4 python ldc_2d.py, I met an issue as shown in the figure: mulitple process will shown on rank 0.

image1398×502 38.6 KB

Do you know the possible reason? The environment works well with Modulus v21.06.
Does anyone successfully run with multiple GPUs in Modulus v22.03 docker container with mpirun?
ThanksThis will make simulation hangs in there. Is this expected?
Any comments on how to solve this issue are appreciated?
@TomNVIDIA @ramc
ThanksHi @Shen666,I am hoping @ramc can help, as I am not a technical resource for Modulus.Thanks @TomNVIDIAHello, so the multiple processes on GPU 0 are expected. Can you post an output of where it hangs? We have not encountered this before. Does it run fine on a single GPU?Thanks @ohennigh. It runs fine on a single GPU.
For multiple GPUs, I run with mpirun -np 4 python ldc_2d.py or any other examples, it hangs after print [step 0] loss.

image1920×1102 266 KB
I’m suffering from the same issue. When I tried to run fpga_flow via mpirun it hangs right after the first step.Furthermore, after training it with a single GPU, I tried to run fpga_heat via mpirun and some error occurred. I suspected that it is related to the find_unused_parameters option in DDP, so I edited it to be False within continuous/constraints/constraint.py. At first glance it seemed it works as I saw all GPUs were being used through nvidia-smi, but the problem is that the training is not accelerated at all - at the same speed as a single GPU.Thanks @sy0319.kim for your experience.
@ramc @ohennigh This seems to be a common issue. I suggest you also test using NGC. Please let us know if you have any suggestions on the MPI hanging issuesWas this issue resolved? I am stuck with the same problem running 2 Quadro RTX 5000s. Running the examples with a single GPU works fine but whenever I try to utilize both using mpirun as explained here, the program will go through the first step then stop, leaving each GPU at 100% utilization indefinitely until I kill the program.Experiencing the same issue that the fpga froze after step 1. I am using the modulus 22.03 container.It turned out that if you turn off the validator,   the program will continue running.It is suggesting that there is a bug in validator whey applying multiGPU.Follow up with anyone running 22.03.There was a bug for FPGA multi-gpu that is related to the validator confusing DDP, as @yunchaoyang pointed out in 22.03. This has been corrected in 22.07. If the validator is absolutely needed in this version, you may want to try setting requires_grad=False to see if that fixes the hang or shut if off during training.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
193,gpu-compatibility-with-nvidia-modulus,"I am having a runtime error message with CUDA out of memory. I want to verify that the GPU chip is compatible with this software?
69757550403__2D5B2C33-14AE-4066-9E91-80E0CC5470361920×2560 307 KB
ThanksHi @isabella.hillmanThanks for your interest in Modulus. If Modulus (more importantly PyTorch) runs at all, then its theoretically compatible. However, Modulus requires decent VRAM (all deep learning does). If you do nvidia-smi this should tell you more information about your card installed.If this is running on a laptop then I would suggest looking at running Modulus remotely on a cluster. Maybe even a collab notebook. In our install notes there are some lists of GPUs we have tested for which can guide if your hardware is likely to be sufficient.Thank you @ngeneva for your response, which cleared up some questions.
I am still unsure if the Graphics listed in the above image as “NVIDIA Corporation / Mesa Intel Graphics (ADL GT2)” falls under any of the categories listed in the recommended hardware portion of the installation documentation.
As well, a common suggested change I found is to decrease the batch size. What would be the easiest way to implement this change in the example files? Can I directly change them in gitlab?Hi @isabella.hillmanYou will want to edit the config file for the example of interest on the machine you’re running on. Its a YAML so any text editor / IDE should do the trick. Once changed just re-run the example as you normally do and it will run with the updated settings.Powered by Discourse, best viewed with JavaScript enabled"
194,encountered-torch-tensor-shape-issue-when-trying-to-solve-a-transient-problem,"Hi,
I am interested to simulate a problem where I am applying an time varied extension at one end of the body and trying to visualize the stress generated as a function of time on the same.The following is my code for the same (using inbuilt Linear elasticity problem):But I am encountering the issue below:I don’t understand the error well here, like what is the error telling me to do? what are “a” & “b” here?  Though I dont face any issues in solving the static problem, thus making me curious why is this happening so in transient problem? is because of the introduction of time axis?Thank youHi @nihalpushkar11Looks like you’re failing to load a previous checkpoint:Perhaps you updated your model architecture so the previous checkpoint is outdated? Try renaming / deleting you old checkpoint and restarting the run.hi @ngeneva,
Thanks for the reply, deleting the same resolved the issue. But now encountered a new problem, the loss function is reaching Nans:could you please help me out with this, also please let me know if you need the scripts required to obtain this error, I would be happy to share it with you.Thank youHi @nihalpushkar11Unfortunately nans are quite more difficult to debug. I would suggest trying to single out which constraint is causing this issue. Once that’s identified then you can start to debug why this would be the case. It could also be something with the hyper-parameters your using, your loss calc, etc. Best of luck!sorry for not mentioning earlier, i have resolved the issue by enumerating the constraints and isolated the error segment 2 days before, thanks for the  reply.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
195,quadpy-now-requires-license,"I am working on a proof-of-concept demonstration project using Modulus, and am running into an issue with the quadpy package required for my use case.quadpy now requires a Sigma license, and now it checks a license server whenever the module is imported. This is hampering my development efforts due to our system restrictions. It will also make it more difficult for me to generate interest in the commercial use of Modulus going forward.Have any solutions been developed for this issue?@matthew.t.gillUnfortunately not at the moment. As you know this was originally developed when quadpy was free. We are not currently and don’t plan to develop this variational examples at the moment. We leave it to the user for quadpy access.Understood, thanks for getting back to me!Powered by Discourse, best viewed with JavaScript enabled"
196,how-to-define-2d-polygon-with-arbitrary-number-of-points,"Hi:
I wish to define 2D polygon with arbitrary  number of points (around 20 points).I wish to ask which option is better:
Option 0. Create a user-defined class to import 2D stl file.Option 1. Create a user-defined class of Polygon using sympy with exact signed distance function (SDF), first calculate the distance of an arbitrary point (x,y) to each line segment in the polygon, then use Sympy Min to obtain the minimum distance.
I tried this option, although Sympy function looks correct, the lambdify of the Sympy function will create a very ridiculous sdf output.Error executing job with overrides: 
An error occurred during Hydra’s exception formatting:
AssertionError()
Traceback (most recent call last):
File “/opt/conda/lib/python3.8/site-packages/hydra/_internal/utils.py”, line 252, in run_and_report
assert mdl is not None
AssertionErrorDuring handling of the above exception, another exception occurred:If I were you I would start from scratch. I have a code that is very close to Modulus but does not use sympy. I manually apply SDF, importance sampling, and other things. Here I get the freedom to use my own data points as the initial sample.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
197,how-to-create-multiple-custom-pdes-in-modulus,"I added a second PDE and am wondering is there anything additional I need to add to my script.Here I created the PDE class with the example of two PDEs. Is this the right way of doing it?class PFR_equation2D(PDE):
name = “PFR_equation2D”Hi @nga77This looks like your headed in the right direction! Although for your last line you’ll probably want to change the key value (PFR_equation) to something unique, otherwise you’ll overwrite the equation above it. E.g.Have a look at the 1D Wave example with its custom PDE as an example.I then validated both PDEs with two sets of data from two different CSV files, but I get an error that the CSV file cannot be found. I know that is not the actual error as the file is within the same directory.What am I actually doing wrong?
Below is a snippet of my code#add validation datac2 = np.loadtxt(“Concentration_data.csv”, delimiter=“,”)
c3=c2.reshape(2450,1) #reshaping array
c_outvar_numpy={“c”:c3}
validator = PointwiseValidator(
nodes=nodes,
invar=invar_numpy,
true_outvar=c_outvar_numpy,
batch_size=128,
plotter=ValidatorPlotter(),
)
domain.add_validator(validator, “val_data_c”)T2 = np.loadtxt(“Temperature_data.csv”, delimiter=“,”)
T3=T2.reshape(2450,1) #reshaping array
T_outvar_numpy={“T”:T3}
validator = PointwiseValidator(
nodes=nodes,
invar=invar_numpy,
true_outvar=T_outvar_numpy,
batch_size=128,
plotter=ValidatorPlotter(),
)
domain.add_validator(validator, “val_data_Temp”)Thank youHi @nga77This is because Hydra moves the local run location. Please use the following util:Here’s a sample of its usage from LDC example:Thank you!I changed my code accordingly and got the following error message:IndexError: index 2449 is out of bounds for dimension 0 with size 2449My csv file has two columns of data. Is there a right batch size that I am suppose to use or is there an error elsewhere in my code?Below is the validation section of my code.#add validation data
mapping = {“Concentration” : “c”,“Temperature” : “Temp”}
val_data = csv_to_dict(
to_absolute_path(“Val_data.csv”), mapping
)
val_outvar_numpy = {
key: value for key, value in val_data.items() if key in [“c”, “Temp”]
}
conc_validator = PointwiseValidator(
nodes=nodes,
invar=invar_numpy,
true_outvar=val_outvar_numpy,
batch_size=128,
plotter=ValidatorPlotter(),
)
domain.add_validator(conc_validator, “val_data”)Hi @nga77The batch size should be fine. Can you please confirm that all arrays in val_outvar_numpy are of the same size Nx1 where N=2449?Now, my program runs when I have all my independent and dependent variables in one CSV file.However, now I get a complex error message.
For the independent values, I had to change the scale to get the same number of rows for all columns in my CSV file. For example, my x-axis range is from of 0 to 1 with 2449 values in between. If these very small values are causing the problem, how else can I go about this?I have an inferencer output with the right plot, but I don’t get a plot for the validator output.error: <modulus.utils.io.plotter.ValidatorPlotter object at 0x7f67b5dd3340>.call raised an exception: QH6154 Qhull precision error: Initial simplex is flat (facet 1 is coplanar with the interior point)While executing:  | qhull d Qz Q12 Qt Qbb Qc
Options selected for Qhull 2019.1.r 2019/06/21:
run-id 916568361  delaunay  Qz-infinity-point  Q12-allow-wide  Qtriangulate
Qbbound-last  Qcoplanar-keep  _pre-merge  _zero-centrum  Qinterior-keep
Pgood  _max-width  1  Error-roundoff 1.4e-15  _one-merge 9.7e-15
Visible-distance 2.8e-15  U-max-coplanar 2.8e-15  Width-outside 5.5e-15
_wide-facet 1.7e-14  _maxoutside 1.1e-14The input to qhull appears to be less than 3 dimensional, or a
computation has overflowed.Qhull could not construct a clearly convex simplex from points:The center point is coplanar with a facet, or a vertex is coplanar
with a neighboring facet.  The maximum round off error for
computing distances is 1.4e-15.  The center point, facets and distances
to the center point are as follows:center point    0.449    0.449   0.4971facet p2449 p2448 p0 distance=    0
facet p722 p2448 p0 distance=    0
facet p722 p2449 p0 distance=    0
facet p722 p2449 p2448 distance=    0These points either have a maximum or minimum x-coordinate, or
they maximize the determinant for k coordinates.  Trial points
are first selected from points that maximize a coordinate.The min and max coordinates for each dimension are:
0:  0.0004083         1  difference= 0.9996
1:  0.0004083         1  difference= 0.9996
2:         0         1  difference=    1If the input should be full dimensional, you have several options that
may determine an initial simplex:If the input is lower dimensional:This is a snapshot of my CSV file
csv11041×193 43.4 KBHi @nga77My suggestion would be to create a custom plotter for this since your last two columns are nearly identical. This should be possible, you can extend / copy the ValidatorPlotter and write your own __call__ function to override it.Then just feed this into your PointwiseValidator. From there you can manipulate matplotlib however you like as long as you return a list[(figure, variable name)].In the built in plotters we do some assuming about the form of the data, so for unique cases like this a custom one will be best to give you the needed control.Hi @ngeneva
I fixed the data in my CSV file and using the CustomValidatorPlotter fixed my previous error. However, now I am getting a new error message:This is my code after importing all the necessary libraries:I tried doing two separate mappings for c and Temp, but that didn’t solve the problem. As you can see from the PDE equations I defined at the top of my code, the second equation relies on three variables and is linked to the other PDE. I believe I am almost close to the solution, but I am having problems fixing the error messagePowered by Discourse, best viewed with JavaScript enabled"
198,discretegeometry-with-parameterization-vs-transfer-learning,"Part of my simulation programmatically alters a geometry and adds each new geometry as a tessellation in a list provided to a discrete geometry.  It runs, but adding each new tessellation increases the memory usage by a significant amount.I’m using a 2070 with 6gb of ram locally, so I have to run at relatively small batch sizes for the constraints.  The values I use for a single geometry push it to 4gb used and each tessellation added to the discrete geometry adds ~1gb more.  Even on the target machines I’m “limited” to 15-20gb per gpu.I’d like to run on the order of 50-100 programmatically generated variations per original geometry.  If I were to dial back the batch size to fit in the memory limits, the accuracy would not be good.Would it make more sense to use transfer learning and use the trained model for the original geometry as a way to inference outputs?  I’m guessing that the main pitfall is that even with transfer learning I will still need to retrain the model for the modified geometries.  Is there any other way to reduce the memory usage for parameterized discrete geometries?Thanks!Hi @pattersonAs you mentioned the easiest way to lower memory usage is reducing batch size but this can impact training. Another alternative is to decrease the size of your neural network, but this will also likely lower accuracy. You could look into first order formulations of PDEs to additional auto-grads from running for higher-order derivatives but this is not always an option.One good option that may work for you is gradient aggregation (sorry no direct link, you’ll have to scroll down half way). The basic idea is to accumulate gradients over multiple mini-batches to mimic a larger batch size at the sacrifice of training time. This could help out here.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
199,modulus-dependent-on-specific-pytorch-git-commit-instead-of-available-releases,"In setting up a bare-metal modulus environment, I’m presented with warnings about TorchScript being unavailable because of unsupported PyTorch versionThis seems rather (unnecessarily) specific, and impossible to meet - short of building pytorch from source at the git commit point.Can the version checking be relaxed to match available pytorch cuda wheels in pip?
Looking at the pytorch container history in ngc, it seems like they’re all built on obtuse commit points:These release notes describe the key features, software enhancements and improvements, known issues, and how to run this container. The PyTorch framework enables you to develop deep learning models with flexibility, use Python packages such as SciPy,...And I had the same experience with the 22.03 Modulus release.
Warnings about not having PyTorch1.12.0a0+2c916ef despite installing 1.12.0+cu116 from pip.Hi @bsarkarThis commit is relates to the PyTorch commit used in the NGC PyTorch docker container we used as the base for building the Modulus image as I think you identified. The torch script requirement is there because presently we primarily serve Modulus through the docker image not, bare-metal, meaning that’s where our tests and performance analysis occurs.This requirement can likely be relaxed (warning can probably be ignored in most cases), but we need to set up the appropriate testing. Hopefully we will be able to do this in the near future. If you don’t want that requirement you should to just override it with setting jit: true in your config files which I think you’re doing already.Hi @ngeneva,Thanks for the reply.
I’ve actually been setting jit: false when I see that warning - I hadn’t thought to try forcing on, will give it a go now.My main surprise is that the PyTorch containers/blobs are being built on commit points in the first place - instead of the released tags - I’d expect the releases themselves to have a bit more reliability due to pytorch’s own CI/testing.Hi @bsarkarYes, the warning shows. If you want to comment that our its found in the trainer file.Yeah, the commit point is a little odd. I believe this is partially related to some internal work that occurs on the NV side to optimize/secure the container for deployment. Regardless, JIT has been a bit of a mixed bag for us over the past few months, so we put some hard constraints if Modulus will use it be default or not (user can always over ride).Powered by Discourse, best viewed with JavaScript enabled"
200,sympy-max-not-working-in-pde-cannot-determine-truth-value-of-relational,"I am interesting in modelling a damage model, where if a PINNs output exceeds a value then the governing equations changes, in linear elastic model only i need to check for the energy associated with deformation, and when it exceeds a certain value it needs to change the governing equation.I am interested in solving: {r1, r2 are pre-defined, |p| is value associated with energy, f is variable of interest}Unfortunately, the Max is not working,Thus I tried to approach the same by defining criteria check on by importing the equations for the same. But then it encounters type error with Sympy and float and I am unable to convert the sympy to numpy/floatPlease help me with this,Thank youSincerely,
NihalHi @nihalpushkar11Max should work, its registered in our sympy converter. With no additional information, its hard to tell what the issue is. One option could be to rewrite this function to use the Heaviside operator instead:Edit: I’m assuming this is referring this error here:For documentation purposes, this is a continuation of this thread:hello @ngeneva ,
Thanks for the reply and suggestion. Now I am successfully able to implement what I intend to.RegardsThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
201,how-to-load-modulus-on-ngc-images-with-nvidia-driver-460,"Usually the Nvidia driver version in NGC image is 460, while Modulus require 465.19 or higher.
I update Nvidia driver by sudo apt install nvidia-driver-465. But when load the Modulus container, it reports with “No supported GPU detected to run this container”.
Do you have any suggestions about load Modulus on NGC images with Nvidia driver 460?
Nvidia-smi works well both in and out the container. After update nvidia-version, the new nvidia-driver is 470.86 with CUDA 11.4.Powered by Discourse, best viewed with JavaScript enabled"
202,error-when-running-modulus,"I just went through the steps (Installation — Modulus 22.07 documentation)  to install Modulus and everything went fine.
However, when I try to run helmholtz.py from the command line I get the following error:This is not the best category to get a response from the Modulus team - so I am moving to a new sub-catgory.This is due to an incompatible hydra version. Downgrade the hydra version should fix this error. The docker image use version 1.1.1. So you can fix it by running pip install hydra-core==1.1.1Had the same issue while trying to get a bare metal installation on Google Colab. Running pip install hydra-core==1.1.1 helped for bypassing the error above, but now I am getting this new error:Hi @alvarez.jo.2017This error is the result of not having Git LFS installed. We use Git LFS in our examples repo to store the data files, without LFS it will just be a pointer file (which is what that sha hash is). Install Git LFS, reclone the examples repo and see if that fixes the problem (validation/helmholtz.csv should have data in it).Please see the warning box in the installation documentation with some additional information.Powered by Discourse, best viewed with JavaScript enabled"
203,plotting-3d-data-with-validator-plotter,"I was trying to plot validator results for data with 3 inputs (“x”, “y” and “t”) . The following variables were mapped to the corresponding columns of input csv file for validation.

mapping = {“time”: “t”, “x”: “x”, “r”: “y”, “Psi”: “Phi_2” }
csv_var = csv_to_dict(
to_absolute_path(“file.csv”), mapping
)
csv_invar_numpy = {
key: value for key, value in csv_var.items() if key in [“t”,“x”,“y”]
}
csv_outvar_numpy = {
key: value for key, value in csv_var.items() if key in [“Phi_2”]
}Validator of the following form was defined. The default ValidatorPlotter() was used here.

csv_validator = PointwiseValidator(
nodes=nodes,
invar=csv_invar_numpy,
true_outvar=csv_outvar_numpy,
batch_size=16,
plotter=ValidatorPlotter(),
)The default ValidatorPlotter class is capable of handling dimensions <= 2 only.  The following message is displayed while training the model.
[09:27:45] - [step:          0] record constraint batch time:  4.232e-01s
Default plotter can only handle <=2 input dimensions, passing
[09:27:45] - [step:          0] record validators time:  2.474e-01s
Are there other validator plotters in modulus which can take care of such problems? Also, is there a way to freeze one of the dimensions to enforce variation along the remaining two dimensions only? I tried removing the “y” dimension, but that lead to graph unrolling error due to insufficient number of specified inputs.Hi @shubhamsp2195Unfortunately no, the built in plotter for Tensorboard can only handle up to 2 dimensions. We put this limitation in since 3D data can arrive in different forms. You will likely need to define a custom validator method to do plotting of 3D data. An example that does this is the super-resolution turbulence problem where we output to a VTI format for viewing in para-view.Powered by Discourse, best viewed with JavaScript enabled"
204,scaling-and-nondimensionalizing-parameterized-geometry,"Hi,
I followed the recommendations (Linear Elasticity) to non-dimensionalize my pdes using characteristic length and characteristic displacement. Nevertheless, the bracket example is for a non-parameterized geometry and the bounds are (-1,1) in all x,y and z directions. My geometry (I-section beam) has bounds ((0,8),(0,125),(0,10)) thus i set up characteristic length to be 125. If i parameterize my geometry along (width,length and height), how do then setup the characteristic length. Do I set to the maximum length of the length range parameter or dynamically change for every beam geometry?
The tutorial also recommends scaling the geometry. If i scale the parametrized geometry with the length dimension to be bounded in the range (0,1), do i need to correspondingly change the characteristic length now to 1 and thus the question remains how does characteristic displacement and other parameters change?
Hope I made my issue clear. ThanksHi @k.narayananScaling / Nondimensionalization is a critical part of learning physical systems and each case needs to be handled differently depending on the physics at play. Regarding your question about scaling the bounds of the geometry, your approach sounds correct. You should define you characteristic length such that the non-dimensionalized spatial coordinates fall into a good range.However, this isn’t the end of the story. You need to make sure you adjust all other physical parameters for this new coordinate system (essentially anything that has a length unit will be effected. e.g. the force applied, stress tensor, etc.). There is some additional information on non-dimensionalizing the linear elastic equations here. We also have some support for using the Pint package which allows automatic scaling of variables. An example of this is the cylinder flow problem in the examples repo.So for every parameterized geometry, its own characteristic length and displacement are computed to make sure the coordinates are in the good range. In the documentation, a good range is defined as [-1,1], I have bounded (only the length as the width and height are smaller than the length, their bounds are much smaller ) by geometry to [0,1] and set up the nondimensionalization. Would this work too? Thanks a lot.Yes that should be fine. The key here is to scale the inputs for the machine learning model to improve convergence (similar to how you scale data in a traditional DL setting). What the absolute best scaling is a judgement call / empirical (again analogous to data-driven problems where you could min/max norm, guassian norm, etc.).Powered by Discourse, best viewed with JavaScript enabled"
205,modulus-vs-modulus-sym-post-processing-using-the-model-after-training,"Which modulus version should we use to run oour cases. I see that modulus-sym has the example cases and have been using that. For future cases we develop, should we use modulus or modulus-sym?Secondly, once a model is trained, how do we use it for a live example? or deploy it for our purposes?Thank youHi @mitanshtripWhich modulus version should we use to run oour cases. I see that modulus-sym has the example cases and have been using that. For future cases we develop, should we use modulus or modulus-sym?The goal of Modulus and Modulus-Sym are slightly different. Don’t think of these as versions, but rather different components / libraries of Modulus. Modulus (Core) is a more PyTorch developer orientated tool kit while Modulus-Sym provides an abstract framework with the symbolic loss representation. I.e. Are you interested in PINNs? Use Modulus-Sym. Are you a PyTorch developer looking at general Physics-ML, use Modulus (Core). Some discussion in our migration guide.Secondly, once a model is trained, how do we use it for a live example? or deploy it for our purposes?Please see the following thread:Powered by Discourse, best viewed with JavaScript enabled"
206,how-to-write-piecewise-function-in-the-source-of-a-poisson-equation,"my equation is :-(u_xx + u_yy + u_zz) = f(r)where r = sqrt(x**2 + y**2 + z**2)andf(r) = 1  for r < 0.5
f(r) = 0  for r > 0.5I have tried:but failed:I have searched the keyword piecewise on the examples but found nothing helpful.I am a very beginner so I dont know if there is some method to write such a source term.Thank you very much.Now I have tried to use Heaviside to solve this problem.
But I still dont know how to write the code if this piecewise function is not easy to be described by Heaviside function.Hi @Zhao-ZCInteresting that the piecewise function does not work. But you should be able to convert it into a Heaviside representation (e.g. this example here).Another option is to have two constraints, one for each part of the domain in your piecewise function. I.e have one constraint with a geometry that only contains the portion with the  source term 1 and another constraint with a geometry that only contains the portion with source term 2. Not the cleanest, but would allow you to address the PDE source term in a isolated forms.Multi-constraints is a good solution!
Thank you very much!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
207,trouble-installing-modulus-extension-ubuntu-22-04-lts,"Hi I’m trying to install the modulus extensionmy system is Ubuntu 22.04 LTS, 11th Gen Intel® Core™ i7-11850H @ 2.50GHz × 16, NVIDIA Corporation GA104GLM [RTX A5000 Mobile] / Mesa Intel® UHD.i ran Create 2022.1.3 from terminal window using ~/.local/share/ov/pkg/create-2022.1.3/omni.create.sh
the installation of the extension kicks up the network adapter then nothing happens after a while:

image2584×1585 122 KB

i’ve also navigated to /tmp and don’t actually see the zip file appearing (hidden files revealed with Ctrl+H)

image1267×1765 252 KB
this is my terminal log:Loading user config located at: ‘/home/samson/.local/share/ov/data/Kit/Create.Next/2022.1/user.config.json’
[Info] [carb] Logging to file: /home/samson/.nvidia-omniverse/logs/Kit/Create.Next/2022.1/kit_20220614_103227.log
[0.142s] [ext: omni.stats-0.0.0] startup
[0.156s] [ext: omni.gpu_foundation-0.0.0] startup
2022-06-14 02:32:27 [137ms] [Warning] [carb] FrameworkImpl::setDefaultPlugin(client: omni.gpu_foundation_factory.plugin, desc : [carb::graphics::Graphics v2.5], plugin : carb.graphics-vulkan.plugin) failed. Plugin selection is locked, because the interface was previously acquired by:
[0.159s] [ext: carb.windowing.plugins-1.0.0] startup
[0.164s] [ext: omni.assets.plugins-0.0.0] startup
[0.165s] [ext: omni.kit.renderer.init-0.0.0] startup
MESA-INTEL: warning: Performance support disabled, consider sysctl dev.i915.perf_stream_paranoid=0|---------------------------------------------------------------------------------------------|
| Driver Version: 510.73.5      | Graphics API: Vulkan
|=============================================================================================|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|---------------------------------------------------------------------------------------------|
| 0   | Intel(R) UHD Graphics (TGL GT1)  |        |     | 47984   MB | 8086      | 0          |
|     |                                  |        |     |            | 9a60      | 60e01855… |
|---------------------------------------------------------------------------------------------|
| 1   | NVIDIA RTX A5000 Laptop GPU      | Yes: 0 |     | 16384   MB | 10de      | 0          |
|     |                                  |        |     |            | 24b6      | f88a3084… |
|=============================================================================================|
| OS: Linux samson-HP-ZBook-Fury-15-6-inch-G8-Mobile-Workstation-PC, Version: 5.15.0-37-generic
| Processor: 11th Gen Intel(R) Core™ i7-11850H @ 2.50GHz | Cores: Unknown | Logical: 16
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 63979 | Free Memory: 60354
| Total Page/Swap (MB): 2047 | Free Page/Swap: 2047
|---------------------------------------------------------------------------------------------|
2022-06-14 02:32:29 [2,229ms] [Warning] [gpu.foundation.plugin] Disabling OpenGL Interop. Device 0 mismatched with OpenGL device: Mesa Intel(R) UHD Graphics (TGL GT1).
OpenGL can only run on the main GPU. It requires the app to run with activeDevice setting set to that GPU. On laptops, you may also need to specify which GPU or driver to run on in your system (Integrated or Discrete).
2022-06-14 02:32:29 [2,230ms] [Warning] [gpu.foundation.plugin] Realm: no OpenGL interop context.
2022-06-14 02:32:29 [2,283ms] [Warning] [carb.cudainterop.plugin] On Linux only, CUDA and the display driver does not support IOMMU-enabled bare-metal PCIe peer to peer memory copy.
However, CUDA and the display driver does support IOMMU via VM pass through. As a consequence, users on Linux,
when running on a native bare metal system, should disable the IOMMU. The IOMMU should be enabled and the VFIO driver
be used as a PCIe pass through for virtual machines.
[2.312s] [ext: omni.kit.window.splash-0.0.0] startup
[2.328s] [ext: omni.kit.async_engine-0.0.0] startup
[2.339s] [ext: omni.kit.agent-0.1.0] startup
[2.340s] [ext: omni.kit.splash-0.2.1] startup
[2.349s] [ext: omni.kit.pipapi-0.0.0] startup
[2.351s] [ext: omni.usd.config-1.0.0] startup
[2.351s] [ext: omni.usd.libs-1.0.0] startup
[2.493s] [ext: omni.kit.pip_archive-0.0.0] startup
[2.496s] [ext: omni.usd.schema.semantics-0.0.0] startup
[2.531s] [ext: omni.usd.schema.audio-0.0.0] startup
[2.536s] [ext: omni.hydra.iray-0.1.0] startup
[2.542s] [ext: omni.kit.telemetry-0.1.0] startup
[3.921s] [ext: omni.services.pip_archive-0.4.0] startup
[3.924s] [ext: omni.kit.loop-default-0.1.1] startup
[3.924s] [ext: omni.appwindow-1.0.0] startup
[3.927s] [ext: omni.client-0.1.0] startup
[3.933s] [ext: omni.kit.test-0.0.0] startup
[3.959s] [ext: omni.kit.renderer.core-0.0.0] startup
[4.124s] [ext: omni.ui-2.10.3] startup
[4.135s] [ext: carb.audio-0.1.0] startup
[4.159s] [ext: omni.kit.mainwindow-0.0.0] startup
[4.161s] [ext: omni.uiaudio-1.0.0] startup
[4.162s] [ext: omni.kit.uiapp-0.0.0] startup
[4.162s] [ext: omni.usd.schema.physics-1.0.0] startup
[4.170s] [ext: omni.usd.schema.anim-0.0.0] startup
[4.199s] [ext: omni.usd.schema.omnigraph-1.0.0] startup
[4.205s] [ext: omni.timeline-1.0.2] startup
[4.206s] [ext: omni.hydra.scene_delegate-0.2.0] startup
[4.211s] [ext: omni.kit.commands-1.2.2] startup
[4.213s] [ext: omni.kit.audiodeviceenum-1.0.0] startup
[4.214s] [ext: omni.usd-1.5.3] startup
[4.596s] [ext: omni.kit.asset_converter-1.2.30] startup
[4.610s] [ext: omni.usd.schema.forcefield-0.0.0] startup
[4.616s] [ext: omni.usd.fileformat.e57-0.1.6] startup
[4.616s] [ext: omni.usd.schema.sequence-2.0.11] startup
[4.623s] [ext: omni.usd.schema.destruction-0.2.1] startup
[4.628s] [ext: omni.usd.fileformat.sbsar-0.8.0] startup
[4.654s] [ext: omni.usd.schema.physx-0.0.0] startup
[4.674s] [ext: omni.services.transport.client.base-1.2.0] startup
[4.675s] [ext: omni.services.facilities.base-1.0.2] startup
[4.676s] [ext: omni.kit.widget.path_field-2.0.3] startup
[4.678s] [ext: omni.services.core-1.2.0] startup
[4.760s] [ext: omni.kit.search_core-1.0.2] startup
[4.761s] [ext: omni.services.client-0.3.0] startup
[4.762s] [ext: omni.services.transport.server.base-1.0.2] startup
[4.762s] [ext: omni.kit.widget.versioning-1.3.8] startup
[4.764s] [ext: omni.kit.widget.browser_bar-2.0.3] startup
[4.765s] [ext: omni.kit.widget.filebrowser-2.2.26] startup
[4.768s] [ext: omni.services.transport.client.http_async-1.2.1] startup
[4.768s] [ext: omni.services.transport.server.http-1.1.2] startup
[4.779s] [ext: omni.kit.notification_manager-1.0.5] startup
[4.781s] [ext: omni.kit.window.popup_dialog-2.0.7] startup
[4.783s] [ext: omni.kit.thumbnails.images-0.2.3] startup
[4.825s] [ext: omni.mdl.neuraylib-0.1.0] startup
[4.827s] [ext: omni.kit.window.filepicker-2.4.29] startup
UsdE57FileFormat
OmniAssetFileFormat
[4.871s] [ext: omni.mdl-0.1.0] startup
[4.884s] [ext: omni.kit.window.file_importer-1.0.4] startup
[4.885s] [ext: omni.kit.menu.utils-1.2.11] startup
[4.891s] [ext: omni.kit.stage_templates-1.1.2] startup
[4.892s] [ext: omni.kit.material.library-1.3.10] startup
[4.894s] [ext: omni.kit.window.file_exporter-1.0.4] startup
[4.895s] [ext: omni.kit.menu.create-1.0.2] startup
[4.895s] [ext: omni.kit.window.file-1.3.16] startup
[4.897s] [ext: omni.kit.window.drop_support-1.0.0] startup
[4.897s] [ext: omni.kit.context_menu-1.3.9] startup
[4.899s] [ext: omni.kit.window.content_browser-2.4.28] startup
[4.912s] [ext: omni.kit.window.property-1.6.3] startup
[4.913s] [ext: omni.kit.widget.graph-1.4.2] startup
[4.915s] [ext: omni.kit.widget.stage-2.6.15] startup
[4.918s] [ext: omni.kit.widget.prompt-1.0.1] startup
[4.918s] [ext: omni.kit.property.usd-3.14.8] startup
[4.941s] [ext: omni.hydra.engine.stats-1.0.0] startup
[4.949s] [ext: omni.kit.viewport.legacy_gizmos-1.0.0] startup
[4.952s] [ext: omni.hydra.pxr-1.1.0] startup
[4.954s] [ext: omni.graph.tools-1.3.5] startup
[5.045s] [ext: omni.renderer-rtx-0.0.0] startup
[5.046s] [ext: omni.hydra.rtx-0.1.0] startup
[5.051s] [ext: omni.debugdraw-0.1.0] startup
[5.056s] [ext: omni.graph.core-2.27.1] startup
[5.062s] [ext: omni.kit.widget.settings-1.0.0] startup
[5.066s] [ext: omni.graph-1.22.1] startup
[5.108s] [ext: omni.kit.window.viewport-0.0.0] startup
2022-06-14 02:32:33 [5,713ms] [Error] [omni.hydra.pxr] Cannot use omni.hydra.pxr without OpenGL interop
[5.806s] [ext: omni.kvdb-0.0.0] startup
[5.807s] [ext: omni.ui_query-1.1.1] startup
[5.808s] [ext: omni.kit.window.preferences-1.2.1] startup
[5.836s] [ext: omni.graph.ui-1.6.1] startup
[5.852s] [ext: omni.kit.ui_test-1.2.0] startup
[5.854s] [ext: omni.graph.action-1.17.1] startup
[5.862s] [ext: omni.kit.widget.searchfield-1.0.6] startup
[5.863s] [ext: omni.convexdecomposition-1.4.13] startup
[5.864s] [ext: omni.localcache-0.0.0] startup
[5.866s] [ext: omni.usdphysics-1.4.13] startup
[5.868s] [ext: omni.graph.scriptnode-0.5.0] startup
[5.870s] [ext: omni.physx-1.4.13-5.1] startup
[5.947s] [ext: omni.graph.nodes-1.25.0] startup
[5.960s] [ext: omni.kit.usd_undo-0.1.0] startup
[5.961s] [ext: omni.mdl.usd_converter-1.0.0] startup
MDL python binding about to load …
MDL python binding loaded
[omni.mdl.usd_converter] MDL to USD converter startup
[5.963s] [ext: omni.kit.selection-0.1.0] startup
[5.963s] [ext: omni.rtx.window.settings-0.6.1] startup
[5.967s] [ext: omni.kit.compatibility_checker-0.1.0] startup
[5.968s] [ext: omni.kit.stage.mdl_converter-1.0.0] startup
[5.969s] [ext: omni.anim.camera_tool-103.1.2] startup
[5.972s] [ext: omni.anim.shared-103.6.12] startup
[5.977s] [ext: omni.anim.curve-103.7.10] startup
[5.981s] [ext: omni.hydra.pxr.settings-1.0.2] startup
[5.982s] [ext: omni.kit.menu.file-1.0.8] startup
[5.983s] [ext: omni.kit.window.provide_feedback-1.0.1] startup
[5.984s] [ext: omni.anim.timeline-103.0.3] startup
[5.987s] [ext: omni.kit.collaboration.channel_manager-1.0.2] startup
[5.989s] [ext: omni.kit.viewport_widgets_manager-1.0.4] startup
[5.990s] [ext: omni.kit.window.cursor-1.0.1] startup
[5.992s] [ext: omni.kit.window.about-1.0.1] startup
[5.993s] [ext: omni.kit.collaboration.viewport.camera-1.0.1] startup
[5.994s] [ext: omni.graph.examples.cpp-1.0.0] startup
[5.997s] [ext: omni.kit.widget.imageview-1.0.1] startup
[5.997s] [ext: omni.kit.search.files-1.0.4] startup
[5.999s] [ext: omni.kit.window.imageviewer-1.0.6] startup
[6.000s] [ext: omni.kit.tool.asset_exporter-1.1.7] startup
[6.003s] [ext: omni.anim.window.timeline-103.5.18] startup
[6.006s] [ext: omni.services.browser.asset-1.2.7] startup
[6.021s] [ext: omni.kit.widget.timeline-103.1.25] startup
[6.023s] [ext: omni.kit.widget.stage_icons-1.0.2] startup
[6.024s] [ext: omni.kit.widget.layers-1.5.17] startup
[6.032s] [ext: omni.kit.browser.asset_provider.actorcore-1.0.5] startup
[6.034s] [ext: omni.kit.window.title-1.1.1] startup
[6.035s] [ext: omni.anim.curve_editor-103.7.11] startup
[6.043s] [ext: omni.kit.mesh.raycast-103.7.3] startup
[6.048s] [ext: omni.kit.graph.delegate.default-1.0.15] startup
[6.049s] [ext: omni.kit.hydra_texture-1.0.3] startup
[6.054s] [ext: omni.kit.graph.usd.commands-1.0.0] startup
[6.055s] [ext: omni.kit.widget.zoombar-1.0.3] startup
[6.056s] [ext: omni.kit.graph.editor.core-1.3.3] startup
[6.058s] [ext: omni.kit.widget.material_preview-1.0.5] startup
[6.059s] [ext: omni.kit.renderer.capture-0.0.0] startup
[6.061s] [ext: omni.kit.browser.core-2.0.12] startup
[6.063s] [ext: omni.kit.window.material_graph-1.5.0] startup
[6.097s] [ext: omni.kit.thumbnails.mdl-1.0.12] startup
[6.106s] [ext: omni.kit.browser.folder.core-1.1.13] startup
[6.108s] [ext: omni.kit.window.quicksearch-2.3.1] startup
[6.110s] [ext: omni.command.usd-1.0.1] startup
[6.113s] [ext: omni.physx.commands-1.4.13-5.1] startup
[6.116s] [ext: omni.kit.browser.material-1.2.8] startup
[6.117s] [ext: omni.kit.property.material-1.8.5] startup
[6.119s] [ext: omni.kit.menu.edit-1.0.6] startup
[6.120s] [ext: omni.physx.ui-1.4.13-5.1] startup
[6.171s] [ext: omni.kit.window.material-1.0.17] startup
[6.177s] [ext: omni.kit.window.toolbar-1.2.4] startup
[6.181s] [ext: omni.paint.system.core-103.2.7] startup
[6.188s] [ext: omni.kit.widgets.custom-0.6.4] startup
[6.193s] [ext: omni.physx.demos-1.4.13-5.1] startup
[6.195s] [ext: omni.kit.property.physx-0.1.0] startup
2022-06-14 02:32:33 [6,192ms] [Warning] [omni.physx.plugin] Deprecated: getSimulationEventStream is deprecated, please use getSimulationEventStreamV2
[6.216s] [ext: omni.physx.zerogravity-1.4.13-5.1] startup
[6.220s] [ext: omni.physx.tests-1.4.13-5.1] startup
[6.310s] [ext: omni.paint.system.ui-103.4.6] startup
[6.315s] [ext: omni.services.facilities.monitoring.progress-0.2.2] startup
[6.317s] [ext: omni.kit.window.console-0.2.0] startup
[6.323s] [ext: omni.physx.vehicle-1.4.13-5.1] startup
[6.330s] [ext: omni.kit.activity.widget.monitor-1.0.6] startup
[6.333s] [ext: omni.physx.cct-1.4.13-5.1] startup
[6.368s] [ext: omni.services.transport.client.idl_http_async-0.2.0] startup
[6.368s] [ext: omni.physx.camera-1.4.13-5.1] startup
[6.373s] [ext: omni.kit.widget.collection-0.1.8] startup
[6.375s] [ext: omni.services.facilities.monitoring.metrics-0.2.1] startup
[6.381s] [ext: omni.kit.activity.model.file_status-1.0.5] startup
[6.382s] [ext: omni.kit.activity.model.usd_status-1.0.5] startup
[6.382s] [ext: omni.kit.activity.model.cache_status-1.0.5] startup
[6.383s] [ext: omni.physx.bundle-1.4.13-5.1] startup
[6.383s] [ext: omni.kit.property.collection-0.1.7] startup
[6.384s] [ext: omni.services.thumbnails.mdl-0.1.3] startup
[6.387s] [ext: omni.kit.quicksearch.material-0.8.6] startup
[6.389s] [ext: omni.kit.quicksearch.commands-1.1.3] startup
[6.389s] [ext: omni.kit.activity.progress.bundle-1.0.2] startup
[6.390s] [ext: omni.paint.brush.scatter-103.1.13] startup
[6.394s] [ext: omni.ui.scene-1.4.7] startup
[6.398s] [ext: omni.kit.quicksearch.settings-0.8.4] startup
[6.399s] [ext: omni.kit.search.service-0.1.3] startup
[6.423s] [ext: omni.graph.expression-1.0.0] startup
[6.426s] [ext: omni.paint.brush.scripting-103.6.6] startup
[6.467s] [ext: omni.paint.brush.modify-103.1.6] startup
[6.473s] [ext: omni.kit.manipulator.transform-1.4.0] startup
[6.477s] [ext: omni.kit.viewport.registry-1.0.2] startup
[6.479s] [ext: omni.kit.manipulator.viewport-1.0.6] startup
[6.480s] [ext: omni.paint.brush.attribute-103.3.3] startup
[6.486s] [ext: omni.paint.brush.select-103.1.2] startup
[6.493s] [ext: omni.kit.window.status_bar-0.1.1] startup
[6.496s] [ext: omni.videoencoding-0.1.0] startup
[6.499s] [ext: omni.kit.property.layer-1.1.2] startup
[6.500s] [ext: omni.kit.manipulator.prim-1.5.2] startup
[6.503s] [ext: omni.kit.quicksearch.select-0.8.3] startup
[6.504s] [ext: omni.paint.system.bundle-103.3.14] startup
[6.504s] [ext: omni.rtx.settings.core-0.5.5] startup
[6.507s] [ext: omni.kit.capture.viewport-1.1.9] startup
[6.510s] [ext: omni.kit.property.audio-1.0.5] startup
[6.511s] [ext: omni.kit.property.skel-1.0.1] startup
[6.512s] [ext: omni.kit.property.render-1.1.0] startup
[6.513s] [ext: omni.kit.property.camera-1.0.3] startup
[6.514s] [ext: omni.kit.property.geometry-1.2.0] startup
[6.515s] [ext: omni.kit.tool.collect-2.1.6] startup
[6.518s] [ext: omni.kit.property.light-1.0.5] startup
[6.519s] [ext: omni.kit.widget.sliderbar-1.0.10] startup
[6.520s] [ext: omni.kit.property.transform-1.0.2] startup
[6.522s] [ext: omni.kit.tool.asset_importer-2.3.20] startup
[6.525s] [ext: omni.kit.menu.aov-1.1.1] startup
[6.526s] [ext: omni.kit.browser.asset-1.1.7] startup
[6.527s] [ext: omni.kit.window.section-103.2.7] startup
[6.533s] [ext: omni.kit.environment.core-1.0.27] startup
[6.543s] [ext: omni.kit.property.bundle-1.2.4] startup
[6.543s] [ext: omni.kit.primitive.mesh-1.0.0] startup
[6.546s] [ext: omni.kit.widget.calendar-1.0.5] startup
[6.548s] [ext: omni.flowusd-0.1.0] startup
[6.554s] [ext: omni.iray.settings.core-0.6.3] startup
[6.559s] [ext: omni.kit.property.sbsar-0.8.0] startup
[6.561s] [ext: omni.kit.browser.asset_provider.local-1.0.7] startup
[6.563s] [ext: omni.kit.property.environment-1.0.13] startup
[6.565s] [ext: omni.kit.pointclouds-0.0.11] startup
[6.567s] [ext: omni.kit.window.movie_capture-1.2.12] startup
[6.570s] [ext: omni.kit.window.usd_paths-1.0.3] startup
[6.571s] [ext: omni.kit.quicksearch.actions-0.8.10] startup
[6.573s] [ext: omni.kit.window.environment-1.1.5] startup
[6.575s] [ext: omni.kit.graph.delegate.modern-1.6.0] startup
[6.576s] [ext: omni.kit.graph.widget.variables-2.0.2] startup
[6.577s] [ext: omni.kit.thumbnails.usd-0.5.1] startup
[6.579s] [ext: omni.services.starfleet.auth-0.1.2] startup
[6.584s] [ext: omni.graph.visualization.nodes-1.1.1] startup
[6.587s] [ext: omni.scene.visualization.core-103.4.1] startup
[6.594s] [ext: omni.graph.window.core-1.22.1] startup
[6.599s] [ext: omni.anim.retarget.core-103.1.14] startup
[6.603s] [ext: omni.graph.io-1.0.10] startup
[6.608s] [ext: omni.ramp-103.0.10] startup
[6.613s] [ext: omni.graph.instancing-1.1.4] startup
[6.617s] [ext: omni.graph.tutorials-1.1.2] startup
[6.627s] [ext: omni.graph.window.action-1.3.8] startup
[6.628s] [ext: omni.anim.graph.core-103.1.23] startup
2022-06-14 02:32:33 [6,610ms] [Warning] [omni.graph.core.plugin] Found duplicate of category ‘animation’ - was ‘Nodes dealing with Animation.’, adding ‘’
2022-06-14 02:32:33 [6,610ms] [Warning] [omni.graph.core.plugin] Found duplicate of category ‘animation’ - was ‘Nodes dealing with Animation.’, adding ‘’
2022-06-14 02:32:33 [6,610ms] [Warning] [omni.graph.core.plugin] Found duplicate of category ‘animation’ - was ‘Nodes dealing with Animation.’, adding ‘’
2022-06-14 02:32:33 [6,610ms] [Warning] [omni.graph.core.plugin] Found duplicate of category ‘animation’ - was ‘Nodes dealing with Animation.’, adding ‘’
[6.633s] [ext: omni.particle.system.core-103.3.0] startup
[6.641s] [ext: omni.kit.window.stage-2.3.7] startup
[6.643s] [ext: omni.curve.creator-1.1.1] startup
[6.646s] [ext: omni.graph.bundle.action-1.0.0] startup
[6.646s] [ext: omni.kit.widget.searchable_combobox-1.0.4] startup
[6.647s] [ext: omni.graph.window.particle.system-103.1.14] startup
[6.649s] [ext: omni.particle.system.ui-103.2.0] startup
[6.656s] [ext: omni.curve.manipulator-103.4.0] startup
[6.665s] [ext: omni.curve.nodes-103.3.1] startup
[6.674s] [ext: omni.kit.browser.sample-1.0.5] startup
[6.675s] [ext: omni.kit.quicklayout-1.0.1] startup
[6.676s] [ext: omni.particle.system.bundle-103.2.20] startup
[6.676s] [ext: omni.kit.window.collection-0.1.8] startup
[6.677s] [ext: omni.anim.graph.ui-103.1.31] startup
[6.685s] [ext: omni.kit.browser.asset_provider.sketchfab-1.0.9] startup
[6.686s] [ext: omni.kit.window.script_editor-1.6.2] startup
[6.691s] [ext: omni.kit.window.extensions-1.1.0] startup
[6.694s] [ext: omni.kit.window.privacy-0.1.0] startup
[6.695s] [ext: omni.anim.skelJoint-103.2.20] startup
[6.698s] [ext: omni.anim.graph.bundle-103.1.4] startup
[6.699s] [ext: omni.kit.menu.common-1.0.0] startup
[6.700s] [ext: omni.create.app.resources-2022.1.0] startup
[6.700s] [ext: omni.services.usd-1.0.1] startup
[6.702s] [ext: omni.anim.retarget.ui-103.1.12] startup
[6.707s] [ext: omni.kit.quicksearch.hdri-0.8.8] startup
[6.708s] [ext: omni.kit.stage_column.variant-1.0.3] startup
[6.710s] [ext: omni.kit.sequencer.usd-103.1.4] startup
[6.712s] [ext: omni.kit.quicksearch.menu-0.8.6] startup
[6.713s] [ext: omni.kit.browser.asset_store-1.0.0-beta.25] startup
[6.716s] [ext: omni.anim.retarget.bundle-103.1.5] startup
[6.717s] [ext: omni.kit.widget.extended_searchfield-1.0.11] startup
[6.721s] [ext: omni.kit.widget.live-0.1.0] startup
[6.725s] [ext: omni.kit.sequencer.core-103.1.2] startup
[6.726s] [ext: omni.kit.preferences.time-0.0.6] startup
[6.730s] [ext: omni.kit.property.sequence-0.0.5] startup
[6.731s] [ext: omni.kit.profiler.window-1.4.4] startup
[6.734s] [ext: omni.kit.browser.asset_provider.turbosquid-1.0.7] startup
[6.735s] [ext: omni.kit.viewport.ready-1.0.1] startup
[6.736s] [ext: omni.kit.stage_column.payload-1.0.6] startup
[6.737s] [ext: omni.graph.window.generic-1.3.8] startup
[6.738s] [ext: omni.kit.quicksearch.props-0.8.5] startup
[6.738s] [ext: omni.kit.window.sequencer-103.1.9] startup
[6.753s] [ext: omni.create.app.setup-2022.1.0] startup
[6.755s] [ext: omni.kit.window.stats-0.1.1] startup
[6.756s] [ext: omni.create-2022.1.3-rc.10] startup
[6.929s] app ready
[11.709s] RTX ready
[61.048s] [ext: omni.kit.registry.nucleus-0.0.0] startup
[73.179s] Async pulling extension: modulus_ext.core-22.3.1 from the registry.
[omni.kit.registry.nucleus]: [omni.kit.registry.nucleus]: downloading: ‘https://kit-103-0-public-extensions.s3.amazonaws.com/public/3/archives/modulus_ext.core-22.3.1+lx64.r.cp37.zip’ → ‘/tmp/tmp2f1pl3hc/modulus_ext.core-22.3.1+lx64.r.cp37.zip’…I have the same problem tooPowered by Discourse, best viewed with JavaScript enabled"
208,about-fixed-dataset-and-importance-measure,"I am using Modulus to solve a PDE equation. And I want to use importance_measure to sample more points in the area where the constraint violation is larger.As the notes in the description of  fixed_dataset, if I set fixed_dataset = True, the points are fixed and will not be resampled in the train process.How ever, I want to resample the points, so I should set fixed_dataset to False?But Modulus will give an error:Did I misunderstand something?Hi @Zhao-ZCYou’re correct in your understanding of fixed_dataset. The importance sampling works by weighting the points in a fixed dataset, so ones of more importance are sampled more frequently. I.e. in the API docThis means we are resampling the existing points already from the geometry (yeah its a bit confusing with having different processes sampling different things). If you’re interested the code for this process lives in DictImportanceSampledPointwiseIterableDataset which consumes two dictionaries of finite size (your points sampled from the geometry). This is the dataset that is created in the constraint when you use importance sampling.Powered by Discourse, best viewed with JavaScript enabled"
209,fourier-and-inverse-fourier,"how can we use Fourier and inverse Fourier transformation using modulus.
suppose we have some equation and we want to solve it using Semi-Implicit Fourier-Spectral Method,Hi @big4085bossYou can do any sort of manipulation of data through custom nodes which can then get chained in your constraint, so long as auto-diff can work with it. Nodes just add some meta data to torch modules, so what exactly you do inside of there it up to you so long that you symbolically define what the input / output is. Our FNO model uses PyTorch’s FFTs under the hood.If things are even more complex, you may have to write a custom constraint.Powered by Discourse, best viewed with JavaScript enabled"
210,boundedness-of-network-output,"Hello,I’m trying to extend the Navier-Stokes PDEs to multiphase flows using Volume Of Fluid (VOF) approach, as it is done here. This requires to compute an auxiliary variable ‘alpha’ that represents the volume fraction of fluid (e.g. water), and that is bounded between 0 and 1.I’m looking for a way to specify a sigmoid activation function for this output only, leaving the other output activations unchanged. However, I can’t see a simple way to implement that with Modulus. Is there a way to do that?Thank you,
MicheleHi @michele.messina.95Thanks for using Modulus!My recommended approach would be to define a temporary version of this variable (alpha_hat). You neural network model will predict this variable plus others (e.g. u,v,p,alpha_hat). Now we define a custom node that goes from alpha_hat → alpha. E.g.Then just add this to your node list and keep all your PDEs / loss functions the same. Operating through temporary variables / fields to make more customized outputs should be very flexible.This is working well! Thank you for your quick reply.MicheleThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
211,loading-modulus-container-in-pycharm,"Hi Sir/Madam,I tried to follow the tutorial on modulus, but I cannot debug the code since I cannot import modulus in my PyCharm IDE.How can I load the modulus container in the PyCharm IDE? And how can I modify and debug the source code in the modulus container?Thanks.Hi @dehao.liu12For details on managing docker containers in PyCharm, I would suggest looking at PyCharm documentation.To edit/develop the source code of Modulus I would suggest the following process:This will allow any edit to the source code to take effect inside the docker container / installed Modulus package.Hi, I’m really new to this forum (hence I don’t know where to start a new thread) and also new to NVIDIA developer, ML and Modulus, I actually haven’t used it yet and that’s why I have the following question:Thanks for the responses.Hi @user87462Most of Modulus will function is PyTorch can function using the bare-metal install. Only a few features will not be available. However, the examples provided may need to have their parameters or model size adjusted based on the hardware you are using.Next time, please create a new post by clicking on the relevant category (e.g. technical support) then clicking “New Topic”. Thanks.Hi ngeneva,Thanks for your reply. I can run and debug the code in /examples folder by loading the modulus image first into the docker container. I want to add new pdes in modulus.eq.pdes now so that I can run test new examples.In order to develop the source code of Modulus, I need to mount the source code in the docker container by using the -v option. Do I need to load the modulus image into the docker first? If so, when I modify the source code of Modulus, the example script will import the modulus module in the source code or the modulus module in the modulus image?I wish that the Modulus team can provide more detailed documentation on the developing procedure for the Modulus so that more users can use and contribute to the Modulus package.Thanks.Best,DehaoHi @dehao.liu12Thanks for the feedback, we are actively working on making it easier for people to contribute / customize / extend Modulus.Regarding you question, individual responses are below:In order to develop the source code of Modulus, I need to mount the source code in the docker container by using the -v option.Correct, -v mounts a directory on your local machine into the docker image. This allows you to edit files on in your file system as opposed to inside the image itself. Any edits to these files outside the docker container will be updated inside the container.Do I need to load the modulus image into the docker first?Yes, you want to use the Modulus container because this has all the dependencies installed. The idea is to mount your own Modulus source code, then overload the container Modulus via a python install.If so, when I modify the source code of Modulus, the example script will import the modulus module in the source code or the modulus module in the modulus image?Correct, if you python setup.py develop using your mounted version inside the container this will be prioritized when running the examples (when you import modulus). The “develop” install will allow you to make edits to the source code and immediately have the changes impact and script that imports Modulus.Hopefully this helps, let me know if you have additional questions.Powered by Discourse, best viewed with JavaScript enabled"
212,quasi-random-sampling-seems-not-to-work-for-three-fin-2d,"Hello,I would like to apply Quasi-Random Sampling to three_fin_2d but it seems not to work.
Please refer to the attached  image.
quasi-random872×924 385 KB
I added quasirandom code in config.yaml and heat_sink.py.
Are anything else necessary?Regards,Powered by Discourse, best viewed with JavaScript enabled"
213,why-the-result-with-openacc-is-different-without-openacc-in-the-following-code,"I write a following example to test acc routine declared with ‘!$acc routine seq’. But I found the result is different between openacc and non-openacc. I am confused to find the reason. Could anyone help me? Thank you very much!Code example:
test.f90:
program test
use mod_a
integer :: i,j,k
call fun_up()
k=100
!$acc update host(a)
write(,) “1st, a=”,a
!$acc parallel loop seq present(a) copyin(k)
do i=1,10
do j=1,10
a(j,i)=a(j,i)+k
k=k+1
end do
end do
!$acc update host(a)
write(,) “2nd, a=”,a
end programmodule mod_a
module mod_a
integer :: a(10,10)
!$acc declare create(a)
contains
subroutine fun_up()
!$acc routine seq
integer :: i,j
k=1
do i=1,10
do j=1,10
a(j,i)=k
k=k+1
end do
end do
call fun_down()
end subroutine
subroutine fun_down()
!$acc routine seq
integer :: i,j
k=10
do i=1,10
do j=1,10
a(j,i)=a(j,i)+k
k=k+1
end do
end do
end subroutine
end moduleResults without openacc (nvfortran -o test.exe test.f90  mod_a.f90)
1st, a=           11           13           15           17           19
21           23           25           27           29           31
33           35           37           39           41           43
45           47           49           51           53           55
57           59           61           63           65           67
69           71           73           75           77           79
81           83           85           87           89           91
93           95           97           99          101          103
105          107          109          111          113          115
117          119          121          123          125          127
129          131          133          135          137          139
141          143          145          147          149          151
153          155          157          159          161          163
165          167          169          171          173          175
177          179          181          183          185          187
189          191          193          195          197          199
201          203          205          207          209
2nd, a=          111          114          117          120          123
126          129          132          135          138          141
144          147          150          153          156          159
162          165          168          171          174          177
180          183          186          189          192          195
198          201          204          207          210          213
216          219          222          225          228          231
234          237          240          243          246          249
252          255          258          261          264          267
270          273          276          279          282          285
288          291          294          297          300          303
306          309          312          315          318          321
324          327          330          333          336          339
342          345          348          351          354          357
360          363          366          369          372          375
378          381          384          387          390          393
396          399          402          405          408Results with openacc (nvfortran -acc -Minfo=all -o test.exe test.f90  mod_a.f90)
1st, a=            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0            0
0            0            0            0            0
2nd, a=          100          101          102          103          104
105          106          107          108          109          110
111          112          113          114          115          116
117          118          119          120          121          122
123          124          125          126          127          128
129          130          131          132          133          134
135          136          137          138          139          140
141          142          143          144          145          146
147          148          149          150          151          152
153          154          155          156          157          158
159          160          161          162          163          164
165          166          167          168          169          170
171          172          173          174          175          176
177          178          179          180          181          182
183          184          185          186          187          188
189          190          191          192          193          194
195          196          197          198          199Powered by Discourse, best viewed with JavaScript enabled"
214,training-with-multiple-geometries,"I would like to train a more general model that can predict flow over an arbitrary 2D airfoil. I have successfully trained models on a single geometry and a single geometry with parameterized boundary conditions.Is it possible to train a model on a number of different nonparametric geometries?In other data driven frameworks it is a matter of passing in a large number of example geometries. From the documentation it appears that modulus either requires the geometry to be parameterized or the model to be retrained using transfer learning for each geometry.Any advice would be welcome. Thank youHi @LimitingFactorIf I’m using it correctly, which I’m still not sure about, then the answer is yes!  They have an example in the geometry folder of their examples:Gitlab Parameterized Tesselated ExampleThis appears to work for STL files and based on a quick look at their code for discrete geometry I think it would work for 2D geometry constructions.  Disclaimer: I barely know what I’m doing with Modulus and python isn’t my first language so I could be wrong.Powered by Discourse, best viewed with JavaScript enabled"
215,transfer-learning-with-mulitple-gpus,"I’ve got a program that runs on multiple GPUs, but would like to use the outputted model for transfer learning in a similar geometric case (different enough that I believe the parametric approach won’t be accurate).When running the modified geometry I include the outputted model “flow_network.0.pth” in an otherwise empty outputs folder.  When examining the output, I can see that the model is loaded:However, I can also see that it is not loading the model for other GPUs:When including the model, is the best practice to simply copy the outputted and saved model to however many GPUs you are planning to use? Meaning, ‘flow_network.0.pth’ gets copied to **.1.pth, **.2.pth, … **.n.pth.I’ve been operating on the assumption that the model weights are combined at the end of training and that is the reason that there is only one model saved. If that is not the case, is there a reason that I am only seeing one final outputted model when running in parallel? At the moment I run on 8 GPUs, but only ‘flow_network.0.pth’ is saved at the end.Hi @pattersonLate response, but putting this here for future reference.Modulus only saves the root process (proc 0) checkpoint since all weights across processes are the same. Hence only flow_network.0.pth is present to save some memory. On load you are right, Modulus does try to load checkpoints for each GPU out of default behavior.However, PyTorch DDP only requires you to load the weights on process 0 because it will automatically broadcast process 0’s model weights to all other processes at the beginning of training. Quoted from the user guide:The DDP constructor takes a reference to the local module, and broadcasts state_dict() from the process with rank 0 to all other processes in the group to make sure that all model replicas start from the exact same state.Manually creating the other checkpoint files as you suggest works fine but should not be required.Great, that keeps it easier for me. Thanks for info.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
216,plotting-of-training-and-validation-losses,"Is there any other method to plot the training and validation losses since the tensorboard is not working in Modulus?Hi @id21resch11019Presently, no. Tensorboard is our built in logging backend in Modulus. However customizing Modulus to log any way you want is straight forward. In the trainer.py, you can add a logging method of your choice based on the summary_freq. The losses for a given iteration are stored in the losses dictionary.Powered by Discourse, best viewed with JavaScript enabled"
217,parameterized-stl,"When do you expect it to be possible to parameterize complex geometries from the STL Module? Thanks in AdvanceGood news!  Support for parameterized STL will be available in 22.07 release (about 7-10 days from now).  What is your use case?Wow, that sounds amazing! Will it be possible to optimize the position of an stl object inside another stl object according to certain flow parameters?Powered by Discourse, best viewed with JavaScript enabled"
218,error-running-aneurysm-example-what-library-not-found,"Hi, I mananged to install SimNet 2106 and also tested the helmholtz example succesfully. I then built the PySDF library. No error msg is reported.However, when I tried to run the aneurysm example, I got the error:May I know what’s wrong? I have this error across a few clusters which I tested. I have also added the export LD_LIBRARY_PATH … in my bashrcHope someone can help. Thanks.Powered by Discourse, best viewed with JavaScript enabled"
219,importance-sampling-based-on-pde-loss,"I’m interested in using importance sampling based on the local PDE error, however there is no existing computable variable in the computational graph representing PDE error. Is there a better way to implement this than rewriting the PDE loss calculation within the importance model graph? It seems inefficient to have to calculate PDE loss at each collocation point twice (one for importance sampling and a second time for loss formulation)Hi @rohan.patelThe PDE error is typically the residual produced from the PDE nodes. If the residual isn’t the right quantity you’re interested in consider adding another Node (for example the Node.from_sympy() is quite useful) that calculates this quantity for you.For importance sampling, the calculation of the measure will always occur at the defined resample frequency. If performance is an issue, consider creating this dataset manually and then constructing a pointwise constraint.The challenge here is that the importance function needs to be recalculated for the entire dataset of points (not just 1 mini-batch). Additionally there is no guarantee that all points will be used before a resampling, thus the most straight forward solution is to periodically have repeat work.Powered by Discourse, best viewed with JavaScript enabled"
220,how-to-save-derivatives-to-vti-and-npz,"Hello,We would like to save derivatives of velocity(u__x, u__y, …) to vti and npz when inferencing like taylor_green.py.
To export u__x, u__y, … in PointVTKInferencer results in failure.Can you please let us know how to do it?The code we tried is as followserror messages:
Traceback (most recent call last):
File “myinfer.py”, line 240, in run
slv.solve()
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/continuous/solvers/solver.py”, line 133, in solve
self._eval()
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/trainer.py”, line 617, in _eval
self._record_inferencers(step)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/trainer.py”, line 280, in _record_inferencers
self.record_inferencers(step)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/continuous/solvers/solver.py”, line 111, in record_inferencers
self.domain.rec_inferencers(
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/continuous/domain/domain.py”, line 77, in rec_inferencers
inferencer.save_results(
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/continuous/inferencer/inferencer.py”, line 217, in save_results
pred_outvar = self.forward(invar)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/continuous/inferencer/inferencer.py”, line 90, in forward_nograd
pred_outvar = self.model(invar)
File “/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py”, line 1110, in _call_impl
return forward_call(*input, **kwargs)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/graph.py”, line 147, in forward
outvar.update(e(outvar))
File “/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py”, line 1110, in _call_impl
return forward_call(*input, **kwargs)
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/derivatives.py”, line 74, in forward
grad = gradient(var, grad_var)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
File “/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/derivatives.py”, line 17, in gradient
“”""
grad_outputs: List[Optional[torch.Tensor]] = [torch.ones_like(y, device=y.device)]
grad = torch.autograd.grad(
~~~~~~~~~~~~~~~~~~~ <— HERE
[
y,
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fnSet the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
inference is finished
copy moldflow result data
cp -r /examples/isid/utils/template/fillrate_csv_mf_b1 ./
python /examples/isid/utils/plot_results_mold_r5.2.py myinfer 1.0 n3 176.063877 normal 0.002000607 0.007099696 22.40110954 1.0 0000
model output directory : ./outputs/myinfer
Traceback (most recent call last):
File “/examples/isid/utils/plot_results_mold_r5.2.py”, line 154, in 
tke_points = tke_points / np.max(tke_points)
File “<array_function internals>”, line 180, in amax
File “/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py”, line 2791, in amax
return _wrapreduction(a, np.maximum, ‘max’, axis, None, out,
File “/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py”, line 86, in _wrapreduction
return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
ValueError: zero-size array to reduction operation maximum which has no identity
mv mold_stat.csv outputs/mold_1f_26.7.6/mold_stat_0000.csv
mv: cannot stat ‘mold_stat.csv’: No such file or directory
postproc is finishedHi @yokoi.toshiakiPlease try turning on requires_grad=True in your PointVTKInferencer. By default this is off to save on computation, but this means the any gradients cannot be computed. Turning this on will enable gradients during inference at the sacrifice of increased memory usage, so monitor your batch size.The same is true if you are using a validator or monitor:Powered by Discourse, best viewed with JavaScript enabled"
221,k-e-turbulence-model,"hello, I’m currently learning the official case for channel flow (k-ep turbulence model).I am very confused about the setting of the weight of the loss function. I really want to know what is the basis for the setting of these weights? 10, 100, 1000, 10000?When I set all these weights to 1, the training results do not match the results of the standard case at all.Then when I train a new object, how do I set these weights, and what indicators can I refer to?If anyone can help me with this confusion, I would be very grateful!Hi @12227126These weighting of the different constraints are done out of intuition and simply training the model partially or to convergence and observing which parts of the loss failed to converge.Roughly speaking its good to have all losses in the same order of magnitude, but sometimes one constraint can be significantly more strong than another for multiple reasons. So it comes down to testing and observing the model.There is some literature on automatic weighting (e.g. neural tangent kernels which is in Modulus in some form) but wide spread adoption of these approaches has not occurred.Thank you very much for your reply.I am still more puzzled. For example, when all loss weights are set to 1 for training, how can I judge which ones have failed through the results or the loss curve? How should I adjust the magnitude of the weight through this result？I wonder if you can share some experience of your engineers when adjusting the magnitude of this weight?The second doubt is that you said that all losses should be at the same magnitude as possible, but I have observed that in some cases that have converged, their losses are not necessarily at the same magnitude.Regarding the automatic weighting method, I have also tried several methods, but none of these methods seem to have achieved better results, and even the results of some methods are completely wrong.Powered by Discourse, best viewed with JavaScript enabled"
222,how-to-run-nvidia-modulus-v22-09-with-fp64,"I wish to ask how to run Nvidia Modulus v22.09 with FP64 (double precision).
I did not find the way to set this double precision in official tutorial. I am using Nvidia A100 GPU accelerator.Hi @SpartacusWe have some defaults defined in the constants file:
https://gitlab.com/nvidia/modulus/modulus/-/blob/release_22.09/modulus/constants.py#L17This should update Modulus datasets / dataloaders to use FP64. I would also use the PyTorch way to update the default tensor type torch.set_default_tensor_type(t) which should update models to FP64.Powered by Discourse, best viewed with JavaScript enabled"
223,nvidia-modulus-on-jupyter-lab-ipykernel-launcher-py-error-unrecognized-arguments,"I copied the lid-driven cavity code and pasted it in a jupyter notebook in different cells without making any changes.This part of code gives me an error.How to resolve this issue?You have to run in from the command line. So save as python file and then run the python file from the command line.Yes that is how modulus is made to work. But I remember that SimNet used to work in Jupyter-lab flawlessly. I don’t know why Modulus doesn’t work in the same way.
See this example,

image982×483 91.2 KB
I use in google colab. I just save as a seperate python file and the call it from the command line.For example:

image1045×533 29 KB
Hi sir! I am wondering if I can run Modulus on google colab since my PC does not have GPU that is compatible. May I ask what should I do for creating environment / dependencies in colab so that I can also run simulations like you do in your screenshot?  Thank you so much!Interesting.You can connect to gpu in colab for free. Search it online.Powered by Discourse, best viewed with JavaScript enabled"
224,problems-installing-modulus-sym-in-google-colab-with-pip,"Hi there,I want to get Modulus Sym to run on Google Colab since my own computer (a Mac) doesn’t satisfy the hardware requirement of Modulus.So, I am trying to install Modulus Sym on Google Colab with “pip install nvidia-modulus.sym”.When I run the command in Google Colab (using !pip install nvidia-modulus.sym and the Python version is 3.10.11), I get the following error:Collecting nvidia-modulus.sym
Using cached nvidia_modulus.sym-1.0.0-py3-none-any.whl (304 kB)
Collecting nvidia-modulus>=0.1.0 (from nvidia-modulus.sym)
Using cached nvidia_modulus-0.1.0-py3-none-any.whl (167 kB)
Collecting hydra-core>=1.2.0 (from nvidia-modulus.sym)
Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)
Requirement already satisfied: termcolor>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from nvidia-modulus.sym) (2.3.0)
Collecting chaospy>=4.3.7 (from nvidia-modulus.sym)
Using cached chaospy-4.3.13-py3-none-any.whl (254 kB)
Collecting Cython==0.29.28 (from nvidia-modulus.sym)
Using cached Cython-0.29.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)
Collecting numpy-stl==2.16.3 (from nvidia-modulus.sym)
Using cached numpy-stl-2.16.3.tar.gz (772 kB)
Preparing metadata (setup.py) … done
Collecting opencv-python==4.5.5.64 (from nvidia-modulus.sym)
Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)
Collecting scikit-learn==1.0.2 (from nvidia-modulus.sym)
Using cached scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)
Collecting symengine==0.6.1 (from nvidia-modulus.sym)
Using cached symengine-0.6.1.tar.gz (721 kB)
error: subprocess-exited-with-error× python setup.py egg_info did not run successfully.
│ exit code: 1
╰─> See above for output.note: This error originates from a subprocess, and is likely not a problem with pip.
Preparing metadata (setup.py) … error
error: metadata-generation-failed× Encountered error while generating package metadata.
╰─> See above for output.When I run the pip install command in a terminal on my machine, I also get the error, but it’s a little more verbose:[…]Collecting symengine==0.6.1 (from nvidia-modulus.sym)
Downloading symengine-0.6.1.tar.gz (721 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 722.0/722.0 kB 47.1 MB/s eta 0:00:00
Preparing metadata (setup.py) … error
error: subprocess-exited-with-error× python setup.py egg_info did not run successfully.
│ exit code: 1
╰─> [24 lines of output]
/Users/gilbert/anaconda3/envs/modulus-sym-env/lib/python3.10/site-packages/setuptools/init.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.
!!note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed× Encountered error while generating package metadata.
╰─> See above for output.Do you have any recommendation of how I can get this to work on Google Colab? Unfortunately my machine is a Mac and doesn’t satisfy the Modulus hardware requirements.Thanks so much for your help!GilbertHi @gilbertpLooks like this is because some of these dependencies are not compatible with Python 3.10. I’ll log this as a bug to address in our next release. Thanks for reporting this. In the mean time try downgrading python in your collab notebook (for example python 3.8):Hi @ngeneva,Thanks so much for the tip and for the detailed instructions! I now successfully installed Modulus Sym on Google Colab under Python 3.8.10 and was able to run the helmholtz.py example using a T4 GPU.All the best,GilbertThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
225,integral-continuity-in-aneurysm,"Hello,I will create a new CFD model based on Aneurysm example and have 2 questions about the constraint of outvar ‘integral_continuity’.*Environment
Simnet version : 21.06*QuestionsIs the value of ‘integral_continuity’ calculated in IntegralContinuity.make_node() in navier_stokes.py?
If it was wrong, please let me know where it is calculated.Why is the constraint value of ic_2 integral_continuity negative(-2.540) as line 119 in aneurysm.py?
I think the value should be positive(2.540) so that it is equivalent as ic_1.---------------------------------- aneurysm.py ------------------------------------
…
112     # Integral Continuity 1
113     ic_1 = outlet_mesh.boundary_bc(outvar_sympy={‘integral_continuity’: 2.540},
114                                    lambda_sympy={‘lambda_integral_continuity’: 0.1},
115                                    batch_size_per_area=128)
116     self.add(ic_1, name=“IntegralContinuity_1”)
117
118     # Integral Continuity 2
119     ic_2 = integral_mesh.boundary_bc(outvar_sympy={‘integral_continuity’: -2.540},
120                                      lambda_sympy={‘lambda_integral_continuity’: 0.1},
121                                      batch_size_per_area=128)
122     self.add(ic_2, name=“IntegralContinuity_2”)
…
---------------------------------- aneurysm.py ------------------------------------Thanks,
Toshiaki YokoiHi Toshiaki,Hi Mnabian-san,Thank you for your reply.understood.I have a new question.
Where is the normal direction of the second plane written?
Could you please let me know how to understand that the normal is in the opposite direction of the flow?Thanks,
Toshiaki YokoiPowered by Discourse, best viewed with JavaScript enabled"
226,model-requirement-for-multi-gpu-training,"Hello,I tried to train heat_sink.py parallel with multi-gpu server, however the following error was returned.How can I enable that parallel training?I can normally train fpga_flow.py parallel with the same server.Can you let me know what is the requirement of simulation model for parallel training?Regards,Hi @yokoi.toshiaki , can you confirm what version of Modulus are you using? We have had some issues with parallel training for these heat sink problems in the past, but have made some bug fixes for issues like this. Thanks for reporting.Check if you used checkpoint mechanism, maybe you can solve this problem by turning off the checkpoint.Powered by Discourse, best viewed with JavaScript enabled"
227,resnets-blocks-in-pinns,"Hello,I’m trying to implement ResNet blocks in my PINN design similar to the work by Cheng et al.  (Water | Free Full-Text | Deep Learning Method Based on Physics Informed Neural Network with Resnet Block for Solving Fluid Flow Problems). Will Modulus support this architecture in a future version?
Is it straightforward to add ResNets as an architecture model in the current version as I could not find it among the current implemented architectures in Modulus?Thank you for all your efforts!Hi @cpe.skHave a look at the Highway Fourier Net model which has skip connections. Additionally you can always implement your own custom Network Model to use. Consider using the Fully Connected code as a starting point.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
228,combining-pinn-with-fvm,"Inspired by this paper, I am trying to combine PINN with FVM, but I don’t know how to get the values around the collocation points. For example,  $u_{e}$ .

image653×546 35.3 KB

Is it possible to get values around collocation points in Modulus other than using Taylor series approximation?
Thanks!Hi @1440590317I have not read the paper in full, however something inside of Modulus that could provide some inspiration is our Meshless Finite Derivative nodes which query neighboring stencil points on top of the training points. Derivatives are them computed using finite difference (more information in our user guide).Seems to be a fairly similar idea to this, but finite difference tends to extend across multiple PDEs more (although FVM is more well suited for flow related problems). Hope this can give you some ideas.Thanks a lot for your reply, where should I get the source code for MeshlessFiniteDerivative?Inside the Modulus source folder, you can find related code in:modulus/eq/derivatives.pyas well as
modulus/eq/mfdThanks. And another question, how to use Monte Carlo integration for loss formulation instead of general loss function ? Where I can get the source code for Monte Carlo integration?Hi @1440590317I am assuming you are referring to the integral based loss functions (typically used in continuity planes in many of our flow problems). For more information on these please see:modulus/domain/constraint/continuous.py and find the classes IntegralConstraint or IntegralBoundaryConstraint. In general the idea is each training example is a set of points each with a approximate area they represent, which can then be all summed up for a Monte Carlo integration loss. So a single batch of these integral constraints is actually a set of these point sets.These use a special loss function which is IntegralLossNorm found in modulus/loss/loss.py.Several of examples that are shipped with modulus use these constraints, one I would recommend would be the annular ring problem found in the examples repo under: annular_ring/annular_ring/annular_ring.pyWait, I thought the Monte Carlo integration for loss formulation is the default loss in Modulus.See this,Yes, you’re correct! The default point wise loss is posed in a integral form since it is just the summation of the training points over the domain with a given area size.@1440590317 if you are not referring to the integral constraint based losses and rather the default loss used in our standard boundary/interior this is enabled by default as @prakhar_sharma mentioned. This is again found in modulus/loss/loss.py in class PointwiseLossNorm.@ngeneva I used finite volume methods on some equations, which led to some integral terms in the equations.  I’m solving an integral-differential equation. My idea is to use Monte Carlo integrals to solve the integral term in the equation, while the differential term is still automatic differentiation. My problem at the moment is that I don’t know how to get the value of the neighborhood around the collocation points.During the forward execution of all constraints, variables are collected in a variable dictionary: {x: torch.Tensor, y: torch.Tensor, ...}. You can probably write a custom constraint or node (like the meshless finite difference node) that can manually build these needed neighborhood collocation points.Alternatively, if you want to define these collocation points ahead of time on initialization, it sounds like you need a custom dataset. I am not 100% sure of what the exact needs are here. But I would look into extending a dataset or a constraint. The Darcy problems with FNO implement a custom dataset and the super-resolution problem has a custom constraint for reference.Thanks for your reply. I will try it.Hi @1440590317,This is a very interesting use case and we would be interested in chatting about your use case. Would you be interested in discussing with the modulus team to share more details on the use case and we can try to share more insights on how to apply Modulus for you problem. You can reach out to us directly at modulus-team@exchange.nvidia.comThanks
RamPowered by Discourse, best viewed with JavaScript enabled"
229,turbolence-models,"Hello, its since November '21 that I am enjoying the precious work done by the NVidia devs about the Pinns, DeepONet and other wanderful hybrid model and data driven models.I need the pde describing the turbolence model known as k-omega. I am pleased that you have a 2-d customization (inside the turbolence_channel example).
There are 2 custom k-omega rubolent custom pdes (both in two dimentions). If I got the difference correctly among thems, the difference is that one has symbolic u_tau and the other has explicit k values, right?In the example of such problem Fully Developed Turbulent Channel Flow - NVIDIA Docs , the pdes written (188-189 formulas) have the time included, however looking at the code there are not symbolic variables “t” involved in the computations.
I need to adapt the k-omega model in 3-Dimentions (having the 2-D is already a great start! thx) and that would incldue the time; adding a spatial dimention is pretty stright forward, however I am not sure where i should incldue the variable ‘t’.
Greetings,
Thanks in advanceP.S. when it will be next release, and where can I find a “road map” or something similar? :DHi @vale_valerioFor these channel flow problems, we are solving for steady state case (fully-developed channel), so the time derivatives go to zero. Note that the network that predicts the flow only depends on the spatial coordinates relative to the wall (not time). You will need to include time if you are planning to try to learn a transient solution, but this is considerably more difficult. Good luck!Gentile @ngeneva thanks for your reply.
I am more a computer scientist myself rather than a physicists, so my comprhension of PDE is not perfect. Nonetheless I have tried to implement the transient solution for the k-omega model, including time and the third spatial dimention.
The simplest PDE tried to inform a NN is the following (it is a chunk of code inside a class that inherit from the Modulus PDE class)However is not converging to anything good (I’ve set lambda wheits very high, maybe that’s the problem?)
Does the previous code really represent a close implementation of the k-omega model in 3 dimentions with transient solution?Hi @vale_valerioYes the K-Omega model is the form from standard turbulence literature. Regarding convergence problems, this could be from a multitude of sources. I would highly suggest trying to simplify the problem and the slowly building up to you 3D case, particularly if you’re not completely familiar with the underlying PDEs. Its good to confirm results for smaller problems to sanity check problem set ups.For our 3D problems we use a lot of techniques to improve convergence. Check out the recommend practices section of the documentation with some ideas (e.g. Integral continuity planes).Powered by Discourse, best viewed with JavaScript enabled"
230,report-a-bug-simnet-only,"To report bugs to Nvidia, you will need to first register with our developer program here. Doing this enables you to file and get feedback on bugs at the following link.https://developer.nvidia.com/nvidia_bug/add 547Please be prepared to provide the following details:Powered by Discourse, best viewed with JavaScript enabled"
231,how-to-install-physx-5-sdk,"I want to build and experiment with latest PhysX demos, like with kaplademo before. So I found PhysX page, clicked Get PhysX 5 in
Omniverse, installed Omniverse… And now what? I don’t see any PhysX SDK mentions. Where to find demos and sources for them? How to install PhysX SDK and get access to its .lib and .h files?I also want to know this.  It says “apply for early access to get physx 5” but doesn’t explain how or whereFollowing this too…Also, where is the PhysX SDK 5.0 documentation?You need to install Omniverse Kit to get it through Omniverse. They should make the instructions more clear.For the C++ PhysX 5 SDK, the download is here:NVIDIA PhysX SDK. Contribute to NVIDIA-Omniverse/PhysX development by creating an account on GitHub.In a nutshell:This is the forums for Modulus deep learning package. You are unlikely to find support for PhysX here. Post any questions / issues on the PhysX github page. Locking thread.Powered by Discourse, best viewed with JavaScript enabled"
232,how-to-separate-losses-of-the-same-quantity,"Hi,
I have two loss terms associated with the same quantity v. The one is the symmetry boundary, where v=0. The other is the  PointwiseConstraint used to perform inversion, where v=v_data. In the losses.items(), it seems these two losses are combined automatically as loss_v. I am wondering how to separate them.Thanks a lot.Hi @zhangzhenthuThat is correct, modulus combines the logging of losses when the variable is the same. The idea here is to show the logs between the different variables losses to understand how the convergence of each output state variable is balanced.Unfortunately to change this functionality needs some editing to the source code. I have not tried this myself, but the loss keys/names are assigned here in the domain.py file. One could try modifying this to be something like:which should hopefully log each loss of each constraint uniquely. See the install from source steps for some info of how to install from the source code if you are not too familiar with developing python packages.Hi, thank you for your help. It works well.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
233,three-fin-3d-example-cannot-run,"Hello,
I am currently testing Modulus  using the 3D fin examples. However, after I run the “three_fin_flow.py”,
it gives me the following errors:

image1629×1004 155 KB
can anyone help me to address this issue?Hi  @cxi1This is not an error I have seen before arising from the PyTorch dataloader. Can you provide additional information on the development environment? Is this a bare-metal / pip install?  What hardware are you running on?Also do other examples work (typical Helmholtz example is a good one to verify your install works)?Hi @ngeneva ,
Thank you so much for your replying to my posted issue.  I am using a bare-metal installation on my workstation and created an anaconda environment for modulus on windows.  Recently I found that I need to use the linux terminal instead of windows powershell to execute the code, and the issue disappears.  And the examples works out perfectly without problems anymore.Best Regards,
CeThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
234,how-to-run-modulus-thru-docker-in-saturn-cloud,"Hi,Nividia has kindly provided me some GPU cloud computing credits on Saturn cloud. I tried to set up using docker file but it doesn’t work as there’s some steps to follow. I tried to ask the admin there for help but it didn’t work out. Does anyone has experience in this area?Thanks.Hi @tsltaywbUnfortunately we cannot provide complete technical support for every cloud platform / cluster from our end. However, setting up the docker image for Modulus should work if you’re allowed and nvidia docker runtime is available.We have had users where docker doesn’t work fully / isn’t allowed. Right now there are two options:Best of luck!ok thanks!Hello there, you can use the support chat on Saturn Cloud for help on these questions.
You may also find these docs helpful.Hi smoelsh,Sure, I will take a look. Thanks!Powered by Discourse, best viewed with JavaScript enabled"
235,distribution-of-flow-velocity-is-wrong,"Hello,I created a cfd model of cylindrical geometry based on Aneurysm example and executed training.
However the result was not as I expected. The distribution of flow velocity is wrong. The velocity magnitude in outlet is greater than that in inlet about for 30%.My env. is SimNet 21.06.I uploaded the model package.
Could you let me know what is wrong?
cylinder_isid.zip (644.9 KB)Thanks,
Toshiaki YokoiPowered by Discourse, best viewed with JavaScript enabled"
236,wsl-modulus-docker-run-error-libnvidia-ml-so-1-file-exists-unknown,"Hi. I’m trying to use Modulus with docker on wsl2 ubuntu20.04 (windows11)
And I have a problem.
Running docker with below commanddocker run --gpus all -v ${PWD}/examples:/examples -it --rm nvcr.io/nvidia/modulus/modulus:22.09 bashThen an error like this is comingdocker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #0: error running hook: exit status 1, stdout: , stderr: Auto-detected mode as ‘legacy’
nvidia-container-cli: mount error: file creation failed: /var/lib/docker/overlay2/d34848e7089996bdb31f9dd8ce55a3e27c6446eee30259c33ffce6ba4777833a/merged/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1: file exists: unknown.how could I solve this?I’m using RTX 3060, 12.1 CUDA versionI think it’s not the problem with gpu or drivers.sudo docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi
with this commandFri Jun  9 06:03:12 2023
±--------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.47                 Driver Version: 531.68       CUDA Version: 12.1     |
|-----------------------------------------±---------------------±---------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060         On | 00000000:01:00.0  On |                  N/A |
|  0%   47C    P8               18W / 170W|    868MiB /  8192MiB |      0%      Default |
|                                         |                      |                  N/A |
±----------------------------------------±---------------------±---------------------+±--------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A        20      G   /Xwayland                                 N/A      |
|    0   N/A  N/A        26      G   /Xwayland                                 N/A      |
|    0   N/A  N/A       595      G   /Xwayland                                 N/A      |
±--------------------------------------------------------------------------------------+this result comes outHi @kdg5424Looks like our Nvidia docker is giving you some troubles on WSL. We don’t test or officially support WSL with the Modulus container but consider having a look at this relevant Github issue with some possible solutions:### Issue or feature description
when i use docker to create container, i get t…his error 

```
docker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #0: error running hook: exit status 1, stdout: , stderr: Auto-detected mode as 'legacy'
nvidia-container-cli: initialization error: driver rpc error: timed out: unknown.
```
### Steps to reproduce the issue
* when  i executed the following command
`sudo docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi`
* i get the following error
`docker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #0: error running hook: exit status 1, stdout: , stderr: Auto-detected mode as 'legacy'
nvidia-container-cli: initialization error: driver rpc error: timed out: unknown.`
* but when i executed this following command, it has the expected output
`sudo docker run hello-world`

### here is some Information
* Some nvidia-container information
```
gpu-server@gpu-server:~$ nvidia-container-cli -k -d /dev/tty info

-- WARNING, the following logs are for debugging purposes only --

I0621 07:07:51.735875 4789 nvc.c:376] initializing library context (version=1.10.0, build=395fd41701117121f1fd04ada01e1d7e006a37ae)
I0621 07:07:51.735941 4789 nvc.c:350] using root /
I0621 07:07:51.735947 4789 nvc.c:351] using ldcache /etc/ld.so.cache
I0621 07:07:51.735963 4789 nvc.c:352] using unprivileged user 1000:1000
I0621 07:07:51.735984 4789 nvc.c:393] attempting to load dxcore to see if we are running under Windows Subsystem for Linux (WSL)
I0621 07:07:51.736064 4789 nvc.c:395] dxcore initialization failed, continuing assuming a non-WSL environment
W0621 07:07:51.739205 4791 nvc.c:273] failed to set inheritable capabilities
W0621 07:07:51.739329 4791 nvc.c:274] skipping kernel modules load due to failure
I0621 07:07:51.739807 4793 rpc.c:71] starting driver rpc service
W0621 07:08:16.774958 4789 rpc.c:121] terminating driver rpc service (forced)
I0621 07:08:20.481845 4789 rpc.c:135] driver rpc service terminated with signal 15
nvidia-container-cli: initialization error: driver rpc error: timed out
I0621 07:08:20.481972 4789 nvc.c:434] shutting down library context
```
*  Kernel version
`Linux gpu-server 4.15.0-187-generic #198-Ubuntu SMP Tue Jun 14 03:23:51 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux`


* Driver information
```
==============NVSMI LOG==============

Timestamp                                 : Tue Jun 21 07:13:57 2022
Driver Version                            : 515.48.07
CUDA Version                              : 11.7

Attached GPUs                             : 4
GPU 00000000:01:00.0
    Product Name                          : NVIDIA A100-SXM4-40GB
    Product Brand                         : NVIDIA
    Product Architecture                  : Ampere
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : Disabled
        Pending                           : Disabled
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 1561221014674
    GPU UUID                              : GPU-b67da01e-feba-d839-62c5-2773d4e963f0
    Minor Number                          : 0
    VBIOS Version                         : 92.00.19.00.13
    MultiGPU Board                        : No
    Board ID                              : 0x100
    GPU Part Number                       : 692-2G506-0202-002
    Module ID                             : 3
    Inforom Version
        Image Version                     : G506.0202.00.02
        OEM Object                        : 2.0
        ECC Object                        : 6.16
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : 515.48.07
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x01
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x20B010DE
        Bus Id                            : 00000000:01:00.0
        Sub System Id                     : 0x144E10DE
        GPU Link Info
            PCIe Generation
                Max                       : 4
                Current                   : 4
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : N/A
    Performance State                     : P0
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 40960 MiB
        Reserved                          : 571 MiB
        Used                              : 0 MiB
        Free                              : 40388 MiB
    BAR1 Memory Usage
        Total                             : 65536 MiB
        Used                              : 1 MiB
        Free                              : 65535 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : Enabled
        Pending                           : Enabled
    ECC Errors
        Volatile
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
        Aggregate
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows
        Correctable Error                 : 0
        Uncorrectable Error               : 0
        Pending                           : No
        Remapping Failure Occurred        : No
        Bank Remap Availability Histogram
            Max                           : 640 bank(s)
            High                          : 0 bank(s)
            Partial                       : 0 bank(s)
            Low                           : 0 bank(s)
            None                          : 0 bank(s)
    Temperature
        GPU Current Temp                  : 32 C
        GPU Shutdown Temp                 : 92 C
        GPU Slowdown Temp                 : 89 C
        GPU Max Operating Temp            : 85 C
        GPU Target Temperature            : N/A
        Memory Current Temp               : 34 C
        Memory Max Operating Temp         : 95 C
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 54.92 W
        Power Limit                       : 400.00 W
        Default Power Limit               : 400.00 W
        Enforced Power Limit              : 400.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 400.00 W
    Clocks
        Graphics                          : 1080 MHz
        SM                                : 1080 MHz
        Memory                            : 1215 MHz
        Video                             : 975 MHz
    Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Default Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Max Clocks
        Graphics                          : 1410 MHz
        SM                                : 1410 MHz
        Memory                            : 1215 MHz
        Video                             : 1290 MHz
    Max Customer Boost Clocks
        Graphics                          : 1410 MHz
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : 731.250 mV
    Processes                             : None

GPU 00000000:41:00.0
    Product Name                          : NVIDIA A100-SXM4-40GB
    Product Brand                         : NVIDIA
    Product Architecture                  : Ampere
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : Disabled
        Pending                           : Disabled
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 1561221014888
    GPU UUID                              : GPU-6ca82e47-c63a-1bea-38ad-d3af9e1dc26b
    Minor Number                          : 1
    VBIOS Version                         : 92.00.19.00.13
    MultiGPU Board                        : No
    Board ID                              : 0x4100
    GPU Part Number                       : 692-2G506-0202-002
    Module ID                             : 1
    Inforom Version
        Image Version                     : G506.0202.00.02
        OEM Object                        : 2.0
        ECC Object                        : 6.16
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : 515.48.07
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x41
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x20B010DE
        Bus Id                            : 00000000:41:00.0
        Sub System Id                     : 0x144E10DE
        GPU Link Info
            PCIe Generation
                Max                       : 4
                Current                   : 4
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : N/A
    Performance State                     : P0
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 40960 MiB
        Reserved                          : 571 MiB
        Used                              : 0 MiB
        Free                              : 40388 MiB
    BAR1 Memory Usage
        Total                             : 65536 MiB
        Used                              : 1 MiB
        Free                              : 65535 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : Enabled
        Pending                           : Enabled
    ECC Errors
        Volatile
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
        Aggregate
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows
        Correctable Error                 : 0
        Uncorrectable Error               : 0
        Pending                           : No
        Remapping Failure Occurred        : No
        Bank Remap Availability Histogram
            Max                           : 640 bank(s)
            High                          : 0 bank(s)
            Partial                       : 0 bank(s)
            Low                           : 0 bank(s)
            None                          : 0 bank(s)
    Temperature
        GPU Current Temp                  : 30 C
        GPU Shutdown Temp                 : 92 C
        GPU Slowdown Temp                 : 89 C
        GPU Max Operating Temp            : 85 C
        GPU Target Temperature            : N/A
        Memory Current Temp               : 40 C
        Memory Max Operating Temp         : 95 C
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 57.45 W
        Power Limit                       : 400.00 W
        Default Power Limit               : 400.00 W
        Enforced Power Limit              : 400.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 400.00 W
    Clocks
        Graphics                          : 915 MHz
        SM                                : 915 MHz
        Memory                            : 1215 MHz
        Video                             : 780 MHz
    Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Default Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Max Clocks
        Graphics                          : 1410 MHz
        SM                                : 1410 MHz
        Memory                            : 1215 MHz
        Video                             : 1290 MHz
    Max Customer Boost Clocks
        Graphics                          : 1410 MHz
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : 700.000 mV
    Processes                             : None

GPU 00000000:81:00.0
    Product Name                          : NVIDIA A100-SXM4-40GB
    Product Brand                         : NVIDIA
    Product Architecture                  : Ampere
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : Disabled
        Pending                           : Disabled
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 1561221015040
    GPU UUID                              : GPU-7e4b55d2-75fc-8ab5-e212-09e69e84704b
    Minor Number                          : 2
    VBIOS Version                         : 92.00.19.00.13
    MultiGPU Board                        : No
    Board ID                              : 0x8100
    GPU Part Number                       : 692-2G506-0202-002
    Module ID                             : 2
    Inforom Version
        Image Version                     : G506.0202.00.02
        OEM Object                        : 2.0
        ECC Object                        : 6.16
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : 515.48.07
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x81
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x20B010DE
        Bus Id                            : 00000000:81:00.0
        Sub System Id                     : 0x144E10DE
        GPU Link Info
            PCIe Generation
                Max                       : 4
                Current                   : 4
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : N/A
    Performance State                     : P0
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 40960 MiB
        Reserved                          : 571 MiB
        Used                              : 0 MiB
        Free                              : 40388 MiB
    BAR1 Memory Usage
        Total                             : 65536 MiB
        Used                              : 1 MiB
        Free                              : 65535 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : Enabled
        Pending                           : Enabled
    ECC Errors
        Volatile
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
        Aggregate
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows
        Correctable Error                 : 0
        Uncorrectable Error               : 0
        Pending                           : No
        Remapping Failure Occurred        : No
        Bank Remap Availability Histogram
            Max                           : 640 bank(s)
            High                          : 0 bank(s)
            Partial                       : 0 bank(s)
            Low                           : 0 bank(s)
            None                          : 0 bank(s)
    Temperature
        GPU Current Temp                  : 32 C
        GPU Shutdown Temp                 : 92 C
        GPU Slowdown Temp                 : 89 C
        GPU Max Operating Temp            : 85 C
        GPU Target Temperature            : N/A
        Memory Current Temp               : 33 C
        Memory Max Operating Temp         : 95 C
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 54.65 W
        Power Limit                       : 400.00 W
        Default Power Limit               : 400.00 W
        Enforced Power Limit              : 400.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 400.00 W
    Clocks
        Graphics                          : 1080 MHz
        SM                                : 1080 MHz
        Memory                            : 1215 MHz
        Video                             : 975 MHz
    Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Default Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Max Clocks
        Graphics                          : 1410 MHz
        SM                                : 1410 MHz
        Memory                            : 1215 MHz
        Video                             : 1290 MHz
    Max Customer Boost Clocks
        Graphics                          : 1410 MHz
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : 712.500 mV
    Processes                             : None

GPU 00000000:C1:00.0
    Product Name                          : NVIDIA A100-SXM4-40GB
    Product Brand                         : NVIDIA
    Product Architecture                  : Ampere
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Disabled
    MIG Mode
        Current                           : Disabled
        Pending                           : Disabled
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 1561221014695
    GPU UUID                              : GPU-66ba085a-5496-d204-d4da-aa9f112d3fd8
    Minor Number                          : 3
    VBIOS Version                         : 92.00.19.00.13
    MultiGPU Board                        : No
    Board ID                              : 0xc100
    GPU Part Number                       : 692-2G506-0202-002
    Module ID                             : 0
    Inforom Version
        Image Version                     : G506.0202.00.02
        OEM Object                        : 2.0
        ECC Object                        : 6.16
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : 515.48.07
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0xC1
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x20B010DE
        Bus Id                            : 00000000:C1:00.0
        Sub System Id                     : 0x144E10DE
        GPU Link Info
            PCIe Generation
                Max                       : 4
                Current                   : 4
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 0 KB/s
        Rx Throughput                     : 0 KB/s
    Fan Speed                             : N/A
    Performance State                     : P0
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 40960 MiB
        Reserved                          : 571 MiB
        Used                              : 0 MiB
        Free                              : 40388 MiB
    BAR1 Memory Usage
        Total                             : 65536 MiB
        Used                              : 1 MiB
        Free                              : 65535 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : Enabled
        Pending                           : Enabled
    ECC Errors
        Volatile
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
        Aggregate
            SRAM Correctable              : 0
            SRAM Uncorrectable            : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows
        Correctable Error                 : 0
        Uncorrectable Error               : 0
        Pending                           : No
        Remapping Failure Occurred        : No
        Bank Remap Availability Histogram
            Max                           : 640 bank(s)
            High                          : 0 bank(s)
            Partial                       : 0 bank(s)
            Low                           : 0 bank(s)
            None                          : 0 bank(s)
    Temperature
        GPU Current Temp                  : 30 C
        GPU Shutdown Temp                 : 92 C
        GPU Slowdown Temp                 : 89 C
        GPU Max Operating Temp            : 85 C
        GPU Target Temperature            : N/A
        Memory Current Temp               : 38 C
        Memory Max Operating Temp         : 95 C
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 59.01 W
        Power Limit                       : 400.00 W
        Default Power Limit               : 400.00 W
        Enforced Power Limit              : 400.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 400.00 W
    Clocks
        Graphics                          : 1080 MHz
        SM                                : 1080 MHz
        Memory                            : 1215 MHz
        Video                             : 975 MHz
    Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Default Applications Clocks
        Graphics                          : 1095 MHz
        Memory                            : 1215 MHz
    Max Clocks
        Graphics                          : 1410 MHz
        SM                                : 1410 MHz
        Memory                            : 1215 MHz
        Video                             : 1290 MHz
    Max Customer Boost Clocks
        Graphics                          : 1410 MHz
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : 737.500 mV
    Processes                             : None

```
* docker version
```
Client: Docker Engine - Community
 Version:           20.10.17
 API version:       1.41
 Go version:        go1.17.11
 Git commit:        100c701
 Built:             Mon Jun  6 23:02:56 2022
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.11
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.16.9
  Git commit:       847da18
  Built:            Thu Nov 18 00:35:16 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.6.6
  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1
 nvidia:
  Version:          1.1.2
  GitCommit:        v1.1.2-0-ga916309
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```
* NVIDIA container library version
```
cli-version: 1.10.0
lib-version: 1.10.0
build date: 2022-06-13T10:39+00:00
build revision: 395fd41701117121f1fd04ada01e1d7e006a37ae
build compiler: x86_64-linux-gnu-gcc-7 7.5.0
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fplan9-extensions -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections
```
*  NVIDIA packages version
```
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend
|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)
||/ Name                                 Version                 Architecture            Description
+++-====================================-=======================-=======================-=============================================================================
ii  libnvidia-container-tools            1.10.0-1                amd64                   NVIDIA container runtime library (command-line tools)
ii  libnvidia-container1:amd64           1.10.0-1                amd64                   NVIDIA container runtime library
un  nvidia-container-runtime             <none>                  <none>                  (no description available)
un  nvidia-container-runtime-hook        <none>                  <none>                  (no description available)
ii  nvidia-container-toolkit             1.10.0-1                amd64                   NVIDIA container runtime hook
un  nvidia-docker                        <none>                  <none>                  (no description available)
ii  nvidia-docker2                       2.7.0-1                 all                     nvidia-docker CLI wrapper
```Also the Nvidia Modulus container is not on CUDA 12.0 yet, but I am not sure if this is the issue. You could consider a pip install.Interesting. Consider trying the Nvidia Pytorch base container that we build from to see if that works fine. If it does we know its some issue with the Modulus container (although a fix is unknown).Hi, @ngeneva .
I tried as you told me.
And it seems working.kdg@DESKTOP-7ICQ4NK:~$ docker run --gpus all -it --rm nvcr.io/nvidia/pytorch:22.12-py3NVIDIA Release 22.12 (build 49968248)
PyTorch Version 1.14.0a0+410ce96Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.Copyright (c) 2014-2022 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:145.24 KBNOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be
insufficient for PyTorch.  NVIDIA recommends the use of the following flags:
docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 …root@7fff099603ff:/workspace#And I think it looks lie some issue with the Modulus container.@ngeneva @kdg5424This has been a known problem with the Modulus containers for some time. The Pytorch container has always worked without issue.For Modulus 22.09 you had to remove some of the injected files included in the container. Here’s the below dockerfile to generate a working 22.09 container from the existing oneThanks for reply.
It works well.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
237,zero-equation-model-error-function-object-has-no-attribute-free-symbols,"I am attempting a zero equation case of my own. My solver class is as follows.Like the LDC example I’ve ran my case with just the naiver stokes equation successfully before adjusting it for Zero Equation model. I added nu to the validation data and then made the necessary adjustments to the solver class detailed above.
However, when  attempting to train, I get the following error:My question is how should I resolve the following error?
The major difference between my case and the LDC case is that I meshed my geometry from an STL.Powered by Discourse, best viewed with JavaScript enabled"
238,getting-this-error-trying-to-run-examples-importerror-cannot-import-name-modulusconfig-from-modulus-hydra,"Any help is greatly appreciated.I am running Ubuntu 20.04 and Docker.
The error on multiple files is:
ImportError: cannot import name ‘ModulusConfig’ from ‘modulus.hydra’Make sure you are using Modulus22.07 Docker for it also.Seem like you are using Modulus22.03 Docker with 22.07 example.I tried both ways.  I am using the modulus22.07 with the 22.07 examples.  I can process 22.03 examples?Sound like your 22.07 container is actually a 22.03 container if its working with 22.03 examples.Verify the Modulus version inside you’re container is in fact 22.07:Powered by Discourse, best viewed with JavaScript enabled"
239,problems-with-pysdf-in-a-docker-container,"Hello,I have a problem with pysdf library. I’m using a modulus docker image v23.05 on a cluster and when I try to use tessellation I get this error message:I installed docker image specifically for using this feature but it doesn’t seem to work in my case. Is there anything I can do solve this issue?Driver Version: 525.105.17; CUDA Version: 12.0; GPU: A100Hi @gorpinich4Can you launch an interactive docker session of the docker container and first check:If this doesn’t work check for libsdf.so in /external/lib/. This will be present in the container.Now verify that this path is present in your LD_LIBRARY_PATH.Make sure you are not somehow changing the LD_LIBRARY_PATH when running your container.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
240,how-to-enable-amp,"Hello,I would like to enable AMP to reduce the used memory and time in training simnet model.
However it looks like not to work.
Could you show me how to enable AMP?Our Environment
HW ; AWS EC2 g4dn.xlarge
Amazon EC2 G4 Instances — Amazon Web Services (AWS)
SimNet Version 21.06(docker container)
Example : helmholtzResult(2 cases)Case 1. without modifying code
%python ./helmholtz.py --amp AMP
…
[0m: AdamOptimizer, /usr/local/lib/python3.8/dist-packages/simnet-21.6-py3.8.egg/simnet/optimizer.py
beta1: 0.9
beta2: 0.999
epsilon: 1e-08
amp: False
…Case 2. with modify /simnet/build/lib/simnet/optimizer.py
fix the default value of AMP True
%vi /simnet/build/lib/simnet/optimizer.py
…
group.add_argument(‘–amp’,
help=‘use Automatic Mixed Precision (AMP)? (0/1)’,
type=str2bool,
default=True)
#default=False)
…
%python ./helmholtz.py --amp AMP
result was same as Case.1Also in the both of case1 and 2 the training time was almost same as the case without --amp AMP option.Thanks,
Toshiaki YokoiThanks for reporting this. This is a bug and will be fixed in the next release. For now you can activate AMP by changing the environment variable:export TF_ENABLE_AUTO_MIXED_PRECISION=1Please note that there are known issues with AMP when used for second and higher-order derivatives, and with AMP your training loss may go to NaN/Inf. We are working on fixing this issue.Hi,Thank you for your reply.
I’m trying that.Thanks a lot,
Toshiaki YokoiPowered by Discourse, best viewed with JavaScript enabled"
241,cannot-run-modulus-after-modulus-bare-metal-installation,"Hi Sir/Madam,I can import modulus after modulus bare metal installation. However, I cannot run the example since the permission to the hydra config file is denied. Any suggestions? Thanks.
Screenshot_2022-11-09_11-20-42863×181 30.5 KB
Hi @dehao.liu12We have not seen this error before. This is a permissions issue, so there is likely not much we can debug from our end.Right now I would suggest first trying to run the intro hydra tutorial. If this does not work, I would consider opening a ticket on the Hydra github repo to ask about a solution.Hi ngeneva,I tried to run the script in sudo way. But there is another error.
image742×222 36.8 KB
I think you don’t have the permission. Please put the output of ls -la in your directory.The problem has been resolved.Thanks for the help.Powered by Discourse, best viewed with JavaScript enabled"
242,which-step-the-network-model-is-saved,"Hello,When modulus training is finished I would like to know if the model(.pth) was saved at the step when the aggregated loss got minimum in the training.Can you let me know how to know the model saved step?Regards,Hi @yokoi.toshiakiThe model is saved based on save_network_freq parameter in the trainer which is set on your config YAML with:Right modulus just saves a single checkpoint, see in the save_checkpoint function. You could modify this to use the step parameter in the file name. Also could try the stop criteria feature (at the bottom of the page).Powered by Discourse, best viewed with JavaScript enabled"
243,modulus-v22-03-installation-error-on-cluster,"Hi:
I installed Nvidia Modulus v22.03 successfully on my laptop. However, when I was trying to install Nvidia Modulus v22.03 on a cluster with a Conda environment (no root). After installation, the job helmholtz.py cannot run with the following error, I wish to ask how to solve this:Traceback (most recent call last):
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 124, in initialize
DistributedManager.initialize_env()
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 67, in initialize_env
rank = int(os.environ.get(“RANK”))
TypeError: int() argument must be a string, a bytes-like object or a number, not ‘NoneType’During handling of the above exception, another exception occurred:Traceback (most recent call last):
File “/project/user/DL/modulus2203/examples/helmholtz/helmholtz.py”, line 95, in
run()
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/hydra/utils.py”, line 58, in func_decorated
DistributedManager.initialize()
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 127, in initialize
DistributedManager.initialize_slurm(port)
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 108, in initialize_slurm
DistributedManager.setup(
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/site-packages/modulus-22.3-py3.9.egg/modulus/distributed/manager.py”, line 150, in setup
os.environ[“MASTER_ADDR”] = addr
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/os.py”, line 684, in setitem
value = self.encodevalue(value)
File “/project/user/DL/anaconda3/envs/modulus2203/lib/python3.9/os.py”, line 756, in encode
raise TypeError(“str expected, not %s” % type(value). name )
TypeError: str expected, not NoneTypeI got the same error months ago. See my previous posts. I am using Nvidia Modulus through a python venv not Conda. The problem is that the Hydra i.e. the configuration manager is not able to set some of the environment variables from the conda env, which is not a problem in python venv.Just check for python --version. If the default python version is very old create an empty conda env and then use that env to create a python venv. please let me know if you need detailed instructions.I am having a very similar situation… I have not tried venv yet.  I would really appreciate if you would send me the detailed instructions.might be issue but I am using 22.07Powered by Discourse, best viewed with JavaScript enabled"
244,modulus-installation-using-github-not-successfull-no-module-named-modulus-hydra,"Hello!I am trying to install Modulus on Ubuntu in my workplace. However, as we are not allowed to use Docker, I am trying to install it the Bare Metal version from Github (GitHub - NVIDIA/modulus: A PyTorch based deep-learning toolkit for developing DL models for physical systems)I installed all requirements using:pip install matplotlib transforms3d future typing numpy quadpy
numpy-stl==2.16.3 h5py sympy==1.5.1 termcolor psutil
symengine==0.6.1 numba Cython chaospy torch_optimizer
vtk chaospy termcolor omegaconf hydra-core==1.1.1 einops
timm tensorboard pandas orthopy ndim functorch pintAnd then cloned and installed Modulus using pip.
I can import modulus successfully on Python, however I get a “no module” error for trying to import modulus.hydra or modulus.key.When I look at the github file, there are no specific hydra or key sublibraries though…How could I solve this? Thank you for your help!DanielHi @cdanielcWe will be releasing additional documentation soon, but you need to be use the Modulus Symbolic repo if you’re trying to run existing Modulus examples. If you’re trying to run an example here you’ll need update imports from:toWe are working on updating all of this behind the scenes right now. Thanks!Powered by Discourse, best viewed with JavaScript enabled"
245,simnet-21-06,"Based on the user guide, Simnet 21.06 requires python 3.6, tensorflow 1.15, and horovod 0.21.0. However, this horovod version is not compatible with python 3.6.  Can Simnet 21.06 be run on python 3.8?Welcome to the NVIDIA Developer forums.
I haven’t used Modulus personally - but I had a quick look on the horovod site and the summary of the 0.21.0 release and even the latest version implies it supports 3.6 and higher.
horovod · PyPI
When you tried what error or warning suggested that Python 3.6 wasn’t supported ?Thanks for your response. I’m trying to install nvidia-horovod (See the attachment).

nvidia-horovod1520×82 6.55 KB
I’m using simnet 21.06, and I want to run a script using multi-gpu. I’m not sure whether I must install nvidia-tensorflow and nvidia-horovod to run simnet.If possible, I would like to know all the packages I need to perfectly run simnet.Powered by Discourse, best viewed with JavaScript enabled"
246,partial-outputs-of-simnet-could-not-unroll-graph,"Hi!I am solving a 3-dimensional linear elasticity problem. When declaring a solver class, you have to specify 3 displacement components and 6 components of the stress tensor as output. Is it possible to restrict ourselves to only a part of the stress tensor components (for example, 3)At the moment I have something like this:But I would like to see something like that:An error occurs “could not unroll graph!”. What am I doing wrong?This is because the 3d linear elasticity equations include the the entire 6 stress components and without some of these the equations are not complete. Based on the 3d equations, the network requires to compute sigma_zz, sigma_xz, sigma_yz but you are not specifying these components anywhere and therefore you are getting the graph unrolling error.Powered by Discourse, best viewed with JavaScript enabled"
247,modulus-fourcastnet-pytorch-learning-rate-scheduler-warning,"@ngeneva @tbednarz
PyTorch warning:-…/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of lr_scheduler.step() before optimizer.step(). In PyTorch 1.1.0 and later, you should call them in the opposite order: optimizer.step() before lr_scheduler.step().  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at torch.optim — PyTorch 1.13 documentation
warnings.warn(""Detected call of lr_scheduler.step() before optimizer.step(). ""Hi @john.taylor1Thanks for bringing this to our attention. I’ll get it added to our backlog.This warning message is important to keep in mind for users of PyTorch 1.1.0 and later. It advises to call optimizer.step() before lr_scheduler.step() to avoid PyTorch skipping the first value of the learning rate schedule. Following this recommendation will ensure that the learning rate is updated correctly during training, resulting in better model performance. It’s always helpful when software packages provide such warnings to help users avoid potential issues.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
248,l-bfgs-and-adahessian-optimizers,"Hi I have a couple of questions.1-) How can I use l-bfgs optimizer? I can not find any example. I want to use it just by itself. and also, I want to use it after an optimization period by using adam optimizer then l-bfgs optimizer. Several papers used this approach.2-) how can I use Adahessian optimizer. Agai  I can not find any example.3-) During the training I only want to save the best model. But as far as I see, periodically given a parameter value, modulus saves models sequentially. How can I save only the best model?
Best Regards
Thank youHI @udemirezenThanks for your interest in Modulus. Responses to your questions are sectioned below:How can I use l-bfgs optimizer? I can not find any example. I want to use it just by itself. and also, I want to use it after an optimization period by using adam optimizer then l-bfgs optimizer. Several papers used this approach. how can I use Adahessian optimizer. Agai I can not find any example.Switching between optimizers should be as simple as changing the your config.yaml file. There’s info on optimizers we support in the config in the user-guide. Related source code if you are familiar with Hydra. For example:The reason why we have no examples that use L-BFGS / AdaHessian is that typically we have found that Adam works. But its still great to experiment with these. Note that you may have to tune the parameters of the optimizer which can be done in the yaml as well. The parameters you can control / defaults are found here.During the training I only want to save the best model. But as far as I see, periodically given a parameter value, modulus saves models sequentially. How can I save only the best model?If your training is set up correctly and stable, the best model should be the model at the end of training which should have the lowest training/validation loss if there is no over fitting. If you’re interested in early stopping based on validation error have a look at the stop criteria utility which can be set up in your config (there is presently a bug with this feature, please see this post with the fix).Thank you very much for your good explanation. Now everything is crystal clear :DHi @udemirezen, any idea how to customize Modulus with adam + l-bfgs optimizer? as you mentioned, it is getting popular to see combining these two optimizers. thanks.Hi,Regarding the use adam + l-bfgs optimizer, is it possible to run e.g. 10,000 steps with adam. Then I change the optimizer to l-bfgs and resuming running from the 10,000th step? Does it work this way?ThanksHi @jay_caseRight now its not possible to have the combination of the two directly working with each other in the training loop. It should be possible however to train for a fixed number of epochs, grab the model checkpoint, then train using that checkpoint and a different optimizer as @tsltaywb mentioned.Deleting (or renaming, preferred) your optim_checkpoint.pth in the outputs folder will force modulus to not try to reload the old optimizer state. Thus you can switch from say Adam to BFGS in your config and use the same training directory.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
249,cannot-change-the-activation-function-for-the-ldc,"Dear All,
I am using Nvidia modulus 22.09
I am trying to change the activation function for the LDC problem.But When I import the required library as shown in the tutorial:from modulus.models.layers.layers import ActivationI get this error
No module named ‘modulus.models.layers.layers’Thanks in advanceHi @omarkhaledsallamPlease try from modulus.models.layers import ActivationWhich tutorial are you referring to here? Please provide the link if you can and we will get it fixed. Thank you!Thanks for you replyI get this from the tutorial link below:
https://docs.nvidia.com/deeplearning/modulus/user_guide/features/configuration.htmlIn the (Changing Activation Functions) sectionI changed the the import to
from modulus.models.layers import Activationand it worked  :)
ThanksHi @ngenevaI wanted to change the activation function as well and I already changed the path.However, I get following error:How can fix this issue?Many thanks in advance.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
250,time-dependent-boundary-conditions,"Hello all,I want to solve a time-dependent diffusion problem where the boundary temperatures are a function of time.Is it possible to implement time-dependent boundary conditions in Modulus ? If so, can we give some discrete data like a table that represents time vs temperature on a boundary?Can you please give any suggestions on this? Thanks.Hi @bvss89Assuming that the current time is an input variable t and there’s a analytical function for the boundary condition u_{boundary} = f(t,...). This should be achievable by providing a sympy expression as the output/target variable of boundary constraint.An example of this (not a function of time, but of space) is in the annular ring example examples/annular_ring/annular_ring/annular_ring.py which can be found on the examples GitLab repo. This problem has a parabolic inlet velocity profile enforced using a sympy expression:A similar approach can be used but with a function of time for a time dependent boundary condition.Now for a discrete table of values, you will likely need to make a custom dictionary loader for your data. I.e. you will need to manually build a dictionary of input and output variables that reflect the different discrete points in time you have on file. The PointwiseConstraint.from_numpy() function should help here located in modulus/domain/constraint/continuous.py.An example that uses this can be found in examples/seismic_wave/wave_2d.py.Thanks a lot @ngeneva for the detailed explanation.Hi @bvss89 ,Hope the response was able to help you move forth with your use case. Would you be interested in speaking to the modulus team to share more details on the use case and we can try to share more insights on how to apply Modulus for you problem. You can reach out to us directly at modulus-team@exchange.nvidia.com.Thanks
RamThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
251,enquires-about-running-jobs-using-multiple-gpus,"Hi,I think I managed to run my job using 2 GPUs. I tried to benchmark 2 jobs - 1st one running 1 GPU, and 2nd one with 2 GPUs. The step size is 10,000.Both took around the same time using 1.5hrs.
The loss for the 2nd case is lower, but not by much -[step:      10000] loss:  2.716e-02, time/iteration:  2.154e+02 ms
vs
[step:      10000] loss:  3.458e-02, time/iteration:  2.006e+02 msIn the 2nd job, there’s a msg which seems to imply I’m using 2 GPUs:Initialized process 0 of 2 using method “openmpi”. Device set to cuda:0
Initialized process 1 of 2 using method “openmpi”. Device set to cuda:1So am I using 2 GPUs in the 2nd job? Why is it that both job took the same time to complete?In  https://docs.nvidia.com/deeplearning/modulus/user_guide/features/performance.htmlit is mentioned that:This data parallel fashion of multi-GPU training keeps the number of points sampled per GPU constant while increasing the total effective batch size. You can use this to your advantage to increase the number of points sampled by increasing the number of GPUs allowing you to handle much larger problems.Is this what is happening now? So in a multi-GPU run, I am actually using twice the batch size in total for 2 GPUs, is this correct? Hence, the time taken will be the same.Please clarify. Thank you.Hi @tsltaywbThanks for your interest in Modulus, and good question. You are correct. Batch sizes in Modulus are defined such that this is the batch size per process. In physics driven problems we generate training input “data” on initialization, which is simply batch_size * batch_per_epoch. So if you don’t half this number going from one to two GPUs, you’re actually increasing your dataset by a factor of two.This is weak scaling and maintaining the same performance (wall clock) is the ideal. Theres some additional information in this thread here that can hopefully clear things up.Powered by Discourse, best viewed with JavaScript enabled"
252,unable-to-get-3d-geometry-in-modulus,"I am unable to run a pipeline with 3D geometry from STL files (even from Modulus examples: Blood Flow in Intracranial Aneurysm).
I get an error when I define the mesh as True (to make it a closed surface):But then I get the following error:
image1022×361 55.4 KB
And it seems there is an issue with the closed geometry.Then, I try with False (meaning it would be an open geometry)And I get an error for it not having any volume.The machine being used is Dgx1 using redhat8 and I am running it inside a podman container. I am using an official Nvidia container for modulus with version Modulus v22.09. I have access to the GPUs and driver’s version.I have successfully run other Nvidia examples that don’t involve STL files nor 3D geometries.Any comment or feedback would be greatly appreciated, thank you for the help!Hi @maria-jose.castano-sancheThanks for trying out Modulus. This is a rather unusual problem given that your using the docker container. What is the current CUDA version / drivers you’re using. This Modulus container is based on CUDA 11.7, which requires NVIDIA Driver release 515.  Wondering if its an issue related to CUDA versions.Hello,
Thank you for getting back to me. The cuda is 11.4 and drivers 470.129.06 that I am currently using. Is there a Modulus version fit for these parameters? Or is there anything to be done?
Thank you!Powered by Discourse, best viewed with JavaScript enabled"
253,guideline-for-variable-scaling-in-modulus,"Hello,I don’t understand how to decide the scale of variables(time, length, mass, etc.) for normalization in training various type of modulus models.If you know some kind of guideline for such a scaling, I would like you to let me know.Thanks,Hi @yokoi.toshiakiWe have some information on variable scaling in our user-guide with some external links. We also have some automated utils to help with scaling/non-dimensionalization which can be seen in the cylinder example.There’s also a few posts on this forum discussing this topic such as:Hi @ngenevaThank you for your reply.I have tried sevral approaches in the unsteady CFD problem with low Re num. based on that document so far.
However I can’t find a good scaling condition in which NN convergence is achieved.Therefore I have a question.In the most of your CFD samples, nu is ~0.01 and they work well.
How did you find such a good conditions?Thanks,.Mostly experience and empirical testing. Think about this like normalizing data for traditional DL models, there are a lot of ways to do this with varying results (as commented here).Regarding the viscosity, its also key that a system is selected that’s not too complex in terms of the underlying dynamics. That’s why for many of the flow problems are at lower Reynolds number or have a turbulence models to help with the smaller scales.Sadly, there isn’t one sure-fire solution for all problems, rather a lot of techniques that can be used to improve convergence in certain instances. Check out the user guide with a list of ideas to test. For example, integral continuity planes can really help with flow problems as used in many of our examples including annular ring.Powered by Discourse, best viewed with JavaScript enabled"
254,cant-find-archive-for-modulus-ext-ui-2-0-0-cp37,"Hello, I’m trying to use latest example of modulus scenarios in Omniverse. I’ve tried different version of Omniverse, in all of them was able to instastall hpcvis.vtkm and modulus_ext.core extensions, but I cannot install modulus_ext.ui-2.0.0.In Omniverse console it says that “[Error] [omni.kit.registry.nucleus.utils] [omni.kit.registry.nucleus]: [kit/public] Can’t find archive for: ‘modulus_ext.ui-2.0.0+cp37’.”Also trying to manually wget the extension from this link: https://kit-103-0-public-extensions.s3.amazonaws.com/public/3/archives/modulus_ext.ui-2.0.0%2Bcp37.zip doesn’t work.How can I get modulus ui extension?Hi @michaltakacThanks for the report. We’ve restaged the UI extension. Please give it another install attempt and let me know if you’re still having issues downloading it! Thanks!Works now!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
255,pytorch-grad-issue-while-using-solve-in-derivatives,"I have been trying to develop and run a custom model for my physics informed NN, but I don’t understand the issue facedScript:The error I am facing:which arises in the side script:You see, the variable “y” is defined in the side script, and I am unable to enable require_grad as recommended online.Please help me out with this issue. I would be really obliged if you could please help me out @ngenevaAccording to me this file should run without any issuesThank youHi @nihalpushkar11Do you know precisely which constraint / inferencer is causing this error. If not could you isolate it? This is happening because you are requesting a gradient that cant be computed because it has not been registered with auto-grad to record its gradients (this is what requires_grad does).hi @ngeneva
sorry for not mentioning earlier, but this error is encounter on adding the inferencer, thank you for you advice i was now able to review that one of the variable was not enabled with “requires_grad” and hence it was not running.removing that variable solved the issue, but how can add that variable with auto-grad? could you please recommend some documentations?Thanks and regardsNihalHi @nihalpushkar11This is typically handled for inputs using the requires_grad=True inference parameter, however you mentioned here that doesn’t work for some reason. Otherwise variables inside the symbolic graph allow gradients to be calculated.Which variable did you remove?Apologies, Actually I was editting the require_grad = True in the wrong file. Your solution worked, Thank youPowered by Discourse, best viewed with JavaScript enabled"
256,can-i-generate-a-3d-geometry-form-2d-geometry,"if I have a 2d geometry, i want to stretch 2d geometry to generate 3D geometry, more complex, can I stretch 2D geometry spirally?Hi @tao-zhan18Not right now. Presently, you’ll need to use the 3D geometric primitives to create a volume to sample from. If you use a CAD software you can consider exporting this to STL and using the tessellated geometry feature in the docker image.Powered by Discourse, best viewed with JavaScript enabled"
257,parameterization-for-grown-ups,"Hello:I want to add another twist to the parametrized solution shown in “Parameterized Simulations and Design Optimization: 3D heat sink”What if you have not just 6 dimensions that are a possible parameter, but a whole function?Simple example: f(x)_xx + k(x)*f(x) = 0,but there are many possible functions k(x) and you want the network to learn the output f(x) under many k(x), so in the future you have a new k(x) as an input and want the network to get the most likely answer f(x).Any ideas? Thx in advance.Hello, One approach to solving something like this is to use “Neural Operators” like our example here Darcy Flow with Physics-Informed Fourier Neural Operator — Modulus 22.03 Release documentation. In this case our k(x) is is the permeability and we are solving for the darcy flow. You can physics inform this using several methods as shown. Another approach is to parameterize your k(x) function. For example, you could take the first couple of terms of the Taylor series and solve for them.Powered by Discourse, best viewed with JavaScript enabled"
258,no-module-named-quadpy-cn-helpers-error-in-quad-rect-in-interface-problem-by-variational-method-example,"I’m trying to follow along with the “Interface Problem by Variational Method” example, but when I try to use quadpy with:
quad_rec = Quad_Collection(Quad_Rect, paras),I run into the error :
ModuleNotFoundError: No module named 'quadpy.cn._helpers'with the traceback showing:Has this been encountered before? Is it an issue with newer versions of quadpy?Update - according to Nico Schlömer nschloe@mondaytech.com, private functions such as quadpy.cn._helpers are no longer accessible by default. Is there an updated version of Modulus that takes this into account?Hi @matthew.t.gillUnfortunately not right now, presently we aren’t updating the variational utils given that quadpy is no longer OSS. The most recent update code is always on github: GitHub - NVIDIA/modulus-sym: An abstracted framework for training AI surrogates of physical systems using physics-based symbolic loss functionsUnderstood. Are there plans to eventually restore variational util functionality?Powered by Discourse, best viewed with JavaScript enabled"
259,modulus-release-22-09-helmholz-example-fails-with-runtimeerror-cuda-out-of-memory-on-geforce-gtx-1650,"Hi,On this cardlspci  | grep NVIDIA
21:00.0 VGA compatible controller: NVIDIA Corporation TU117 [GeForce GTX 1650] (rev a1)
21:00.1 Audio device: NVIDIA Corporation Device 10fa (rev a1)with this SMInvidia-smi
Fri Nov  4 09:36:22 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce …  Off  | 00000000:21:00.0 Off |                  N/A |
| 30%   32C    P8     4W /  75W |     73MiB /  3911MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      3207      G   /usr/lib/xorg/Xorg                  9MiB |
|    0   N/A  N/A      3383      G   /usr/bin/gnome-shell                2MiB |
|    0   N/A  N/A      5130      C   python                             57MiB |
±----------------------------------------------------------------------------+I get this error, when failing to allocate 20 Megabytes - so I don’t think it is related to the reatively weak GPUIt reads as if TorchScript (part of PyTorch) doesn’t have access to the memory reserved by PyTorch?Hi @maricThe error tells the whole store:
3.82 GiB total capacity; 897.88 MiB already allocated; 20.25 MiB free; 3.06 GiB reserved in total by PyTorchPyTorch will allocate its own chunk of VRAM for running, and what’s left (MiB free) is the max additional memory you can additionally allocate during run time at this point in the script. So you’re running out of GPU memory, which for a card with only 4Gb of ram thats expected.Be mindful that we develop on NVIDIA V100s which have at least 16Gb of memory. This is stated in our userguide. That doesn’t mean all problems need 16Gb (quite the opposite) but this means for you’re hardware you will likely need to adjust.The immediate options you have are:Thanks @ngeneva , all clear, I have misread the error message, I thought 3.06 GiB reserved in total by PyTorch was what Modulus has available in total so an the requested 20.00 MiB belong to that memory, while 20.25 MiB free (almost nothing) is what is left for other processes.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
260,attribute-error-when-building-a-isosceles-prism-using-the-csg-module,"I am trying to build a 3D isosceles prism with the csg module. I assign the required arguments in the format stated in the documentation. However, I get an Attribute Error of ‘Add’ object has no attribute ‘dot’. The full trace can be seen in the pictures below and my code is copied below.
image1097×706 49.9 KB


image1069×743 51.2 KB
import numpy as np
from sympy import Symbol, Eq
import modulus
from modulus.hydra import to_absolute_path, to_yaml, instantiate_arch
from modulus.hydra.config import ModulusConfig
from modulus.csv_utils.csv_rw import csv_to_dict
from modulus.continuous.solvers.solver import Solver
from modulus.continuous.domain.domain import Domain
from modulus.geometry.csg.csg_3d import Box, Cylinder, IsoTriangularPrism, TriangularPrism
from modulus.continuous.constraints.constraint import (
PointwiseBoundaryConstraint,
PointwiseInteriorConstraint,
)
from modulus.continuous.validator.validator import PointwiseValidator
from modulus.continuous.inferencer.inferencer import PointwiseInferencer
from modulus.key import Key
from modulus.node import Node
from modulus.PDES.linear_elasticity import LinearElasticity
from modulus.plot_utils.vtk import var_to_polyvtkx, y, z = Symbol(“x”), Symbol(“y”), Symbol(“z”)
prism_one_centre = (0,0,0)
prism_one_base = 0.05196
prism_one_height = 0.015
prism_one_height_prism = 0.1prism_one = IsoTriangularPrism(prism_one_centre, prism_one_base, prism_one_height, prism_one_height_prism)Powered by Discourse, best viewed with JavaScript enabled"
261,adaptive-density,"Hello!At the moment I am trying the functionality of the framework on the Kirsch problem. And for a good solution, it requires a lot of density around the cutout. Is it possible to adaptively compact the sample closer to the edges during training? At the moment I have divided the area into two parts - the small area around the cutout and everything else. Are there any smarter ways?Kirsch problemDividing the interior domain into two low and high-resolution regions is a good approach for this problem. We have an example similar to the Kirsch problem that is using the same approach, and can be found in examples/fuselage_panel. Another approach you can try is the importance sampling. Please refer to the user guide and the sample example in examples/annular_ring/annular_ring_importance_sampling.py for more details.Thanks, but while working, I noticed that while the annular_ring example was running, no logging occurred. If you pause the model and then continue training, sampling starts from the beginning.Powered by Discourse, best viewed with JavaScript enabled"
262,modulus-container-no-longer-functions-after-updating-to-latest-display-cuda-drivers,"Hello,We have an 8x GPU (v100) system running RHEL8 that we’ve been using with modulus for research (EDU).
Our IT department recently updated the system, installing the latest gpu drivers + cuda available from the nvidia stream, but now the modulus container no longer functions.
Running any modulus script within the container we  now get the following error message:Our currently installed driver and cuda versions are:I’ve repulled the latest modulus image from NGC (22.09), that says it was updated Oct 31st, and see the same error.
Yet this document indicates that v22.09 deep learning containers should be supported on our driver/cuda combination:This support matrix is for NVIDIA® optimized frameworks. The matrix provides a single view into the supported software and specific versions that come packaged with the frameworks based on the container image.In the meantime, I’ve managed to get a bare-metal install of modulus running in a conda environment, it’s giving me warnings about unsupported pytorchscript version conflicts (I’ll start another topic about that), but otherwise seems to run fine with the same scripts that fail in the container.I’m using the 22.09 release from the modulus gitlab, which I assume is the same as within the 22.09 container images - so I wonder if the CUDA runtime error is being thrown by an older PyTorch version within the container that needs to be updated?Hi @bsarkar, does the NGC PyTorch container work for you or does that fail too?
nvcr.io/nvidia/pytorch:22.08-py3Yes, that one does seem to workRunning the same in the modulus image, without executing my scripts directly, I see a few more error messages at the top regarding the compat lib during container startupI don’t see the compat folder in my local filesystem, so is that part of the container image overlay?ok, with that information in hand I was able to create a writeable copy of the containerWhich now allows the removal of the compat library during startup(despite the warning about nv files not being writable, this still seemed to work)Is this a fundamental difference between docker / singularity?
i.e. system not mutable unless explicitly build that way?We can’t use docker in our university HPC environment, so I had followed the ngc instructions on creating singularity builds.This user guide details how to navigate the NGC Catalog and step-by-step instructions on downloading and using content.Powered by Discourse, best viewed with JavaScript enabled"
263,the-results-of-ldc-2d-zeroeq-py-is-not-the-same-as-those-in-simnet-v21-06-user-guide,"I tried to run the example ldc_2d_zeroEq.py without any modification, but the results I got were not the same as shown in SimNet_v21.06_User_Guide.The overall loss goes down, but the momentum_imbalance takes a huge value compared to the user guide. As a result, the validation score takes a terrible value.

Web キャプチャ_1-2-2022_113430_10.193.1.731584×1216 188 KB


Web キャプチャ_1-2-2022_113443_10.193.1.731584×1216 185 KB

I made a graph of the prediction result of u, but it is not the prediction that appears in the user guide.
By the way, when I trained ldc_2d.py, it did not match the user guide, but it scored better than the user guide.

Web キャプチャ_1-2-2022_114556_10.193.1.731584×1216 180 KB

So, I don’t think the computational environment is the cause of the problem. But just to be sure, here’s how my environment is.Tesla V100
NVRM version: NVIDIA UNIX x86_64 Kernel Module  470.82.01  Wed Oct 27 21:21:55 UTC 2021
GCC version:  gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)
Modulus 21.06 container for linuxPowered by Discourse, best viewed with JavaScript enabled"
264,any-example-about-using-microsoft-nni-with-nvidia-modulus,"Or is there any example of auto-tuning the hyperparameters of the net?What makes me confused is how to report_intermediate_result.I can not find a method to report the loss during training.Is modulus capable of some tricks, like calling the callback function every 1000 steps?Thank you very much.Hi @Zhao-ZCIf you want to add a custom callback inside the training loop you can add it in the trainer.py file. For example, if you want to record the losses at line 546, the losses for that iteration are stored in a dictionary losses which can be used to save to file.Thank you very much!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
265,pde-based-training-of-new-models-in-modulus-core,"Hello,I’m interested in trying out the graph and recurrent network models, introduced in Modulus Core, with a PDE based loss function. Is there currently a way to do this? Modulus Sym currently doesn’t have those models while Modulus Core doesn’t appear to be set up for custom PDE-based loss functions.ThanksHi @rohan.patelThat is correct. Modulus (Core) is a more PyTorch developer orientated tool kit while Modulus-Sym provides an abstract framework with the symbolic loss representation. Presently PDE based loss calculations (with automatic gradient calculations) is something limited to Modulus-Sym, which does not support RNNs or graph NNs.Models in Modulus Core presently require you the manually write PDE loss functions in standard PyTorch methods.The RNNs and GNNs in Modulus core were developed with data-driven applications in mind, thus not fully compatible with Modulus Symbolic at the moment.Powered by Discourse, best viewed with JavaScript enabled"
266,solving-higher-order-differential-equation,"RuntimeError:
Module ‘Derivative’ has no attribute ‘gradient_dict’ (This attribute exists on the Python module, but we failed to convert Python type: ‘dict’ to a TorchScript type. Dictionary inputs must have entries. Its type was inferred; try adding a type annotation for the attribute.):
File “/modulus/modulus/eq/derivatives.py”, line 82
def forward(self, input_var: Dict[str, torch.Tensor]) → Dict[str, torch.Tensor]:
output_var = {}
for var_name, grad_sizes in self.gradient_dict.items():
~~~~~~~~~~~~~~~~~~ <— HERE
var = input_var[var_name]
grad_var = self.prepare_input(input_var, grad_sizes.keys())while solving higher order equations getting thus errorHi @ms21mtech11006The information provided is pretty limited here. My suggestion would be to try shutting off torch script (JIT) and seeing if that runs:config.yaml: jit: falseit was already written in code and it is not working getting, above error after this only.Powered by Discourse, best viewed with JavaScript enabled"
267,rounded-corners-3d-geometry,"Hi,
in the geometry module, i see examples (Ahmed body) with chamfered or rounded edges to rectangle. But i dont see any examples as to how one could do that with CSG. Are there some examples that I could see to get an idea of how to do this?
RegardsHi @k.narayananGeometry with such features can become increasingly difficult to implement in our CSG model which currently only supports a handful (but the essential) primitives. One could for example achieve rounded corners using cubes and cylinders, or beveled corned by subtracting an angle cube from another’s corner. So its possible with CSG ops, see this chapter in the user-guide for some more info. Python files are on the public Gitlab examples repo. Also some of the heatsink problems have some geometry set up which may have info that useful.But for really complex geometries, we typically don’t recommend the CSG module because of the set up cost right now.Instead suggest users to use our STL support with PySDF for these complex geometries. Most 3D files can be converted into STLs, then imported into Modulus for sampling which we have an example for in the userguide.We are actively working on improving support for geometries such as Ahmed body, so there are better features in the pipeline for the next few releases.Powered by Discourse, best viewed with JavaScript enabled"
268,issues-with-hydra-configuration-file-in-google-collab,"I’m using Modulus on Google Colab and was able to run the hydra example. Now, when trying to implement my own problem, it seems that I am having an issue with the configuration file.image991×302 12 KBWhen I run the traceback I get this:
image862×730 34.4 KBI’m pretty sure the issue has to do with the configuration file as when I removed the wrapper @modulus.main(config_path=""conf"", config_name=""conf_flow"") the code works until I get to flow_slv = Solver(cfg, flow_domain) which needs a cfg to run.I was wondering whether there were any workarounds to using a config file as its not working at all for me right now.I’m just learning Modulus myself, but perhaps this will help.The first error is saying that you passed -f into the command line and -f isn’t a command line parameter that it can recognize. You may be running it differently from how I do it, but removing -f should get rid of the first error. I assume you were doing -f mathieusalz1s_config.yaml, but I don’t believe this is necessary.I was able to use my own config file by creating a new file in the conf folder. E.g. conf/my_config.yaml and specify that in the wrapper. For example my altered aneurism sample might be:Hi @mathieusalz1First confirm that theres no additional flag getting added when running. I’m not sure what that -f is.Also, Hydra is known cause some head aches in Jupyter (an maybe Collab I suppose) notebooks. However, we provide a hydra compose function that should allow you to generate the config without the decorator. Give something like this a try:Some official Hydra docs on the compose function exists, but keep in mind that Modulus has its own implementation. I also found this sample collab notebook that may help.Powered by Discourse, best viewed with JavaScript enabled"
269,unknown-runtime-specified-nvidia,"Hi,I apologize in advance if the solution to my question is trivial. I was trying to run the docker image and mount the modulus examples using the following command
sudo docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 
–runtime nvidia -v ${PWD}/examples:/examples 
-it --rm modulus:22.09 bashI verified that nvidia-docker2 has been installed, but I received the following error
docker: Error response from daemon: Unknown runtime specified nvidiaAny help is appreciated!Hi @haowwangDid you restart your machine / docker? Please check this potential solution on the Nvidia Docker Github.I have the same issue. And I tried to restart the docker and it did not work. @haowwang Did you solve your problem?After restarting my computer and changing “–runtime nvidia” to “–gpus all”, it works.Powered by Discourse, best viewed with JavaScript enabled"
270,roadmap-releases,"Hello,This is an exciting project with lots of possibilities.Is there a development roadmap or release schedule for this project?Thank youHi @LimitingFactorThanks for your interest in Modulus, we understand that in recent months the team has not been that clear regarding development but with good reason.Perhaps you saw the GTC announcement, but Modulus is now moving to open-source development to give max transparency to our users + a lot of new features/improvements! Although I cannot give specifics about roadmaps/release schedules right now, please know that the team is working hard to make this significant transition with official releases coming in the not-so-distant future.Thanks!Physics-informed machine learning (physics-ML) is transforming high-performance computing (HPC) simulation workflows across disciplines, including computational fluid dynamics, structural mechanics…Thank you. I hadn’t seen that.Hi @ngeneva , is there a timeline for when will documentation for v23 be released? I use Modulus for some of my projects and am not sure if I should wait for v23 or continue using v22.09.I am super happy to see the new version on public GitHub!@ngeneva Thank you this is an exciting project. Is there a plan to release a beta version of pysdf as well? At the moment it isn’t possible to run the beta code without it when trying to import stl files. For example trying to run the aneurysm example case.ThanksHi,I thought we have always been able to download the full source code of Modulus, so how is this different from the project going open source now?Will development still continue as before with regular releases?Thanks!Hi @tsltaywbThe major change is a switch to Github to make the code more accessible as well as a re-architecture of the underlying code base to make it easier for both PyTorch experts as well as non-DL engineers to work with Modulus. Existing APIs are still supported and releases will still be happening.More information coming very soon. Thanks!Is it possible to combine new modulus / modulus-launch with examples for modulus-sym? modulus-sym is using Domain, Constraints and Solver, modulus-launch is a more standard PyTorch way of writing training code. How can I use both modulus / modulu-launch features and modulu-sym PDEs and constraints?This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
271,why-sin-x-in-k-omega-turbulence-model,"Hi,i want to solve a problem like this example. I understand how the k-omega model is implemented and then resolved in Modulus. However i don’t understand why is important to add the normalization to the variable “x” to “sin(x)” and at the same time why  this normalization is used in flow_net, k_net and om_net but not in the p_net.
Running the same problem without this normalization generate a solution far from the solution of the example.Thanks for your answers.Hi @tom_02The sin(x) here is used to implicitly enforce periodic boundary condition in the channel.Hi, there is a physical reason for this choice?The problem definition is a periodic channel. We found its better to implicitly force (The model can only output periodically) this as this removed a optimization loss that we would need to worry about.Normalization is applied to “x” as “sin(x)” to ensure that the range of values of “x” remains within a reasonable and consistent range. This prevents issues like overflow or underflow of values that can lead to numerical instability in the solution.In the specific case of flow_net, k_net, and om_net, normalization is used because these variables play a significant role in the k-omega model and directly influence the flow behavior and turbulence. Normalizing them helps to achieve a consistent and reliable solution.Powered by Discourse, best viewed with JavaScript enabled"
272,circular-3d-plane,"Hi,
Is it possible to create a circular plane that works like the object from the class Plane (from geometry.primitives_3d)?Hi @tom_02I suppose there are a couple options you could try:This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
273,error-in-running-some-example-tutorial-code-zeroequation,"I am trying to run the example with the NVIDIA modulus 22.07 container. Everything run fine until examples that contain the use of ZeroEquation which require to compute the sdf derivatives. (Example code: ldc/ldc_2d_zeroEq.py, three_fin_2d/heat_sink.py). I always get the following error when running the code.I am suspecting there is some bug in initializing the variable without the required_grad option enable. Anyone can give some suggestion on how to run these examples ?Hi @Hin,ldc_2d_zeroEg.py seems to be running fine for me. For this example can you please check to see if the Inferencer, Validator and Monitor have the requires_grad=True set. E.g. for the LDC example:The heat sink example also requires this to be turned on for the global_monitor monitor.Typically inputs to these components do not have input gradients turned on (so you can’t compute gradient quantities) to help save memory during inference/validation. So if you require autodiff gradients (needed for the nu calculation I believe in this case) you will need to make sure that you tell Modulus that gradients will be required.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
274,news-simnet-teratec,"TERATEC: 22-24 JUNEJoin NVIDIA at Teratec for the 16th annual forum, bringing together top international experts in high performance computing, simulation and big data.Hear from NVIDIA founder and CEO - Jensen Huang - for a special keynote on June 23, where he will discuss the latest news and innovations in HPC.There is also a section on Nvidia SimNet that might interest you!For the rest of the event, you will find keynotes, plenary and roundtable sessions, application and technical workshops and virtual exhibitions from decision makers and scientific experts as they present their latest innovations. Meet the HPC community to debate digital, simulation and AI challenges.Powered by Discourse, best viewed with JavaScript enabled"
275,how-to-plot-the-error-between-modulus-and-validation-data,"Hi there,I’d like to create a validation file (.vtp), which also contains the pointwise error between the validation data (.csv from openfoam) and the values of Modulus.The file “validation.vtp” already contains the selection of predicted and true values, but how can I combine them to plot the error of each output?Is there a way doing this without changing the source code?Many thanks in advance.I think you can define your custom validation functions to create new validation files or edit existing ones.
https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/features/post_processing.htmlThank you.According to my understanding the CustomValidatorPlotter is only for plotting in Tensorboard. My goal is to get the file “validation.vtp” including the error, just like the ValidatorPlotter does in TensorBoard.I’ve already tried to use var_to_polyvtk, but I’m not shure how to access the arrays of the true values (from validation file).Hi @jflatterIf I understand your question correctly, assuming you already have the prediction and true values in the same VTK file, then the best way is to simply apply a calculator filter on the data in Paraview to get your quantity of interest. (You can then save that VTK file) This is the intended workflow.If you want this done in Modulus automatically, then you would have to make some adjustments to the code. Theres some docs on the VTK utils in Modulus but you would need to add your quantity of interest to the output in the validator/inferencer/constraint (e.g. for validator).Powered by Discourse, best viewed with JavaScript enabled"
276,typeerror-unsupported-operand-type-s-for-tensor-and-mul-in-pointwisemonitor,"Hi, I am using modulus 22.09 to train a model that provide flow field prediction for a 2D airfoil with changing angle of attack and inlet velocity.
I have trained the model and used the PointwiseMonitor to generate force coefficients outputs as the following codes:Then I run the code in eval mode and encountered the error:The code works when I only add in the angle of attack as the variable, when I introduced in let velocity as the variable, the error occures. Can anybody help me with this?Hi @TinsenLYIts a little hard to say from this code snippet here but seems your error is because theres a Sympy symbolic multiplication class getting combined with a tensor.My suggestion would be to create your metric functions with a print statement to get the type of these variables to debug whats going on. E.g.Is inv_Re some sympy expression thats perhaps causing this? I’m guessing this since this error is occurring when you’re adding the inlet velocity.Powered by Discourse, best viewed with JavaScript enabled"
277,2-phase-transient-flow-in-porous-media,"Hi there,I recently came across Nvidia Modulus and checked the user guide. However, I could not find any tutorials about two-phase flow e.g. capturing a liquid and an air phase for void and filling prediction. Is there an implementation that enables similar simulation to the interFOAM CFD solver?Best Regards
StefanoHello, Multi-phase flows are not supported yet in Modulus. Internally we have looked into this a bit but don’t have any definite plans for releasing anything yet. The primary issue is handling the changing boundary between the fluids. There is some work doing this with PINNs though here, [2006.05311] Deep learning of free boundary and Stefan problems.Powered by Discourse, best viewed with JavaScript enabled"
278,modulus-documentation-website-down,"Yesterday I noticed that the documentation website for Modulus was slow. Yesterday afternoon I received a response stating that “Page Not Found” and “This page no longer exists. It is a non-supported format.” When will the webpage be back up?Hello,Thanks for bringing this to our attention. I have the team looking into this now.
I will post updates her when I have new information.Thanks,
TomHi @tstoneWe have been moving the docs site to a new system. Apologies for the confusion. The Modulus docs is live here with the 22.09 docs here.If you can let me know where the URL you were using was from please let me know so I can get the team to update it. Thanks!Great, thank you for the update. here is the link to the old sitehttps://docs.nvidia.com/deeplearning/modulus/user_guide/theory/phys_informed.htmlHi @tstoneGreat thanks, do you know where you got this link from? (e.g. Nvidia DevZone, Somewhere on Gitlab, Blog post, etc?). No worries if you don’t, just trying to prevent other users having the same problem.Thanks again!Hello,I had this book marked and would usually reference it. I also did a search with google and the old link was one of the top pages that came up (I am there isn’t much that can be done with that). Lastly, i went to nvidia documentation page and searched for Modulus and that page came uphttps://docs.nvidia.com/search/index.html?facet.subcollection[]=Technical%20Documentation&page=1&sort=relevance&term=ModulusGreat thanks for the extra info. I appreciate it!It looks like the new documentation is incomplete. I’m not seeing anything like the user-guide from the “old modulus” that covers stuff like installation, setup, and hardware/driver requirements. Should I install and run the old 22.09, i.e. is this new open-source refactoring not yet ready for use? I’m running into a number of dead links on google and am unsure as to what would be the best path for a company looking to start using modulus.– Manufacturing Data Scientist looking to start our Modulus journeyHi,Is it possible to keep the v22.09 documentation at least for a while?Cos we’re still using v22.09 and we would like to finish our project before upgrading. Hence, we still need to refer to the v22.09 documentation.Thanks.Hi @tsltaywbPrevious version of docs is still accessible already. Thanks.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
279,error-calculation-difference-between-true-solution-and-prediction,"Hello and thank you for the support,I have a question about the prediction results: In the validation function, how is the u_diff calculated? Is it using the L2 norm between the prediction and the true solution? Where can I look at the implementation of the validation function?
fully_connected_VAL_004_u1477×424 69.6 KB
Hi @cpe.skGood question. The built in validators calculate the the relative L2 error for the output loss metric, but this isn’t what is plotted. The absolute error is what is shown in the contours by the default validation plotter.Powered by Discourse, best viewed with JavaScript enabled"
280,fluid-simulation,"Hi,
i’m working on a problem similar to Conjugate Heat Transfer example. I have a channel where a hot fluid (air) heats a piece and an outlet where the fluid can exit the channel.
I want to create a simulation of the fluid in this channel, i introduced the “t” variable in Navier-Stokes equation and modify the constraints adding parameterization: time_range (time_range my interval of simulation).
From the outputs i’ve never received an output where the fluid seems to evolve over time.
The fluids seems to be really static (see below, this is a simulation of 10 seconds with an inlet velocity of 5m/s)
Thanks.I think you can check OpenFOAM settings. If this is a case of heat diffusion, you might need to increase the resolution and/or check units.I cannot help you with nvidia modulus though as I am a beginner too.Powered by Discourse, best viewed with JavaScript enabled"
281,error-libxdamage-so-1-cannot-open-shared-object-file,"Hi, on my sch’s cluster, I sometimes met with this error msg:It’s quite random and the admin is not too helpful. He said that it shouldn’t happen since this is only for app with GUI requirement. I have to keep submitting jobs until one worked, which is quite frustrating.So may I know which part of Modulus uses this lib and is there anyway to disable this requirement?Thanks!Hi @tsltaywbWe have not seen this error before, is this using the docker image? I am not familiar with this library and so I’m not 100% sure why this would show up.If its being required by Modulus its in one of the dependencies. My immediate guess would be PySDF which uses OptiX. So I would try problems that do not use PySDF (if its OptiX related you make need to manually remove it from the docker image or do a bare metal install). Otherwise I would begin checking PyTorch, Numpy, Matplotlib, Tensorboard, etc. to see if these function fine on your cluster.Hi @ngenevaIt’s not PySDF and it happens randomly for even simple example. I’m using a singularity converted docker file. My admin is now trying to create a new singularity file with the libXdamage lib installed. Hopefully it can work.Powered by Discourse, best viewed with JavaScript enabled"
282,how-are-ranges-sampled-in-parameterization-objects,"Hello,I was looking at the wave_1d example and was curious on how the values for the parameter time are chosen?In the code I see the following linestime_range = {t_symbol: (0, 2 * L)}Line 53-61What are the steps used for the time range or is it some type of random distribution that is used? Is it possible to change this to use time steps or other options?Thank you for your help.Hi @tstoneYes sampled uniformly in that range. For future reference in the parameterization class you’ll fine the sample function which calls the _sample_ranges function for each variable which is indeed uniformly sampling. Unless of course you choose quasirandom sampling or provide a discrete list / fixed value/ etc.For fixed time-steps you could replace that tuple with a numpy array and it will select a value from the given array. Have a look at this source code here to see what happens for a given input. Hope this helps!Great, thank you for your help.Powered by Discourse, best viewed with JavaScript enabled"
283,boundary-constraints-on-a-section-of-an-edge-of-the-geometry,"The problem that I am working on demands for constraints on a section of edge of the problem geometry. The issue can be illustrated using the following diagram.
image730×301 1.2 KB
I want my constraints to be imposed on BC portion of the edge AD.  In my case I tried imposing the constraint as followsBut I was running into an error as depicted belowThis error is thrown only if the constraint is imposed on an intermediate portion or a point of geometry edge. For example, there’s no error if “x: (6.5,7.5)” is not specified under parametrization option of PointwiseBoundaryConstraint(). Also, the program runs fine if ‘x’ is at one of the corners (i.e. x=0 or x =13) of problem geometry.Is there a way around this issue?Hi @shubhamsp2195 ,First, have you considered using the Line primitives instead of the Rectangle?  This way you’d be able to break apart your domain into line segments:Geometry in Modulus DocsSecond option, and probably the one that requires least modification to your code, is that you could retain your rectangle geometry but make use of the ‘criteria’ argument for PointwiseBoundaryConstraint.PointwiseBC in Modulus DocsI’m not sure I have the numbers right, but you could use something like:Make sure you get the logical operators from Sympy if you take this approach:Hi @patterson ,
Thank you for sharing this information.
I tried the second option suggested by you where very few modifications are needed.  I hope that you wanted the parameterization to includeinstead ofThere’s no error if (y>0.5) is used under “criteria”. But imposing y==0.7 leads to similar issues.
Also, I feel that the functionality of “criteria” is the same as that of “parameterization”.  What I mean is that the “criteria” option is performing the same operation as achieved with ranges for variables in “parameterization” (My earlier approach).Hi @shubhamsp2195 ,If you’ve set up the problem to parameterize t_symbol, then your parameterization with only t_symbol should be correct.  If you are also parameterizing the location of the location/size of the BC line then you would need to include x and y in the parameterization.Is there a reason you need to use y== 0.7?  If you are using a boundary constraint and the boundary is above the threshold you pick (I picked 0.5 somewhat arbitrarily, it was greater than -0.3 and less than 0.7 so it would only pick points from the top line when combined with the x-location criteria).  You could test that the PointwiseBoundaryConstraint is only sampling from the boundary by sampling the boundary of the rectangle with the same criteria:If you need to specify y is a specific value instead of just greater than something else, you could use sympy Eq:The Three Fin example has a few cases of this:Three Fin example in GitlabI disagree about the criteria vs parameterization.  Criteria are used for sampling points for Boundary or Interior Samples within given ranges and specifying regions where Constraints are applied, either on a Boundary or an Interior.  Parameterization is a modification of how constraints are formulated and applied and how the architecture is formulated:Parameterized Geometry in the documentationHi @patterson
Thanks a lot. This indeed would be very helpful for me.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
284,how-to-update-geometry-based-on-displacements-from-a-pinn-solution-using-the-linearelasticity,"I am trying to make a pinn code for prediction of a deformation of plate with the Linear Elasticity.
I obtained the displacements as solution and want to update the geometry to the deformed geometry.
Modulus shows only a displacements field in contour.
Could anyone let me know a method?Hi @coolcwgI’m assuming you want to visualize the displaced geometry to present? If so I have not tried this myself but perhaps look into using Paraview to visualize the displaced geometry via filters like Warp by Vector. Good luck.Powered by Discourse, best viewed with JavaScript enabled"
285,what-are-the-learnable-parameters-when-using-adaptive-activation,"Hello,I would like to use the Adaptive activation function in my code as I had read some papers that this can help with convergence. I was able to update this in the configuration file but from what I am reading, besides enabling adaptive activation with a boolean value there should also be a hyper parameter I can change. Is there any documentation that I can reference to adjust the hyper parameters?Thank you for your help,
TommyHi @tstoneThere is some theory information on adaptive activations in our docs. The adaptive activation that is built into some of Modulus Symbolic models is a scalar one. As you mentioned right now there is only toggle control to turn this feature on and off (E.g. fully connected, note the learnable parameter here). Thus any customization or more advance scheme would require modification of the source code, but this should be fairly straight forward for most models.Great, thank you for the information.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
286,understanding-the-taylor-green-script,"Hello,
I am trying to understand how to script a transient problem, thus looking into the examples and found taylor-green.Here I didn’t understand 2 things:Could you please provide some reading on the same so I can understand this better?Thank youHi @ngeneva, could you please suggest some resources that could help me understand the 2 problems/ doubts I am facing?Thank you for your timeSincerely,
NihalHi @nihalpushkar11The Taylor-Green implementation is pretty specific and I would first evaluate what type of dynamical system you are trying to learn. You can easily define time as another input variable to any PINNs example. E.g. wave equation.Regardless please see the documentation for this problem for some details. Responses to questions are below:One for the initial state and the other for the current time window. This is because the initial state has a different (analytical function) constraint than the time-window constraints (N-S PDE and others).These are generated under the hood when using a moving time window architecture. Basically this model wrapper will store two models (one of the current time window and the previous) and return the difference in predictions between the two models. So this constraint is imposing continuity between time windows.hi @ngeneva,
Thank you for the reply. I went through the scripts on “MovingFrame” there I found how the “_prev_step” & “_prev_step_diff” are been defined.Thanks and regardsThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
287,error-while-running-modulus-chip-2d-py,"Hello,I have encounter this error. Please advice.
Thank you.[16:12:40] - JIT using the NVFuser TorchScript backend
[16:12:40] - JitManager: {‘_enabled’: True, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[16:12:40] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
Error executing job with overrides: 
An error occurred during Hydra’s exception formatting:
TypeError(“print_exception() got an unexpected keyword argument ‘etype’”)
ValueError: could not convert string to float: ‘oid sha256:bab3dfcabf2f87a642bbb91f87d494ecfef60115f99bb6325bc6c72d9bdcecf0’The above exception was the direct cause of the following exception:Traceback (most recent call last):
File “/home/uos/MODULUS/examples/chip_2d/chip_2d.py”, line 185, in 
run()
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/modulus-22.9-py3.10.egg/modulus/hydra/utils.py”, line 91, in func_decorated
_run_hydra(
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 377, in _run_hydra
run_and_report(
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 294, in run_and_report
raise ex
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 211, in run_and_report
return func()
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/utils.py”, line 378, in 
lambda: hydra.run(
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/hydra.py”, line 111, in run
_ = ret.return_value
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/core/utils.py”, line 233, in return_value
raise self._return_value
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/hydra/core/utils.py”, line 160, in run_job
ret.return_value = task_function(task_cfg)
File “/home/uos/MODULUS/examples/chip_2d/chip_2d.py”, line 161, in run
openfoam_var = csv_to_dict(to_absolute_path(“openfoam/2D_chip_fluid0.csv”), mapping)
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/modulus-22.9-py3.10.egg/modulus/utils/io/csv_rw.py”, line 33, in csv_to_dict
values = np.loadtxt(filename, skiprows=1, delimiter=delimiter, unpack=False)
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/numpy/lib/npyio.py”, line 1356, in loadtxt
arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,
File “/home/uos/anaconda3/envs/modulus/lib/python3.10/site-packages/numpy/lib/npyio.py”, line 999, in _read
arr = _load_from_filelike(
ValueError: could not convert string ‘oid sha256:bab3dfcabf2f87a642bbb91f87d494ecfef60115f99bb6325bc6c72d9bdcecf0’ to float64 at row 0, column 1.Process finished with exit code 1HI @nuraliya.sheffieldThis is another Git  LFS issue, those oid sha256:bab3dfcabf2f87a642bbb91f87d494ecfef60115f99bb6325bc6c72d9bdcecf0 are from a pointer file that represents a larger data file on the repo.More info:Thank you. It works now.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
288,failing-to-run-modulus-after-loading-the-container-on-windows-subsystem-for-linux,"I am trying to install modulus on a windows machine via WSL2 and so far I managed to install the nvidia-docker and run two of the nvidia sample container (jupyter) successfully. nvidia-smi also detects the GPU driver (Geforce RTX 3060).
However when running modulus image, I get this errorAny lead how to fix this?Hi @smraniakiUnfortunately this seems to be a known issue with Nvidia Docker, a bit outside our control. There’s some information in the linked thread below that may help. If nothing works you can always try a bare metal install using pip.Hi @ngenevaIs it possible that the modulus containers are being built with the nvidia runtime enabled, and thus the injected *.so files are mistakenly included in the image? The response from Nvidia docker about issues with modulus seems to suggest this. An issue related to how the container is built would also explain why I’m able to run the PyTorch container on WSL2 without any issues, but am unable to run the Modulus containerHi @rohan.patelI cannot not fully confirm if that’s the case, but its possible one of the dependencies of Modulus is potentially causing this. In the mean time, if you don’t need PySDF, you can try building your own container using the Modulus source code (we include our dockerfile in the repo you can modify).We will look into getting some tests for WSL environments for testing for future releases. Thank you for getting back to us with info.Powered by Discourse, best viewed with JavaScript enabled"
289,adding-an-argument-to-slv-solve-for-prediction-of-trained-model,"Hi,I’m now trying to use PointwiseMonitor to predict my angle of attack of airfoil using my trained model.In my code, the general structure is:Now I plan to run in ‘eval’ mode and do prediction and adding some arguments like:Is this possible? I tried but the variable “angle_attack” is not inserted correctly:UnboundLocalError: local variable 'angle_attack' referenced before assignmentSo how should I solve this problem?Thank you.Update on my problem.I am now using slv.eval().I am trying to modify the source code such that I can use:slv.eval(AoA_test)I tried to change /opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/solver/solver.py:and /opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/trainer.pyBut somehow it still gives the same error. So what should be the way to insert argument?UnboundLocalError: local variable ‘angle_attack’ referenced before assignmentThis error means you havent defined this variable in your training script.I am trying to modify the source code such that I can use:
slv.eval(AoA_test)Instead of modifying Modulus-Sym source consider the following:Create a numpy dictionary of inputs + attack angles such as {x:[0,0,0,0], y:[1,1,1,1], aoa:[0.25, 0.35, 0.45, 0.5]} to get the outputs at point (0,1). Then create a monitor from that dictionary. Then the solver.eval() will evaluate all the given configurations. You can then increase the batch size of the Monitor to increase the calculation speed.Or just loop inside over all your AoA’s in your trainer and create a new Monitor / solver for each angle of attack (not a very good solution).But if you want to do just querying that feeds into some other process, then maybe writing a custom monitor/util would be best (should be achievable)Hi ngeneva,I need to use slv.eval(AoA_test) within an optimization loop, to couple with an optimizer something like:The AoA will be determined on the fly during the optimization by the optimizer. That’s why I can’t create a numpy dict beforehand.Hence, I thought maybe I can do a simple hack on the source code. Else, I will look into creating a new Pointwise monitor, which can accept an argument and also give a value immediately instead of saving to a csv file (and then we need to read it out).Hi @tsltaywbI see, yes for a in the loop type connection this hack would be the quickest. One thing to make sure isn’t happening is that your geometry is changing (Im assuming AoA is adjusting inlet velocity). These primitives that get added the domain sample their points once on initialization by default, so if your geometry (airfoil boundary in the x,y space) is changing then you need to re-initialize and resample. If your just changing the angle of u_infinity then you’re totally fine.If this is something that you’re planning on spending a lot of time using, I would recommend trying to build your own Monitor for this (or even eval function) to make it a little more clean and so it can return the output in memory.(me personally I would manually load the model on my own then call my custom monitor directly in this for loop, but this would require a little more familiarity with modulus-sym source code.)@ngeneva Sure, thanks for the tips. Will give it a try.I didn’t see it mentioned here but I came across it in the docs. It looks like you can also specify the following line in your Hydra config
run_mode: 'eval'https://docs.nvidia.com/deeplearning/modulus/modulus-v2209/user_guide/features/configuration.html#configPowered by Discourse, best viewed with JavaScript enabled"
290,issues-with-modulus-vtk-postprocessing,"Hello,
I am currently using modulus to solve conjudate heat transfer problems.
Can anyone show me how to visualize the output variables such as “u”,
“v”, “w”, “p” and “temperature” in the flow region and solid region separately?It would be great if someone can give me an example of using vtk to save all the variables to a mesh. I have looked into the PointVTKInferencer, but it  gives me errors because of the mask functon definition. Can I just save all the variables such as x, y, z, u, v, w, p, t all together to a vtk file and visualize the output?Hi @cxi1We have some documentation on using the VTK exporters in our user guide. It would probably be easiest to create two meshes, one for the flow and one solid region, then load these into two separate inferencers. This will generate two VTK filea you can then load together in Paraview and have a good level of control when visualizing.The VoxelInferencer, works when you dont have a mesh to sample from and is pretty easy to use if you know a bounding box.I have looked into the PointVTKInferencer, but it gives me errors because of the mask function definition.I would need some additional details about the error you are seeing. The mask function is a callable that should take the input spacial coordinates then returns a boolean value. On false, the values stored in the VTK point will be set to NaN which can be filtered out in Paraview (see the bottom of the docs here. for example).Hi @ngeneva ,
Regarding the three_fin_3d example, how to create 2 meshes for the flow and the heat sink?
For example, if the heat sink is created using the primitives geometry, but it only gives me point cloud instead of mesh, right? Also I saw all the contraints are saved as vtp file in the example, when I open it in paraview, it also shows the point cloud instead of mesh.Is there a way to convert these vtp files to vtk files and visualize them within a mesh? I saw some examples have some yaml config settings such as “save_filetype =vtk”, will that help with the mesh postprocessing? Or should I create a mesh using other CAD software?Thank you,
CeYou would need to define a mesh for the heat sink ahead of time. Continuous geometry does not have a mesh representation (its continuous), so a mesh doesn’t exist for it in this example.You have two options: use the Voxel inferencer for a solid representation or two run a mesh generation filter on the point cloud (Delaunay 3D filter in Paraview).Just as a head up Delaunay filters require tuning, can be expensive to run and / or completely fail.@ngeneva
Great tips, I will give it a try for both of the options.Hi @ngeneva ,
Above is the code for postprocessing of limerock case, which create a grid_inferencer for the limerock and the solid part. But after I opened the vti file in paraview, it only gives me a whole square domain.
Basically I wanna conduct inference on the fluid and solid region separately, do the codes above mean the same intention?  If so, how to do with this whole bounding box? will it only show the heat sink region by some filter in paraview?

Capture1648×932 131 KB
Hi @ngeneva ,
BTW, Do you know how to define the source term in modulus heat transfer example?
If I have a chip that has power of 250w, how to impose it in modulus? I notice the source
term in modulus are of the unit K/m, how to do the conversion to make it correct?
And also the three fin examples are insulated at the wall, what if I want to set up some
film coefficient of h to it to consider the air convection? How should I change the temp_grad_norm at the wall?And I found a strange thing in my code. I define the inlet temp = 300 C, outlet gradnorm = 0, and insulation at all the other walls. But when I monitor the chip temperature, it’s the same as the fluid inlet temperature of 300 C. I impose a 400k/m at the heat sink bottom, it should give me a different temperature instead of the same as fluid?
I don’t know what happened to my setup.Powered by Discourse, best viewed with JavaScript enabled"
291,pysdf-error-in-modulus-22-03,"Hello,I am trying a bare metal installation of Modulus 22.03. The operating system used is Ubuntu 20.04 LTS.The Modulus and the PySDF library installations completed without error and “examples/ldc/ldc_2d.py” was successfully executed. However, the following error occurred when executing “examples/aneurysm/aneurysm.py”.junichi@GLM:~/Modulus/examples/v22.03/examples/aneurysm$ python3 aneurysm.py
Error importing pysdf. Make sure ‘libsdf.so’ is in LD_LIBRARY_PATH and pysdf is installed
Traceback (most recent call last):
File “aneurysm.py”, line 25, in 
from modulus.geometry.tessellation.tessellation import Tessellation
File “/home/junichi/.local/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/geometry/tessellation/tessellation.py”, line 11, in 
import pysdf.sdf as pysdf
ImportError: libsdf.so: cannot open shared object file: No such file or directoryThe above error was avoided by modifying line 11 in “Modulus/modulus/geometry/tessellation/tessellation.py” as follows.import pysdf.sdf as pysdfimport pysdf as pysdfHowever, when “aneurysm.py” was run again, the following error occurredjunichi@GLM:~/Modulus/examples/v22.03/examples/aneurysm$ python3 aneurysm.py
training:
max_steps: 1500000
grad_agg_freq: 1
rec_results_freq: 10000
rec_validation_freq: ${training.rec_results_freq}
rec_inference_freq: ${training.rec_results_freq}
rec_monitor_freq: ${training.rec_results_freq}
rec_constraint_freq: 50000
save_network_freq: 1000
print_stats_freq: 100
summary_freq: 1000
amp: false
amp_dtype: float16
ntk:
use_ntk: false
save_name: null
run_freq: 1000
profiler:
profile: false
start_step: 0
end_step: 100
name: nvtx
network_dir: .
initialization_network_dir: ‘’
save_filetypes: vtk
summary_histograms: false
jit: false
device: ‘’
debug: false
run_mode: train
arch:
fully_connected:
target: modulus.architecture.fully_connected.FullyConnectedArch
layer_size: 512
nr_layers: 6
skip_connections: false
adaptive_activations: false
weight_norm: true
loss:
target: modulus.aggregator.Sum
weights: null
optimizer:
params:
compute_gradients: adam_compute_gradients
apply_gradients: adam_apply_gradients
target: torch.optim.Adam
lr: 0.001
betas:
- 0.9
- 0.999
eps: 1.0e-08
weight_decay: 0.0
amsgrad: false
scheduler:
target: custom
name: tf.ExponentialLR
decay_rate: 0.95
decay_steps: 15000
batch_size:
inlet: 1100
outlet: 650
no_slip: 5200
interior: 6000
integral_continuity: 310
custom: ???

Error executing job with overrides: [  ]
Traceback (most recent call last):
File “aneurysm.py”, line 153, in run
interior = PointwiseInteriorConstraint(
File “/home/junichi/.local/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/continuous/constraints/constraint.py”, line 399, in __init__
invar = geometry.sample_interior(
File “/home/junichi/.local/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/geometry/tessellation/tessellation.py”, line 375, in sample_interior
sdf_field, sdf_derivative = self.sdf(sampled_points)
File “/home/junichi/.local/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/geometry/tessellation/tessellation.py”, line 64, in _sdf
sdf_field, sdf_derivative = pysdf.signed_distance_field(
AttributeError: module ‘pysdf’ has no attribute ‘signed_distance_field’

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.I would appreciate it if you could advise me how to resolve this error.Best regards,
Junichi FukuiI faced the same issue. I used the pysdf from the older version with the older steps. It works fine.Thank you for your advice! I will try to run the tutorial with the older version of pysdf library.Hello, unfortunately we decided to pull the pysdf support for the bare metal installation because it became too cumbersome to maintain. This is reflected in the installation instructions. If the tessellated geometry module is required then we suggest using the Docker image. We are pushing now to have pysdf released as a separate library but don’t have any release date for this. In the mean time we are looking into a slower fallback option when pysdf is not installed.Hi I managed to install pysdf in the bare metal installation using the provided egg file via easy_install. Here are the stepsdowngrade setuptools (pip3 install setuptools==42.0.0) since easy_install command is not exposed in the latest setuptools versions. see ref.install the provided egg filecd path_to_modulus_source_code/modulus/external/eggs
python3 -m easy_install pysdf-0.1-py3.8-linux-x86_64.eggyou can make sure the installation is successful by checking pip3 list. You can also upgrade setuptools back to the latest version.add libsdf.so to your LD_LIBRARY_PATHthen you can successfully run aneurysm.py without changing the source code.Hi, I’m now using 22.09 and using bare metal installation. I tried the mtd by zhongyf111.Step 1 is ok but step 2 is not cos the egg file is not found. I went to take the 22.03 version and run the command.The lib file is @ /opt/conda/lib/python3.8/site-packages/pysdf-0.1-py3.8-linux-x86_64.egg/pysdf/sdf.cpython-38-x86_64-linux-gnu.so.I also copied libsdf.so from 22.03 and put it in the same dir and the dir to the LD_LIBRARY_PATH. However, it’s still not working:Hope someone can help.Hi zhongyf111,I realised that there’s some errors with my mtd. Now I did it this way:
As I do not have root, I have to install using:python3 -m easy_install --prefix=/home/svu/tsltaywb/.local pysdf-0.1-py3.8-linux-x86_64.eggI copied the libsdf.so into a dir and add it to LD_LIBRARY_PATH.Now the error msg I got is:tsltaywb@volta01:~/hpctmp_tsltaywb/modulus/examples_2209/aneurysm$ python aneurysm.py
[21:08:15] - JitManager: {‘_enabled’: False, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[21:08:15] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
/home/svu/tsltaywb/.local/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/geometry/tessellation.py:90: RuntimeWarning: divide by zero encountered in divide
np.full(x.shape, triangle_areas[index] / x.shape[0])
terminate called after throwing an instance of ‘std::runtime_error’
what():  the provided PTX was compiled with an unsupported toolchain.
Aborted (core dumped)Anyone can help? Btw, I’m running in a cluster.what does “pysdf from the older version” means? can you give an link to this old version? thank you so muchPowered by Discourse, best viewed with JavaScript enabled"
292,accessing-for-manipulation-in-python-saving-to-csv-etc-optimization-history-training-history-from-tensorboard-files,"Hi, title of the question sums up my question: I want to access (for manipulation in python/Saving to csv etc) Optimization History (Training History) from Tensorboard files.Is there a way to do this? Thanks.  I am not very familiar with tensorboard, have simulation results, and would like to use the loss function values over the course of (say, adam and lbfgs) optimizationThanks!Hi @ctalbotI know the Tensorboard package has some methods for accessing the raw data as Pandas dataframes. Perhaps you could use the information in this tutorial: Accessing TensorBoard Data as DataFrames  |  TensorFlowOtherwise you could edit the trainer class to save the loss value to a CSV manually which would be pretty straight forward.Powered by Discourse, best viewed with JavaScript enabled"
293,cuda-out-of-memory-error-after-adding-a-pointwisemonitor,"Hi,I trained a model using Modulus 22.09 to predict the flow field for a 2D airfoil with varying angle of attack and inlet velocity. I am trying to calculate the error between the model’s predictions and the validation data, specifically the error in u, v, and p. To do this, I created a PointwiseMonitor to calculate the desired error values.However, I encountered a CUDA out of memory error as the following:The PointwiseMonitor is implemented as the following:I suspect that this section of the code may be the cause. I am currently investigating the issue and am unsure why it is happening. I was wondering if there is a better way to calculate the error between the model output and target values, and would appreciate any help in advance.Thank you.Hi @TinsenLYI would encourage you to use validator nodes for comparing between target and output data. For example the annular ring is a good example that uses openfoam data from a CSV.Monitors have no batch processing (typically just use for like a few points of interest, like pressure at the nose of a object in a fluid flow). So thats the reason your seeing a memory issue. Validators will process things in batches which you can define.Powered by Discourse, best viewed with JavaScript enabled"
294,training-on-loaded-meshes,"Hello!Is it possible to load the mesh generated by another solver and train SimNET on its nodes?The training domain then would have only those mesh nodes as points which would be too few. The data driven networks can be trained on mesh data since there is plenty of training data but the physics driven networks, the network is solving for the PDEs and the losses need to be evaluated on the domain in a near continuous manner.Powered by Discourse, best viewed with JavaScript enabled"
295,modulus-prediction-based-on-the-trained-model,"How can I make prediction once the model is trained?
Let say I’ve trained the LDC case from the tutorial, and would like to make prediction for various lid velocities. It wasn’t explained in the tutorial. Any clue?Hi @smraniakiPlease the following post here with some information:The easiest way is to set up a slimmed down version of your training script with just an inferencer in it and a dataset of the cases you want to test on (then use solver.eval()).The ov.py in inferencers has some more direct inference methods that avoid the use of the Modulus trainer which could be useful if you prefer a more traditional PyTorch inference script.Hello. I actually have the same question. All links that were posted to gitlab no longer appear to be valid. I cannot find the modulus project in gitlab. Do you have any updated links?Thank you for your help.@tstoneDid you register for access to the Modulus GitLab project? If so and you have access to https://gitlab.com/nvidia/modulus/modulus these links should work.I have a gitlab account but I do not see the option to register access to Modulus Gitlab project. Do you have the registration link? When I clink the URL you provided I get a 404 error “page not found”Please see the Modulus download page on DevZone and register your GitLab account there. Then you should gain access, please use the following thread if you still have issues:That’s perfect. I typically train a model and load it into another notebook to perform inference. I saw the load_network function in the trainer.py. Is it possible to pass the configuration file into the network_load function so that I can load the model? If not how is this normally done in modulus?Yep, thats correct.The load_model function does the loading of the checkpoint. This method composes the path of the checkpoint file based on i_dir + ""/"" + model.checkpoint_filename which is the output folder and the checkpoint file name. The information provided to both this function and others in the trainer class are based on your parsed config, in other words you need to go through the trainer class if you want it to be automated using your YAML.The checkpoint file path is then passed to the model.load function inside the Arch class (basically torch load at this point). So if you want to do things manually you call your model’s .load() function and give it the path of the PyTorch checkpoint.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
296,results-and-post-processing,"How validation results (ground truth, DeepONet prediction, and difference, respectively) are produced.
Fig. 95 DeepONet validation result, sample 1
what changes we need to get these image validation results are produced, when we run this DeepONet ( [Problem 3: Darcy flow (data-informed)]) we do not get these validation result.Hi @big4085bossIndeed, unfortunately the DeepONet example was contributed without a validation plotter like the other Darcy examples. But Modulus  has support of users adding their own plotters either embedded into TensorBoard or even exporting to VTK formats.Have a look at the post processing part of the forums for some documentation and examples.Powered by Discourse, best viewed with JavaScript enabled"
297,how-to-use-exact-continuity-in-2d-cases,"Hi there,I have a question on how to use the exact continuity in 2D cases.My error message:My code:

image492×520 12.2 KB
How do I use the function “curl” in this 2D case?Many thanks in advance.Hi @jflatterRight now the curl requires all three dimensions to calculate. I’m not sure if this would work (we have not tried exact continuity in 2D as far as I know), but you could feed in a constant z value of zero to all your inputs.The easiest way to do this would be via the parameterization parameter in the constraint. A simple example of this can be seen in the wave example. Again, not sure if this will work properly but this would be a quick hack to try.Powered by Discourse, best viewed with JavaScript enabled"
298,errors-occured-when-training-fourcastnet-with-multiple-gpu,"I tried to train fourcastnet model with 2 or more GPUs, but some errors occurred.
The training on only 1 GPU was working properly in my environment.
I ran my training script in modulus:22.09 docker image with 2 v100 gpus, usingmpirun -n 2 --allow-run-as-root python fcn_era5.py
The driver and cuda version are: Driver Version: 460.106.00   CUDA Version: 11.2
Any suggestion that I can solve these issues?The errors :

image1508×654 55 KB


image996×506 20.3 KB
Hi @yswang891121Based on when the error occurred, seems this is an issue with the cuda graphs getting recorded. Please try turning cuda graphs off by adding the following to your configuration.I noted that in the NCCL documentation, cuda graph support with NCCL is only support CUDA version 11.3+, so this could be an older driver issue. Try just shutting of cuda graphs first before a driver update.Thank you, it works!  but how does  cuda_graphs affect training if it’s turned off?Hi @yswang891121This can impact performance for some problems (many see some speed up using CUDA graphs, it depends). You’ll need to do a driver update to use them. Check out these articles for background on cuda graphs in PyTorch and cuda graphs in Modulus for more information.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
299,create-2022-2-0-rc-15-extension-modulus-fpga-could-not-be-activated-and-suddenly-create-application-is-shutdown,"I am using the Create 2022.2.0.rc.15 version, and I activated Modulus Core Extension to test Modulus.
Afterwards, I tried to activate Modulus FPGA Extension, but the Create app did not respond and then shut down suddenly.
For this, attach the log file in the following path:
/home/nvidia/.nvidia-omniverse/logs/Kit/Create.Next/2022.2/kit_20230102_095142.logHi @seungha.leeIs the Modulus core and UI extension able to be enabled properly on its own? I cannot tell much from this error log unfortunately. Please be sure you are using the correct launch commands.Powered by Discourse, best viewed with JavaScript enabled"
300,cannot-git-clone-modulus-examples-from-gitlab,"Hi @ngeneva I have now been granted access to the repo (through dev zone). Thanks so much!Hi, I have the same issue.
My gitlab username is:zhhwssThanks for your help.
Regards,Hi @517287648Can you please confirm that you’ve submitted the access forum on dev zone using your correct username? Thanks!I am having the same issue trying to access Nvidia Modulus source code on Gitlab. My user name is swapan2.  Can you please help ?
image1186×184 9.09 KB

yes,  I can confirm that. The above picture is my submission history.Same issue here.The language keeps changing here and there so the updated examples are the main source.Sent my registration more than 6 months ago and nothing.My GitLab username is    farrateHi @swapan and @517287648You should be added to the Gitlab repo. Please follow up if you’re still not. Thanks!Will get the engineers to add you. Thank you for your patience.@ngeneva
hi, Same issue here
My GitLab username is liulei277Since i have submitted wrong username “liulei”. How could I change my username to access nvidia GitLabWhere are the examples?The Modulus GitLab repository at https://gitlab.com/nvidia/modulus is sending me to a “404 Page Not Found” error.Did you misplaced the folder? Is it a registration error?I had the same issue here. I could access: https://gitlab.com/nvidia/modulus/examples, however the git clone:returned:This is due to the fact that the access was being performed throughout my GitHub account by default. There must be a faster solution, but I solved the issue by forking the repository nvidia/modulus/example to my account (e.g. to [my_user]/example) and cloning it:This prompted me to my GitLab login, allowing me to clone the forked version without problem (and the original code, afterwards).Hi @user39440You should have access now, please verify. Thanks.Hi @liulei2770919You should be added now.Hi:Thanks for the access. I will continue building the PINNs solution to my IDE using the detailed examples.A while ago I asked about the lack of integral conditions, like d/dx u(x) + Integral (-1 to 1) u(Tau) d Tau = 1, but unfortunately NVIDIA said that it was not available directly. Maybe through a modification of current classes. I will have to deal with that eventually.The next step is to use DeepOnets. I remember having issues last year when using a non-trivial outvar function. I hope the issue was resolved.RegardsFelipe Arrate, PhDSenior Research Data ScientistVarian Medical Systems a Siemens-Healthineers companyPalo Alto, CalfironiaHi, I cannot access the Gitlab examples.
I have already get Gitlab account registered. It mentions I have already submitted this form. But I never receive the email.My gitlab username is alofil98There is no example folder in the github repo mentioned here Modulus | NVIDIA NGC and the address is :(NVIDIA/modulus: A PyTorch based deep-learning toolkit for developing DL models for physical systems (github.com))I don’t know how I can register my gitlab account on the gitlab group. Can you help me with this?Hi @mshishehExamples for Modulus are now completely public on Github.Gitlab repositories are deprecated, replaced with new Github repositories.Powered by Discourse, best viewed with JavaScript enabled"
301,bcs-for-2d-unsteady-channel-flow,"Hi,I would like to simulate 2D unsteady channel flow for arbitrary geometry.
I guess that it is suitable to do such simulation by using the Moving Time Window Method as like Taylor Green Vortex Decay (section 6 in the simnet user guide).
To do this, I should modify “def make_periodic_boundary…” in the Solver domain in taylor_green.py.
However, I have no idea which boundary condition should be written in the Solver domain.
Is it OK to write geo.boundary_bc(…) in the Solver domain as like the Train domain in the ldc_2d.py?Hi,My problem was been already resolved.
In the TrainDomain, it is correct to set boundary conditions as like ldc_2d case.Thanks.Powered by Discourse, best viewed with JavaScript enabled"
302,no-variables-to-optimize,"I’m trying to solve a 3D flow problem with SimNet but keep getting this exception: “No variables to optimize”. I’ve tried changing the boundary conditions but to no avail. Not sure if my system is over constrained, under constrained, or what else might be causing this issue. I have attached the full terminal output, which includes the exception stack trace. Thanks!exception_stack_trace.txt (6.5 KB)Can you please attach your script for this example?I realized it was a silly mistake, I made a class that inherited from TrainDomain but forgot to use it. I accidentally set train_domain to TrainDomain instead of my subclass when I inhereted from Solver. That’s why I got “No variables to optimize”, because the solver didn’t get any boundary conditions.
Ex:class MyTrain(TrainDomain):
…  # implementation hereclass MySolver(Solver):
train_domain = TrainDomain  # should be: train_domain = MyTrain
…This topic was automatically closed 2 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
303,news-simnet-isc-2021,"Join us @ ISC 2021 as we speak about SimNet and the infinite possibilities that SimNet can unlock for you and your simulation needs!
https://app.swapcard.com/widget/event/isc-high-performance-2021-digital/planning/UGxhbm5pbmdfNTMxMzg5Powered by Discourse, best viewed with JavaScript enabled"
304,differential-equation-cannot-take-in-a-range-of-values-for-one-of-its-coefficent,"Hello, I am working on a PINNs model and the last line in my section of code below represents a differential equation, which includes an end term with a coefficient k.
k is a separate equation which I also defined below, and it takes in a range of temp values to give a range of k values.#numpy imported as np
class PFR_equation2D(PDE):
name = “PFR_equation2D”The differential equation cannot take in a range of k values. I’ve tried using a for loop for k, but that didn’t work. How can I go about this?
Thank youHi @nga77It seems to me that you should not set the value of k here but rather parameterize it (so sample it while generating training points). We use this approach for time-series problems which have a similar range requirement.See the ODE spring mass example.  The input variable t is set as an input and sampled when generating training points via parameterization=time_range.Powered by Discourse, best viewed with JavaScript enabled"
305,error-in-installing-modulus-bare-metal-version-in-wsl2,"Hello,I installed modulus in wsl2 and the following error is appearing while running the example. can you please give me any advice. thanksTraceback (most recent call last):                                                                                                                                                                                                             File “helmholtz.py”, line 96, in                                                                                                                                                                                                       run()                                                                                                                                                                                                                                      File “/usr/local/lib/python3.8/dist-packages/modulus-22.7-py3.8.egg/modulus/hydra/utils.py”, line 73, in func_decorated                                                                                                                        _run_hydra(                                                                                                                                                                                                                              TypeError: _run_hydra() missing 1 required positional argument: ‘args’To resolve this I have downgraded the hydra version by following this thread – Error when running Modulus - Modulus Physics-ML Model Framework / Technical Support - NVIDIA Developer ForumsAfter this I am getting the following error –Error executing job with overrides:                                                                                                                                                                                                        Traceback (most recent call last):                                                                                                                                                                                                             File “helmholtz.py”, line 72, in run                                                                                                                                                                                                           openfoam_var = csv_to_dict(to_absolute_path(“validation/helmholtz.csv”), mapping)                                                                                                                                                          File “/usr/local/lib/python3.8/dist-packages/modulus-22.7-py3.8.egg/modulus/utils/io/csv_rw.py”, line 33, in csv_to_dict                                                                                                                       values = np.loadtxt(filename, skiprows=1, delimiter=delimiter, unpack=False)                                                                                                                                                               File “/home/bharat/.local/lib/python3.8/site-packages/numpy/lib/npyio.py”, line 1163, in loadtxt                                                                                                                                               chunk.append(packer(convert_row(words)))                                                                                                                                                                                                   File “/home/bharat/.local/lib/python3.8/site-packages/numpy/lib/npyio.py”, line 1142, in convert_row                                                                                                                                           return [*map(_conv, vals)]                                                                                                                                                                                                                 File “/home/bharat/.local/lib/python3.8/site-packages/numpy/lib/npyio.py”, line 725, in _floatconv                                                                                                                                             return float(x)  # The fastest path.                                                                                                                                                                                                     ValueError: could not convert string to float: ‘oid sha256:aeac30245e5ac347f39c4c076101decc448c674dd1531fe200a1c5e598c9557c’                                                                                                                                                                                                                                                                                                                                                              Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.Any advice please.Cool. The following link helped to resolve the issue. Thanks all. Unable to run helmholtz.py after installing 22.03.1 - Modulus Physics-ML Model Framework / Technical Support - NVIDIA Developer ForumsYou probably missed something. Are you using a conda enviironement? Try with a python venv.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
306,fourcastnet-inference-duplicate-output,"I have successfully trained a model using Fourcastnet. I have been using the inferencer.py code to capture the true and recursive_pred output of a trained model. The input is on128x64 grid.When I plot the output of both the true and predicted data I seem to have two 64x64 versions of the full grid in the 128x64 output data. I am expecting a 128x64 output grid matching the input?I have verified that the input data is the correct 128x64 field without duplicates.Is this an issue with a setting or a bug?The figure shows the two 64x64 grids in the 128x64 output array produced by the model. The lines at 180 degrees are an artefact of the plotting (no wrap points included).Here is the input data:-This is the code that I use to extract the data:-surft_p[nsave, tstep,:,:] = pred_recursive[0,:,:].cpu().detach().numpy()
surft_t[nsave, tstep,:,:] = true[0,:,:].cpu().detach().numpy()Hi @john.taylor1That is odd, was the model trained on 128 x 64 data? Also did you set the img_shape to the correct size for the tiling? Looking at your outputs it looks like the output is shifted (I can see the Andes temp in the middle of the pacific). Could this be a potential clue?Hi @ngeneva @tbednarzI have now confirmed that the dataloader call in inferencer.py:-for tstep, (invar, true_outvar, _) in enumerate(dataloader):returns Invar as a 128x64 field. true_outvar is two 64x64 fields and the call to model returns pred_outvar_recursive as two 64x64 fields. So the Dataloader is the source of the error.Yes the model was trained on 128x64 data correctly. The plot labelled sea surface temperature (above) is the input data on a 128x64 grid taken from an input file.Note also that both the predicted and true data fields are both on a 64x64 grid. This will mean that you will still get credible estimates of RMSE and ACC using inferencer.py so you would only spot this problem if you plot the data as I have done.Here is an example of one half of the 128x64 output field ie 64x64. You can see that this is can be correctly mapped to the full world map assuming that there are only 64 longitude point not 128. It is odd that it is only happening with the longitude dimension. Note also that the two 64x64 grids for both the predicted and true fields are different ie not simple repeats.Here is the output from inferencer.pyinvar = {‘x_t0’: tensor([[[[-1.3271, -1.2201, -1.1344,  …, -1.2121, -1.2679, -1.5170],
[-1.3434, -1.2300, -1.1234,  …, -1.1773, -1.3166, -1.5388],
[-1.3759, -1.2575, -1.1204,  …, -1.2088, -1.3996, -1.5502],
…,
[-1.4543, -1.2096, -1.0638,  …, -1.3316, -1.4448, -3.2561],
[-1.4061, -1.2203, -1.1135,  …, -1.2970, -1.3545, -2.7634],
[-1.3567, -1.2162, -1.0895,  …, -1.2672, -1.2819, -1.5542]]]],
device=‘cuda:0’)} [128, 64]
pred_outvar_recursive  torch.Size([1, 128, 64])here is a plot from the validator output showing the expected output: -Hi @john.taylor1Thanks for looking into this. I’ll make sure we have a look at the dataloader/dataset from our side to figure out what the issue is.So to clarify the input tensor is 128x64 and the true_outvar tensor is 2x64x64? But the model correctly gives pred_outvar_recursive to be 128x64? Want to make sure I know exactly what tensors are the correct and incorrect shape to try to replicate. Thanks!Hi @ngeneva @tbednarzI have now solved the problem. It seems to be a PyTorch error as It relates to converting a PyTorch tensor to a numpy array. The conversion to a numpy array does not check the shape and throw an error when [128x64] tensor was written to an [64x128] numpy array, so this error remained invisible:-surft_p = np.transpose(pred_recursive[0,:,:].cpu().detach().numpy())Note that the root cause of this problem is that the original ECMWF data, written in netcdf format, follows the accepted standard meteorological community standards and is written as a […,latitude, longitude] data set. The HDF5 files used by Fourcastnet have reversed this and use a […,longitude, latitude] format, not consistent with the accepted meteorological format. I recommend that Fourcastnet use the netcdf file format as used by ECMWF and that the data be formatted […,latitude, longitude]. Here is an example field from an ECMWF data file: -short sst(time, latitude, longitude) ;
sst:scale_factor = 0.000586115577027986 ;
sst:add_offset = 289.800610262524 ;
sst:_FillValue = -32767s ;
sst:missing_value = -32767s ;
sst:units = “K” ;
sst:long_name = “Sea surface temperature” ;This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
307,add-new-data-for-a-pre-trained-network,"Hello, I have trained a neural network using pointwise constraint, and now I need to add new training data, what is the correct way to train the pretrained network?Hi @matiyanezYou should be able to have Modulus load a model and train on it again with another script. For loading a already trained model there are some examples of this in our examples such as the Three Fin where the flow model is already trained (in this case it not optimized here).In general, Modulus will attempt to load the model checkpoint by default on initialization. So if you’ve got the checkpoint already in the correct directory theres no extra work needed. This will call the _load_model() method. You can also load it manually, in your script using model.load(path, mapping), see example in the trainer.You can then create a new constraint for the new data and train.Powered by Discourse, best viewed with JavaScript enabled"
308,parametrized-kirsch,"Hello!At the moment I am trying functionality of the framework on the Kirsch problem, specifically parameterize model due to the cutout radius in first experiment and model due to the angle of rotation of a elliptical cutout in secondLinks to repo you can find above.
There you can find scripts and config files(I used config_fc.yaml with default parameters for fully connected neural network) for my experiments. But I have very large losses for all time during my training(minimal value ~ 1e4). Could anybody explain my mistake?
I attach my Tensorboard’s graphics.
Снимок экрана 2022-04-19 в 20.16.441920×1028 161 KB
Hello, have you tried normalizing your equations? I remember when we did the linear elasticity problems we spend a while coming up with the correct normalization. Ideally you want all of the equations/boundary conditions to have around the same scale. This can be somewhat tricky with these kinds of problems though.Powered by Discourse, best viewed with JavaScript enabled"
309,query-regarding-acceptable-gpu-for-modulus-installation,"Hi all,I am a bit new to modulus sym. Is it possible to install the software on A2000 or A3000 gpu ? It is very crucial for my project.Thanks.A3000It looks like both of those cards support 12GB of VRAM. You’ll likely struggle with VRAM allocation issues, however it may be enough to get your feet wet and evaluate if the tool works for you. I’m running the aneurysm sample (without a validator, to see what happens) right now and it’s using 11.4GB. I’m running on an RTX 3090 with 24GB of VRAM and have had no issue running out of VRAM myself. When I do run out, I reduce how many sample points I’m looking at.Hi @kanadsen01Presently we do not officially test on A2000 or A3000 GPUs. But given the right CUDA version / driver Modulus should work fine. As @npstrike correctly suggested, the struggle will typically be with VRAM size (this is true with any deep learning). Be aware that many of the examples provided are developed on GPUs with much more VRAM, so you may need to adjust for some.Is this a deal breaker? No, not really. You can decrease the size of your model or your batch-size to fit things onto the device. Granted this will impact convergence slightly.Good rule of thumb is if PyTorch works, most of Modulus should work (at least on a single GPU).Thanks a lot for the info.Powered by Discourse, best viewed with JavaScript enabled"
310,modulus-on-jetson-orin-nx-nano,"Can Modulus run on NVIDIA Jetson Orin NX/Nano modules?  Their GPUs are built on the Ampere architecture but the memory interface/bandwidth as well as the GPU/Tensor Core count is significantly lower compared to the recommended GPUs; and Orin modules use the ARM instruction set, not x86.Hi @igor_furoaThats correct, the Docker image is compiled on a x86 instruction set so it wont work on an ARM platform I would think. You can however use most of Modulus with a python (bare metal) install. Only things missing will be PySDF (for raytracing of tessellated geometries) and tiny-cuda-dnn (optimized NN library).This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
311,how-to-accelerate-running-new-geometries-for-a-previously-trained-model,"Hello!I recently discovered the NVIDIA SimNet framework and am very excited to start testing it! I’m especially interested in cases like the aneurysm example. In particular, I would like to be able to train a model to predict fluid flow interacting with many different STL geometries. I read in the User Guide for the aneurysm example that Transfer Learning can be used to expedite the model training for new geometries but I have a a couple questions regarding this:In general, what is the best approach to apply a previously trained model to a new version of the same problem (different boundary or initial conditions, same equations)? I’m assuming this is possible, as I think this capability is a primary use case for any simulation tool, but please let me know if this isn’t possible and I’m misunderstanding the capabilities of SimNet.Thank you in advance for your time and help!Powered by Discourse, best viewed with JavaScript enabled"
312,modulus-dockerfile-missing-custom-deps-onnxruntime-gpu-1-14-0-cp38-cp38-linux-x86-64-whl,"Hello,I ma trying to build the docker image using the Dockerfile supplied in the modulus github repository :However a “custom built” onnx runtime is missing, where can I find this file ?Extract from DockerfileBest RegardsFrankHi @frank.guibert.workWe have a fix pushed to a different branch, sorry for the confusion. Please try the one here.Powered by Discourse, best viewed with JavaScript enabled"
313,stop-the-training-when-training-loss-reach-a-tolerance-value,"Currently, only these stopping criteria are supported;I wanted to stop the training when the training loss goes below a certain limit. In simple words.I am using a bare metal NVIDIA Modulus, so I can edit the source code, if it needs slight modification to achieve this. I can see in the trainer.py a simple break is implemented to stop the training when stopping criteria is met or when maximum training iterations is reached.  https://gitlab.com/nvidia/modulus/modulus/-/blob/release_22.09/modulus/trainer.py#L669I want to add the if condition here at the start of each iteration. https://gitlab.com/nvidia/modulus/modulus/-/blob/release_22.09/modulus/trainer.py#L496
How do I access the training loss? Is it a part of the dictionary losses?I also need to save the iteration number where the training loss met this criteria.Hi @prakhar_sharmaYes, losses is a dictionary of loss values computed here. So you can add any logic involving your losses after that to exit the training loop (can make a exit flag, set step = self.max_steps + 1 to break the loop, etc.).(For info about what is that loss dictionary, you can see the trainer iterating over the losses for logging here)This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
314,clarity-required-in-the-dimensions-of-inputs-and-outputs-of-fno-1d,"I stumbled upon the following information regarding dimensions of input and output variables to FNO.All the parameters except “size” are familiar to me. Can you help me with some description of these dimensions, especially the size dimension?Hi @shubhamsp2195The “size” here is what were refer to as variable dimension in the physical sense. For example most physical quantities just have a dimension of 1 at a given point. In the Darcy example an input has size=1 since its the permeability field.In the pythonic or DL sense size here is the channel size of the input tensor. FNO operates on a euclidean grid like a image. So I find thinking about the input for FNO as an image to make the most sense. Its just that Modulus focuses on connected DL with physical quantities, so its named slight different in the docs.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
315,parameterised-tessellation-very-gpu-memory-intensive-any-suggestions,"I am trying to use a set of roughly a dozen NACA airfoil meshes with slightly different parameters to use in the parameterized tessellation example, trying to optimise the parameters. (Example here: https://gitlab.com/nvidia/modulus/examples/-/blob/release_22.09/geometry/parameterized_tesselated_example.py).I am using an A100 80GB GPU, but as soon as I am trying to constrain it and run the simulation, the GPU goes to >100% and the kernel crashes.Is there a way to somehow limit the memory requirements and enable training of even larger sets on an 80GB machine?Thanks!Hi @benedikt_dietzDoes Modulus crash when its sampling the points of from the STL files or while training? I would start with lowering the number of points your using via the batch_per_epoch and batch_size parameters in your constraints.For some really complicated geometry we have also resorted to pre-sampling the STL files in a separate script with the geometry module and saving them to memory in say a numpy array. Then in the actual training loop, load them from the numpy file. This useful for speeding up testing as well.Hi, thanks for getting back!I tried to implement this like the following:and then tried to sample from the tessellated geometries like this to do the sampling outside of the actual training loop:Unfortunately, this breaks the kernel (almost) every time I run it, even though I’m working on a fairly large GPU and only sampling a very limited number of points on the geometries.Do you have a suggestion on how to manage this? I believe it’s due to excessive memory utilization, do you think that’s a correct diagnosis of the issue?Thanks a lot in advance!Hi @benedikt_dietzPlease try with the updated Modulus container if possible, migration should be very straight forward (guide here). I believe we had a few fixes to pySDF in this recent release.Powered by Discourse, best viewed with JavaScript enabled"
316,example-cases-from-v22-09,"Hello, its great to see the new update in v23 of modulus. I remember in v22.09 there were example cases of heat transfer etc that helped understand how to code in this environment. Does the new version have similar example or can we use the previous examples?Hi @mitanshtripThe examples are present in the Github repo now. If you are wanting to use version 22.09 then its a simple update of the imports in these example scripts. In other words, follow the migration guide in reverse. APIs are consistent between the versions.Powered by Discourse, best viewed with JavaScript enabled"
317,error-divide-by-zero-when-setting-up-train-domain-from-stl-file,"Hello, I am attempting to create a simple simulation of flow through a cylindrical pipe. I am following a methodology similar to the aneurysm tutorial. I receive a “divide by zero” error when the script tries to initialize the inlet face in the training domain.I have attached a copy of my inlet geometry file, the modified python script, and the error message. I suspect the error might have something to do with the way the STL files are constructed, as I have gotten this code to work with different (albeit worse) meshes.
Note: there are 3 more geometry files (outlet, walls, and closed) that I am unable to attach to this post due to link limits.Thanks,
DanMeshes:
inlet.stl (18.5 KB)
Code:
pipeflow.py (6.1 KB)
Error:
simnet_error_01 (1.1 KB)Here are the remaining three geometry files:Meshes:
closed.stl (185.2 KB)
outlet.stl (18.5 KB)
walls.stl (148.4 KB)I think I had a similar issue before. I believe it might be due to the meshes being too small. When you specify the batch size per area to be 128, the mesh area is so small that no actual points are taken on the mesh, eventually causing a divide by zero error. The hotfix for me was increasing the hardcoded batch size per area. A better solution might be normalizing your geometries dimensions or basing the batch size per area off of the surface area/volume in question.ateske92 is correct. This is the cause of the issue however we will look into providing an appropriate error message or work around. We suggest normalizing the geometry to fix this issue for now though.Powered by Discourse, best viewed with JavaScript enabled"
318,flow-around-a-cylinder-in-the-microscale-with-viscous-fluid,"Hi there, thank you for the attention.I’m currently working on a physics based approach very similar to the cylinder_2d.py example.
The key difference is that my domain is in the microscale (only 60x60 µm, Cylinder 7 µm) and my fluid has a density of about 1000 kg/m³ and is highly viscous at about 0.05 kg/(m*s).The problem is that the trained model does not even show flow around a cylinder (as can be seen in the image below). In some cases it even seems that the cylinder is not taken into account when using a microscale domain.My idea was using the nonDimensionalizer to scale the values, but I couldn’t find any solution for this either. From my point of view, the reason for this seems to be the microscale.Any idea how to solve this problem? Can Modulus produce good results at the microscale?Many thanks in advance!Hi @jflatterYes, the scaling of the problem can be very important. You should non-dimensionalize or scale your system which may require some experimenting.However another option to try is integral planes which are used in a number of out flow problems. The idea is to create an integral constraint that will force mass flow rate to be correct across different cross sections of the flow domain. We find these can help with flow related problems.A simple example this is in the annular ring problem and there’s information on these in our user-guide.Hi @ngenevaThank you for your answer.I have already tried to use the nonDimensionalizer, but I often get the error message that the geometry has no surface. I looked at the source code, but I couldn’t figure out how the non-dimensional values are calculated in detail.For example, I have defined a value of 0.00003 m and a lenght-scale of 10 m: How does the nonDimensionalizer calculate the non-dimensionalized value in this example?Many thanks in advance!Hi @jflatterI am not sure what would cause that error message. The cylinder example provides an example of this utility. Also the non-dimensionalizer code uses Pint under the hood. So perhaps those docs can also help guide you.Hi @ngenevaThank you for your answer, I’ve figured it out now. The values you set are devided with the scaling parameters.But I have another question regarding the continuity planes. How can I set planes on different cross sections in the channel? I tried to use following code, but all planes were generated at the outlet:criteria=Eq(x, channel_length[1]),And is there a list of possible outvar criterias? I have only seen the pressure, velocities and the NormalDotVec as criterias.Thanks in advance!HI @jflatterThe criteria is a geometric criteria that is a sympy expression. This defines how to sub-sample the geometry, thus isn’t related to the flow variables. The flow variables (in/outlet boundary condition) are defined via the outvar (target) variables which can be a variety of boundary conditions.So the example you provided constrains the geometry to just the outlet where x == channel_lenght[1]. This is on the boundary of the domain (assuming boundary constraint) so it will not be able to sample the interior at certain cross sections.If you have a interior domain where you want to train on some specific cross sections. I would suggest you define a seperate geometry with just these cross-sections then use a PointwiseInteriorConstraint to impose any conditions you have. (There are also examples that have integral planes that use cross section)E.g. If my domain is a rectangle, this cross-section geometry may be a union of 2D lines at specific locations. I would then use the new geometry in a interior constraint to impose conditions needed.Hi @ngenevaThank you again. This makes perfect sense to me.I will give it a try.Powered by Discourse, best viewed with JavaScript enabled"
319,cuda-error-operation-not-permitted-when-stream-is-capturing,"Execution of my modulus code is resulting in the following error.The culprit seems to be the constraint corresponding to the equationas can be seen from the error. What can be the potential causes for this issue? Is it possible that exponential terms are too large for the gradients to be computed?Hi @shubhamsp2195This error occurs when there’s a tensor / cuda object getting created or transferred inside a recorded graph. All CUDA objects need to be initialized and on the GPU prior to recording a graph. I’m not sure why exactly this is occurring for you, but you can shut off Cuda graphs in your config.yaml using cuda_graphs = False.Powered by Discourse, best viewed with JavaScript enabled"
320,radiative-heat-transfer,"Hello, just discovered your framework and had a look at the documentation. As far as i understand, simnet can simulate conductive an convective heat transfer aka CHT, but what about surface radiative heat transfer ? Can it be used for fully coupled thermal problem using black/gray radiation models ?Best regards.We do not currently have the radiative heat transfer equations in SimNet. However, SimNet APIs are customizable and users can include their own physics and PDEs. We also welcome external contributions to SimNet.Powered by Discourse, best viewed with JavaScript enabled"
321,real-world-sensor-connected-to-modulus-in-real-time,"Could you please indicate a workflow to connect a real-world sensor (IoT), for example, it could be a flow, temperature, pressure sensor, etc., with the Real-time simulation in Modulus?My goal is to see the simulation taking place in real time from real measurements.Is this possible? If so! WAW!!!How to make?Hi @contato48Modulus is a Physics-ML framework that allows you to build AI surrogates of physical systems. You could image an AI model that takes in this sensor reading as a parameter and perhaps spatial coordinates / material parameters that can then predict the response field. Naturally inference of the surrogate can be magnitudes faster than a numerical solver, creating real time estimates.There a lot of nuance though that can make this have varying level of difficulties: how complex are the physics, is there data, what range can the sensor be in, are you interpolating or extrapolating at test time, etc.To answer your question: “Is this possible?” it depends a lot on your problem of interest, but in many cases its very possible!WAW! This is amazing!
Could you share with us some tutorial or documentation on how to connect Modulus with real sensors?Powered by Discourse, best viewed with JavaScript enabled"
322,boundary-constraint-with-criteria-vs-boundary-constraint-of-tesselation-subset,"I am working on creating an automated wind tunnel for my Fluids/CFD students to use.  I create a rectangular solid using simple plane STL files and scale and insert (with inverted faces) a user specified STL object into the middle of the rectangular solid. When setting up the no-slip boundary constraint for the object, I can use the interior volume (of the combined rectangle-object tesselation) with position-based criteria (bounding box surrounding the object) in a pointwise boundary constraint.  Unless I am misunderstanding the operations it carries out, I could also pass a tesselation of the original scaled object.Passing the original object (no outer rectangular solid) to the pointwise boundary constraint with no required criteria takes significantly less time and memory to set up.  I don’t see any SDF use within the boundary constraint or its parent classes, is this a feasible approach? Or am I missing a bigger picture problem that would prevent this from working?Hi @pattersonI don’t think the SDF is in the boundary constraints here because when sampling the boundary we know the exact surface of it from the STL file. Since its exact on the discrete mesh, the SDF is always zero. Note in the tessalation code here the sample function which looks at the mesh triangles to build a pseudo curves object which is used to sample boundary points.Regarding you comment, yes it is approximately possible with only one small issue which is that you could potentially be sampling inside the object when getting points inside your wind tunnel volume! The STL sampling with a closed volume will make sure the points are in fact in the wind tunnel but also not the object. This could potentially impact training (it could not at all). So just something to be aware of, it things look like they converge (who knows it may be fine) then sounds like a good solution.Sounds good, I’ll run some test cases with large sample counts to make sure it is sampling where I expect it to occur.Powered by Discourse, best viewed with JavaScript enabled"
323,how-to-use-multi-gpus-on-a-single-mechine-to-run-the-cases-in-modulus,"Is that correct to run “mpirun -np XX python xx.py”? Or should I set something into the hydra config? Thanks!Hi, I tested the case three_fin_2d/heat_sink.py using one, two, and four GPUs by mpirun. Their times for 500 steps are:
1 GPU: 1m30s
2 GPUs: 1m50s
4 GPUs: 2m5s
I am confused why using more GPUs takes more time to train the same steps?
Could anyone give me some ideas? Thanks!Hi, if I guessed correctly, it’s because the way Modulus with multi-GPUS works is that the batch sizes on each GPU are fixed.Hence, total batch sizes increases when more GPUs are used. If you want to fix total batch sizes, then you need to edit the yaml .e.g half batch sizes if 2 GPUs are used.I got it. Thank you!Btw, does anyone know how to automate it? ie divide the batch sizes in the code automatically when > 1 GPUs are used.I tried to query the number of GPUs used using:It prints the correct no. of GPUs, but I can’t seem to use it as an integer to divide the batch sizes.Does anyone know why?Hi @tsltaywbA good way to get the size of a DDP training session is the distributed manager in Modulus / Modulus-Sym.from modulus.sym.distributed.manager import DistributedManager# Initialize the singleton
DistributedManager.initialize()
# Get a manager object
manager = DistributedManager()# Parallel attributes
manager.rank
manager.local_rank
manager.world_size
manager.device
cfg.batch_size = cfg.batch_size / manager.world_size # Lets adjust our batch sizeSome additional information here:Ok thanks! I’ll try it out.Powered by Discourse, best viewed with JavaScript enabled"
324,issue-with-mixed-form-navierstokes-initialising,"Hello,I have tried to run the cylinder_2d example with the only change being mixed_form=True in the NavierStokes initialiser.However this doesn’t appear to initialise with it taking hours to start and it ran out of system memory crashing. As far as I can tell it is the PointwiseInteriorConstraint that is taking so long to setup.Are there any tricks to getting NavierStokes to work with mixed_form? I have ~64Gb of system memory available, is it expect that using NavierStokes in this form would require more than this?Best RegardsLimitingFactorHi @LimitingFactorWe have an example of mixed-form Navier-Stokes that you could use a reference. Does it hang on the definition of the N-S node, is it hanging when its generating points for a constraint, or else where?I found going to hardBC solved this issue.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
325,can-cad-geometry-be-optimized-for-parameters,"The object of parameter optimization in the example is geometry that can be described in code. Can parameter optimization be performed on CAD geometry?Hi @tao-zhan18I think you’re looking for DiscreteGeometry:DiscreteGeometry in GitlabHi @tao-zhan18Have a look at our geometry page in our user guide to see the different parameterizations of geometry we support in Modulus.https://docs.nvidia.com/deeplearning/modulus/user_guide/features/csg_and_tessellated_module.htmlPowered by Discourse, best viewed with JavaScript enabled"
326,best-way-to-normalize-the-input-of-a-pinn,"Hello,I’m trying to reproduce the results of this paper: Physics-informed neural networks for transcranial ultrasound wave propagation - ScienceDirectThe metrics used are multi-scale (e.g. milliseconds (ms) and kiloHertz (kHz)). The setup of the problem requires the normalization of the input to PINNs to obtain accurate results.Does Modulus have a specific feature that can be used to deal with multi-scale problems? If so, what do you recommend?
If not, then what is the best approach to have the input normalized before training and prediction?Please share any suggestions to work around this.Hi @cpe.skI have not read this paper but Modulus does have multiple Fourier networks which have been seen to learning multi-scale physics better than standard fully-connected. Using these could help. Regarding normalization, typically the best approach is to non-dimensionalize the system if possible then make further adjustments. Theres quite a few “tricks” you can try for difficult problems you could consider in our documentation.Powered by Discourse, best viewed with JavaScript enabled"
327,pressure-gradient-boundary-condition,"The Lid driven cavity flow example does not use a pressure boundary condition, but for ordinary CFD, a boundary condition of zero pressure gradient is imposed on the wall surface.
So I used GradNormal as shown in the attached file, and added a boundary condition where “normal_gradient_p” is zero on the wall surface, but it does not seem to be learning well. Could you give me any ideas as to the cause or what I should fix?ldc_2d.py (3.7 KB)Hi @user106225With physics-informed learning, similar methods to numerical solvers can be used but do not always work the best. The optimization of a solver and a neural network are very different, thus sometimes different strategies need to be used for training a AI surrogate. For all practical purposes, its largely comes down to empirical testing. Each PDE is different and may require different strategies for getting good convergence.Does this mean a pressure gradient boundary won’t work? No, I’m sure there’s a way to weight the losses or adjust the learning appropriately to get something the learns better. But that’s up to the user to figure out. I would suggest looking through the different examples we have as well as the literature in the field for guidance based on methods other’s have found successful. We also have a recommended practices section in our user guide with some typical strategies we found to help.Hi,I tried to understand user106225’s ldc and three fin 3d’s code to adapt to my problem. I have some qns:gn_p = GradNormal(‘p’, dim=2, time=False)nodes = … + gn_p.make_nodes()no_slip = PointwiseBoundaryConstraint(
nodes=nodes,
geometry=rec,
outvar={“u”: 0, “v”: 0, ‘normal_gradient_p’: 0},
batch_size=cfg.batch_size.NoSlip,
criteria=y < height / 2,
)
ldc_domain.add_constraint(no_slip, “no_slip”)Is that so? It seems that I can give any name (e.g. gn_p) to the GradNormal but normal_gradient_p can’t be changed.outlet = PointwiseBoundaryConstraint(
nodes=nodes,
geometry=rec,
outvar={“p__x”: 0},
batch_size=cfg.batch_size.TopWall,criteria=Eq(x,channel_length[1]),
)
ldc_domain.add_constraint(outlet, “outlet”)Is this valid as well? Thanks.Hi, @tsltaywb
If the Neumann boundary is parallel to the axis, as in ldc_2d.py, it is equivalent to impose constraints on “normal_gradient_p” and “p_x”, thus either method gives the same result.
If the Neumann boundary is not parallel to the axis, I think “normal_gradient_p” should be used.Hi user106225,Thanks for the explanations!Powered by Discourse, best viewed with JavaScript enabled"
328,how-to-use-fourier-gradient-method-for-fourth-order-derivative,"In PINO example, the following line of code is used to solve first and second order derivative
f_du, f_ddu = fourier_derivatives(u, [2.0, 2.0])What changes should I make to solve fourth order derivative?Hi @gaijinliugangmeiI would not recommend using the derivative method described in the PINO paper (described as the “exact” method in the Darcy example) for anything above second order due to the computational cost. It is very expensive and not scalable.For higher-order I would suggest trying a finite difference approach or the fourier derivative approach which will be very cheap to compute. Finite difference will probably be the easiest to implement quickly. From our independent study in our Darcy problem, all achieved about the same convergence.Powered by Discourse, best viewed with JavaScript enabled"
329,torch-autograd-fails-on-single-gpu-when-using-continuous-parameterization,"For a while I’ve been running (and developing) my Modulus based simulations on a cluster via a converted Singularity container.  Long story, short… I didn’t realize the differences between docker and singularity and now need to fix my singularity setup.  Instead of trying to fix the singularity submission system while improving on my simulation program, I returned to development on my local machine.I’ve created two parameterizations, one that modifies the kinematic viscosity nu to run a single STL file for a range of Re values and, separately, one that uses a discrete geometry and multiple STL files to compare geometric changes.Prior to my forced return to development on my local machine, both of these were working.  Now, when I try to run the parameterization of ‘nu’, same code that was working on the cluster, I get the following when the Solver starts up:My input keys into the NS for this parameterization are defined as:I pass a single float value to my ZeroEquation step for nu and then pass the ZeroEq.equations[“nu”] to my NS equation.My working (on the cluster) version passed the following parameterization:Following the ThreeFin example, each constraint is passed the following parameterization:I get the same error by specifying the vertical array or keeping it as a range.  Perhaps I’m still doing something incorrectly, but it seems odd that it would work on the cluster and not locally.  I thought that the parallel (slurm) part may be keeping more in memory for communication purposes so I modified the torch.autograd.grad call in derivatives.py to include “retain_graph = True”, but it must be clearing it from memory from a separate call as this resulted in the same error.Let me know if you need any other info or if I’m just missing something*edit because I forgot another piece.
The second parameterization is set up in a very similar way, but uses discrete geometry for multiple STL files.  The parameter I use is just an integer index referring to the modified STL file.  Aside from the discrete geometry part, this is the main difference between the two.Hi @pattersonPerhaps a little late, but this is very unusual that things work differently of different systems. My only guess right now is that somehow Modulus is getting confused between the parameterized nu and the  ZeroEq.equations[“nu”].I.e. when unrolling the symbolic graph, perhaps Modulus is injecting constants from the parameterization into the graph which is then causing things to get messed up as Pytorch attempts to calculate autograd on what it thinks are outputs of the turbulent equation but are really just constants. (This is just speculation)I would perhaps try using another name for the input key Key(nu) you give to the ZeroEquation (e.g. nu0) and then use that in your parameterization. I’m just guessing, I don’t think this explains why some items work on your cluster vs local.Not too late… I’ll give this a try.  It’s secondary to what I’m trying to achieve with the STL parameterization, but it’d still be nice to have.Powered by Discourse, best viewed with JavaScript enabled"
330,idle-gpu-power-draw-over-100-ubuntu-rtx3090,"Running 20+ supermicro servers. with RTX3090, A5000, and GTX1080in this instance we have dual RTX3090 running. however, GPU0 is drawing over 100% power with zero workload.OS: Ubuntu 20
Headless (no monitor attached to server)
attached nvidia-smi output

Screenshot 2022-12-20 at 12.46.59 PM1326×930 100 KB
Powered by Discourse, best viewed with JavaScript enabled"
331,gpus-parallel-program-does-not-exit-after-training,"Hi, I used the openmpi and three GPUs to run the case “/modulus-sym/examples/three_fin_2d/heat_sink_inverse.py”. After training, the program did not exit automatically. What is the possible reason?
Thanks!Hi @zhangzhenthuIts impossible to fully tell why a multi-process just hangs without logs. If this is still an issue, please provide some additional information such as your environment, if the job finished training / saving the outputs, when you kill the process are there any logs / errors, etc.But just as a heads up, soft locks / hangs like this with MPI can be extremely difficult to fully debug. This may just be some MPI / PyTorch anomaly.Hi, thank you for your reply!
Yes, it still happen. I am using the docker environment. All output is fine, and there is no log or error when I kill the process.
This issue doesn’t have much impact. Considering the debugging is difficult, we can just jet it go.
Thanks again.Hi @ngenevaWe are encountering the similar issue of parallel GPU training with modulus-sym via Open MPI.We have successfully mounted the latest version of the Modulus-sym container (Ver. 22.12) on our A40 server. It is able to perform the Lid Driven Cavity (LDC) example with single-GPU training.However, when attempting to execute multi-GPU training, the program gets stuck at iteration 0, and fails to regularly update iteration information and store iteration results.Regarding parallel GPU training, officially documents recommend using the “mpirun --allow-run-as-root -np #” in conjunction with the original command to implement it.One can find more details in the following links:
Performance - NVIDIA Docs
Turbulence Super Resolution - NVIDIA DocsWe have attached the log files related to this issue, as well as the GPU information.
ldc_2d_training_OpenMPI_1gpu (3.3 KB)
ldc_2d_training_OpenMPI_2gpu (5.4 KB)
nvidia_smi (5.5 KB)Here are the system details:
Operating System: Ubuntu 20.04.6 LTS
Docker version: 24.0.1
GPU: NVIDIA A40*8
Driver version: 530.30.02 from NVIDIA’s public website
CUDA driver: 12.1We would greatly appreciate any recommendations or assistance one can provide to resolve this issue.Hi @johnlaideI’ve tested running the LDC example with mpirun --allow-run-as-root -np 2 python ldc_2d.py  on a V100 DGX box with out issues (This is on older drivers Driver Version: 510.47.03    CUDA Version: 11.8).Typically a good place to start is shutting off optimizations (turn off JIT, functorch and cuda graphs) to see if that changes anything. These can be shut off in your config.yaml:Expected output of LDC with two MPI processes:Powered by Discourse, best viewed with JavaScript enabled"
332,working-with-custom-constraints-criteria-and-outvar,"hello, I am trying to simulate a problem where we have to predict a damage in a solid mechanical model, but in doing so I am facing an problem with conditions on the same.I need to solve the equation: self.equation[""f""] = Max(|p| - r1, 0) + r2*f = 0, so I defined the same in modulus and in constraint section with outvar={""f"":0}but I am facing the following error:But applying the max operator is not helping, so I tried to separately define the 2 cases with criteria constraint.But this pops out the following error:So I decided to tweak the script for PointwiseInteriorConstraint as follows:But even this didn’t helped and now the error is:Now I am out of ideas how I can make it work please help me with the same.Thank youSincerely,
NihalHi @nihalpushkar11Starting off with the first error, try removing the =0. I.e.The loss function of f will impose that this goes to zero. See the wave example for a sample implementation of a custom PDE if you have not already.The second error seems to be because sigma_xx is not defined. Verify that you’ve defined this equation / symbol.For the third error, verify that you have installed modulus with the custom implementation of the constraint. You could pip install your modified modulus version with a standard pip install or use a development mode / editable install.hi @ngeneva, thank you for replying but could you please help me with these queriesactually the constraint is f = -Max(|p| - r1, 0)/r2that needs to be satisfied everywhere. But the issue I am facing is with the Max operator as removing that solves the problem but with Max it pops out the error mentioned in part-1Where should I define them, like in the main script or the supporting scripts? {from where I import the equations}.Could you please share some in-depth documentations on the same, so I can understand the structure and usage of the variables well.Thanks and regardsNIhalAs per your suggestion for part-2, I defined the symbol sigma_xx, but now facing a new error with the same:Please helpPowered by Discourse, best viewed with JavaScript enabled"
333,what-is-the-use-case-for-modulus,"Hi!
Thank you for releasing Modulus/SimNet - it is a very interesting piece of tech! Im having a bit of a trouble understanding what is the actual use case for it:
For a fix problem/geometry the training takes much longer than obtaining a solution from a standard FEM solver or similar (on my RTX3080 helmholtz problem takes few minutes to train, waveguide2D takes about 10h, both can be solved much faster using Elmer).
I understand that once trained we have a network that we can query for solution a any input, which is not possible for standard FEM solver without remeshing and resolving, but how important is this?
If we do parametrize the input geometry (like with fpga example) than we indeed can try to optimize in that parametrisation space, but to train a network with this extra parametrisation is even slower.So is the general idea that we parametrize our problem, than train the solution on a GPU cluster for days or weeks but then once we have the solution we can use it for fast optimisation, or anything else that requires a quick forward pass?In the Simnet paper ([2012.07938] NVIDIA SimNet^{TM}: an AI-accelerated multi-physics simulation framework) when you report on Table 3 the time needed for optimization of the fpga and Simnet is 45000x faster than a FEM solver that does not include the training time, right? What was the training time for it? (on the 8xV100 setup you used)Thank you for any info regarding my understanding of the use cases, and the training timing.Hey,you may look at the papers from the CRUNCH grouphttps://www.brown.edu/research/projects/crunch/homeIn their papers, they display various use cases for physically informed neural networks (PINNs).An example: In one of these papers, PINNs allowed for Runge Kutta simulations of extreme  order.From may experience, you are right: PINNs shine in design optimization, when you try different model configurations (subject to physical constraints) based on a multitude of parameters.From my point of view, the general idea of PINNs for design optimization is not too dissimilar to this recent NVIDIA paper concerning autlod: Appearance-Driven Automatic 3D Model SimplificationHi,I am also interested in a response to this question. Your sentiments match the general feeling I have gotten through working with PINNs for various CFD applications. The compute/GPU time for PINN applications seem like a major barrier to entry compared to existing simulation techniques like FEM/FD/FV.Current AI methods will be slower than the traditional solvers for training of a single case/geometry. Advantages of Physics-ML technology are for (these are also covered with examples in the Modulus presentation):This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
334,unable-to-install-nvidia-sym-no-matching-distribution-found-for-vtk-9-1-0,"I have been following: GitHub - NVIDIA/modulus-sym: An abstracted framework for training AI surrogates of physical systems using physics-based symbolic loss functions for installing the same, but vtk is giving me issues. I even tried with uninstalling but still no luck, below is the log for the same.Thank youShould I edit the project.toml file inorder to suffice the versions? but would that be safe to do so?Even doing so has lead to the following error:Hi @nihalpushkar11This is likely because your Python version is too new (e.g. >=3.10), try downgrading your python version to say 3.8 and trying. The VTK dependency in Modulus sym doesn’t support newer python versions. We are tracking this issue to fix.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
335,boundary-conditions-for-pressure-driven-flows,"Hi there, thank you for the attention.I would like to train a model of a flow around a cylinder with a pressure driven flow.However, I could not figure out how to set the boundary conditions correctly. I only have given two pressures (inlet: x Pa; outlet: 0 Pa), but no velocities or flow rates.
In openfoam, you can use functions like zeroGradient or InletOutlet to satisfy the boundary conditions. Which BC are needed in Modulus? Are there predefined functions for this setup?
And how do I create the full-slip BC on the channel walls in this case?Many thanks in advance.Hi @jflatterWhat the best boundary condition is to use in Modulus is a bit of a tough question. Its very problem dependent and is research/experimental subject. I would suggest trying a few approaches (starting with perhaps is easiest to implement for you and what you would use in a numerical solver).Unfortunately this process can be quite empirical, so be sure to look at our fluid flow examples for some initial guidance.Things like zeroGradient can be imposed using the gradient terms in the outvar (they will be calculated using autodiff in the constraint so you can use them in your loss).Similarly a full-slip boundary would be imposed by setting the wall normal gradient of the wall-parallel component to zero. This will be easy for boundaries along a given axis (e.g. for a wall on x-axis just set du/dy=0), but for off-axis walls you’ll need the boundary normal which should be able to be obtained from the geometry module. In the turbulent channel example the wall normal is used to for a wall function which may provide some guidance.Hi @ngenevathank you for your answer.I tried implementing the full-slip BC for the channel walls. I used follwing code:However, I get following error:Thanks in advance.Hi @jflatterIf you’re graph cannot unroll this means that it can’t figure out how to compute some needed output variable, in this case du/dy. Defining it in you main script does not tell the constraint what this is, this is the job of the node list. There’s two options here:Create a custom node that is added to your node list that tells modulus how to compute du/dy. Look at the Node.from_sympy() method. Several of our examples should use this.Use variable that modulus will understand. As seen in our examples that have derivatives as target variables, e.g. 1D wave, modulus uses double underscores to denote derivatives. I.e. du/dy == ""u__y"". Modulus will figure out how to compute the gradient for you.Hi @ngenevaThank you for your help. The full-slip boundary condition seems to work fine.However, the pressure BCs for pressure driven flow are still not working properly, even using weighting. My idea was to use hard BC. I looked at the annular_ring and hemlmholtz example, but I am not shure how to apply my BC.How do I specify hard BC for pressure at the inlet and outlet? Following code only seems to work for the outlet:omega_E_p = omega_1outvar[""p""] = omega_E_p * invar[""p_star""]Do I need to define an equation to set hard BC for my geometry? As example:
Thanks in advance.Powered by Discourse, best viewed with JavaScript enabled"
336,assertion-error-when-restarting-training,"I’m getting an error when reloading models during training phase. Has anyone got any advice?Thanks,
Ben
image1147×752 36.3 KB
Hi @mn17b2mCan you provide some information regarding what version of Modulus you are running. Is this a bare metal install or a Docker image.I have personally not seen this issue before but based on a related Github issue seems its a bug others are seeing in current PyTorch version that could be related to Cuda Graphs.Perhaps try shutting off Cuda Graphs with cuda_graphs: False in your config to disable this feature?Where do I place it in the config file?
image247×577 8.76 KB
I keep getting errors. Have tried it in a few locations.I’m running v22.03 and it is bare metal install on google colab@mn17b2mCuda Graphs is a feature present in 22.07, not 22.03 so its not relevant. Based on that PyTorch issue thread I linked, you may want to try downgrading your PyTorch version. (Seems this is happening for people on PyTorch 1.12). Please have a look there for more information that may be relevant to you.Powered by Discourse, best viewed with JavaScript enabled"
337,custom-loss-and-visualization,"Hi All!
I may be missing something very simple, but have been trying for a while now and not getting anywhere.
I have a custom loss function where I compute a loss based on boundary normals (normal_x, normal_y) and some derivaties of ‘u’ (using tf.gradients etc).  - all very similar to tutorial 9 of the Manual.
Inside the custom_loss I have access to x, y of the domain together with normal_x, normal_y through domain_invar.Now for debugging purposes I would like to be able to plot normal_x, normal_y and my computed derivatives of u in the InferenceDomain so it gets saved to the vtu and I can visualize it.Whatever I try I always get only ‘x’,‘y’,‘z’,‘area’,‘sdf’ and ‘u’ saved in the (inference) vtu. How can I:Thanks for any pointers,
JarekPowered by Discourse, best viewed with JavaScript enabled"
338,multidimensional-array-constraint-issue,"I was trying to implement a physics problem where constraints are in the form of 3D arrays. Following code snippet explains the problem setup (only a single constraint was used for the sake of depicting this issue).But the execution is stalling before the training startsThe execution does not proceed after this point. I waited for more than an hour.This issue is not present when 1D arrays as expressed below are used for specifying constraintsI tried to implement the same constraint with 2D arrays of the formand got the following error.Is it because multidimensional arrays are not supported in modulus constraints?a physics problem where constraints are in the form of 3D arrays3D arrays are like cube or cuboid. Is that what you are saying?ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 2 has 2 dimension(s)The error tells you that xp_ar,  yp_ar and tp_ar0 have different dimensions. This will obviosuly give you an error. If your constraints are u(x,y,t)at specific spatiotemporal locations just create a 2D array with size n*3. Where n is the number of BC points.
In your case, you need three 1D arrays for each x,y,t location. And right now xp_ar,  yp_ar and tp_ar0  are definitely not 1D.3D arrays are like cube or cuboid. Is that what you are saying?Yes. If you look at the following constraintsthere must be a 3D mesh grid for c_s(x,y,t), which in turn means that a 3D array is required to store values at each of the points. This mesh gird will also mean that the arrays xp_ar, yp_ar and tp_ar0 must be 3D as they are a part of the same constraint “IC_an” (all arrays must be of the same dimension for a particular constraint).The error tells you that xp_ar , yp_ar and tp_ar0 have different dimensions. This will obviosuly give you an error.You can look at the dimensions of arrays. All of them are the same (definition of arrays in “grid_generation” code snippet). Also, the code stalls without giving error for the 3D array case. Error is observed only when 2D arrays are used.In your case, you need three 1D arrays for each x,y,t location. And right now xp_ar , yp_ar and tp_ar0 are definitely not 1D.I think this won’t work in my case as the function c_s(x,y,t) is part of the same constraint.  All arrays must have the same dimension.For documentation Modulus uses 1D arrays for its point constraints:Powered by Discourse, best viewed with JavaScript enabled"
339,unable-to-run-helmholtz-py-after-installing-22-03-1,"I was able to run the modulus v22.03.1 docker container but when I try to run helmholtz.py, i encountered the following error.root@0c905d725071:/examples/helmholtz# python helmholtz.py
Traceback (most recent call last):
File “helmholtz.py”, line 4, in 
from modulus.hydra import to_absolute_path, instantiate_arch, ModulusConfig
ImportError: cannot import name ‘ModulusConfig’ from ‘modulus.hydra’ (/opt/conda/lib/python3.8/site-packages/modulus-22.3-py3.8.egg/modulus/hydra/init.py)Hi @yeokiwi ,Thanks for your interest in Modulus.
You’re likely running version 22.07 of the examples if I had to guess. We had a lot of changes to the imports in 22.07 so things will not line up with 22.03.1 image.Is there any reason you’re running 22.03.1 specifically? If so I can provide you the import fixes.I downloaded 22.07 but I encountered the following issue when I ran docker:Error processing tar file(exit status 1): unexpected EOF.So, i downloaded 22.03.1 and it worked but I could not run the examples.Should I redownload the 22.07 and try again?Hi @yeokiwi ,Yes please try again, we had some issues with the devzone image and reuploaded it. Hopefully should be fixed.Please let me know if it does not work.Note (for future reference) we also provide Modulus containers on NGC which can also be pulled as an alternative option: Modulus | NVIDIA NGCHi @ngeneva,The installation works! Thanks.However, I still encounter problem running the example.root@623966b3241a:/examples/ldc# python ldc_2d.py
Error executing job with overrides: 
Traceback (most recent call last):
File “ldc_2d.py”, line 82, in run
openfoam_var = csv_to_dict(
File “/modulus/modulus/utils/io/csv_rw.py”, line 33, in csv_to_dict
values = np.loadtxt(filename, skiprows=1, delimiter=delimiter, unpack=False)
File “/opt/conda/lib/python3.8/site-packages/numpy/lib/npyio.py”, line 1163, in loadtxt
chunk.append(packer(convert_row(words)))
File “/opt/conda/lib/python3.8/site-packages/numpy/lib/npyio.py”, line 1142, in convert_row
return [*map(_conv, vals)]
File “/opt/conda/lib/python3.8/site-packages/numpy/lib/npyio.py”, line 725, in _floatconv
return float(x)  # The fastest path.
ValueError: could not convert string to float: ‘oid sha256:4c68adf2b0a04c53f0abd4d3920f3fec618669399638dd5ece84785f474d1fa6’Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
root@623966b3241a:/examples/ldc#I can run the ode_spring_mass example correctly though.RgdsHi @yeokiwi ,Looks like you don’t have Git LFS installed. We use Git LFS in our examples repo to store the data files, without LFS it will just be a pointer file. With Git LFS installed, try re-cloning the examples repo. That CSV file for LDC should now have proper data in it and the example should run.More information about Git LFS can be found here.Hi @ngeneva ,Thanks! It’s working correctly now.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
340,values-of-output-variables-keys-at-grid-points,"I am dealing with a problem wherein the difference between solutions at ends of 1D domain is required as shown below.

self.equations[“Energy”] = T.diff(t) - I*(R_a**2/D_c)/(717*298) * (4.3 - (Phi_1.subs(x,13) - Phi_1.subs(x,0)))

I am hoping that “Phi_1.subs()” will evaluate “Phi_1” at the desired “x” location as is the case with sympy expressions.When I print the equation using pprint() function, following expression is displayed.

-0.00412793799668642Phi_1 + 0.00412793799668642Phi_1 + T__t - 0.0177501333857516
Is the subs() function working here? This is not clear from the printed expression.If it’s not working, is there a way around to achieve the same.@ngeneva
Can you help me with this?Hi @shubhamsp2195I would imagine that as long as Phi_1 is a valid sympy expression, this should work fine although I don’t recall an example of us ever using this function.To sanity check this you could take your custom PDE class, create the nodes using .make_nodes(), then manually check the evaluation of the equation via node.evaluate property to then feed in input variables manually. An example can be found here in the docs.Thank you @ngeneva for this informationPowered by Discourse, best viewed with JavaScript enabled"
341,the-results-of-ldc-2d-py-is-not-the-same-as-those-in-simnet-v21-06-user-guide,"I tried to run the first example ldc_2d.py without any modification, but the results I got were not the same as shown in SimNet_v21.06_User_Guide. It seems stop simulation with large error. The solution was not convergent and it stopped with total loss 0.00039. I ran the example with the bare metal version. Actually I installed the environment on the container service in the TWCC service in our center. The container used is the  NGC TensorFlow Release 20.11 stated in
[TensorFlow Release Notes :: NVIDIA Deep Learning Frameworks Documentation]

image002650×590 67.8 KB
Hello, I believe that its working but you will need to train it for longer to recreate the loss curves seen in the user guide. This problem is setup to run for 400K iterations but the plots you have are only for 2.5K. To test though, could you run the helmholtz example? This converges much faster in 20K iterations and you can plot the results to see if they match the given validation data.How can I train it for longer? I used the same setting as in the original ldc_2d.py file. I ran and stopped at about 2.5K. And I have already tried the helmholtz example and the results look good. It converges to the validation results. The results for all steps show in the ldc_2d.py example are listed here:
total_loss: 0.00879224
time: 0.07409589767456054
total_loss: 0.0059654717
time: 0.013278253078460693
total_loss: 0.004125621
time: 0.013525300025939942
total_loss: 0.0030642985
time: 0.013485288619995118
total_loss: 0.0033810143
time: 0.013271934986114502
total_loss: 0.002713479
time: 0.013546154499053956
total_loss: 0.0017080866
time: 0.013386952877044677
total_loss: 0.0017460646
time: 0.013371756076812744
total_loss: 0.0013436687
time: 0.013651156425476074
total_loss: 0.001052431
time: 0.021090617179870607
saved to ./network_checkpoint_ldc_2d/
total_loss: 0.0009754368
time: 0.07807020187377929
total_loss: 0.00073354295
time: 0.013308625221252441
total_loss: 0.0010020003
time: 0.013653841018676758
total_loss: 0.0006775806
time: 0.013463542461395264
total_loss: 0.00049137336
time: 0.013459904193878174
total_loss: 0.0006492392
time: 0.013576748371124268
total_loss: 0.00039436677
time: 0.013347928524017333
total_loss: 0.00047523764
time: 0.013303215503692628
total_loss: 0.0005249865
time: 0.013294055461883544
2021-06-24 13:21:55.283895: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
total_loss: 0.00035619925
time: 0.04161646842956543
saved to ./network_checkpoint_ldc_2d/After stop the job, I rerun the python ldc_2d.py. And I got the following information including one failure message:
For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:TensorFlow is an open-source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) that flow between them....2021-06-29 10:48:26.334006: W tensorflow/core/common_runtime/process_function_library_runtime.cc:688] Ignoring multi-device function optimization failure: Invalid argument: Node ‘_arg_continuity_0_3_0_arg’: Node name contains invalid characters
total_loss: 0.00034051613
time: 0.13434922218322753
total_loss: 0.00038129173
time: 0.01298861026763916
2021-06-29 10:48:40.876196: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothingto do
loss went to NansThe error message suggests that perhaps you are using automatic mixed precision, which is not currently supported in SimNet. Can you please doexport TF_ENABLE_AUTO_MIXED_PRECISION=0and run this example again?W tensorflow/core/common_runtime/process_function_library_runtime.cc:688] Ignoring multi-device function optimization failure: Invalid argument: Node ‘_arg_continuity_0_3_0_arg’: Node name contains invalid charactersGlad to hear it is working now. Yes, you can ignore this warning message.Powered by Discourse, best viewed with JavaScript enabled"
342,error-running-22-07-container-with-examples-failed-to-create-shim-task,"Seems like 22.02 will not install?  This is my current error.  Can anyone help me with what this is or how to fix it?docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --gpus=all -v ${PWD}/examples:/examples -it modulus:22.07 bash
docker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #0: error running hook: exit status 1, stdout: , stderr: Auto-detected mode as ‘legacy’
nvidia-container-cli: mount error: file creation failed: /var/lib/docker/overlay2/ca5de1d2dbb200798f83372e1d274ce3e2fe6773eb5805ed35859d4e2c02e76f/merged/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1: file exists: unknown.Hi @ckitchell ,Is there any chance your running NVIDIA Container Toolkit on WSL? There seems to presently be a known issue with nvidia-docker on Windows systems.More information:### 1. Issue or feature description
I prepare environment follow this [guide:](…https://docs.nvidia.com/cuda/wsl-user-guide/index.html) 
- Windows 11 build 22000 (Insider Preview Beta Channel)
- WSL2, ubuntu20.04 (Linux version is 5.10.16.3)
- [CUDA on WSL](https://developer.nvidia.com/cuda/wsl/download) 510.06
- CUDA Toolkit 11-4 (using [WSL-Ubuntu](https://docs.nvidia.com/cuda/wsl-user-guide/index.html#ch03a-setting-up-cuda))
- docker 20.10.8
- nvidia-docker2  2.6.0-1 (with libnvidia-container1_1.5.1-1, libnvidia-container-tools_1.5.1-1, nvidia-container-toolkit_1.5.1-1, nvidia-container-runtime_3.5.0-1)

When `sudo docker run --gpus all --runtime=nvidia -it --rm <my image name>`, there comes the issue

>docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: /var/lib/docker/overlay2/706b1d1b6de681b6daf1cab979336a9d465d9b333962cc17db663f2e334d5776/merged/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1: file exists: unknown.

Though encounter problems when run my own image, this sample just works fine:
`docker run --gpus all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark`
![image](https://user-images.githubusercontent.com/73638271/135861058-9c361324-04b8-49e8-877d-f6acdbd8bca0.png)

And I also checked that no nvidia driver installed in my image: 
`docker exec -it containerID /bin/bash`
`apt list --installed`
shows there isn't any nvidia* or libnvidia* package, only have some cuda related packages (cuda-compat-10-2, cuda-cudart-10-2, cuda-license-10-2)

### 2. Information

#### nvidia-container information from `nvidia-container-cli -k -d /dev/tty info`
-- WARNING, the following logs are for debugging purposes only --

I1004 13:41:19.446777 13740 nvc.c:372] initializing library context (version=1.5.1, build=4afad130c4c253abd3b2db563ffe9331594bda41)
I1004 13:41:19.447100 13740 nvc.c:346] using root /
I1004 13:41:19.447125 13740 nvc.c:347] using ldcache /etc/ld.so.cache
I1004 13:41:19.447183 13740 nvc.c:348] using unprivileged user 1000:1000
I1004 13:41:19.447196 13740 nvc.c:389] attempting to load dxcore to see if we are running under Windows Subsystem for Linux (WSL)
I1004 13:41:19.465867 13740 dxcore.c:227] Creating a new WDDM Adapter for hAdapter:40000000 luid:f95e09
I1004 13:41:19.478468 13740 dxcore.c:268] Adding new adapter via dxcore hAdapter:40000000 luid:f95e09 wddm version:3000
I1004 13:41:19.478495 13740 dxcore.c:326] dxcore layer initialized successfully
W1004 13:41:19.478894 13740 nvc.c:397] skipping kernel modules load on WSL
I1004 13:41:19.479135 13741 driver.c:101] starting driver service
I1004 13:41:19.537408 13740 nvc_info.c:758] requesting driver information with ''
I1004 13:41:19.551091 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.460.91.03
I1004 13:41:19.552122 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-opticalflow.so.1
I1004 13:41:19.552152 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.460.91.03
I1004 13:41:19.553231 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-ml.so.1
I1004 13:41:19.553264 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.460.91.03
I1004 13:41:19.553295 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.460.91.03
I1004 13:41:19.554246 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvidia-encode.so.1
I1004 13:41:19.554278 13740 nvc_info.c:197] selecting /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.460.91.03
I1004 13:41:19.555174 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libnvcuvid.so.1
I1004 13:41:19.555259 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libdxcore.so
I1004 13:41:19.556208 13740 nvc_info.c:197] selecting /usr/lib/wsl/lib/libcuda.so.1
I1004 13:41:19.556240 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libcuda.so.460.91.03
I1004 13:41:19.556348 13740 nvc_info.c:199] skipping /usr/lib/x86_64-linux-gnu/libcuda.so.460.91.03
W1004 13:41:19.556404 13740 nvc_info.c:397] missing library libnvidia-cfg.so
W1004 13:41:19.556426 13740 nvc_info.c:397] missing library libnvidia-nscq.so
W1004 13:41:19.556429 13740 nvc_info.c:397] missing library libnvidia-fatbinaryloader.so
W1004 13:41:19.556431 13740 nvc_info.c:397] missing library libnvidia-allocator.so
W1004 13:41:19.556433 13740 nvc_info.c:397] missing library libnvidia-ngx.so
W1004 13:41:19.556434 13740 nvc_info.c:397] missing library libvdpau_nvidia.so
W1004 13:41:19.556453 13740 nvc_info.c:397] missing library libnvidia-eglcore.so
W1004 13:41:19.556456 13740 nvc_info.c:397] missing library libnvidia-glcore.so
W1004 13:41:19.556457 13740 nvc_info.c:397] missing library libnvidia-tls.so
W1004 13:41:19.556459 13740 nvc_info.c:397] missing library libnvidia-glsi.so
W1004 13:41:19.556460 13740 nvc_info.c:397] missing library libnvidia-fbc.so
W1004 13:41:19.556462 13740 nvc_info.c:397] missing library libnvidia-ifr.so
W1004 13:41:19.556500 13740 nvc_info.c:397] missing library libnvidia-rtcore.so
W1004 13:41:19.556506 13740 nvc_info.c:397] missing library libnvoptix.so
W1004 13:41:19.556512 13740 nvc_info.c:397] missing library libGLX_nvidia.so
W1004 13:41:19.556514 13740 nvc_info.c:397] missing library libEGL_nvidia.so
W1004 13:41:19.556521 13740 nvc_info.c:397] missing library libGLESv2_nvidia.so
W1004 13:41:19.556524 13740 nvc_info.c:397] missing library libGLESv1_CM_nvidia.so
W1004 13:41:19.556526 13740 nvc_info.c:397] missing library libnvidia-glvkspirv.so
W1004 13:41:19.556527 13740 nvc_info.c:397] missing library libnvidia-cbl.so
W1004 13:41:19.556547 13740 nvc_info.c:401] missing compat32 library libnvidia-ml.so
W1004 13:41:19.556555 13740 nvc_info.c:401] missing compat32 library libnvidia-cfg.so
W1004 13:41:19.556557 13740 nvc_info.c:401] missing compat32 library libnvidia-nscq.so
W1004 13:41:19.556562 13740 nvc_info.c:401] missing compat32 library libcuda.so
W1004 13:41:19.556564 13740 nvc_info.c:401] missing compat32 library libnvidia-opencl.so
W1004 13:41:19.556583 13740 nvc_info.c:401] missing compat32 library libnvidia-ptxjitcompiler.so
W1004 13:41:19.556586 13740 nvc_info.c:401] missing compat32 library libnvidia-fatbinaryloader.so
W1004 13:41:19.556587 13740 nvc_info.c:401] missing compat32 library libnvidia-allocator.so
W1004 13:41:19.556589 13740 nvc_info.c:401] missing compat32 library libnvidia-compiler.so
W1004 13:41:19.556625 13740 nvc_info.c:401] missing compat32 library libnvidia-ngx.so
W1004 13:41:19.556629 13740 nvc_info.c:401] missing compat32 library libvdpau_nvidia.so
W1004 13:41:19.556632 13740 nvc_info.c:401] missing compat32 library libnvidia-encode.so
W1004 13:41:19.556638 13740 nvc_info.c:401] missing compat32 library libnvidia-opticalflow.so
W1004 13:41:19.556640 13740 nvc_info.c:401] missing compat32 library libnvcuvid.so
W1004 13:41:19.556644 13740 nvc_info.c:401] missing compat32 library libnvidia-eglcore.so
W1004 13:41:19.556667 13740 nvc_info.c:401] missing compat32 library libnvidia-glcore.so
W1004 13:41:19.556670 13740 nvc_info.c:401] missing compat32 library libnvidia-tls.so
W1004 13:41:19.556676 13740 nvc_info.c:401] missing compat32 library libnvidia-glsi.so
W1004 13:41:19.556677 13740 nvc_info.c:401] missing compat32 library libnvidia-fbc.so
W1004 13:41:19.556679 13740 nvc_info.c:401] missing compat32 library libnvidia-ifr.so
W1004 13:41:19.556680 13740 nvc_info.c:401] missing compat32 library libnvidia-rtcore.so
W1004 13:41:19.556682 13740 nvc_info.c:401] missing compat32 library libnvoptix.so
W1004 13:41:19.556700 13740 nvc_info.c:401] missing compat32 library libGLX_nvidia.so
W1004 13:41:19.556703 13740 nvc_info.c:401] missing compat32 library libEGL_nvidia.so
W1004 13:41:19.556705 13740 nvc_info.c:401] missing compat32 library libGLESv2_nvidia.so
W1004 13:41:19.556740 13740 nvc_info.c:401] missing compat32 library libGLESv1_CM_nvidia.so
W1004 13:41:19.556745 13740 nvc_info.c:401] missing compat32 library libnvidia-glvkspirv.so
W1004 13:41:19.556746 13740 nvc_info.c:401] missing compat32 library libnvidia-cbl.so
W1004 13:41:19.556748 13740 nvc_info.c:401] missing compat32 library libdxcore.so
I1004 13:41:19.558106 13740 nvc_info.c:277] selecting /usr/lib/wsl/drivers/nv_dispi.inf_amd64_733101c735b9e264/nvidia-smi
W1004 13:41:19.884566 13740 nvc_info.c:423] missing binary nvidia-debugdump
W1004 13:41:19.884603 13740 nvc_info.c:423] missing binary nvidia-persistenced
W1004 13:41:19.884606 13740 nvc_info.c:423] missing binary nv-fabricmanager
W1004 13:41:19.884608 13740 nvc_info.c:423] missing binary nvidia-cuda-mps-control
W1004 13:41:19.884609 13740 nvc_info.c:423] missing binary nvidia-cuda-mps-server
I1004 13:41:19.884611 13740 nvc_info.c:437] skipping path lookup for dxcore
I1004 13:41:19.884617 13740 nvc_info.c:520] listing device /dev/dxg
W1004 13:41:19.884653 13740 nvc_info.c:347] missing ipc path /var/run/nvidia-persistenced/socket
W1004 13:41:19.884663 13740 nvc_info.c:347] missing ipc path /var/run/nvidia-fabricmanager/socket
W1004 13:41:19.884768 13740 nvc_info.c:347] missing ipc path /tmp/nvidia-mps
I1004 13:41:19.884791 13740 nvc_info.c:814] requesting device information with ''
I1004 13:41:19.896593 13740 nvc_info.c:686] listing dxcore adapter 0 (GPU-4949b172-957c-5479-5dc3-12e0ea688389 at 00000000:2d:00.0)
NVRM version:   510.06
CUDA version:   11.2

Device Index:   0
Device Minor:   0
Model:          NVIDIA GeForce RTX 2080 Ti
Brand:          GeForce
GPU UUID:       GPU-4949b172-957c-5479-5dc3-12e0ea688389
Bus Location:   00000000:2d:00.0
Architecture:   7.5
I1004 13:41:19.896655 13740 nvc.c:423] shutting down library context
I1004 13:41:19.897661 13741 driver.c:163] terminating driver service
I1004 13:41:19.898674 13740 driver.c:203] driver service terminated successfully

#### Kernel version from `uname -a`
Linux DESKTOP 5.10.16.3-microsoft-standard-WSL2 #1 SMP Fri Apr 2 22:23:49 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux

#### Any relevant kernel output lines from `dmesg`
[    0.000000] Linux version 5.10.16.3-microsoft-standard-WSL2 (oe-user@oe-host) (x86_64-msft-linux-gcc (GCC) 9.3.0, GNU ld (GNU Binutils) 2.34.0.20200220) #1 SMP Fri Apr 2 22:23:49 UTC 2021
[    0.000000] Command line: initrd=\initrd.img panic=-1 nr_cpus=16 swiotlb=force pty.legacy_count=0
[    0.000000] KERNEL supported cpus:
[    0.000000]   Intel GenuineIntel
[    0.000000]   AMD AuthenticAMD
[    0.000000]   Centaur CentaurHauls
[    0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'
[    0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'
[    0.000000] x86/fpu: xstate_offset[2]:  576, xstate_sizes[2]:  256
[    0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'compacted' format.
[    0.000000] BIOS-provided physical RAM map:
[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009ffff] usable
[    0.000000] BIOS-e820: [mem 0x00000000000e0000-0x00000000000e0fff] reserved
[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x00000000001fffff] ACPI data
[    0.000000] BIOS-e820: [mem 0x0000000000200000-0x00000000f7ffffff] usable
[    0.000000] BIOS-e820: [mem 0x0000000100000000-0x00000004057fffff] usable
[    0.000000] NX (Execute Disable) protection: active
[    0.000000] DMI not present or invalid.
[    0.000000] Hypervisor detected: Microsoft Hyper-V
[    0.000000] Hyper-V: features 0xae7f, privilege high: 0x3b8030, hints 0xc2c, misc 0xe0bed7b2
[    0.000000] Hyper-V Host Build:22000-10.0-0-0.194
[    0.000000] Hyper-V: LAPIC Timer Frequency: 0x1e8480
[    0.000000] Hyper-V: Using hypercall for remote TLB flush
[    0.000000] clocksource: hyperv_clocksource_tsc_page: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[    0.000001] tsc: Detected 3899.997 MHz processor
[    0.000007] e820: update [mem 0x00000000-0x00000fff] usable ==> reserved
[    0.000008] e820: remove [mem 0x000a0000-0x000fffff] usable
[    0.000010] last_pfn = 0x405800 max_arch_pfn = 0x400000000
[    0.000033] MTRR default type: uncachable
[    0.000033] MTRR fixed ranges enabled:
[    0.000034]   00000-3FFFF write-back
[    0.000034]   40000-7FFFF uncachable
[    0.000035]   80000-8FFFF write-back
[    0.000035]   90000-FFFFF uncachable
[    0.000035] MTRR variable ranges enabled:
[    0.000036]   0 base 000000000000 mask FFFF00000000 write-back
[    0.000037]   1 base 000100000000 mask FFF000000000 write-back
[    0.000037]   2 disabled
[    0.000037]   3 disabled
[    0.000038]   4 disabled
[    0.000038]   5 disabled
[    0.000038]   6 disabled
[    0.000038]   7 disabled
[    0.000047] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT
[    0.000059] last_pfn = 0xf8000 max_arch_pfn = 0x400000000
[    0.000071] Using GB pages for direct mapping
[    0.000322] RAMDISK: [mem 0x03035000-0x03043fff]
[    0.000326] ACPI: Early table checksum verification disabled
[    0.000332] ACPI: RSDP 0x00000000000E0000 000024 (v02 VRTUAL)
[    0.000334] ACPI: XSDT 0x0000000000100000 000044 (v01 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000338] ACPI: FACP 0x0000000000101000 000114 (v06 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000341] ACPI: DSDT 0x00000000001011B8 01E184 (v02 MSFTVM DSDT01   00000001 MSFT 05000000)
[    0.000343] ACPI: FACS 0x0000000000101114 000040
[    0.000344] ACPI: OEM0 0x0000000000101154 000064 (v01 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000346] ACPI: SRAT 0x000000000011F33C 0003B0 (v02 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000347] ACPI: APIC 0x000000000011F6EC 0000C8 (v04 VRTUAL MICROSFT 00000001 MSFT 00000001)
[    0.000351] ACPI: Local APIC address 0xfee00000
[    0.000516] Zone ranges:
[    0.000517]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
[    0.000518]   DMA32    [mem 0x0000000001000000-0x00000000ffffffff]
[    0.000519]   Normal   [mem 0x0000000100000000-0x00000004057fffff]
[    0.000519]   Device   empty
[    0.000520] Movable zone start for each node
[    0.000520] Early memory node ranges
[    0.000521]   node   0: [mem 0x0000000000001000-0x000000000009ffff]
[    0.000522]   node   0: [mem 0x0000000000200000-0x00000000f7ffffff]
[    0.000522]   node   0: [mem 0x0000000100000000-0x00000004057fffff]
[    0.000857] Zeroed struct page in unavailable ranges: 10593 pages
[    0.000859] Initmem setup node 0 [mem 0x0000000000001000-0x00000004057fffff]
[    0.000860] On node 0 totalpages: 4183711
[    0.000861]   DMA zone: 59 pages used for memmap
[    0.000862]   DMA zone: 22 pages reserved
[    0.000862]   DMA zone: 3743 pages, LIFO batch:0
[    0.000884]   DMA32 zone: 16320 pages used for memmap
[    0.000884]   DMA32 zone: 1011712 pages, LIFO batch:63
[    0.010695]   Normal zone: 49504 pages used for memmap
[    0.010698]   Normal zone: 3168256 pages, LIFO batch:63
[    0.011050] ACPI: Local APIC address 0xfee00000
[    0.011055] ACPI: LAPIC_NMI (acpi_id[0x01] dfl dfl lint[0x1])
[    0.011340] IOAPIC[0]: apic_id 16, version 17, address 0xfec00000, GSI 0-23
[    0.011344] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
[    0.011345] ACPI: IRQ9 used by override.
[    0.011346] Using ACPI (MADT) for SMP configuration information
[    0.011353] smpboot: Allowing 16 CPUs, 0 hotplug CPUs
[    0.011362] [mem 0xf8000000-0xffffffff] available for PCI devices
[    0.011363] Booting paravirtualized kernel on Hyper-V
[    0.011365] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.015482] setup_percpu: NR_CPUS:256 nr_cpumask_bits:256 nr_cpu_ids:16 nr_node_ids:1
[    0.016192] percpu: Embedded 52 pages/cpu s173272 r8192 d31528 u262144
[    0.016196] pcpu-alloc: s173272 r8192 d31528 u262144 alloc=1*2097152
[    0.016197] pcpu-alloc: [0] 00 01 02 03 04 05 06 07 [0] 08 09 10 11 12 13 14 15
[    0.016212] Built 1 zonelists, mobility grouping on.  Total pages: 4117806
[    0.016214] Kernel command line: initrd=\initrd.img panic=-1 nr_cpus=16 swiotlb=force pty.legacy_count=0
[    0.018810] Dentry cache hash table entries: 2097152 (order: 12, 16777216 bytes, linear)
[    0.019993] Inode-cache hash table entries: 1048576 (order: 11, 8388608 bytes, linear)
[    0.020038] mem auto-init: stack:off, heap alloc:off, heap free:off
[    0.036796] Memory: 4094128K/16734844K available (16403K kernel code, 2459K rwdata, 3464K rodata, 1444K init, 1164K bss, 388996K reserved, 0K cma-reserved)
[    0.036832] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=16, Nodes=1
[    0.036840] ftrace: allocating 49613 entries in 194 pages
[    0.048726] ftrace: allocated 194 pages with 3 groups
[    0.048929] rcu: Hierarchical RCU implementation.
[    0.048930] rcu:     RCU restricting CPUs from NR_CPUS=256 to nr_cpu_ids=16.
[    0.048931]  Rude variant of Tasks RCU enabled.
[    0.048931]  Tracing variant of Tasks RCU enabled.
[    0.048931] rcu: RCU calculated value of scheduler-enlistment delay is 10 jiffies.
[    0.048932] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=16
[    0.051184] Using NULL legacy PIC
[    0.051186] NR_IRQS: 16640, nr_irqs: 552, preallocated irqs: 0
[    0.051565] random: crng done (trusting CPU's manufacturer)
[    0.051585] Console: colour dummy device 80x25
[    0.051591] printk: console [tty0] enabled
[    0.051595] ACPI: Core revision 20200925
[    0.051693] Failed to register legacy timer interrupt
[    0.051694] APIC: Switch to symmetric I/O mode setup
[    0.051695] Switched APIC routing to physical flat.
[    0.051850] Hyper-V: Using IPI hypercalls
[    0.051851] Hyper-V: Using enlightened APIC (xapic mode)
[    0.051922] clocksource: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x706eb0792cc, max_idle_ns: 881591209130 ns
[    0.051925] Calibrating delay loop (skipped), value calculated using timer frequency.. 7799.99 BogoMIPS (lpj=38999970)
[    0.051926] pid_max: default: 32768 minimum: 301
[    0.051936] LSM: Security Framework initializing
[    0.051958] Mount-cache hash table entries: 32768 (order: 6, 262144 bytes, linear)
[    0.051977] Mountpoint-cache hash table entries: 32768 (order: 6, 262144 bytes, linear)
[    0.052150] x86/cpu: User Mode Instruction Prevention (UMIP) activated
[    0.052167] Last level iTLB entries: 4KB 1024, 2MB 1024, 4MB 512
[    0.052168] Last level dTLB entries: 4KB 2048, 2MB 2048, 4MB 1024, 1GB 0
[    0.052170] Spectre V1 : Mitigation: usercopy/swapgs barriers and __user pointer sanitization
[    0.052170] Spectre V2 : Mitigation: Full AMD retpoline
[    0.052171] Spectre V2 : Spectre v2 / SpectreRSB mitigation: Filling RSB on context switch
[    0.052172] Spectre V2 : mitigation: Enabling conditional Indirect Branch Prediction Barrier
[    0.052172] Spectre V2 : User space: Mitigation: STIBP via seccomp and prctl
[    0.052173] Speculative Store Bypass: Mitigation: Speculative Store Bypass disabled via prctl and seccomp
[    0.052292] Freeing SMP alternatives memory: 52K
[    0.052344] smpboot: CPU0: AMD Ryzen 7 3800X 8-Core Processor (family: 0x17, model: 0x71, stepping: 0x0)
[    0.052403] Performance Events: PMU not available due to virtualization, using software events only.
[    0.052423] rcu: Hierarchical SRCU implementation.
[    0.052753] smp: Bringing up secondary CPUs ...
[    0.052800] x86: Booting SMP configuration:
[    0.052801] .... node  #0, CPUs:        #1  #2  #3  #4  #5  #6  #7  #8  #9 #10 #11 #12 #13 #14 #15
[    0.053300] smp: Brought up 1 node, 16 CPUs
[    0.053300] smpboot: Max logical packages: 1
[    0.053300] smpboot: Total of 16 processors activated (124799.90 BogoMIPS)
[    0.073395] node 0 deferred pages initialised in 10ms
[    0.075402] devtmpfs: initialized
[    0.075402] x86/mm: Memory block size: 128MB
[    0.075402] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604462750000 ns
[    0.075402] futex hash table entries: 4096 (order: 6, 262144 bytes, linear)
[    0.075402] NET: Registered protocol family 16
[    0.075402] thermal_sys: Registered thermal governor 'step_wise'
[    0.075402] cpuidle: using governor menu
[    0.075402] ACPI: bus type PCI registered
[    0.075402] PCI: Fatal: No config space access function found
[    0.075402] HugeTLB registered 1.00 GiB page size, pre-allocated 0 pages
[    0.075402] HugeTLB registered 2.00 MiB page size, pre-allocated 0 pages
[    0.082164] raid6: skip pq benchmark and using algorithm avx2x4
[    0.082164] raid6: using avx2x2 recovery algorithm
[    0.082164] ACPI: Added _OSI(Module Device)
[    0.082164] ACPI: Added _OSI(Processor Device)
[    0.082164] ACPI: Added _OSI(3.0 _SCP Extensions)
[    0.082164] ACPI: Added _OSI(Processor Aggregator Device)
[    0.082164] ACPI: Added _OSI(Linux-Dell-Video)
[    0.082164] ACPI: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)
[    0.082164] ACPI: Added _OSI(Linux-HPI-Hybrid-Graphics)
[    0.085313] ACPI: 1 ACPI AML tables successfully acquired and loaded
[    0.086035] ACPI: Interpreter enabled
[    0.086038] ACPI: (supports S0 S5)
[    0.086039] ACPI: Using IOAPIC for interrupt routing
[    0.086046] PCI: Using host bridge windows from ACPI; if necessary, use ""pci=nocrs"" and report a bug
[    0.086138] ACPI: Enabled 1 GPEs in block 00 to 0F
[    0.086794] iommu: Default domain type: Translated
[    0.086851] SCSI subsystem initialized
[    0.086881] hv_vmbus: Vmbus version:5.2
[    0.086881] PCI: Using ACPI for IRQ routing
[    0.086881] PCI: System does not support PCI
[    0.086881] hv_vmbus: Unknown GUID: c376c1c3-d276-48d2-90a9-c04748072c60
[    0.086881] hv_vmbus: Unknown GUID: 6e382d18-3336-4f4b-acc4-2b7703d4df4a
[    0.086881] clocksource: Switched to clocksource tsc-early
[    0.086881] hv_vmbus: Unknown GUID: dde9cbc0-5060-4436-9448-ea1254a5d177
[    0.170448] VFS: Disk quotas dquot_6.6.0
[    0.170458] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)
[    0.170473] FS-Cache: Loaded
[    0.170496] pnp: PnP ACPI init
[    0.170537] pnp 00:00: Plug and Play ACPI device, IDs PNP0b00 (active)
[    0.170571] pnp: PnP ACPI: found 1 devices
[    0.174903] NET: Registered protocol family 2
[    0.175138] tcp_listen_portaddr_hash hash table entries: 8192 (order: 5, 131072 bytes, linear)
[    0.175316] TCP established hash table entries: 131072 (order: 8, 1048576 bytes, linear)
[    0.175416] TCP bind hash table entries: 65536 (order: 8, 1048576 bytes, linear)
[    0.175625] TCP: Hash tables configured (established 131072 bind 65536)
[    0.175649] UDP hash table entries: 8192 (order: 6, 262144 bytes, linear)
[    0.175671] UDP-Lite hash table entries: 8192 (order: 6, 262144 bytes, linear)
[    0.175712] NET: Registered protocol family 1
[    0.176005] RPC: Registered named UNIX socket transport module.
[    0.176006] RPC: Registered udp transport module.
[    0.176007] RPC: Registered tcp transport module.
[    0.176007] RPC: Registered tcp NFSv4.1 backchannel transport module.
[    0.176009] PCI: CLS 0 bytes, default 64
[    0.176049] Trying to unpack rootfs image as initramfs...
[    0.176181] Freeing initrd memory: 60K
[    0.176183] PCI-DMA: Using software bounce buffering for IO (SWIOTLB)
[    0.176185] software IO TLB: mapped [mem 0x00000000f4000000-0x00000000f8000000] (64MB)
[    0.177614] kvm: no hardware support
[    0.178295] kvm: Nested Virtualization enabled
[    0.178301] SVM: kvm: Nested Paging enabled
[    0.178301] SVM: Virtual VMLOAD VMSAVE supported
[    0.181019] Initialise system trusted keyrings
[    0.181118] workingset: timestamp_bits=46 max_order=22 bucket_order=0
[    0.181643] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    0.182012] NFS: Registering the id_resolver key type
[    0.182019] Key type id_resolver registered
[    0.182019] Key type id_legacy registered
[    0.182021] Installing knfsd (copyright (C) 1996 okir@monad.swb.de).
[    0.182442] Key type cifs.idmap registered
[    0.182496] fuse: init (API version 7.32)
[    0.182618] SGI XFS with ACLs, security attributes, realtime, scrub, repair, quota, no debug enabled
[    0.182874] 9p: Installing v9fs 9p2000 file system support
[    0.182880] FS-Cache: Netfs '9p' registered for caching
[    0.182908] FS-Cache: Netfs 'ceph' registered for caching
[    0.182910] ceph: loaded (mds proto 32)
[    0.185420] NET: Registered protocol family 38
[    0.185422] xor: automatically using best checksumming function   avx
[    0.185423] Key type asymmetric registered
[    0.185424] Asymmetric key parser 'x509' registered
[    0.185429] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 250)
[    0.186121] hv_vmbus: registering driver hv_pci
[    0.186439] hv_pci b85a1f33-3b6d-4a2b-982d-0ce62be71656: PCI VMBus probing: Using version 0x10003
[    0.187115] hv_pci b85a1f33-3b6d-4a2b-982d-0ce62be71656: PCI host bridge to bus 3b6d:00
[    0.187471] pci 3b6d:00:00.0: [1414:008e] type 00 class 0x030200
[    0.191995] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled
[    0.192317] Non-volatile memory driver v1.3
[    0.194890] brd: module loaded
[    0.195604] loop: module loaded
[    0.195630] hv_vmbus: registering driver hv_storvsc
[    0.195949] wireguard: WireGuard 1.0.0 loaded. See www.wireguard.com for information.
[    0.195950] wireguard: Copyright (C) 2015-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.
[    0.195962] tun: Universal TUN/TAP device driver, 1.6
[    0.196041] PPP generic driver version 2.4.2
[    0.196142] PPP BSD Compression module registered
[    0.196143] PPP Deflate Compression module registered
[    0.196144] PPP MPPE Compression module registered
[    0.196145] NET: Registered protocol family 24
[    0.196149] hv_vmbus: registering driver hv_netvsc
[    0.196242] VFIO - User Level meta-driver version: 0.3
[    0.196361] hv_vmbus: registering driver hyperv_keyboard
[    0.196496] rtc_cmos 00:00: RTC can wake from S4
[    0.196809] scsi host0: storvsc_host_t
[    0.197753] rtc_cmos 00:00: registered as rtc0
[    0.198038] rtc_cmos 00:00: setting system clock to 2021-10-03T15:03:26 UTC (1633273406)
[    0.198046] rtc_cmos 00:00: alarms up to one month, 114 bytes nvram
[    0.198221] device-mapper: ioctl: 4.43.0-ioctl (2020-10-01) initialised: dm-devel@redhat.com
[    0.198335] device-mapper: raid: Loading target version 1.15.1
[    0.198404] hv_utils: Registering HyperV Utility Driver
[    0.198405] hv_vmbus: registering driver hv_utils
[    0.198429] hv_vmbus: registering driver hv_balloon
[    0.198437] hv_vmbus: registering driver dxgkrnl
[    0.198452] (NULL device *): dxgk: dxg_drv_init  Version: 2103
[    0.198453] hv_utils: cannot register PTP clock: 0
[    0.198736] hv_balloon: Using Dynamic Memory protocol version 2.0
[    0.198827] hv_utils: TimeSync IC version 4.0
[    0.199020] drop_monitor: Initializing network drop monitor service
[    0.199043] Mirror/redirect action on
[    0.199390] Free page reporting enabled
[    0.199392] hv_balloon: Cold memory discard hint enabled
[    0.199630] (NULL device *): dxgk: mmio allocated 9ffe00000  200000000 9ffe00000 bffdfffff
[    0.199802] IPVS: Registered protocols (TCP, UDP)
[    0.199813] IPVS: Connection hash table configured (size=4096, memory=64Kbytes)
[    0.199835] IPVS: ipvs loaded.
[    0.199836] IPVS: [rr] scheduler registered.
[    0.199836] IPVS: [wrr] scheduler registered.
[    0.199836] IPVS: [sh] scheduler registered.
[    0.199864] ipip: IPv4 and MPLS over IPv4 tunneling driver
[    0.201991] ipt_CLUSTERIP: ClusterIP Version 0.8 loaded successfully
[    0.202382] Initializing XFRM netlink socket
[    0.202426] NET: Registered protocol family 10
[    0.202648] Segment Routing with IPv6
[    0.203692] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver
[    0.203777] NET: Registered protocol family 17
[    0.203790] Bridge firewalling registered
[    0.203796] 8021q: 802.1Q VLAN Support v1.8
[    0.203808] sctp: Hash tables configured (bind 256/256)
[    0.203842] 9pnet: Installing 9P2000 support
[    0.203855] Key type dns_resolver registered
[    0.203863] Key type ceph registered
[    0.203976] libceph: loaded (mon/osd proto 15/24)
[    0.204044] NET: Registered protocol family 40
[    0.204045] hv_vmbus: registering driver hv_sock
[    0.204071] IPI shorthand broadcast: enabled
[    0.204077] sched_clock: Marking stable (203581151, 453300)->(215942200, -11907749)
[    0.204331] registered taskstats version 1
[    0.204338] Loading compiled-in X.509 certificates
[    0.204648] Btrfs loaded, crc32c=crc32c-generic
[    0.206255] Freeing unused kernel image (initmem) memory: 1444K
[    0.271961] Write protecting the kernel read-only data: 22528k
[    0.272551] Freeing unused kernel image (text/rodata gap) memory: 2028K
[    0.273043] Freeing unused kernel image (rodata/data gap) memory: 632K
[    0.273048] Run /init as init process
[    0.273048]   with arguments:
[    0.273048]     /init
[    0.273049]   with environment:
[    0.273049]     HOME=/
[    0.273049]     TERM=linux
[    0.829032] scsi 0:0:0:0: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[    0.829421] sd 0:0:0:0: Attached scsi generic sg0 type 0
[    0.830236] sd 0:0:0:0: [sda] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[    0.830238] sd 0:0:0:0: [sda] 4096-byte physical blocks
[    0.830362] sd 0:0:0:0: [sda] Write Protect is off
[    0.830364] sd 0:0:0:0: [sda] Mode Sense: 0f 00 00 00
[    0.830557] sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    0.874243] hv_pci bb4321df-980a-4d21-afdb-589c18527bf9: PCI VMBus probing: Using version 0x10003
[    0.915773] hv_pci bb4321df-980a-4d21-afdb-589c18527bf9: PCI host bridge to bus 980a:00
[    0.915775] pci_bus 980a:00: root bus resource [mem 0xbffe00000-0xbffe02fff window]
[    0.916751] pci 980a:00:00.0: [1af4:1049] type 00 class 0x010000
[    0.917716] pci 980a:00:00.0: reg 0x10: [mem 0xbffe00000-0xbffe00fff 64bit]
[    0.918396] pci 980a:00:00.0: reg 0x18: [mem 0xbffe01000-0xbffe01fff 64bit]
[    0.919017] pci 980a:00:00.0: reg 0x20: [mem 0xbffe02000-0xbffe02fff 64bit]
[    0.922797] pci 980a:00:00.0: BAR 0: assigned [mem 0xbffe00000-0xbffe00fff 64bit]
[    0.923220] pci 980a:00:00.0: BAR 2: assigned [mem 0xbffe01000-0xbffe01fff 64bit]
[    0.923644] pci 980a:00:00.0: BAR 4: assigned [mem 0xbffe02000-0xbffe02fff 64bit]
[    1.116874] EXT4-fs (sda): mounted filesystem with ordered data mode. Opts: (null)
[    1.202006] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready
[    1.202180] sd 0:0:0:0: [sda] Attached SCSI disk
[    1.251980] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x706eb0792cc, max_idle_ns: 881591209130 ns
[    1.252943] clocksource: Switched to clocksource tsc
[    1.881960] Adding 4194304k swap on /swap/file.  Priority:-2 extents:3 across:4210688k
[    3.152119] scsi 0:0:0:1: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[    3.152455] sd 0:0:0:1: Attached scsi generic sg1 type 0
[    3.152998] sd 0:0:0:1: [sdb] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[    3.152999] sd 0:0:0:1: [sdb] 4096-byte physical blocks
[    3.153082] sd 0:0:0:1: [sdb] Write Protect is off
[    3.153083] sd 0:0:0:1: [sdb] Mode Sense: 0f 00 00 00
[    3.153213] sd 0:0:0:1: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    3.154369] sd 0:0:0:1: [sdb] Attached SCSI disk
[    3.160357] EXT4-fs (sdb): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[    3.215983] FS-Cache: Duplicate cookie detected
[    3.215986] FS-Cache: O-cookie c=00000000aa466783 [p=000000006f69fc41 fl=222 nc=0 na=1]
[    3.215987] FS-Cache: O-cookie d=0000000077b88f2e n=00000000cab53c7d
[    3.215987] FS-Cache: O-key=[10] '34323934393337363132'
[    3.215991] FS-Cache: N-cookie c=0000000061e3e253 [p=000000006f69fc41 fl=2 nc=0 na=1]
[    3.215991] FS-Cache: N-cookie d=0000000077b88f2e n=00000000485d5ccb
[    3.215992] FS-Cache: N-key=[10] '34323934393337363132'
[    3.285697] hv_pci d5ce7240-e76a-439c-ad60-bb77c783e7c5: PCI VMBus probing: Using version 0x10003
[    3.286638] 9pnet_virtio: no channels available for device drvfs
[    3.286641] WARNING: mount: waiting for virtio device...
[    3.325716] hv_pci d5ce7240-e76a-439c-ad60-bb77c783e7c5: PCI host bridge to bus e76a:00
[    3.325718] pci_bus e76a:00: root bus resource [mem 0xbffe04000-0xbffe06fff window]
[    3.326672] pci e76a:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.327614] pci e76a:00:00.0: reg 0x10: [mem 0xbffe04000-0xbffe04fff 64bit]
[    3.328222] pci e76a:00:00.0: reg 0x18: [mem 0xbffe05000-0xbffe05fff 64bit]
[    3.328821] pci e76a:00:00.0: reg 0x20: [mem 0xbffe06000-0xbffe06fff 64bit]
[    3.332517] pci e76a:00:00.0: BAR 0: assigned [mem 0xbffe04000-0xbffe04fff 64bit]
[    3.333024] pci e76a:00:00.0: BAR 2: assigned [mem 0xbffe05000-0xbffe05fff 64bit]
[    3.333449] pci e76a:00:00.0: BAR 4: assigned [mem 0xbffe06000-0xbffe06fff 64bit]
[    3.390415] hv_pci 3f8e3335-82c2-499f-8995-e1c33b9178df: PCI VMBus probing: Using version 0x10003
[    3.391719] 9pnet_virtio: no channels available for device drvfs
[    3.391721] WARNING: mount: waiting for virtio device...
[    3.430257] hv_pci 3f8e3335-82c2-499f-8995-e1c33b9178df: PCI host bridge to bus 82c2:00
[    3.430259] pci_bus 82c2:00: root bus resource [mem 0xbffe08000-0xbffe0afff window]
[    3.431241] pci 82c2:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.432187] pci 82c2:00:00.0: reg 0x10: [mem 0xbffe08000-0xbffe08fff 64bit]
[    3.432796] pci 82c2:00:00.0: reg 0x18: [mem 0xbffe09000-0xbffe09fff 64bit]
[    3.433396] pci 82c2:00:00.0: reg 0x20: [mem 0xbffe0a000-0xbffe0afff 64bit]
[    3.437087] pci 82c2:00:00.0: BAR 0: assigned [mem 0xbffe08000-0xbffe08fff 64bit]
[    3.437505] pci 82c2:00:00.0: BAR 2: assigned [mem 0xbffe09000-0xbffe09fff 64bit]
[    3.437940] pci 82c2:00:00.0: BAR 4: assigned [mem 0xbffe0a000-0xbffe0afff 64bit]
[    3.495623] hv_pci 1b1a11d5-ded9-4bdc-b728-16a6ce447102: PCI VMBus probing: Using version 0x10003
[    3.536074] hv_pci 1b1a11d5-ded9-4bdc-b728-16a6ce447102: PCI host bridge to bus ded9:00
[    3.536076] pci_bus ded9:00: root bus resource [mem 0xbffe0c000-0xbffe0efff window]
[    3.537089] pci ded9:00:00.0: [1af4:1049] type 00 class 0x010000
[    3.537996] pci ded9:00:00.0: reg 0x10: [mem 0xbffe0c000-0xbffe0cfff 64bit]
[    3.538600] pci ded9:00:00.0: reg 0x18: [mem 0xbffe0d000-0xbffe0dfff 64bit]
[    3.539322] pci ded9:00:00.0: reg 0x20: [mem 0xbffe0e000-0xbffe0efff 64bit]
[    3.543300] pci ded9:00:00.0: BAR 0: assigned [mem 0xbffe0c000-0xbffe0cfff 64bit]
[    3.543740] pci ded9:00:00.0: BAR 2: assigned [mem 0xbffe0d000-0xbffe0dfff 64bit]
[    3.544177] pci ded9:00:00.0: BAR 4: assigned [mem 0xbffe0e000-0xbffe0efff 64bit]
[   49.061594] hv_balloon: Max. dynamic memory size: 16344 MB
[   71.292198] TCP: eth0: Driver has suspect GRO implementation, TCP performance may be compromised.
[ 8678.849099] docker0: port 1(veth07ad0a7) entered blocking state
[ 8678.849101] docker0: port 1(veth07ad0a7) entered disabled state
[ 8678.849121] device veth07ad0a7 entered promiscuous mode
[ 8678.849150] docker0: port 1(veth07ad0a7) entered blocking state
[ 8678.849151] docker0: port 1(veth07ad0a7) entered forwarding state
[ 8678.849472] docker0: port 1(veth07ad0a7) entered disabled state
[ 8678.990265] cgroup: runc (5415) created nested cgroup for controller ""memory"" which has incomplete hierarchy support. Nested cgroups may change behavior in the future.
[ 8678.990266] cgroup: ""memory"" requires setting use_hierarchy to 1 on the root
[ 8678.990549] cgroup: cgroup: disabling cgroup2 socket matching due to net_prio or net_cls activation
[ 8679.419693] eth0: renamed from veth984197c
[ 8679.459677] IPv6: ADDRCONF(NETDEV_CHANGE): veth07ad0a7: link becomes ready
[ 8679.459697] docker0: port 1(veth07ad0a7) entered blocking state
[ 8679.459697] docker0: port 1(veth07ad0a7) entered forwarding state
[ 8679.459722] IPv6: ADDRCONF(NETDEV_CHANGE): docker0: link becomes ready
[ 8680.288430] veth984197c: renamed from eth0
[ 8680.349650] docker0: port 1(veth07ad0a7) entered disabled state
[ 8680.445249] docker0: port 1(veth07ad0a7) entered disabled state
[ 8680.445930] device veth07ad0a7 left promiscuous mode
[ 8680.445948] docker0: port 1(veth07ad0a7) entered disabled state
[ 8871.582213] docker0: port 1(veth2124c65) entered blocking state
[ 8871.582215] docker0: port 1(veth2124c65) entered disabled state
[ 8871.582233] device veth2124c65 entered promiscuous mode
[ 8872.129587] eth0: renamed from veth99f60f2
[ 8872.189745] IPv6: ADDRCONF(NETDEV_CHANGE): veth2124c65: link becomes ready
[ 8872.189767] docker0: port 1(veth2124c65) entered blocking state
[ 8872.189768] docker0: port 1(veth2124c65) entered forwarding state
[ 9039.653247] process 'local/cuda-10.2/bin/ptxas' started with executable stack
[ 9387.169252] docker0: port 2(veth0ab1b19) entered blocking state
[ 9387.169254] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.169274] device veth0ab1b19 entered promiscuous mode
[ 9387.169302] docker0: port 2(veth0ab1b19) entered blocking state
[ 9387.169302] docker0: port 2(veth0ab1b19) entered forwarding state
[ 9387.169669] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.657707] docker0: port 2(veth0ab1b19) entered disabled state
[ 9387.657920] device veth0ab1b19 left promiscuous mode
[ 9387.657937] docker0: port 2(veth0ab1b19) entered disabled state
[ 9417.075476] nf_conntrack: default automatic helper assignment has been turned off for security reasons and CT-based  firewall rule not found. Use the iptables CT target to attach helpers instead.
[40931.406310] docker0: port 2(veth8968728) entered blocking state
[40931.406311] docker0: port 2(veth8968728) entered disabled state
[40931.406330] device veth8968728 entered promiscuous mode
[40931.780035] eth0: renamed from veth8b0ae09
[40931.840207] IPv6: ADDRCONF(NETDEV_CHANGE): veth8968728: link becomes ready
[40931.840231] docker0: port 2(veth8968728) entered blocking state
[40931.840232] docker0: port 2(veth8968728) entered forwarding state
[41888.847459] docker0: port 1(veth2124c65) entered disabled state
[41888.847547] veth99f60f2: renamed from eth0
[41888.994901] docker0: port 1(veth2124c65) entered disabled state
[41888.995012] device veth2124c65 left promiscuous mode
[41888.995014] docker0: port 1(veth2124c65) entered disabled state
[41899.075265] docker0: port 2(veth8968728) entered disabled state
[41899.075320] veth8b0ae09: renamed from eth0
[41899.195126] docker0: port 2(veth8968728) entered disabled state
[41899.195201] device veth8968728 left promiscuous mode
[41899.195202] docker0: port 2(veth8968728) entered disabled state
[44983.095711] docker0: port 1(veth579ec1c) entered blocking state
[44983.095713] docker0: port 1(veth579ec1c) entered disabled state
[44983.095767] device veth579ec1c entered promiscuous mode
[44983.095802] docker0: port 1(veth579ec1c) entered blocking state
[44983.095803] docker0: port 1(veth579ec1c) entered forwarding state
[44983.096169] docker0: port 1(veth579ec1c) entered disabled state
[44983.558932] eth0: renamed from vethe31675b
[44983.609007] IPv6: ADDRCONF(NETDEV_CHANGE): veth579ec1c: link becomes ready
[44983.609031] docker0: port 1(veth579ec1c) entered blocking state
[44983.609032] docker0: port 1(veth579ec1c) entered forwarding state
[48140.938717] docker0: port 2(vethe31a522) entered blocking state
[48140.938720] docker0: port 2(vethe31a522) entered disabled state
[48140.938783] device vethe31a522 entered promiscuous mode
[48140.938815] docker0: port 2(vethe31a522) entered blocking state
[48140.938815] docker0: port 2(vethe31a522) entered forwarding state
[48140.939141] docker0: port 2(vethe31a522) entered disabled state
[48140.953626] docker0: port 2(vethe31a522) entered disabled state
[48140.953890] device vethe31a522 left promiscuous mode
[48140.953910] docker0: port 2(vethe31a522) entered disabled state
[48163.430815] docker0: port 2(veth0cd2f65) entered blocking state
[48163.430817] docker0: port 2(veth0cd2f65) entered disabled state
[48163.430836] device veth0cd2f65 entered promiscuous mode
[48164.076307] docker0: port 2(veth0cd2f65) entered disabled state
[48164.076630] device veth0cd2f65 left promiscuous mode
[48164.076652] docker0: port 2(veth0cd2f65) entered disabled state
[48359.265419] docker0: port 2(veth87ce69e) entered blocking state
[48359.265420] docker0: port 2(veth87ce69e) entered disabled state
[48359.265439] device veth87ce69e entered promiscuous mode
[48359.265464] docker0: port 2(veth87ce69e) entered blocking state
[48359.265465] docker0: port 2(veth87ce69e) entered forwarding state
[48359.265939] docker0: port 2(veth87ce69e) entered disabled state
[48359.975849] docker0: port 2(veth87ce69e) entered disabled state
[48359.975930] device veth87ce69e left promiscuous mode
[48359.975932] docker0: port 2(veth87ce69e) entered disabled state
[63661.051609] docker0: port 2(veth2a489c7) entered blocking state
[63661.051611] docker0: port 2(veth2a489c7) entered disabled state
[63661.051692] device veth2a489c7 entered promiscuous mode
[63661.051745] docker0: port 2(veth2a489c7) entered blocking state
[63661.051747] docker0: port 2(veth2a489c7) entered forwarding state
[63661.052438] docker0: port 2(veth2a489c7) entered disabled state
[63661.065926] docker0: port 2(veth2a489c7) entered disabled state
[63661.065991] device veth2a489c7 left promiscuous mode
[63661.065992] docker0: port 2(veth2a489c7) entered disabled state
[63687.006899] docker0: port 2(veth2cbdb00) entered blocking state
[63687.006901] docker0: port 2(veth2cbdb00) entered disabled state
[63687.006921] device veth2cbdb00 entered promiscuous mode
[63687.533240] eth0: renamed from veth869fda5
[63687.613534] IPv6: ADDRCONF(NETDEV_CHANGE): veth2cbdb00: link becomes ready
[63687.613555] docker0: port 2(veth2cbdb00) entered blocking state
[63687.613556] docker0: port 2(veth2cbdb00) entered forwarding state
[63741.561335] docker0: port 3(veth4e13cbd) entered blocking state
[63741.561337] docker0: port 3(veth4e13cbd) entered disabled state
[63741.561359] device veth4e13cbd entered promiscuous mode
[63741.561385] docker0: port 3(veth4e13cbd) entered blocking state
[63741.561386] docker0: port 3(veth4e13cbd) entered forwarding state
[63741.561689] docker0: port 3(veth4e13cbd) entered disabled state
[63742.201594] docker0: port 3(veth4e13cbd) entered disabled state
[63742.201696] device veth4e13cbd left promiscuous mode
[63742.201697] docker0: port 3(veth4e13cbd) entered disabled state
[63945.395071] docker0: port 3(veth5172a71) entered blocking state
[63945.395073] docker0: port 3(veth5172a71) entered disabled state
[63945.395096] device veth5172a71 entered promiscuous mode
[63945.395127] docker0: port 3(veth5172a71) entered blocking state
[63945.395127] docker0: port 3(veth5172a71) entered forwarding state
[63945.395248] docker0: port 3(veth5172a71) entered disabled state
[63946.001462] docker0: port 3(veth5172a71) entered disabled state
[63946.001557] device veth5172a71 left promiscuous mode
[63946.001558] docker0: port 3(veth5172a71) entered disabled state
[63986.856749] docker0: port 2(veth2cbdb00) entered disabled state
[63986.856794] veth869fda5: renamed from eth0
[63986.998482] docker0: port 2(veth2cbdb00) entered disabled state
[63986.999130] device veth2cbdb00 left promiscuous mode
[63986.999133] docker0: port 2(veth2cbdb00) entered disabled state
[63987.085545] vethe31675b: renamed from eth0
[63987.213378] docker0: port 1(veth579ec1c) entered disabled state
[63987.218358] docker0: port 1(veth579ec1c) entered disabled state
[63987.218861] device veth579ec1c left promiscuous mode
[63987.218862] docker0: port 1(veth579ec1c) entered disabled state
[64786.418297] docker0: port 1(vethead51d5) entered blocking state
[64786.418299] docker0: port 1(vethead51d5) entered disabled state
[64786.418318] device vethead51d5 entered promiscuous mode
[64786.872856] eth0: renamed from veth99b057f
[64786.932949] IPv6: ADDRCONF(NETDEV_CHANGE): vethead51d5: link becomes ready
[64786.932966] docker0: port 1(vethead51d5) entered blocking state
[64786.932967] docker0: port 1(vethead51d5) entered forwarding state
[64787.786553] docker0: port 1(vethead51d5) entered disabled state
[64787.786605] veth99b057f: renamed from eth0
[64787.948146] docker0: port 1(vethead51d5) entered disabled state
[64787.948881] device vethead51d5 left promiscuous mode
[64787.948915] docker0: port 1(vethead51d5) entered disabled state
[64807.747511] docker0: port 1(vethb24ff9b) entered blocking state
[64807.747512] docker0: port 1(vethb24ff9b) entered disabled state
[64807.747531] device vethb24ff9b entered promiscuous mode
[64807.747561] docker0: port 1(vethb24ff9b) entered blocking state
[64807.747562] docker0: port 1(vethb24ff9b) entered forwarding state
[64807.747703] docker0: port 1(vethb24ff9b) entered disabled state
[64808.132878] eth0: renamed from vetha7cd44c
[64808.193099] IPv6: ADDRCONF(NETDEV_CHANGE): vethb24ff9b: link becomes ready
[64808.193123] docker0: port 1(vethb24ff9b) entered blocking state
[64808.193124] docker0: port 1(vethb24ff9b) entered forwarding state
[64809.023917] vetha7cd44c: renamed from eth0
[64809.183134] docker0: port 1(vethb24ff9b) entered disabled state
[64809.188226] docker0: port 1(vethb24ff9b) entered disabled state
[64809.188767] device vethb24ff9b left promiscuous mode
[64809.188769] docker0: port 1(vethb24ff9b) entered disabled state
[65194.352051] docker0: port 1(veth9b9311c) entered blocking state
[65194.352053] docker0: port 1(veth9b9311c) entered disabled state
[65194.352072] device veth9b9311c entered promiscuous mode
[65194.352101] docker0: port 1(veth9b9311c) entered blocking state
[65194.352102] docker0: port 1(veth9b9311c) entered forwarding state
[65194.352424] docker0: port 1(veth9b9311c) entered disabled state
[65194.792790] eth0: renamed from veth5d3475b
[65194.832884] IPv6: ADDRCONF(NETDEV_CHANGE): veth9b9311c: link becomes ready
[65194.832906] docker0: port 1(veth9b9311c) entered blocking state
[65194.832907] docker0: port 1(veth9b9311c) entered forwarding state
[65195.722684] veth5d3475b: renamed from eth0
[65195.792916] docker0: port 1(veth9b9311c) entered disabled state
[65195.878049] docker0: port 1(veth9b9311c) entered disabled state
[65195.878715] device veth9b9311c left promiscuous mode
[65195.878732] docker0: port 1(veth9b9311c) entered disabled state
[66182.663567] scsi 0:0:0:2: Direct-Access     Msft     Virtual Disk     1.0  PQ: 0 ANSI: 5
[66182.664300] sd 0:0:0:2: Attached scsi generic sg2 type 0
[66182.664893] sd 0:0:0:2: [sdc] 536870912 512-byte logical blocks: (275 GB/256 GiB)
[66182.664894] sd 0:0:0:2: [sdc] 4096-byte physical blocks
[66182.664973] sd 0:0:0:2: [sdc] Write Protect is off
[66182.664975] sd 0:0:0:2: [sdc] Mode Sense: 0f 00 00 00
[66182.665154] sd 0:0:0:2: [sdc] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[66182.666668] sd 0:0:0:2: [sdc] Attached SCSI disk
[66182.683579] EXT4-fs (sdc): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[66187.399545] EXT4-fs (sdc): mounted filesystem with ordered data mode. Opts: discard,errors=remount-ro,data=ordered
[66187.410623] FS-Cache: Duplicate cookie detected
[66187.410624] FS-Cache: O-cookie c=000000004e228525 [p=000000006f69fc41 fl=222 nc=0 na=1]
[66187.410625] FS-Cache: O-cookie d=0000000077b88f2e n=0000000013e7c87d
[66187.410625] FS-Cache: O-key=[10] '34333031353536303333'
[66187.410628] FS-Cache: N-cookie c=000000005b00e07c [p=000000006f69fc41 fl=2 nc=0 na=1]
[66187.410629] FS-Cache: N-cookie d=0000000077b88f2e n=00000000f3cfd1ce
[66187.410629] FS-Cache: N-key=[10] '34333031353536303333'
[66187.676655] hv_pci c689411f-e482-4a4b-b5ec-379303b0c4a9: PCI VMBus probing: Using version 0x10003
[66187.677922] 9pnet_virtio: no channels available for device drvfs
[66187.677925] WARNING: mount: waiting for virtio device...
[66187.718390] hv_pci c689411f-e482-4a4b-b5ec-379303b0c4a9: PCI host bridge to bus e482:00
[66187.718393] pci_bus e482:00: root bus resource [mem 0xbffe10000-0xbffe12fff window]
[66187.719402] pci e482:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.720467] pci e482:00:00.0: reg 0x10: [mem 0xbffe10000-0xbffe10fff 64bit]
[66187.721103] pci e482:00:00.0: reg 0x18: [mem 0xbffe11000-0xbffe11fff 64bit]
[66187.721739] pci e482:00:00.0: reg 0x20: [mem 0xbffe12000-0xbffe12fff 64bit]
[66187.725644] pci e482:00:00.0: BAR 0: assigned [mem 0xbffe10000-0xbffe10fff 64bit]
[66187.726097] pci e482:00:00.0: BAR 2: assigned [mem 0xbffe11000-0xbffe11fff 64bit]
[66187.726550] pci e482:00:00.0: BAR 4: assigned [mem 0xbffe12000-0xbffe12fff 64bit]
[66187.782347] hv_pci 5de0a50d-7985-4767-96bc-4a4a80b94674: PCI VMBus probing: Using version 0x10003
[66187.783556] 9pnet_virtio: no channels available for device drvfs
[66187.783561] WARNING: mount: waiting for virtio device...
[66187.823210] hv_pci 5de0a50d-7985-4767-96bc-4a4a80b94674: PCI host bridge to bus 7985:00
[66187.823212] pci_bus 7985:00: root bus resource [mem 0xbffe14000-0xbffe16fff window]
[66187.824217] pci 7985:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.825200] pci 7985:00:00.0: reg 0x10: [mem 0xbffe14000-0xbffe14fff 64bit]
[66187.825847] pci 7985:00:00.0: reg 0x18: [mem 0xbffe15000-0xbffe15fff 64bit]
[66187.826493] pci 7985:00:00.0: reg 0x20: [mem 0xbffe16000-0xbffe16fff 64bit]
[66187.830371] pci 7985:00:00.0: BAR 0: assigned [mem 0xbffe14000-0xbffe14fff 64bit]
[66187.830823] pci 7985:00:00.0: BAR 2: assigned [mem 0xbffe15000-0xbffe15fff 64bit]
[66187.831276] pci 7985:00:00.0: BAR 4: assigned [mem 0xbffe16000-0xbffe16fff 64bit]
[66187.887658] hv_pci 28ccd863-7f1b-48fb-a06c-14f1032961b1: PCI VMBus probing: Using version 0x10003
[66187.929043] hv_pci 28ccd863-7f1b-48fb-a06c-14f1032961b1: PCI host bridge to bus 7f1b:00
[66187.929046] pci_bus 7f1b:00: root bus resource [mem 0xbffe18000-0xbffe1afff window]
[66187.930038] pci 7f1b:00:00.0: [1af4:1049] type 00 class 0x010000
[66187.930989] pci 7f1b:00:00.0: reg 0x10: [mem 0xbffe18000-0xbffe18fff 64bit]
[66187.931624] pci 7f1b:00:00.0: reg 0x18: [mem 0xbffe19000-0xbffe19fff 64bit]
[66187.932284] pci 7f1b:00:00.0: reg 0x20: [mem 0xbffe1a000-0xbffe1afff 64bit]
[66187.936143] pci 7f1b:00:00.0: BAR 0: assigned [mem 0xbffe18000-0xbffe18fff 64bit]
[66187.936627] pci 7f1b:00:00.0: BAR 2: assigned [mem 0xbffe19000-0xbffe19fff 64bit]
[66187.937076] pci 7f1b:00:00.0: BAR 4: assigned [mem 0xbffe1a000-0xbffe1afff 64bit]
[66977.281402] docker0: port 1(veth0d37bc8) entered blocking state
[66977.281404] docker0: port 1(veth0d37bc8) entered disabled state
[66977.281423] device veth0d37bc8 entered promiscuous mode
[66977.281453] docker0: port 1(veth0d37bc8) entered blocking state
[66977.281453] docker0: port 1(veth0d37bc8) entered forwarding state
[66977.281748] docker0: port 1(veth0d37bc8) entered disabled state
[66978.181803] docker0: port 1(veth0d37bc8) entered disabled state
[66978.181906] device veth0d37bc8 left promiscuous mode
[66978.181907] docker0: port 1(veth0d37bc8) entered disabled state
[67557.114920] docker0: port 1(veth9c4371d) entered blocking state
[67557.114921] docker0: port 1(veth9c4371d) entered disabled state
[67557.114944] device veth9c4371d entered promiscuous mode
[67557.652243] eth0: renamed from veth99c3a3f
[67557.802389] IPv6: ADDRCONF(NETDEV_CHANGE): veth9c4371d: link becomes ready
[67557.802412] docker0: port 1(veth9c4371d) entered blocking state
[67557.802413] docker0: port 1(veth9c4371d) entered forwarding state
[67558.185775] veth99c3a3f: renamed from eth0
[67558.302350] docker0: port 1(veth9c4371d) entered disabled state
[67558.307904] docker0: port 1(veth9c4371d) entered disabled state
[67558.308442] device veth9c4371d left promiscuous mode
[67558.308444] docker0: port 1(veth9c4371d) entered disabled state
[67593.210939] docker0: port 1(veth228dbe2) entered blocking state
[67593.210940] docker0: port 1(veth228dbe2) entered disabled state
[67593.210960] device veth228dbe2 entered promiscuous mode
[67593.210992] docker0: port 1(veth228dbe2) entered blocking state
[67593.210993] docker0: port 1(veth228dbe2) entered forwarding state
[67593.211282] docker0: port 1(veth228dbe2) entered disabled state
[67593.722096] eth0: renamed from veth20ca901
[67593.782236] IPv6: ADDRCONF(NETDEV_CHANGE): veth228dbe2: link becomes ready
[67593.782257] docker0: port 1(veth228dbe2) entered blocking state
[67593.782258] docker0: port 1(veth228dbe2) entered forwarding state
[68424.882867] init: (195) ERROR: operator():211: shutdown failed 107
[68424.884817] init: (195) ERROR: operator():211: shutdown failed 107
[68424.886584] init: (195) ERROR: operator():211: shutdown failed 107
[68424.888302] init: (195) ERROR: operator():211: shutdown failed 107
[68424.890043] init: (195) ERROR: operator():211: shutdown failed 107
[68424.891745] init: (195) ERROR: operator():211: shutdown failed 107
[68424.893473] init: (195) ERROR: operator():211: shutdown failed 107
[68424.896066] init: (195) ERROR: operator():211: shutdown failed 107
[68424.898353] init: (195) ERROR: operator():211: shutdown failed 107
[68424.900144] init: (195) ERROR: operator():211: shutdown failed 107
[68599.829580] init: (195) ERROR: operator():211: shutdown failed 107
[68599.832116] init: (195) ERROR: operator():211: shutdown failed 107
[68599.834452] init: (195) ERROR: operator():211: shutdown failed 107
[68599.836492] init: (195) ERROR: operator():211: shutdown failed 107
[68599.838390] init: (195) ERROR: operator():211: shutdown failed 107
[68599.840152] init: (195) ERROR: operator():211: shutdown failed 107
[68599.841806] init: (195) ERROR: operator():211: shutdown failed 107
[68599.843637] init: (195) ERROR: operator():211: shutdown failed 107
[68599.845480] init: (195) ERROR: operator():211: shutdown failed 107
[68599.847897] init: (195) ERROR: operator():211: shutdown failed 107

#### Driver information from `nvidia-smi -a`
==============NVSMI LOG==============

Timestamp                                 : Mon Oct  4 21:42:55 2021
Driver Version                            : 510.06
CUDA Version                              : 11.6

Attached GPUs                             : 1
GPU 00000000:2D:00.0
    Product Name                          : NVIDIA GeForce RTX 2080 Ti
    Product Brand                         : GeForce
    Product Architecture                  : Turing
    Display Mode                          : Enabled
    Display Active                        : Enabled
    Persistence Mode                      : Enabled
    MIG Mode
        Current                           : N/A
        Pending                           : N/A
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : WDDM
        Pending                           : WDDM
    Serial Number                         : N/A
    GPU UUID                              : GPU-4949b172-957c-5479-5dc3-12e0ea688389
    Minor Number                          : N/A
    VBIOS Version                         : 90.02.30.00.b7
    MultiGPU Board                        : No
    Board ID                              : 0x2d00
    GPU Part Number                       : N/A
    Module ID                             : 0
    Inforom Version
        Image Version                     : G001.0000.02.04
        OEM Object                        : 1.1
        ECC Object                        : N/A
        Power Management Object           : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GSP Firmware Version                  : N/A
    GPU Virtualization Mode
        Virtualization Mode               : None
        Host VGPU Mode                    : N/A
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x2D
        Device                            : 0x00
        Domain                            : 0x0000
        Device Id                         : 0x1E0410DE
        Bus Id                            : 00000000:2D:00.0
        Sub System Id                     : 0x12AE10DE
        GPU Link Info
            PCIe Generation
                Max                       : 3
                Current                   : 3
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 7000 KB/s
        Rx Throughput                     : 221000 KB/s
    Fan Speed                             : 0 %
    Performance State                     : P8
    Clocks Throttle Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    FB Memory Usage
        Total                             : 11264 MiB
        Used                              : 2840 MiB
        Free                              : 8424 MiB
    BAR1 Memory Usage
        Total                             : 256 MiB
        Used                              : 2 MiB
        Free                              : 254 MiB
    Compute Mode                          : Default
    Utilization
        Gpu                               : N/A
        Memory                            : N/A
        Encoder                           : 0 %
        Decoder                           : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    Ecc Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Errors
        Volatile
            SRAM Correctable              : N/A
            SRAM Uncorrectable            : N/A
            DRAM Correctable              : N/A
            DRAM Uncorrectable            : N/A
        Aggregate
            SRAM Correctable              : N/A
            SRAM Uncorrectable            : N/A
            DRAM Correctable              : N/A
            DRAM Uncorrectable            : N/A
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows                         : N/A
    Temperature
        GPU Current Temp                  : 47 C
        GPU Shutdown Temp                 : 94 C
        GPU Slowdown Temp                 : 91 C
        GPU Max Operating Temp            : 89 C
        GPU Target Temperature            : 84 C
        Memory Current Temp               : N/A
        Memory Max Operating Temp         : N/A
    Power Readings
        Power Management                  : Supported
        Power Draw                        : 20.30 W
        Power Limit                       : 250.00 W
        Default Power Limit               : 250.00 W
        Enforced Power Limit              : 250.00 W
        Min Power Limit                   : 100.00 W
        Max Power Limit                   : 280.00 W
    Clocks
        Graphics                          : 387 MHz
        SM                                : 387 MHz
        Memory                            : 403 MHz
        Video                             : 539 MHz
    Applications Clocks
        Graphics                          : N/A
        Memory                            : N/A
    Default Applications Clocks
        Graphics                          : N/A
        Memory                            : N/A
    Max Clocks
        Graphics                          : 2100 MHz
        SM                                : 2100 MHz
        Memory                            : 7000 MHz
        Video                             : 1950 MHz
    Max Customer Boost Clocks
        Graphics                          : N/A
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : N/A
    Processes                             : None

#### Docker version from `docker version`
Client: Docker Engine - Community
 Version:           20.10.8
 API version:       1.41
 Go version:        go1.16.6
 Git commit:        3967b7d
 Built:             Fri Jul 30 19:54:27 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.8
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.16.6
  Git commit:       75249d8
  Built:            Fri Jul 30 19:52:33 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.10
  GitCommit:        8848fdb7c4ae3815afcc990a8a99d663dda1b590
 runc:
  Version:          1.0.2
  GitCommit:        v1.0.2-0-g52b36a2
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0

#### NVIDIA packages version from `dpkg -l '*nvidia*'` _or_ `rpm -qa '*nvidia*'`
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend
|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)
||/ Name                               Version                    Architecture Description
+++-==================================-==========================-============-================================================>
un  libgldispatch0-nvidia              <none>                     <none>       (no description available)
un  libnvidia-compute                  <none>                     <none>       (no description available)
ii  libnvidia-compute-460-server:amd64 460.91.03-0ubuntu0.20.04.1 amd64        NVIDIA libcompute package
ii  libnvidia-container-tools          1.5.1-1                    amd64        NVIDIA container runtime library (command-line t>
ii  libnvidia-container1:amd64         1.5.1-1                    amd64        NVIDIA container runtime library
ii  libnvidia-ml-dev                   10.1.243-3                 amd64        NVIDIA Management Library (NVML) development fil>
un  libnvidia-ml.so.1                  <none>                     <none>       (no description available)
un  libnvidia-ml1                      <none>                     <none>       (no description available)
un  libnvidia-tesla-418-ml1            <none>                     <none>       (no description available)
un  libnvidia-tesla-440-ml1            <none>                     <none>       (no description available)
un  libnvidia-tesla-cuda1              <none>                     <none>       (no description available)
ii  nvidia-container-runtime           3.5.0-1                    amd64        NVIDIA container runtime
un  nvidia-container-runtime-hook      <none>                     <none>       (no description available)
ii  nvidia-container-toolkit           1.5.1-1                    amd64        NVIDIA container runtime hook
ii  nvidia-cuda-dev                    10.1.243-3                 amd64        NVIDIA CUDA development files
ii  nvidia-cuda-doc                    10.1.243-3                 all          NVIDIA CUDA and OpenCL documentation
ii  nvidia-cuda-gdb                    10.1.243-3                 amd64        NVIDIA CUDA Debugger (GDB)
ii  nvidia-cuda-toolkit                10.1.243-3                 amd64        NVIDIA CUDA development toolkit
un  nvidia-docker                      <none>                     <none>       (no description available)
ii  nvidia-docker2                     2.6.0-1                    all          nvidia-docker CLI wrapper
un  nvidia-driver                      <none>                     <none>       (no description available)
un  nvidia-legacy-304xx-vdpau-driver   <none>                     <none>       (no description available)
un  nvidia-legacy-340xx-vdpau-driver   <none>                     <none>       (no description available)
un  nvidia-libopencl1                  <none>                     <none>       (no description available)
un  nvidia-libopencl1-dev              <none>                     <none>       (no description available)
ii  nvidia-opencl-dev:amd64            10.1.243-3                 amd64        NVIDIA OpenCL development files
un  nvidia-opencl-icd                  <none>                     <none>       (no description available)
ii  nvidia-profiler                    10.1.243-3                 amd64        NVIDIA Profiler for CUDA and OpenCL
un  nvidia-tesla-418-driver            <none>                     <none>       (no description available)
un  nvidia-tesla-440-driver            <none>                     <none>       (no description available)
un  nvidia-vdpau-driver                <none>                     <none>       (no description available)
ii  nvidia-visual-profiler             10.1.243-3                 amd64        NVIDIA Visual Profiler for CUDA and OpenCL

#### NVIDIA container library version from `nvidia-container-cli -V`
version: 1.5.1
build date: 2021-09-20T14:30+00:00
build revision: 4afad130c4c253abd3b2db563ffe9331594bda41
build compiler: gcc-5 5.4.0 20160609
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections

#### NVIDIA container library logs
2021/10/04 21:48:07 Using bundle directory: /var/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/43c805d8ac1895dc62353aa47b2ac77b5a6eb2d7af3a1441658e55abc97fae27
2021/10/04 21:48:07 Using OCI specification file path: /var/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/43c805d8ac1895dc62353aa47b2ac77b5a6eb2d7af3a1441658e55abc97fae27/config.json
2021/10/04 21:48:07 Looking for runtime binary 'docker-runc'
2021/10/04 21:48:07 Runtime binary 'docker-runc' not found: exec: ""docker-runc"": executable file not found in $PATH
2021/10/04 21:48:07 Looking for runtime binary 'runc'
2021/10/04 21:48:07 Found runtime binary '/bin/runc'
2021/10/04 21:48:07 Running nvidia-container-runtime

2021/10/04 21:48:07 'create' command detected; modification required
2021/10/04 21:48:07 prestart hook path: /bin/nvidia-container-runtime-hook

2021/10/04 21:48:07 existing nvidia prestart hook in OCI spec file
2021/10/04 21:48:07 Forwarding command to runtimeYes.  I have been trying to WSL… is there another easier way… 22.03 and 22.07 see to be giving the same issues for me.  I read online WSL is not a good choice.Depending on your needs you could try a bare metal installation. Most of the utilities in Modulus should work if PyTorch works on your system, but of course we encourage the docker image for consistency between our users development environment.Alternatively you could look into a cloud based service.Hi all, I am on WSL and it’s working well up to 22.03.1.I tried the solution given by ngeneva. I deleted the files, one by one when the error lib is given, eg:docker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #0: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: /var/lib/docker/overlay2/a92497fde29f5e4a16659087de1978a2ff7cf59a53b410f240467c3aead3f609/merged/usr/lib/x86_64-linux-gnu/libnvcuvid.so.1: file exists: unknown.
ERRO[0000] error waiting for container: context canceledSo I deleted /usr/lib/x86_64-linux-gnu/libnvcuvid.so.1In the end, after deleting approx 6 files, there’s no more error msg but modulus reports:ERROR: No supported GPU(s) detected to run this containerI run “nvidia-smi” and it did reported my GPU:root@d7a49cf80974:/examples# nvidia-smi
Tue Sep 27 08:59:08 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 515.75       Driver Version: 517.40       CUDA Version: 11.7     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce …  On   | 00000000:01:00.0  On |                  N/A |
| 27%   33C    P8    13W / 275W |    628MiB / 11264MiB |      2%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+However, running the example still gives error:Error executing job with overrides: 
Traceback (most recent call last):
File “helmholtz.py”, line 92, in run
slv.solve()
File “/modulus/modulus/solver/solver.py”, line 159, in solve
self._train_loop(sigterm_handler)
File “/modulus/modulus/trainer.py”, line 521, in _train_loop
loss, losses = self._cuda_graph_training_step(step)
File “/modulus/modulus/trainer.py”, line 694, in _cuda_graph_training_step
self.warmup_stream = torch.cuda.Stream()
File “/opt/conda/lib/python3.8/site-packages/torch/cuda/streams.py”, line 34, in new
return super(Stream, cls).new(cls, priority=priority, **kwargs)
RuntimeError: CUDA error: no CUDA-capable device is detected
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.So the GPU still can’t work correctly.Anyone has a solution?Thanks!Hi @tsltaywbI would start with just getting PyTorch working and making sure the GPU is visible to PyTorch prior to running Modulus.Once just PyTorch works with the GPU then Modulus should function.Hi ngeneva,Well, the problem is that w/o deleting libnvidia* and libcuda* files, I can’t enter the docker modulus environment. But if I entered after deleting these files, the GPU can’t work:
torch.cuda.is_available() will be falseBtw, 22.03.1 is working. I realise that in the docker modulus dir, there’s modulus and external dir. Can I overwrite  them with the newer 22.09 ? Will I get the new features of 22.09 after I did this?Thanks.Hi @tsltaywbIn theory yes you could do that with the modulus folder which should allow most PyTorch related features should function. The external folder is for the 2 external dependencies of Modulus (pysdf and tinycudann). I would be careful copying these over because these are compiled during build for the docker image. Could be worth a try if you want pysdf functionality.I’ve seen you’ve figured out some work around with the 22.08 pytorch container, may also want to try some hacking with that method. Alternatively you could comment out the PySDF items in the docker file in the main repo and build your image with the same folder structure as the one we ship. Then try bringing over a pre-compiled PySDF files from the 22.09 container.Thanks for updating the forums with your solutions for others!Powered by Discourse, best viewed with JavaScript enabled"
343,help-with-predictions-in-nvidia-modulus,"Hello, I have trained a neural network in nvidia modulus, now I need to generate predictions with it, however, I have read the answers from the forum and it is not clear to me how to make the prediction, is there any detailed guide or example of how to make the predictions ?Hi @matiyanezSimilar to my comments in this other post, we leave the deployment part of trained models up to the user. If you want to stay in the Modulus workflow, Modulus provides some inference and validators you can use (Many of our examples use these, please have a look at the example documentation). Define these and add them to your training domain.If you only have inferencers and validators added to your training domain, you can call traner._eval() (solver.eval()) to execute these without any training loop.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
344,nvidia-modulus-documentation-for-a-beginner,"Hello,
I recently came across Nvidia Modulus and was interested in trying it. I am hard time understanding the installation as I am not aware with Docker etc and other stuff. Is there a guided tutorial for installation and some samples cases to get started it. I am very fairly new to this and would appreciate any help provided by the community.Thanks,Hi @manishvankudreFor the use of Modulus-Sym we suggest using the Modulus docker container. There are many resources online for getting familiar with docker and using an interactive session. Some details are in the install guide.Alternatively one can also pip install modulus packages. This is recommended for the Modulus-Core or Modulus-Launch packages. But keep in mind that some features won’t be there / more prone to break.After installed have a look at the introductory example.Hello @ngeneva,
Thanks for the response. I had a follow- up question, I see the docker images are mentioned for Ubuntu and operating systems mention Linux and Ubuntu. Does Nvidia Modulus works only on Ubuntu/Linux?Thanks,
ManishHi @manishvankudreWe only “officially” support linux/ubuntu since that is that’s the environment test and develop on. However, we have had many users use WSL as well with some success (although it can bring issues as well). Modulus is built on PyTorch, so if PyTorch runs then the most of Modulus should function.I’ve ran Modulus on “bare metal” via WSL for Windows, but I would also recommend running it on Docker.
Note: you can run the docker image on a Windows host OS, you would just be using Linux commands in the terminal.Powered by Discourse, best viewed with JavaScript enabled"
345,bugs-feature-requests-and-contributions-to-modulus,"With the recent open-sourced release of Modulus, we encourage users to file the following tickets on our Github page:Note to use the repo for the respective package you are working with:The forums are still the best place for general questions and technical support.Powered by Discourse, best viewed with JavaScript enabled"
346,can-i-get-openfoam-source-in-fpga-heat-sink-with-laminar-flow,"Can i get openfoam source in FPGA Heat sink with Laminar Flow below URL?https://docs.nvidia.com/deeplearning/modulus/text/advanced/fpga.htmlI study PINN using NVIDIA Module. I want to compare computation time between PINN using NVIDIA module and  Openfoam analysis.Powered by Discourse, best viewed with JavaScript enabled"
347,problem-with-using-criterion-based-stopping,"Hi,I have been using Modulus specifying the no. of steps it takes. But I recently found that there’s actually Criterion Based Stopping inside Modulus. I tried to add it to the yaml file:I got the error:So I removed the “-” and I got Modulus running. However, after a while, it is stuck again:So what’s the problem?I. Is my yaml correct?
2. What else should I change to make it work?Thanks!Hi @tsltaywbThis seems to be a bug, can you edit stop_criterion.py in your Modulus source code to change line 73-75 to:(note the underscore in front of the methods).Please let me know if this runs. This Python file should be at /opt/conda/lib/python3.8/site-packages/modulus-22.9-py3.8.egg/modulus/utils/training/stop_criterion.py on your machine based on the error message. Thanks for the report!Ok, just tried it. Looks like it’s working using:stop_criterion:
metric: ‘l2_relative_error_u’
min_delta: 0.1
patience: 5000
mode: ‘min’
freq: 2000
strict: trueThanks for fixing the bug！This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
348,whats-new-in-the-new-modulus-compared-to-v22-09,"Hi,Where can I find the “what’s new” in the new Modulus compared to v22.09?Is it just an API change or are there other things?Thanks.You can read more about it on these links:This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
349,bfgs-config-error-key-max-iters-not-in-optimizerconf,"Hi, I am using the BFGS optimizer. The following is the config:
defaults :Run the case and get the error:In ‘config’: ConfigKeyError raised while composing config:
Key ‘max_iter’ not in ‘OptimizerConf’
full_key: optimizer.max_iters
reference_type=OptimizerConf
object_type=OptimizerConfBut when I delete max_iter in the config, run the bfgs.  In the outputs/casename/.hydra/config.yaml there is a line of “max_iter: 1000”.
Could anyone help me with that? Thanks!Hi @zhangzhenthuThis is unusual since max_iter is in the hydra config settings.Its hard to tell what your yaml looks like with the bulleted list. Can you make sure the optimizer is set prior to the “self” in the defaults list? See an example of what should work here:Hi!
As you said, I put the self prior to the optimizer in the defaults list. It fixed my problem.Thank you!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
350,best-way-to-debug-modulus-code,"Hi, May I know what’s the best way to debug modulus code?Preferably with GUI.In Linux and Windows (with WSL).Thanks!Hi @tsltaywbModulus is a collection of Python libraries, so any Python debugger should be a good choice given your specific needs (developers on our side use IDE’s like VSCode, PyCharm, NeoVIM, etc that each offer different debugging tools). PyCharm is a popular one, with a lot of debugging features from my understanding. If your actively editing the source code of Modulus I would suggest looking into editable pip installing Modulus.Ok thanks!I wonder if anyone has experience with debugging Modulus with Docker in Windows 10 WSL2 and VSCode (or any other debugger). If so, is there any guide on how to set it up? I tried previously a while back but it didn’t work.Powered by Discourse, best viewed with JavaScript enabled"
351,save-outputs-to-a-different-folder,"Hi I am trying to use hydra multirun on top of Nvidia Modulus, I want to store the outputs in a folder name of my choice. What changes do I need to make? I think most of the paths are defined in the solver class. https://gitlab.com/nvidia/modulus/modulus/-/blob/release_22.09/modulus/solver/solver.pyHI @prakhar_sharmaThis should be adjustable using Hydra. Hydra conf changes the programs working location on init, so its controlling where the output folders are. The output folder is defined under the config group /hydra/run/dir I believe (for a single run) and /hydra/sweep/dir (for multirun). You could do this using command line, overrides the config or in the source code here.If you’re looking at the Hydra docs, just remember the docker file is currently using a slightly older version of Hydra that the current release. Most API is consistent however.So,  my code was written in Modulus 22.03. That particular version works with Hydra 1.1. I managed to scrap hydra using the Jupyter notebook tutorial. Then I created a wrapper of Hydra-zen. This package is useful when the hyperparameters are changing (using an algorithm) as we proceed with the multirun.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
352,nonparametric-geometries,"Hello,Is it possible to train a network on a set of nonparametric geometries? For example, train the network on many different nonparametric geometries so I could use an arbitrary geometry on inference.Thanks in advanceHi @gorpinich4Does the DiscreteGeometry component work for your need? We have an example to make a set of tessellated geometry such that it looks parametric (you can define define the parameterization as some arbitrary variable).In the constraint, this will sample one of the provided geometries in a discrete list, than sample a point from that geometry.Powered by Discourse, best viewed with JavaScript enabled"
353,modulus-sym-examples-ldc-error,"Hi, so I have been able to get the helmholtz and chip_2d cases to work. However I am getting an error when running the ldc and ldc_zeroEq models. I saw some answers on this forum but it did not help my case, the error is as such:modulus-sym/examples/ldc# python3 ldc_2d.py
/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See Changes to job's runtime working directory | Hydra for more information.
ret = run_job(
[01:56:29] - JitManager: {‘_enabled’: False, ‘_arch_mode’: <JitArchMode.ONLY_ACTIVATION: 1>, ‘_use_nvfuser’: True, ‘_autograd_nodes’: False}
[01:56:29] - GraphManager: {‘_func_arch’: False, ‘_debug’: False, ‘_func_arch_allow_partial_hessian’: True}
[01:56:34] - attempting to restore from: outputs/ldc_2d
[01:56:34] - optimizer checkpoint not found
[01:56:34] - model flow_network.0.pth not found
Error executing job with overrides: 
Traceback (most recent call last):
File “ldc_2d.py”, line 136, in run
slv.solve()
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/solver/solver.py”, line 173, in solve
self._train_loop(sigterm_handler)
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/trainer.py”, line 535, in _train_loop
loss, losses = self._cuda_graph_training_step(step)
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/trainer.py”, line 716, in _cuda_graph_training_step
self.loss_static, self.losses_static = self.compute_gradients(
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/trainer.py”, line 68, in adam_compute_gradients
losses_minibatch = self.compute_losses(step)
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/solver/solver.py”, line 66, in compute_losses
return self.domain.compute_losses(step)
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/domain/domain.py”, line 147, in compute_losses
constraint.forward()
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/domain/constraint/continuous.py”, line 130, in forward
self._output_vars = self.model(self._input_vars)
File “/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py”, line 1190, in _call_impl
return forward_call(*input, **kwargs)
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/graph.py”, line 234, in forward
outvar.update(e(outvar))
File “/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py”, line 1190, in _call_impl
return forward_call(*input, **kwargs)
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/eq/derivatives.py”, line 99, in forward
grad = gradient(var, grad_var)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
File “/usr/local/lib/python3.8/dist-packages/modulus/sym/eq/derivatives.py”, line 38, in gradient
“”""
grad_outputs: List[Optional[torch.Tensor]] = [torch.ones_like(y, device=y.device)]
grad = torch.autograd.grad(
~~~~~~~~~~~~~~~~~~~ <— HERE
[
y,
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.Hi @mitanshtripSorry you’re having problems with the LDC example, its a bit unusual for this example to have errors. Can you tell me a little more about your environment? Is this inside the Modulus docker container? Or is this with a pip / bare metal install? What is your PyTorch version? What is the hardware you are running on?Its odd that chip_2d works for you but this doesn’t. Can I also ask you to try the annular ring example (another N-S system). Thanks!So I am using “WSL” on windows to run the cases. I used the pip/bare metal installation.The PyTorch version is: 1.13.0+cu116The annular ring example gave me the exact same error that I pasted in the query aboveThank youHi @mitanshtripUnfortunately, we don’t formally test WSL. I would verify that you’re not running out of memory on your GPU. Another item to try is to comment out the JIT decorator here on the gradient calculation and see if the CUDA error is more informative. Otherwise debugging a RuntimeError: CUDA error: unknown error is rather challenging.Hi, so I tested these out on an hpc cluster (just a single node) and I had the same issue, helmholtz and chip_2d working but the ldc and annular ring are not working.Instead of running it on GPU’s can this be run on CPU’s?Hi @mitanshtripI just tested a bare metal install of nvidia-modulus.sym and the LDC problem runs fine on a unix V100 GPU. If you have a CPU installation, and Pytorch runs on the CPU then most of the examples should function maybe with some modification. However, I would strongly suggest against this since training will be very slow and many features will not work.Did you try commenting out the JIT decorator? Also what hardware are you using? Confirm you are not running out of GPU memory.Powered by Discourse, best viewed with JavaScript enabled"
354,issues-emulating-simple-water-flow,"Hello, I’m attempting to use modulus to emulate  a 2 gpm water flow in a ~1/2in pipe with two 90 degree bends. The water flows into the inlet, and out of the inlet_exit. Unfortunately, I am having significant difficulties getting it to converge onto the correct solution. If I render it’s output in ParaView while training I can see it occasionally produces a result close to what I want but it will not stay there. I would appreciate any guidance that can be offered, as I am attempting to evaluate whether this tool will be useful for my company. I have an embarrassing 2 weeks invested into this, but there’s a good chance it’s a relatively basic error that I’m making but cannot see.This project is based off of the anuerism sample.Thanks!my_flow.zip (668.3 KB)Hi @npstrikeI’m having a look at this now and will follow up early next week with any items I see. Thanks for the comprehensive details.Thanks @ngeneva, I appreciate it. I’ve also experimented with an additional integral plane along the tube, I’ll include the stl for that here in case it’s beneficial:INTERNAL_INLET.stl (20.8 KB)Hi @npstrikeSo I did just some initial looking at the outputs and I am seeing some oddities with the points getting sampled from the STL file. I’m curious if you see the same. Namely with this section here:

image1154×373 8.91 KB
I’m not sure whats going on exactly, but looking at the interior constraint I do see considerabley less points sampled in this area. Plotting the interior_volume vtp file in Paraview gives the following. I personally get a lot less points at the end of the pipe section.

image1209×271 13.6 KB
I added a simple voxel inferencer and viewing this in Paraview with a threshold filter, seems the SDF isn’t right in the region either (the SDF is returning some incorrect value and these points are getting masked out as outside the pipe):

image1226×279 17.6 KB
Inferencer code here (I edited the center to be center = (5.433142, 6.5, 0.000000) so its centered more around 0):Edit: looking at that cut off point from the Voxel inferencer on the STL file I see some double layer. I’m guessing this is confusing pysdf any causing some sampling issues.

image959×711 12.7 KB
@ngeneva yes, I’ve seen the same strange cutoff but I wasn’t sure what to make of it. I wasn’t aware of the VoxelInferencer feature, that’s a good tip! This odd behavior is likely because this is just a portion of a larger model, and I was trying to reduce the complexity for debugging by stripping it down to this tube. It would appear that I have had the opposite effect. I really appreciate you looking into this, I think I have some ideas on how I can move forwards now :-). If I have further questions can I send them your way?Hi @npstrikeGreat! PySdf does tend be to pretty picky with how the STL is formed. It can get confused on whats “inside” the mesh if things have some unenclosed parts. Feel free to send additional questions, I can continue to provide support (bandwidth permitting of course).By the way, if this example (laminar flow through a curved pipe) starts working well and is able to be shared publicly, we would be very happy to have it as part of our example collection as well as potentially publicize it and in one our release blog posts. We can discuss more in the future if there’s interest.I have a question regarding creative use of the boundary constraint. One thing I’m playing with is using different types of helpers, similar to the use of the IntegralConstraint. However, what’s more intuitive for me and my use case (in-compressible flow) is to specify u,v, and w to a constraints outvar rather than the norm_dot_vel that’s proposed for IntegralConstraints .As such I’ve been experimenting with using PointwiseBoundaryConstraints defined along the  interior of the volume and using that to provide known velocity vectors. Even if this is odd, are there any reasons that this should fundamentally not work?I’m still working getting my case to produce satisfactory output and I’d like to know if this is a red herring.Thanks!As for the example problem, I doubt my company would allow me to share the full sample of what I’m actually doing, however if I can get our sample working I can likely get a revised version of this simple pipe I provided above using corrected .stl’s if you guys are interested. I’m personally a big supporter of community development, but am limited by our IP policies. I’m happy to contribute what I can though if it helps the project.As such I’ve been experimenting with using PointwiseBoundaryConstraint s defined along the interior of the volume and using that to provide known velocity vectors. Even if this is odd, are there any reasons that this should fundamentally not work?If this is prior physical information that you would know ahead of time for the problem, then you should definitely try to incorporate it to speed up convergence. Similar to numerical solvers, there’s multiple approaches for boundary conditions that work better in some problems and worse in others. Experimenting with different constraint methods is exactly what we do when developing these examples.Ok, thanks! Yes, this is information I know prior, however I wasn’t sure if using a PointwiseBoundaryConstraint might confuse it somehow as I’ve only seen it used as a barrier between the scope of the run and the external world that’s not emulated.Thanks for the feedback :)This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
