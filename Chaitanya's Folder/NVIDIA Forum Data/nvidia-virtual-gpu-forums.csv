,query,data
0,matlab-parallelcomputingtoolbox,"Can you/How do you setup a single RTX-6000 so MATLAB thinks you have more than a single GPU installed?  Preferably as many GPUs as you have normal cores on your computer.  Thanks!Powered by Discourse, best viewed with JavaScript enabled"
1,is-anyone-able-to-use-a-nvidia-tesla-driver-for-windows-2019,"The NV-series virtual machines are powered by NVIDIA Tesla M60 GPUs and NVIDIA GRID technology for desktop accelerated applications and virtual desktops.The only drivers I have been able to find are here:
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/n-series-driver-setup
for Windows Server 2016 and Windows Server 2012 R2Does anyone know how or where to get a driver for Windows 2019?No support for Server 2019 yet.I am having trouble finding nvidia graphics cards compatible with Windows Server 2019.  Are there a list of currently compatible graphics cards?Any prognosis about this? we’re waiting for it.
A target date would be nice.Next major vGPU version should support Win10_1809 and Server 2019. ETA in a few weeks.So around the time Win10_1903 will be released :-)Any new ETA for Microsoft Windows 2019 Datacenter edition?As always, we won’t give an exact ETA for upcoming releases as it is always subject to change. Please file a support ticket with NVES if you need more detailed information.Regards
SimonSo any news on this???Powered by Discourse, best viewed with JavaScript enabled"
2,tesla-m10-memory-shared-problem-help,"Hello,
I added the Tesla M10 graphics card to my Dell R720 server. I want to share this video card to my virtual servers, but it takes the whole video card. I want to add 1GB for each server. How can I do this?Captured with LightshotCaptured with LightshotHiYes, you’re running in Passthrough and you haven’t virtualised the GPU. Remove it from Passthrough, install the vGPU Manager into ESXi and you’ll be able to allocate vGPU Profiles to your VMs, rather than an entire GPU.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
3,sharing-nvidia-quadro-rtx-8000-to-multiple-vms-in-proxmox,"Hi,I have a Nvidia Quadro RTX 8000 48GB Card.
I wanted to use it with proxmox to share the same gpu in upto 4 ubuntu virtual machines using the vGPU Profiles.I installed the nvidia vGPU driver on proxmox and is working fine (nvidia-smi shows). I download the evaluation vgpu drivers from nvid.nvidia.com
The vgpu profiles shows correctly when adding pcie device to VM.Also I was able to install the guest drivers on ubuntu vm, the installation was complete but when running nvidia-smi on guest ubuntu vm it is giving error communicating with device.Has anybody got this setup or similar working.
If anybody can help me on this.
Is this setup even possible with Proxmox?Nvidia officially supports this but with vmware vsphere or citrix hypervisor, i am not familiar with these hypervisors so wanted to give it a try with proxmox.My config:
Dell R750
196 GB RAM
Nvidia Quadro RTX 8000 48 GB - Slot 2
Nvidia A100 80 GB - Slot 1
Latest Proxmox with Latest KernelThanks in advance.Powered by Discourse, best viewed with JavaScript enabled"
4,memory-consumption-of-ctxgfx-exe-and-wdm-exe,"We are moving from vmware to citrix hypervisor 8.2 with nvidia T4 Cards (3 per Host). We have 6x Server 2019 RDSH VAD1912CU3 per Host. Each Worker with a T4-8A profile. We are happy with the benefits of the GPU for overall performance, except for system memory. We see a massive increase in Memory consumption in ctxgfx.exe and dwm.exe. Before our avg. ctxgfx.exe per User was ~70MB now with vgpu its ~265MB and avg. dwm.exe was 23MB and now is 253MB.Are these numbers normal with vgpu? I opend a case with citrix but havent gotten any useful feedback yet.Hi,memory consumption depends on the protocol used. But at least for dwm.exe the increase is expected as the desktop window manager needs to do much more work. RDSH doesn’t support “native” NVENC, therefore the increase in ctxgfx.exe is also expected as you cannot offload to the GPU. It would be different for client OS like Win10 where you would see a decrease in ctxgfx.exe.regards
SimonWell that is kind of a bummer, i guess i buy more RAM then. In total our Sessions went up 800MB - 1 GB per User. In my old envoirment without vgpu i peak at about 25GB of commited memory for 10 Users and with vGPU its somewhere between 34 - 38 GB. That adds up …How many monitors are the users running? Which resolution? In general, the numbers look really high. I just checked on my Citrix 2106 and Win2022 and the usersession consumes 57MB ctxgfx.exe and 17MB dwm.exe on 1 Full HD screen in idle with vGPU 13.
Which Citrix policies have you assigned for these users? Do you use bitmap codec (Thinwire) or Video Codec (H264/H265) ?Those are the numbers, i was used to. Most users have 2x FullHD and we use most current vGPU 13.1.I have to check Codec tommorow.Thinwire with the option to use video codec for parts of the screen where Video or 3D Stuff is displayed.OK, looks good so far. This would be exactly what I would recommend. ACR (actively changing regions) is most likely the best option in your case. Anyways, the numbers for sysmem consumption of the given processes seems to be way to high. By any chance can you test with the current 2109 on a VM to see if it might be related to the LTSR version ???
Another idea could be that there is an issue with ACR (consuming massive amount of resources). You should also disable ACR for a quick test to run Thinwire only and check again if this reduces the sysmem consumption.Do you think i could just upgrade the VDA Agent on the Worker or would i have to build a complete Testenvoirment?I havent been doing much on the protocoll and policy side of citrix (i mainly work on the Masterimages). How would i disable ACR via GPO. I couldnt find a value when i searched for it, maybe its because we use german templates?Thank you so much for your valuable assistance!Just the VDA is enough. I did further testing. Single screen with video playback (ACR) 100MB ctxgfx and 20MB dwm
Running 2xFullHD increases the processes to 130MB ctxgfx and 27MB dwm.
So it scales with 30% increase for the second screen. Removing the second screen goes directly back to the old numbers.
For better ACR policy understanding check my blog: [5 of 6] Mixed Codec (Adaptive Display) – GRID4ALLI just talked to citrix about the issue, they asked me to check if consumption is as high when the vgpu is disabled. When vGPU is removed from the worker the memory consumption of DWM and ctxgfx is exactly as you described. (100MB and 20 - 30MB). Tommorow i will propably do three tests. First ACR policy, second new VDA Agent. Do you think downgrading nvidia vgpu software from 13.1 to 13.0 could be worth the effort? I dont really wanna mess with the citrix hypervisor to much as it seems to work super stable.No need to downgrade vgpu software. I don’t expect NV to be the cause of the issue here.Current state of the issue. Citrix collected info Hypervisor Team moved the ticket to VAD Team, VAD Team moved ticket after collecting more info back to Hypervisor Team.Disabling ACR and trying different codecs did not change consumption noticeably.Monday we try the VDA 2109 Agent.Ok, thanks for the update. Why should this be related to hypervisor? I’m also running XS8.2 in my environment and I don’t see this behavior. I would assume this is related to the OS or the VDA. Another test might be to run the T4 in Passthrough to see if it makes any difference (rule out vGPU).Just tested with 2109 results look pretty similar.Hi, any chance to test with a vanilla OS (Win2019) to see if this is related to your image?We will try with a vanilla system tommorow.I made some screenshots showing the much higher consumption, maybe this helps?
diff947×774 315 KB
Thanks but doesn’t really help. I even checked a Win2019 system to rule out the OS in my lab. 20-30MB dwm.exe usage.
Could you please also try a plain RDP session to see if at least the dwm stays in the expected range? I assume there is a dependency between ctxgfx.exe and dwm.exe whenever the issue occurs. Maybe a sort of memory leak or something like that. What I forgot to ask: Does this happen for specific sessions only? How much FB is in use when the issue occurs? Screenshot from GPUProfiler possible?Thanks for all your effort.dwm on rdp session (left Taskmanager, right Process Explorer) private bytes and working is still higher.
dwm_rdp1047×29 4.2 KB
I will split this into 3 replies as there is a single Image limitation on new users.Memory leak should occur over time, right? The high consumption starts right at the beginning of the session.I would say that all sessions show this behavior (we also checked if there is a relation to workspace or endpoint type but the behavior seems identical).In the screenshot we have 9 Users on the system (mix of single and double FHD) only Office/IT Staff some Office 2019, RDP, Webbrowsers, nothing fancy. Eventhough systen memory usage shows 55% the commit charge is at 100% and then the issue occurs.
profiler.PNG1528×691 119 KB
We tried the same test but reduced the FB by 50% and hammered the system as hard as we could to rule out FB exhaustion causing the issue. Latency goes up obiviously but system is stable. Edit: less users to not run into the commit charge issue.
profiler2.PNG1633×1011 178 KB
i build a vanilla server 2019 with vGPU Software, its doing windows updates right now. I will install VDA tomorow then test.Powered by Discourse, best viewed with JavaScript enabled"
5,grid-k2-in-non-virtualized-stationary,"Just playing: Has anybody have a K2 to work as GPU power in a stationary without virtualization - Windows 10?IE having two graphic cards - one for showing the screen in 4K and the other for calculating? I know that the power of a K2 is not anymore mindblowing:-)Powered by Discourse, best viewed with JavaScript enabled"
6,rtx-8000-memory-limitation,"I have an RTX 8000 and I’m using FFMPEG to transcode multiple streams concurrently. Each stream consume around 575MiB, and when the memory usage reaches around 28000MiB, FFMPEG throw the following message when starting a new transcode session:[h264_nvenc @ 0x55cd1d574800] dl_fn->cuda_dl->cuCtxCreate(&ctx->cu_context_internal, 0, cu_device) failed -> CUDA_ERROR_OUT_OF_MEMORY: out of memory [h264_nvenc @ 0x55cd1d574800] No NVENC capable devices found Error initializing output stream 2:0 – Error while opening encoder for output stream #2:0 - maybe incorrect parameters such as bit_rate, rate, width or heightThe machine is running Ubuntu 20.04 FFMPEG is a snap package from Ubuntu repo ""version 4.2.2-1ubuntu1"" nVidia driver nvidia-driver-435 installed from Ubuntu repocommand used for the transcode: ffmpeg -i SRC -c:v h264_cuvid -vcodec h264_nvenc -preset:v medium -profile:v main -vf ""scale=1920:-2"" -hls_flags delete_segments -hls_init_time 4 -hls_time 4 -maxrate 6000k -g 100 -bufsize 12000k -b:v 3000k -start_number 1 -async 1 -c:a aac -b:a 128k 1080.m3u8I also tried the latest drivers on a Fedora 32 machine but still same results.Is the RTX 8000 have any limitation on the Memory usage? are the parameters I’m using causing this issue?Powered by Discourse, best viewed with JavaScript enabled"
7,does-the-quadro-p1000-support-gpu-passthrough-in-qemu-kvm,"Hi, I am having issues with doing successful passthrough of the Quadro P1000 to a Windows guest on qEMU/KVM (Ubuntu 20.04 host).This is on a Lenovo x3550 M5 server, which can be picky with GPUs, but I confirm that it’s working on native OS.I only recently heard that not all GPUs support passthrough, but there is no information for Quadro P1000. Could someone confirm whether it can or can’t?thanksPowered by Discourse, best viewed with JavaScript enabled"
8,is-vgpu-live-migration-available-for-linux-too-or-just-citrix-vmware,"All mentions about migrations in documentation are related to Citrix and Vmware. But in linux VGPU VFIO driver source code I found code about that. So I can’t figure out is it some ‘universal’ code for all platforms and on Linux it can’t be used because of some restrictions, or I had missed something in documentation and it can be used? Thank you in advance.Powered by Discourse, best viewed with JavaScript enabled"
9,tesla-t4-vsphere-7-0u1c-smi-cant-communicate,"Hypervisor is vSphere 7.0 u 1C
T4 is not in passthrough mode.
Followed the instructions here and installed 11.2 VGPU driver.Any ideas on what else I can check?Blockquote
nvidia-smi
NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.Blockquote
dmesg | grep NVIDIA
2020-12-22T07:54:30.378Z cpu24:2102461)ALERT: NVIDIA: module load failed during VIB install/upgrade.
2020-12-22T07:54:30.390Z cpu25:2102464)NVIDIA: Starting vGPU Services.
2020-12-22T07:54:30.405Z cpu41:2102467)NVIDIA: Starting Xorg service.
2020-12-22T07:54:33.096Z cpu45:2104601)NVIDIA: Starting the DCGM node engine.
2020-12-22T08:36:17.100Z cpu42:2112615)NVIDIA: Stopping the DCGM node engine.
2020-12-22T08:36:17.280Z cpu4:2112625)NVIDIA: Unloading nvidia module during vib remove.
2020-12-22T08:42:27.473Z cpu30:2113597)NVIDIA: Unloading nvidia module during vib install/upgrade.
2020-12-22T08:42:28.106Z cpu37:2113606)ALERT: NVIDIA: module load failed during VIB install/upgrade.
2020-12-22T08:42:28.123Z cpu1:2113607)NVIDIA: Starting vGPU Services.
2020-12-22T08:42:28.140Z cpu36:2113610)NVIDIA: Starting Xorg service.
2020-12-22T08:42:31.344Z cpu8:2115707)NVIDIA: Starting the DCGM node engine.HiHave you configured the BIOS correctly? And what happens if you uninstall / reinstall the driver?RegardsMGBIOS is configured to the best of my knowledge - SR-IOV & 4G decoding are enabled.
Un & Re-installing the driver, I still get the same error.I even tried installing an “older” driver, I get the same error message.Even though the vib install says it is successful, this, I believe is the problem:
2020-12-22T07:54:30.378Z cpu24:2102461)ALERT: NVIDIA: module load failed during VIB install/upgrade.[:~] esxcli software vib list
Name Version Vendor Acceptance Level Install DateNVIDIA-VMware_ESXi_7.0_Host_Driver 450.89-1OEM.700.0.0.15525992 NVIDIA VMwareAccepted 2020-12-23Sorry, I forgot to list the hardware.
Server: SuperMicro SYS-1028U-TNRTP+
GPU: Tesla T4
o/s: vSphere 7.0 u1CHiWhat about the MMIO settings in the BIOS?Just checking … Where did you download the driver from?RegardsMGI have tried different MMIO settings, at this point I’m just guessing, I don’t know what the “correct” settings should be.The driver was downloaded from the nvid.nvidia portal.HiNo need to guess, Google is your friend :-)Try these:FAQ Entry | Online Support | Support - Super Micro Computer, Inc.Incorrect BIOS settings on a server when used with a hypervisor can cause MMIO address issues that result in GRID GPUs failing to be recognized. | NVIDIA (custhelp.com)Make sure the BIOS and all firmware are fully up to date, reset the BIOS to factory default and start again to ensure there are no rogue settings in there.RegardsMGI’m still getting errors even after a BIOS reset.I need to find the right “combo” of BIOS settings.Can you make some sense of this? (see attached)

iKVM_capture1024×768 201 KB
HiRedHat? What happened to VMware?RegardsMGThis was just a test, I’m still using VMware.All related to the lack of driver install

redhat3156×316 31.2 KB
Definitely a BIOS setting issue!
I need to find the right “combo” for the SYS-1028U.I moved the T4 into another SM box SYS-2029BT-HNR, enabled SR-IOV & installed the latest vib, it all works.Here are the SYS-2029 BIOS settings.

sys-1029800×600 121 KB
Powered by Discourse, best viewed with JavaScript enabled"
10,rdsh-hyper-v-dda-display-support,"Good afternoon. I am looking to POC a native RDSH (server 2022 full desktops) using hyper-v with DDA (with four T4 cards) and RDP. I know this is not the best option but cost is paramount. I am having trouble understanding the display support (single vs. multi) along with resolution support. My understanding is that I will need vApps licenses. However, I continue to see this footnote in this guide - https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/Virtual-GPU-Packaging-and-Licensing-Guide.pdf.Applies only to the console display in remote application environments.Does this mean that I can only use a single display when connecting to the RDP session using vApps licensing? or would I need vPC licensing to unlock the additional displays and resolution?The current environemt is RDSH 2012R2 using M60 cards and RemoteFX (which is no longer available). Multiple displays work just fine.Any help would be appreciated. Thanks in advance.Hi,
as the restriction only applies for the console session for sure this is not relevant for RDSH as you use RDP :)
So vApps is the right licensing.regards
Simonis the console session in this case the Win2022 hyper-v host or the console session to the PDSH VM as in mstsc /console?your response leads me to believe that I can support multiple monitors in the RDSH session. correct?Multi-monitor is handled by RDP or the remoting stack on top, so yes, you can use every resolution and amount of monitor that RDP supports.
Our console restriction would be the host session. Even mstsc/console should use a RDP session nowadays.Powered by Discourse, best viewed with JavaScript enabled"
11,which-driver-i-should-install-for-pass-through-now-and-vgpu-later,"Hello all
I am going to deploy a machine with two V100 SXM 32G gpus, it could be 8 in the future.
My hypervisor would be VMWare ESXi.I know if I use the Tesla driver then I don’t need a license but grid need.
At this time, I would just use a guest machine for training, all the work can be done in ssh console, so I may not need OpenGL.
In this case, should I install NVIDIA  vGPU  Manager ? If I installed the NVIDIA  vGPU  Manager in the hypervisor, can I still use Tesla driver(or no license) to get full access to the GPUs(including NVLink and P2P).Then when I have more GPUs, I would like to assign one or two GPU for a guest windows machine to verified my training result. So I must buy the Quadro Virtual Data Center Workstation(vDWS) license ? The other license won’t support CUDA nor Virtual Compute Server would support windows.Besides, the subscription method for Quadro vDWS, if I want to run two VMs at the same time, I need two perpetual license and a SUMS every years ? It would sound better to deploy the windows beyond the VM and using a customer graphics card.Powered by Discourse, best viewed with JavaScript enabled"
12,webpage-license-server-not-found,"Hello. I’m Installed NVIDIA License Server.When I try to open http://my_ip:8080/licserver I get HTTP status 404.My system:
CentOS 8.3
openjdk version “1.8.0_282”
OpenJDK Runtime Environment (build 1.8.0_282-b08)
OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)Hi allkall,Thanks for the question.  Common troubleshooting tips for the Management Interface can be found here: License Server User Guide :: NVIDIA Virtual GPU Software License Server DocumentationDPowered by Discourse, best viewed with JavaScript enabled"
13,confused-on-versioning,"I currently have NVIDIA vGPU version 9.1 installed on all hosts. I am looking to update them but very confused on version numbers.Currently running vSphere 6.7 so I am sorted by that in that Software Downloads section but the VGPU versions are all over the place. Why was version 7.5 released AFTER 9.1? Now most recently 8.3 is available but the previous version before that was 10.1. Do I want to stay on the 9.x versions? Can I go directly to 10.1? Or should I go to 8.3 since it’s the newest? What version do I download to be most up to date?
970×285 39.9 KB
EDIT: Sorry for the terrible image quality ¯_(?)_/¯

{DA1105AA-6991-4B2B-92DE-C01030203A5B}.png.jpg2107×650 148 KB
HiI could answer this with a one line response, but it’s better to explain …NVIDIA maintain and support multiple driver branches. Therefore, different driver branches will have updated releases at different times. The drivers come in two versions: ""Long-Term Support Branch"" (LTSB, sometimes referred to as LTSR (R=Release) same thing, different acronym), and the other is what’s known as ""Current Release"" (CR). NVIDIA will typically support three different branches concurrently, one LTSB and two CR versions (this would explain why 7.x was updated after 9.x).The LTSB version (like all other 3rd Party LTSB / LTSR software) is for Customers that want to run a single version for a prolonged period. This is (supposed) to offer a more stable version that requires only security and / or critical updates and typically this branch will not receive any ""feature"" updates over its supported lifetime. This gives consistency, which is (supposed) to make the environment easier to manage, however, this doesn’t account for bugs introduced by 3rd Party products in the LTSR stack (Hypervisor and VDI components). Currently, the only LTSB variant is 8.x and it’s EOL is April 2022.The CR version (like all other 3rd Party CR software) is for Customers who want to run the latest features and functionality in their environments and the support lifetime for each branch is shorter than that of LTSB. The existing CR versions are 9.x which will become EOL on June 2020 and 10.x which will become EOL on December 2020. After which to maintain Support, you will be required to move to a supported version.vGPU features and functionality apply to more than just what’s happening inside the VM. They apply to the rest of the environment as well. Multi vGPU and vGPU Live Migration to mention just two of them. If newer features and functionality are released throughout the lifecycle of an LTSB release, they will typically be available in the next supported branch, not the existing one.If a Customer keeps their entire environment up to date, then CR is the logical choice. This includes running the latest Hypervisor, VDI platform and Applications. CR is the version I always recommend (it has more than long enough support terms (typically one year)). Despite the claim of LTSB being easier to work with due to longer support, I’m yet to find that the case and personally I don’t recommend it and will never implement a stack built around it. LTSB sounds great on the surface, but in reality, vGPU and other component features are being developed and released so quickly, that being stuck on an older release soon brings problems into the environment. For example, a day one release of LTSB is great because at some point in its release cycle it will be the latest release out of all three branches, but two years in to the platform, it’s now three versions behind the CR, and the platform has very limited feature parity to current versions. Again, that may sound ok on the surface, but look at the feature differences between the current CR and LTSB …I mention all of this because you’ve listed four vGPU versions in your post, including CR and LTSB versions. It’s important to understand why you’re running a specific vGPU version, and the implications of doing so.As mentioned, the 8.x branch is LTSB and the 9.x and 10.x are CR. Whatever happens to 8.x, both CR versions will always be more up to date with more features and functionality. The only changes to the 8.x branch will (or certainly should) be security and bug fixes (no features). Whereas 9.x and 10.x will receive security, bug fix and feature updates.Regarding the way they’re displayed on the website, they’re listed by Release Date (most recent at the top). The Versions are self explanatory. If you’re currently running 9.x then you’re running CR. You want to go to 10.x, so remove the 9.x .vib and install the 10.x .vib. Then upgrade your VMs with the appropriate driver (442.06 assuming you go for 10.1) included in the package.RegardsMGWow, thanks for the long answer. Nice explanationPowered by Discourse, best viewed with JavaScript enabled"
14,tesla-m40-1gb-tlb,"Is there any way to patch resizable bar compatibility to Tesla Maxwell GPUs or any other way to bypass/workaround the M40’s 1GB  translation lookaside buffer (TLB) limitation?Powered by Discourse, best viewed with JavaScript enabled"
15,tesla-m60-tensorflow-cuda-compatibility,"It is my understanding that the Tesla M10 is mainly developed for multi-device application support etc. We are thinking about purchasing this GPU for deep learning purposes. We have very high memory data so it would be very useful.I have reviewed a lot of documentation online but it’s not clear to me if this GPU can be used with the newest versions of cuda (v10+) and therefore keras and tensorflow. Tesla M10 is also 4 GPUs linked together, so it is possible to utilize the full 32GB of RAM when linked like this? Does nvidia forbid this in any way? Does the card work like 4 separate GPUs or one united one? And I have seen licensing for using it as a vGPU but if we are just connecting this GPU to one server and plan to use it only there, do we need a separate license for this (does that require GRID licensing for instance?)?Thanks for any help here!HiThe M10 is for entry level workloads, it’s not designed for DL. The CUDA Core count is pretty low, so you’d be better looking at other GPUs. Also, the 4 GPUs are separate, meaning 4 x 8GB, not 1 x 32GB. Even if you add all GPUs to a single VM, your application may use 4 GPUs but it will only make use of 8GB Memory total.For DL, at a minimum, you’d be better looking at either a P100 (16GB) or P40 (24GB) which are both high-performance single GPUs. As you’ve mentioned you use a lot of Memory the P100 might be a good choice due to using HBM2, whereas although the P40 has 24GB, it uses GDDR5 which has a lot less bandwidth, however it does have a few hundred more CUDA Cores (3584 vs 3840), so it depends which your workload makes more use of.If you use vGPU, then you need a license (probably vCompute (vCS)). However, if you install it in Passthrough then you can use the standard Tesla driver without the need for a license.Either option will be far superior to an M10.RegardsMGWow thanks you confirmed my suspicions for this GPU - seems like it is just not in the market for what we are thinking about. P100 and P40 are really out of our price range right now…we have been training on AWS and looking to get something in house for training and using AI in our current architecture. I am now leaning towards something like the Titan RTX…Can you explain why if P100 has less memory HBM2 makes it more desirable than GDDR5? Most past training was on a 4GB GeForce 745 or 16GB Tesla V100 on Amazon. We have a mix of 2&3D images so the local GeForce can do small batches of 2D but any 3D images needed to go on Amazon and still only process 1 image/batch.HiBecause HBM2 is much faster than GDDR5, so it depends how your application / workload uses the hardware. Typically you want to get data into the GPU and process it as fast as possible, so HBM2 would be better in this instance. If you needed more capacity than 16GB, then the P40 would obviously be better due to having a higher capacity. The V100 has HBM2 as well.The Titan RTX is a good GPU, just be careful of its cooling requirements when pushed hard for long periods. There’s a reason why the Quadro GPUs all have Blower fans …RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
16,add-nvidia-quadro-rtx-6000-to-vsphere-6-enterprise-plus-in-redhat-7,"Hi all,I want to add NVIDIA QUADRO RTX 6000 to VSphere (VMware vSphere 6 Enterprise Plus) and use it as a vGPU in many Linux Redhat 7.8. After using the following guide:Quickstart guide for installing NVIDIA® Drivers for Linux.I encounter this error in dmesg:NVRM:
The NVIDIA probe routine failed for 1 device(s).
None of the NVIDIA graphics adapters were initialized!
nvidia-nvlink unregistered the nvlink core major device number 242
nvidia-nvlink: Nvlink Core is being initialized, major device number 242
the nvidia gpu 0000:02:02.0 (PCI ID: 10de:1e30)
installer in this system is not supported by the NVIDIA 450.51.06 driver release
Please see ‘Appendix A - Supported NVIDIA GPU products’
…Should I use another NVIDIA driver, and is it possible to implement this scenario?Thank you in advanceBest Regards,
AshkanHi AshkanTo use vGPU, you’ll need to use a specific driver. You can register for an evaluation of it by following this URL: Virtual GPU (vGPU) Software Free 90Days Trial | NVIDIA which will then allow you to download the correct driver.You’ll also need a License Server to host the evaluation licenses, full details are available here (Quick Start Guide): NVIDIA Virtual GPU Software DocumentationRegardsMGThank you for your response. I have already Quadro vDWS	license (do we need an additional license?). Could you please help me to find which driver I need to solve the problem. According to the following link Nvidia 450.51 support Quadro RTX 6000:Download the English (US) Linux x64 (AMD64/EM64T) Display Driver for  Linux 64-bit systems. Released 2020.6.24Please let me know if there is any other way to extract additional errors from the system.Regards,
AshkanHiYou’re looking in the wrong place for the driver. You can download the correct driver from the same location that you obtained the vGPU license and license server installer from: https://nvid.nvidia.com/RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
17,question-about-90-days-test-quadro-vdws,"Hi, i know this can sounds dumb, but i’m preety new to this, sorry for anything, so here is my question:
i just applied for the 90 days test at this link: NVIDIA Enterprise Account Registration
My question is, this evaluation don’t provide an access to a virtual gpu cloud hosted by nvidia right? Just the license of a software to virtualize my own gpus that i already have it?
Thanks in advance, best regards.Hi,yes you are absolutely right. It’s just the licenses and access to download and activation section in Nvidias Licensing Portal for Nvidia vGPUs solution (license server, vGPU Manager and in Guest drivers etc) to test the different vGPU profiles on top of your very own vGPU capable physical GPUs with your supported Hypervisor.Download NVIDIA GRID datasheets, guides, solution overviews, white papers, and success stories. Watch GRID videos, webinars, and webcasts.Reference the documentation for all releases of NVIDIA virtual GPU software.All dependencies are listed there.Cheers,
Ron.Powered by Discourse, best viewed with JavaScript enabled"
18,implementing-a-for-template-kernel,"Hello,
I’ve been thinkering a lot with Cuda lately, and since the program I’m trying to migrate from serial-CPU to parallel-GPU is very complex an has many fors that could be parallelized, I wanted to create a ‘drop in’ template to parallelize all the fors.After trying out basically everything, the only approach I found that works is the following:It requires:And there is a distinction to be made between cudaFor and nestedCudaFor:The usage is quite simple as it uses C++ lambda syntax, you need to pass a simple lambda that receives the integer position between zero and the size you specify (0 <= index < size).
There are few extra constraints tho:In theory this implementation should also have almost the same performance of creating the kernel functions by hand, since cuda’s compiler should be expanding the template functions into the correctly typed ones during compilation (since this is the only reason it even works at all, compared to other shenanigans I tried, like valradic functions), and then you’re basically making the compiler write all the boring stuff in your place!I wanted to post this because I couldn’t find any implementation like this online and maybe it might be useful to someone else, but also because I’m curious if you guys know better ways to achieve this.Powered by Discourse, best viewed with JavaScript enabled"
19,hyper-v-2019-rdsh-2019-tesla-m10,"Hello,We are working on a new infrastructure which will contain 2 clustered Hyper-V 2019 hosts, each with 1 Tesla M10 board. They will be hosting 4x RDSH 2019 VM’s in a 50/50 workload.
As I have understood, for RDSH we would need the DDA function of Hyper-V and you can empower a maximum of 4 VM’s with a Tesla M10 (4 GPU per board) through DDA, which would suffice in case one host fails or is put in maintenance.The documentation is referring to vGPU types such as M10-1A and the maximum amount of vGPU’s for each GPU of a M10 (8 in the case of M10-1A). Does this mean it can support merely 8 RDSH sessions on 1 RDSH VM? Or is vGPU in this case referring to VDI VM’s? So the questions are as following:Thanks in advance.Hi s3,you are on the right track. You need to run DDA and you can use 4xRDSH with 1xM10. So you have 8GB of FB per VM and this should be sufficient for up to 30 CCUs depending on the use case and load. 60 CCUs should be easily doable with 4x RDSH VMs per physical host. In general I see 100 - 120 CCUs per M10 in other customer deployments.
vGPU 8.0 does support Server 2019!Hope this helps.regards
SimonI have a question, where does one find the drivers to install an M10 when passed through using DDA.  Or do we need to get an enterprise license/trial to download these.M10 requires licensing and therefore you can only get the drivers in the licensing portalPowered by Discourse, best viewed with JavaScript enabled"
20,w115-panic-in-progress-ungrabbing,"Hi,We used 4 tesla m10 with svga on esxi6.7 but we have sometime this panic :
W115: Panic in progress… ungrabbingBy the link you find the dump file and log
https://sharing.provencale.lu/sharing/xMG9iJmOdHave an idea of the root cause ?thanks, jeromePowered by Discourse, best viewed with JavaScript enabled"
21,error-in-cuda-c-program,"Hi
I am trying to learn Cuda C programming. I have successfully written a code involving many matrix operations.  For matrix size = 256x256, my program is working. when I used matrix size = 512x512 then it gives me the following error message during compilation-CUDA error at TBS_GPUcode.cu:244 code=700(cudaErrorIllegalAddress) “cudaMemcpy(d_shirinR, shirinR, mem_size1, cudaMemcpyHostToDevice)”I shall very much appreciate if one can help me how to resolve this issue.The specifications of my machine is attached.
GPUDetails.pdf (38.0 KB)Ratan K Saha
IIIT AllahabadPowered by Discourse, best viewed with JavaScript enabled"
22,does-grid-vgpu-on-a100-must-support-sr-iov,"I have deployed vgpu on A100 and  run “systemctl start nvidia-vgpud”.But there is no “mdev register” in dmesg and no mdev_bus dir in /sys/class/. After I run “/usr/lib/nvidia/sriov-manger -e ALL”, vgpu works.Does grid vgpu on A100 must support SR-IOV? I follow the latest document “2.11.2.1. Creating a Legacy NVIDIA vGPU on a Linux with KVM Hypervisor”, it can also support vgpu without sriov.Powered by Discourse, best viewed with JavaScript enabled"
23,issue-in-vgpu-setup-in-ubuntu-20-04-3,"Currently, I am trying to set up ""vGPU "" in Ubuntu following Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software Documentation.GPU model : “NVIDIA RTX A6000”
OS: “Ubuntu 20.04.3 LTS (Focal Fossa)”
Kernel: “5.11.0-41-generic”
Motherboard model: X12SCA-FAm able to get output for nvidia-smi vgpu command executionBut while trying to create vGPU through /usr/lib/nvidia/sriov-manage -e ALL no mdev devices are getting created.
As well as not able to see mdev_supported_types directory in /sys/bus/pci/devices/0000:01:00.0 path.How to get mdev_supported_types, let me know if any missing modules.Please post the full output from nvidia-smi -q
I assume you run the A6000 in the wrong mode. Keep in mind that this is a workstation GPU and needs to be switched into DC mode with modeselector tool to make it work with vGPU!hope this helps@sschaber ,
Do I need to follow gpumodeswitch User Guide :: NVIDIA Virtual GPU Software Documentation for “NVIDIA RTX A6000”. Because in this page I came across supported products as “Tesla M60” and "" Tesla M6""Hi, not GPUModeswitch but mode selector tool. Totally different story.
As expected your GPU is running in wrong mode. You need the BIG BAR (64GB) size instead of 256MB@sschaber ,I want to create “C-series	Compute-intensive” vGPUs, for that, I need to set “Physical Display Ports Disabled” .currently I see the following options.Also, I don’t see that “(64GB)” optionphysical_display_disabled is the right option. Check nvidia-smi -q afterwards and you will see the BIG BAR1 size :)@sschaber I have uninstalled vGPU manager and executed ./displaymodeselector  --gpumode compute and received the below message.Currently, server is stuck in PCI Bus Enumeration for quite a long time and not booting up ;( does it take quite a long time.Not sure if the message above is related to mode selector.  What hardware (OEM) are you using? I assume/hope you have a onboard GPU for serving as primary GPU. Otherwise you won’t be able to boot anymore. You always need to have a second GPU (onboard GPU) to serve as the primary display.@sschaber
Yes, I am using X12SCA-F supermicro motherboard. Supermicro X12SCA-F Motherboard ATX Single Socket LGA-1200 (Socket H5) for Intel Xeon W-1200 Processors | Wiredzone.Also, I am using IPMI to login system and no monitors are connected to actual hdmi/vga port.OK, sounds good. SR-IOV also needs to be enabled in BIOS to support the Ampere GPU in datacenter mode.
Are you still stuck or can you boot properly?@sschaber Yes, SR-IOV is already enabled in BIOS and still it’s stuck in the same DXE--PCI Bus Enumeration screen. Not even boot selection etc… are getting displayed.Already tried power off/power on from IPMI but no luck.@sschaber
Looks EFI setting being chosen for PCIe/PCI bios setting and made it to legacy. Now system booted successfully & I was able to create the mdev devices following Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software DocumentationNice to hear it’s finally working!@sschaber
After attaching vGPU through virsh edit command, while booting vm its displaying Failed to set iommu for container: Invalid argument nvidiaDo we need to add any specific grub or module in the VM?Below is the detail from hypervisor HOST with vGPU manager installed.Also, can you please share if any specific BIOS setting reference for the Hypervisor host?Hi, unfortuantely we cannot provide any details on the BIOS settings necessary as this depends on the OEM. They need to provide the settings required. But you could check this (maybe also relevant in your case):
https://enterprise-support.nvidia.com/s/article/PCIe-AER-Advanced-Error-Reporting-and-ACS-Access-Control-Services-BIOS-Settings-for-vGPUs-that-Support-SR-IOV@sschaber ,While I execute /usr/lib/nvidia/sriov-manage -e ALL found below in syslog. Any inputs on this to resolve or can be ignored?@sschaber ,
For A6000 GPU-related issue, I have reached OEM for BIOS settings and waiting for a reply.
Based on Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software Documentation document, I would like to confirm similar to A6000 for A5000 GPU we need to change the GPU mode using “displaymodeselector tool” right.
I tried using displaymodeselector tool but end up with a error message saying Specified GPU mode not supported on this device 0x2231.
Requesting for your guidance.You’re right. A5000 also needs to be changed into DC mode with modeselector tool. These are the 2 workstation GPUs that can be used for vGPU after mode change@sschaber
Thanks for the confirmation.
as mentioned in the message it’s not working out.But in this A5000 GPU server, the host OS is Centos Stream 8. Do that matter or suspect something else?Powered by Discourse, best viewed with JavaScript enabled"
24,gpu-passthrough-help,"Dear members,We are implementing NVIDIA A40 GPU on each of our 5 x ESXi Hypervisors to be allocated as Passthrough to a Single VM.
Will GPU passthrough to a single VM allows us to migrate (while GPU connected ) to other nodes?
If no, then is vGPU the only solution?also, does A40 work with ESXi 8.0a?All help appreciatedthanks againPowered by Discourse, best viewed with JavaScript enabled"
25,nvidia-smi-dmon-sm-and-mem-utility-both-have-a-sudden-decreaset,"
screenshot865×510 14.4 KB

SM and Memory utility both have a sudden decrease, then they can recover in next second, but it will cause a long time processing latency about 500 miliseconds.Hello,Welcome to the NVIDIA Developer forums! You posted in the feedback category, unfortunately, there is no one from support monitoring this section.Please provide more details of your issue and how it relates to Nvidia products, platforms, etc, and I will move this to the correct forum.Thanks,
TomThanks for your suggestions. We use Nvidia Tesla T4 GPU, PCIe x 8, everything goes well if we run gpuburn for stress test. But if run some application on them, we will occasionally get the latency, then see the utility monitor show as the screenshot. It looks like one processing frame drop. We don’t know it is related to user application or something else, hope we can get some help here for troubleshooting.
In our application, one server take two Tesla T4 PCIe x8 (Gen3) per GPU, but the bandwidth looks enough: average 1,200 MB/s, peak value is 1,500 MB/s

image1801×308 108 KB
Thanks. I am moving this to the Tesla Boards category for better visibility.Powered by Discourse, best viewed with JavaScript enabled"
26,switch-driver-between-nvidia-virtual-pc-and-nvidia-workstation,"Hi everybody,
How can choose which licence type I want when I generate a token frome licence portal ?
I am on the 3 month trial and should have access to vWS and vPC but I get only vPC licence:The license aquired depends on the vGPU profile assigned to the VM. You assigned a B profile, so a vPC license is aquired. Adding a Q profile will aquire a vWS licenseit works like a charm, thanks for the hintThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
27,gpu-accelerate-one-rdsh-windows-server-2019-on-vmware-essentials-plus,"Dear NVIDIA experts.Since Windows Server 2016/2019 RDSH we are experiencing high CPU load with at many customers, with the same amount of users, where Server 2012R2 had no problems at all.
Trying out and talking a lot with others, we’ve run into the result, that 2016/2019 simply needs GPU performanceNow we want to accelerate NORMAL RDSH users (no CAD application, etc.) on ONE RDSH host with NVIDIA GPU performance at the minimum level of at least license costs (so NO GRID, NO VMWare Enterprise plus if possible).
As Hypervisor we run VMWare 7.0 (Essentials Plus license).
We know without GRID and VMWare Enterprise plus, we can only share the full GPU direct to the VM, and lose also functions like VMotion, Snapshot, etc.We’ve checked the VMWare Compatibilty guide, and the
TESLA T4
would be supported in our Hardware/VMWare constellation with vDGA, so far. So we’ve already put a T4 to one of our VMWare hosts, and it’s recognized. But now we have some questions:HiYou’re using the wrong GPU.If you want to use any Tesla GPU with Graphics, you’ll need to pay for that feature. If you don’t want to pay for any licenses, you need to use a Quadro GPU in Passthrough, then you can use the standard Quadro driver from the public website.You need to configure the default Graphics adapter and you can do that with a GPO.RegardsMGHi,Sorry for that delay, didn’t got the notification.
So TESLA GPU is only possible with GRID implementation and licenses, right?For our purpose (one 2019-RDSH, fixed to one VM 7.0 ESXi host), would you say the Quadro adapter is the better choice, if we just experience high CPU load, because 2016/2019 seems to expect GPU for a lot of things?
Would be a NVIDIA Quadro RTX4000 be usable WITHOUT GRID, so for our purposes?Another thing, I’m confused: How can you change the default graphics adapter?
I just found the GPO, which tells RDP using the default graphics adapter, but not how to define a NVIDIA card as the default graphics adapter (instead of the VMWare one)And a second question using GRID licenses:Of course we would like to pay for the GRID licenses as they are not that expensive.
But is there actually any method, using the T4 with GRID WITHOUT a VMWare Enterprise license?In the moment we just have VMWare vSphere 7 Essentials Plus licensed at the customer. And the really expensive seems to be the VMWare Enterprise license, not the GRID itself.Publishing the T4 just to one VM, limited to one ESXI host wouldn’t be the problem for us. As well, not having VMotion available or that memory has to be taken the full amount as reserved.Because upgrading the license to VMWare Enterprise is the really expensive topic here, i think.Or what would you recommend?HiYes, the RTX4000 will be fine for initial testing, but it only has 8GB of framebuffer, this may be ok depending on your workload and user density, but it will be the first thing you max out.You don’t need to explicitly define the Default Graphics Adapter, just configuring the GPO will be sufficient.If you run the T4 in Passthrough, you should be able to use the vGPU driver with it and then license it accordingly (QvDWS / vApps / vCS) per CCU depending on your workload. As you’re not virtualizing the GPU, you won’t need (VMware) Enterprise Plus licensing. Obviously, you’ll then run in to all the usual limitations of not virtualising, but at least it should work.RegardsMGHi Mr. Grid,So in our case I think you would recommend using the T4, as there is a ""cheaper"" way to use it without VMWare Enterprise Plus, as you described, and in case it’s too less, we still have the option to use more complex GPU virtualization scenarios like cascading the T4 and use GPU virtualization with Enterprise plus license, right?I’m a little bit afraid of the RTX4000, because you can find some informations of crashing DWM.exe, if there are more than 15-30 users on a RDSH, so it could be a one-way-street, with problems:Microsoft Q&A is the best place to get answers to all your technical questions on Microsoft products and services. Community. Forum.Or is there a third way, you could recommend to us in our case?Hi,We’ve successfully passthrough the T4 to the GRID driver in Windows Server over ESXi 7.0 without VMWare Enterprise license
GPU is responsable and GRID licensing is working.
Just a last question:In the PCI Device passthrough-section of ESXI-host I have 32 device IDs from 1 T4 card.
First of all, I cannot select all of them for passthrough, but is it enough to select ONE device ID, and the whole GPU is addressed to my VM?
And how can I check, that the whole GPU performance is available on my VM?
830×376 45.5 KB


832×600 53.2 KB
HiIf that link is the only source you have of a reported issue with the RTX4000, then I really wouldn’t worry about it. Besides, with only 8GB of FB and 30 users crammed on to it, the user you’ve linked to is probably running out of Framebuffer which is causing his issue. He states he tested with lower resolutions compared to his production ones. No idea why you’d test with one use case, then use a different one in production? …For the T4, adding just one of them will be sufficient. You can test whether it’s working by using tools like GPUProfiler: https://github.com/JeremyMain/GPUProfiler/releasesRegardsMGHi,Thank you, so checking one T4 hardware ID in the passthrough section is sufficient.Regarding dwm.exe there are several issues reporting crashing dwm.exe with RTX4000 like also:1 vote and 2 comments so far on Reddithttps://social.technet.microsoft.com/Forums/lync/en-US/6779b586-c158-491c-b76b-353d5a490642/server-2016-rds-connections-maxing-out-and-crashing-dwmexe?forumIn the meantime, ourself we experienced crashing DWM.exe, with T4 passthrough and GRID driver, when around 50-55 users are logged in to the server, and GPU memory of 15 GB is nearly used completely, that’s the time, when dwm.exe crashes.
Is there any possibility to avoid that? If we put a second T4 into the system, and passthorugh again, we can use both T4 and the double of memory, over the GRID driver, and should be able to avoid that crashing dwm.exe, or not?HiYou can’t put 2x GPUs in the same VM and split the load across the GPUs, that’s not how RDSH works. You’ll need another VM and run the additional T4 in Passthrough with that. Then you’ll need to load-balance the VMs so you get an even user / workload distribution.RegardsMGOkay, so that won’t solve my problem.
What’s about that crashing dwm.exe? Is it actually connected to the size of the buffer, and if the buffer is full or not, or is it about something else, which won’t be solved with a SINGLE GPU with 32GB memory for example?
Offloading the user to two RDSH will be a solution of course too, but we normally would have just one…Btw: Are you sure, RDSH is not supporting multiple GPUs?
Because at Microsoft they tell, loadbalancing from multiple GPUs presented to the OS is supported since Server 2019
WhatsApp Image 2020-12-14 at 12.25.09695×492 65.9 KB
Yes, I’m sure. Try it and see for yourself if you like :-)Is 50 concurrent users on a single VM not enough? The whole idea of this is that you then have multiple VMs of the same spec running on the host and scale out across the physical host. With most modern servers supporting at least 6x T4s, if not more, that would be 300 concurrent users per host, assuming you didn’t run into CPU or Storage contention before hitting that number.RegardsMGI’ve built a lot of VM infrastructure for high density deployments in data center hosting environments. The amount of RAM and/or IOPS are always the first two things to run out of if unless you solve for both with providing ample amounts of RAM and IOPS with with SSD or NVME disks. You should be quite happy with 50 concurrent users on a single VM honestly. For high density, you can push it, but you need more physical resources to realistically accommodate that requirement. You’re trying to push Niagara Falls through a garden hose there.Powered by Discourse, best viewed with JavaScript enabled"
28,w10-1809-stability-issues-driver-update,"Which component is responsible for the crash? dxgkrnl.sys?Yes!Probably caused by : dxgkrnl.sys ( dxgkrnl!memset+a4 )
km:av_invalid_dxgkrnl!memset->
…
PAGE_FAULT_IN_NONPAGED_AREA (50)
Invalid system memory was referenced.  This cannot be protected by try-except.
Typically the address is just plain bad or it is pointing at freed memory.
Arguments:
Arg1: ffffae8bfa693000, memory referenced.
Arg2: 0000000000000002, value 0 = read operation, 1 = write operation.
Arg3: fffff80260e12324, If non-zero, the instruction address which referenced the bad memory
address.
Arg4: 0000000000000002, (reserved)
…Hi,we have the same issue on Citrix Hypervisor 8.0Regards
KorbinianHi,we have the same issue on Citrix Hypervisor 8.0Regards
KorbinianDo you have a Citrix case number we can point at when opening a case there ourselves?Any news about this issue? I am experiencing the same problem and can reproduce it every time.
I changed the screensaver timeout to 5 minutes. After unlocking the VM crashes immediately.
The crashdump also says: ""AV_INVALID_dxgkrnl!memset""Details about our environment:
Citrix VDA 1903 (connected to Citrix Cloud)
Windows 10 1809
VMware vSphere 6.7 Update 2
NVIDIA GRID vGPU grid_m10-1b
NVIDIA Driver version 425.31""C:\Program Files\Citrix\ICAService\NvFBCEnable.exe"" -checkstatus gives me the result that FBC is disabled. After enabling FBC (-enable paramater) I cannot reproduce the issue anymore. I will do some further testing with this setting.The Citrix documentation says this: GPU acceleration for Windows single-session OS | Citrix Virtual Apps and Desktops 7 2206[i]Install and upgrade NVIDIA drivers
The NVIDIA GRID API provides direct access to the frame buffer of the GPU, providing the fastest possible frame rate for a smooth and interactive user experience. If you install NVIDIA drivers before you install a VDA with HDX 3D Pro, NVIDIA GRID is enabled by default.To enable NVIDIA GRID on a VM, disable Microsoft Basic Display Adapter from the Device Manager. Run the following command and then restart the VDA: NVFBCEnable.exe -enable -noresetIf you install NVIDIA drivers after you install a VDA with HDX 3D Pro, NVIDIA GRID is disabled. Enable NVIDIA GRID by using the NVFBCEnable tool provided by NVIDIA.To disable NVIDIA GRID, run the following command and then restart the VDA: NVFBCEnable.exe -disable -noreset[/i]Hi JP,I don’t think this is relevant here. I cannot reproduce the issue no matter if I run NVFBC enabled or disabled. This is most likely a timing issue with ICA idle.
In addition Citrix changed the capture mode from NVFBC to DDAPI with 1809 and CVAD1903…HiI can replicate this consistently with 1809 in my Lab (ESXi 6.7 U2 > Clean build of W10 1809 with all Windows Updates > CVAD 1906 > vGPU 8.0 with QvDWS). The moment I lock the VM, it crashes.I’ve also tested the exact same configuration with W10 1903, and although vGPU 8.0 with 1903 is currently unsupported, this crashing issue does not occur.You have a couple of choices … Either stay on 1803 and be supported without the issue, or if you really need to upgrade, move to 1903 currently unsupported but (from my tests) working and in preparation for the next vGPU release. I’ve tried 3D Apps on 1903 and had no issues with stability or performance and due to NVIDIA’s quick release cycle, it shouldn’t be too long before a vGPU upgrade comes along that will support 1903 …RegardsBenWith the above in mind, vGPU 9.0 has just been released, and this does have support for W10 1903 if you wanted to move to it.I’ve tested W10 1809 with vGPU 9.0, and for me, the issue still remains. So my recommendation would be to skip W10 1809 and go to W10 1903.RegardsBenOnce again:
This is not a vGPU issue so independent from vGPU version. It can only be reproduced with Citrix stack involved and Citrix is already further investigating.
@Ben: Thanks for testing with 1903 as we now have at least a workaround until Citrix provides a fix for 1809.regards
SimonThanks! I can confirm 1803 and 1903 are working fine without BSODs.W10 1903 works for us, too - even with K1 and much older drivers…Regards,
'docI am running W10 1809 and Driver 8.1.940. I still have freeze issues with multi monitors.
Going to W10 1903 is not option right now. Does  anybody if there will be a updated driver?regard,FlorisHi Floris,as mentioned above this issue is related to Citrix and not a NV driver issue. So how should this be fixed with an updated driver? You should contact Citrix if you cannot move to Win10 1903EDIT: 1809 still has an issue. We’re going to stick with 1607LTSB or 1903.We ran into a problem with dxgkrnl.sys causing a BSOD. Also Windows 10 1809 with driver version 431.02.We created a support ticket at Citrix. If we have a solution, i’ll post it here.For your reference:
Xendesktop 7.15CU4
Nvidia grid M10, driver version 431.02
VDA 1906.2
Windows 10 Enterprise 1809
Vmware tools 10346
ESXi 6.7.0 13981272HiAny updates on this? Did Citrix provide solution?We have the same issue on the following config:
XenDesktop 1906.2 and 1909
NVidia Tesla M10, driver versions  418.66, 430.27 and 430.46
VDA 1906 and 1909
Windows 10 LTSC 1809
VMWare Tools 10346
ESXi 6.7.0 14320388ThanksWe tried 3 different versions (8.1, 8.2 and 9.1) of the nvidia driver and also implemented the TDRdelay regisry key, but still no luck.Nvidia told us there are indeed more customers with the BSOD problem and 1809. The advice is the try version 1803 and 1903 because the problem does not exist with these versions. That’s why we’re pointed back to MS. We’re not in the position the switch to these versions because we have to test our entire landscape again and these versions have a shorter support period than the 1809.We’re thinking about starting a parallel traject with the currently unsupported 1909, rather than to wait for a solution./edit 21-11-2019
currently testing 1909 with driver 8.2Does anybody know if this is fixed in the new 9.2 release?https://docs.nvidia.com/grid/9.0/grid-vgpu-release-notes-vmware-vsphere/index.html#bug-2678149-sessions-freeze-randomly-xid-31We have tested Windows 10 1909 for a week now and we don’t have the BSOD anymore.Does anybody know if this is fixed in the new 9.2 release?https://docs.nvidia.com/grid/9.0/grid-vgpu-release-notes-vmware-vsphere/index.html#bug-2678149-sessions-freeze-randomly-xid-31Yes it is!!!Powered by Discourse, best viewed with JavaScript enabled"
29,purchase-advice,"Hello,  I got a Dell R420 for free and thought I could run Ark gaming servers on it.  I cannot because Ark on Windows requires running the GUI which requires running with a GPU.  Even with all 24 cores as a test, it ran horribly and crashed more than ran.  vGPUs seem to be the way to best achieve this.  My goal is to run 14 VMs with 12 gaming VMs with a single app running.  The OS has to be Windows10 as my kids play on Xbox and I play on PC.  I’ve read around and have a worry that what I don’t know could cause me to waste time and money.  So I’m asking a knowledgeable group.  I’ve told ya the goal and now what I believe I should buy.  Please inform me on where my knowledge needs to be adjusted, thanks.This is personal usage and so high end is not where I am going when buying this server.  Even going the server route for gaming is kinda high end if you think about it.  It is surely cheaper to rent than do it this way.  But this way I get to have side VMs that I do need anyways.  So…1). Which license model?  I believe I should go with GRID application licensing.  $10/yr for each of the 12 vGPUs.Dell R720 with 2x 2.4 GHz 8-core or higher GHz
16GB RAM per VM2). Which card?  GRID K1 Kepler using 1GB application profilesYes, K1 is an older card.  Given my usage, doesn’t this make sense to use this card when going $2k for a card isn’t in the arena?  I simply need the cheapest way to use vGPUs and this seems to be possible.  But, IDK.3). Which VM host OS?  I used ESXi before with light usage.  No expert here.  But as my posiible card choice is a K1, am I best to go Citrix?  Or is ESXI just fine using older NVIDIA vGPU driver inside of VmWare VMs?  It seems the GRID 4 version is the latest driver and which Hypervisor best supports that version comes from people’s knowledge, not marketers or how to videos.  History of tech is of value.Where am I wrong on my setup?  What are you thoughts?  I appreciate your time, thank you!!!Yes, K1 is an older card. Given my usage, doesn’t this make sense to use this card when going $2k for a card isn’t in the arena? I simply need the cheapest way to use vGPUs and this seems to be possible. But, IDK.YOU can also get to know more about from https://apkraid.com/Here are some of the requirements for dedicated server hardware that will help you ensure you can host the latest titles. These should be the basics for most 32-player games, but you’ll likely need more capacity to play 64-player games or higher. Please Note: If there are more players on the server, the more pressure will be on the hardware.  jigsaw puzzlePowered by Discourse, best viewed with JavaScript enabled"
30,xendesktop-on-vmware,"we are ordering hardware with two xeon CPU and one v100 GPU.we are thinking about using the server to host both VGPU and non-vGPU desktops.can  a single GPU  be shared across virtual desktops on both the CPU? or do I need a GPU on each CPU PCIE bus.awaiting your valuable advise.
ThanksHiYou can share the GPU across both CPUs.As you’ve touched on, there can be efficiencies in mapping specific CPUs / CPU Cores to a GPU, however, what you’re looking to do is fine.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
31,proper-installation-of-grid-k520,"Hi - I’m new here. I’ll try to keep this short…I currently have a GRID K520 in a server that’s running ESXi 6.5U3. I’d like to know the following:I’m trying to make sure I don’t skip over anything, but am not sure if I’m doing this right.The reason why I ask this is due to the fact that when I looked into the GRID K2 and K520, the K2’s installation process involved drivers for both the hypervisor server and the VM guests, and GRID software for the server. However, I was not able to find the same files for the K520. Perhaps I missed something?Powered by Discourse, best viewed with JavaScript enabled"
32,hello-world-can-vgpu-uses-gpus-from-multiple-machines,"Hello world! First post here.In a two-node HCI structure, if each node is a bare metal with vGPU capable GPUs, can vGPU profiles use resources from both bare metals?Thanks!Hi,
You cannot use vGPU with baremetal at all. In addition, it is not possible to assign GPU resources from different hosts to a single VM.Regards
SimonThanks.I was meant to say each bare metal’s GPU. Bare metal OS is EXSi.The use case is a 2-node HA cluster for remote CAD work. Identical bare metal spec.  Each machine has one GPU. Perhaps better to have two GPUs on the same machine? But what if that machine fails?Powered by Discourse, best viewed with JavaScript enabled"
33,create-license-server-vgpu-on-linux,"hello, I have availed 90 day trial version and I am stuck in downloading license server on linux
please help me out…There are videos for window and  didn’t find any for linux.Hi,could you please be more specific what you are going to achieve?  There are different license servers available. You could use the legacy licserver or the new appliance which is always a linux template that you would import.
Here the documentation for the legacy:
https://docs.nvidia.com/grid/ls/2021.07/grid-license-server-user-guide/index.html#installing-nvidia-grid-license-server-linuxBTW: You find the software for the licservers in the NV portal when you are in software downloads at the right top corner (additional software).
regards
Simon
Screenshot (374)1920×1080 295 KB

please explain me whats the issue hereWhat GPU are are you using? As you can see from the error message that the installer didn’t detect a capable GPUwhat is the meaning of capable gpu…i am unable to download driver 472.98  but my system is capable as it says the hardware needed is windows10 - 64bit  or windows 11Please let me know what GPU we are talking about. Capable=supported GPU. The driver needs to support the DeviceID for the given GPU, otherwise the installer won’t work!DeviceID for the given GPU, otherwise the installer won’t work!can you tell me what is the requierement of architecture for vgpu 90 day free trial.
AND DO YOU MEAN DEVICE ID == MAC ADDRESS OF MY DEVICEHi,
It seems you are not really aware of the vGPU concept. You need a GPU that supports vGPU like T4, A40, A16 or others. In addition you need the software from NV portal which you already have.
Why don’t you tell us which GPU you have in your system?
I’m sorry but I cannot help further if you don’t answer the questions.Regards Simoni have geforce mx130…Ok thanks. Geforce is not supported nor do I understand what you tried to achieve with vGPU.
This is a technology to share GPU performance of professional or datacenter GPUs in server systems. So you can serve multiple VMs with a GPU slice called vGPU profile.
Hope this helps for better understandingokay
…can you explain how can I install omniverese as I dont have rtx gpusOmniverse won’t work either without a RTX GPU. You would need a GPU like A5000 first or at least a Geforce 3080 or 3090. Omniverse requires a lot of GPU memory to run.on cloudso for vgpu we must have a system with very high gpu like t4,a100 and from there it can serve to vms createdCorrect!so if we take subscription of aws virtual workstation .  we need not to have gpu in our systemCorrect, but make sure to use the new offering with the A10G if you want to use Omniverse with this VMit would be much appreciated if you could share the linkSure. Please check the following offering:Amazon EC2 G5 instances are the latest generation of NVIDIA GPU-based instances that can be used for a wide range of graphics intensive and machine learning use cases. Thanks , but it is not available in our region mumbai,IndiaPowered by Discourse, best viewed with JavaScript enabled"
34,tesla-m10-driver,"Good afternoon,I am going to tell you about a problem I have with a customer and the situation in which I find myself, since Nvidia and PNY do not give me support for this card or for the use that my client wants to give him.The issue is the following:I have a clone computer which has a M10 card and a TITAN V card. This computer is used for scientific data processing and all kinds of files, ranging from gb to tb.The problem is the M10 graphic that the system does not recognize it, it uses an Ubuntu system, which in the nvidia panel if it reflects the 4 memory modules and if it recognizes the model of the card as TESLA M10.In the information tells me that in each module are entering 18w and that its use is 0%, the temperature starts normal 35 º, 40 º. As time goes by without any data processing the graphic starts to heat up by itself reaching a temperature of 90 ° then I decided to turn off the system as it did not seem normal and more with a passive cooling graphic like this.After a few minutes I start the computer and try to launch a process for both graphics, but this process only runs on the TITAN V in the tesla m10 still does not “recognize it”.For ease and compatibility I opted to change the disk and install a w10 from 0 clean to see if from Windows to get it to work.At the time of booting the desktop update the system to the maximum, I recognize the TITAN V and I download the Gforce to see if the tesla m10 I get from the panel nvida, I do not get. In the device manager it shows me the 4 memory modules of that card, but I can’t install any driver. The card starts to warm up on the desktop with virtually no stress for it.I tried this card in the 3 PCI available on the board and got the same result.Since from Nvidia and PNY tell me that these cards are only for vgpu and desktop virtualization and also have to be used in a certified servers and with a license of this type of “software”.My question in this post is, if there is any possibility to work with this TESLA M10 graphics card for scientific data processing?I have tried with other drivers to see if I could “fit” m60, m6, etc for Windows server and ubuntu on both platforms without any possibility or any result.Please if anyone has any information or if this card has a hardware lock which does not allow such use.Best regards and thanks!Translated with DeepL Translate: The world's most accurate translator (free version)Powered by Discourse, best viewed with JavaScript enabled"
35,nvidia-grid-vgpu-support-has-detected-a-mismatch-with-the-supported-vgpus,"I’m getting the following alert in VMWare Horizon 7.7:""NVIDIA GRID vGPU support has detected a mismatch with the supported vGPUs""All 4 of the ESXi hosts are:ECC is disabled across all hosts.nvidia-smi -q | grep -i virtualization
GPU Virtualization Mode Virtualization mode : Host VGPUnvidia-smi -q
ECC Mode Current : Disabled
ECC Mode Pending : DisabledThe hosts do have different GPU’s in, but it was my understanding that the GPUs didn’t have to be the same throughout each host.If anyone has any ideas it would be greatly appreciated.This error displays when your VMware cluster has ESXi hosts with different vGPU configurations. Say one host has an M10, and another host in the same VMware Cluster has both an M10 and an M60, this warning will show because they are different within the same cluster demarcation.A way to work around this is to create multiple clusters with homogeneous hosts in them. Or like in my lab, in my vCenter inventory, there’s 3 clusters, each only with one host, just for this reason.The error has no consequences whatsoever, so you can also just ignore it.Powered by Discourse, best viewed with JavaScript enabled"
36,assigning-each-cpu-with-a-gpu,"Hello,I am running computational fluid dynamics software PyFR on CUDA backend. My cluster has 8 A100 GPUs and two CPUs each node. What I want to do is to assign each CPU core with its own GPU to reach the best performance. After some googling, here is the procedure to do it in one node:This is working good. However, I need to run this with more nodes (ie two nodes). I changed my command to srun -n 16 --mpi=pmix --cpunobind=none ./script_gpu pyfr .... but this is not working. I tried srun without script which is working but not working with best performance. Advised by some discussions online I tried numactl rather than taskset but also not working. Here is the record of what I have tried so far:Does anyone have comments on this? I am a student in fluid dynamics so I am not very familiar with these. Can anyone give me some detailed explanation? Really appreciate any answer.Best wishes,
ZhenyangPowered by Discourse, best viewed with JavaScript enabled"
37,maya-2024-not-starting-in-aws-ec2-winserver-2022-ami-image,"Nice to meet everyone in the community. I am reaching out because we are doing a PoC using the AWS Marketplace Image Windows Server 2022 and the default installation of Maya 2024 crashes at startup with a blank splash window.Enabled tracing level in the log but it does not show anything relevant.Someone was able to install Maya 2024 on that image?Thanks2023-08-03 23:29:25.846 [O] Created AdlSdk Logger level [trace], API version [7.4.2.47]
2023-08-03 23:29:25.847 [T] CAdlsAdapter::Init()
2023-08-03 23:29:25.847 [T] CAdlSdkSocket::GetServiceAddress()
2023-08-03 23:29:25.847 [T] CAdlsAdapter::CustomizeWebUi()
2023-08-03 23:29:25.847 [T] CAdlsAdapter::InterlockedValidateExchangeState()
2023-08-03 23:29:25.848 [D] CAdlSdkSocket::GetServiceAddress(): url=[ws://127.0.0.1:50651/ws/v1/sdk?cryptversion=2]
2023-08-03 23:29:25.848 [D] easywsclient: connecting: host=[127.0.0.1] port=[50651] path=/[ws/v1/sdk?cryptversion=2]
2023-08-03 23:29:25.849 [T] CAdlsAdapter::Authorize()
2023-08-03 23:29:25.849 [T] CAdlsAdapter::InterlockedValidateExchangeState()
2023-08-03 23:29:25.849 [D] easywsclient: Connected to: [ws://127.0.0.1:50651/ws/v1/sdk?cryptversion=2]
2023-08-03 23:29:25.849 [T] CAdlSdkSocket::AdlsSocketThread()
2023-08-03 23:29:25.849 [T] CAdlsAdapter::Connected()
2023-08-03 23:29:25.921 [D] CAdlsAdapter::ProcessIncomingMessage() [{“msgId”:“9f3aafe4-1f7b-47d8-90dd-0040a9cda831”, “registerResp”:{“sdkId”:“SDK_FA6321C7-8EC4-4AC6-6FEE-82B962E53C4F”, “locale”:“en_US”, “errorInfo”:{“error”:false, “vendor”:“SERVICE”, “code”:0, “text”:“Success”}, “svcVersion”:“11.11.0.4128”}}]
2023-08-03 23:29:25.921 [T] CAdlsAdapter::ProcessRegisterMessage(): RegisterResp received
2023-08-03 23:29:25.921 [D] CAdlsAdapter::ProcessRegisterMessage(): Sending queued request…
2023-08-03 23:29:25.922 [D] CAdlsAdapter::ProcessRegisterMessage(): Sending queued request…
2023-08-03 23:29:25.954 [D] CAdlsAdapter::ProcessIncomingMessage() [{“msgId”:“MSG_53D3EDE0-1C6C-4F9A-4140-6784972DE1E6”, “launchExe”:{“path”:“C:\Program Files (x86)\Common Files\Autodesk Shared\AdskLicensing\13.2.0.9150\AdskLicensingAgent/AdskLicensingAgent.exe”, “args”:“-i 0d2ad74f-bbbc-45d3-4cb6-db3dd802c801 -c 2”, “envVar”:{“ADLSDK_LOG_LEVEL”:“T”, “ALLUSERSPROFILE”:“C:\ProgramData”, “APPDATA”:“C:\Users\Administrator\AppData\Roaming”, “AWS_EXECUTION_ENV”:“EC2”, “CLIENTNAME”:“MacBook-Pro-de-”, “COMPUTERNAME”:“EC2AMAZ-LP7VUGK”, “ComSpec”:“C:\Windows\system32\cmd.exe”, “CommonProgramFiles”:“C:\Program Files\Common Files”, “CommonProgramFiles(x86)”:“C:\Program Files (x86)\Common Files”, “CommonProgramW6432”:“C:\Program Files\Common Files”, “DriverData”:“C:\Windows\System32\Drivers\DriverData”, “EC2LAUNCH_TELEMETRY”:“1”, “HOME”:“C:/Users/Administrator/Documents”, “HOMEDRIVE”:“C:”, “HOMEPATH”:“\Users\Administrator”, “LOCALAPPDATA”:“C:\Users\Administrator\AppData\Local”, “LOGONSERVER”:“\\EC2AMAZ-LP7VUGK”, “MAYA_APP_DIR”:“C:/Users/Administrator/Documents/maya”, “MAYA_CONTENT_PATH”:“C:/Program Files/Autodesk/Maya2024/Examples”, “MAYA_LOCATION”:“C:/Program Files/Autodesk/Maya2024”, “MAYA_MODULE_PATH”:“C:/Program Files/Autodesk/Maya2024/modules;C:/Users/Administrator/Documents/maya/2024/modules;C:/Users/Administrator/Documents/maya/modules;C:/Program Files/Common Files/Autodesk Shared/Modules/maya/2024”, “MAYA_PLUG_IN_PATH”:“C:/Users/Administrator/Documents/maya/2024/plug-ins;C:/Users/Administrator/Documents/maya/plug-ins;C:/Program Files/Autodesk/Maya2024/bin/plug-ins”, “MAYA_REVERSE_FILEFORMAT_EXT”:“1”, “MAYA_SCRIPT_BASE”:“C:/Program Files/Autodesk/Maya2024”, “MAYA_SCRIPT_PATH”:“C:/Users/Administrator/Documents/maya/2024/scripts;C:/Users/Administrator/Documents/maya/scripts;C:/Users/Administrator/Documents/maya/2024/presets;C:/Users/Administrator/Documents/maya/2024/prefs/shelves;C:/Users/Administrator/Documents/maya/2024/prefs/markingMenus;C:/Users/Administrator/Documents/maya/2024/prefs/scripts;C:/Program Files/Autodesk/Maya2024/scripts;C:/Program Files/Autodesk/Maya2024/scripts/startup;C:/Program Files/Autodesk/Maya2024/scripts/shelves;C:/Program Files/Autodesk/Maya2024/scripts/others;C:/Program Files/Autodesk/Maya2024/scripts/AETemplates;C:/Program Files/Autodesk/Maya2024/scripts/unsupported;C:/Program Files/Autodesk/Maya2024/scripts/paintEffects;C:/Program Files/Autodesk/Maya2024/scripts/fluidEffects;C:/Program Files/Autodesk/Maya2024/scripts/hair;C:/Program Files/Autodesk/Maya2024/scripts/cloth;C:/Program Files/Autodesk/Maya2024/scripts/live;C:/Program Files/Autodesk/Maya2024/scripts/fur;C:/Program Files/Autodesk/Maya2024/scripts/muscle;C:/Program Files/Autodesk/Maya2024/scripts/turtle;C:/Program Files/Autodesk/Maya2024/scripts/FBX;C:/Program Files/Autodesk/Maya2024/scripts/mayaHIK”, “NUMBER_OF_PROCESSORS”:“48”, “OS”:“Windows_NT”, “PATHEXT”:“.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC”, “PROCESSOR_ARCHITECTURE”:“AMD64”, “PROCESSOR_IDENTIFIER”:“Intel64 Family 6 Model 85 Stepping 7, GenuineIntel”, “PROCESSOR_LEVEL”:“6”, “PROCESSOR_REVISION”:“5507”, “PSModulePath”:“C:\Windows\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files\WindowsPowerShell\Modules”, “PUBLIC”:“C:\Users\Public”, “Path”:“C:/Program Files/Autodesk/Maya2024/bin/Cg;C:/Program Files/Autodesk/Maya2024/bin;C:/Windows/system32;C:/Windows;C:/Windows/System32/Wbem;C:/Windows/System32/WindowsPowerShell/v1.0/;C:/Windows/System32/OpenSSH/;C:/Program Files/Amazon/cfn-bootstrap/;C:/Users/Administrator/AppData/Local/Microsoft/WindowsApps;”, “ProgramData”:“C:\ProgramData”, “ProgramFiles”:“C:\Program Files”, “ProgramFiles(x86)”:“C:\Program Files (x86)”, “ProgramW6432”:“C:\Program Files”, “SESSIONNAME”:“RDP-Tcp#0”, “SystemDrive”:“C:”, “SystemRoot”:“C:\Windows”, “TEMP”:“C:\Users\ADMINI~1\AppData\Local\Temp\2”, “TMP”:“C:\Users\ADMINI~1\AppData\Local\Temp\2”, “TMPDIR”:“C:\Users\ADMINI~1\AppData\Local\Temp\2”, “USER”:“Administrator”, “USERDOMAIN”:“EC2AMAZ-LP7VUGK”, “USERDOMAIN_ROAMINGPROFILE”:“EC2AMAZ-LP7VUGK”, “USERNAME”:“Administrator”, “USERPROFILE”:“C:\Users\Administrator”, “WF_IMF_CIN_CORRECTION”:“both”, “WF_IMF_CIN_WHITE_POINT”:“685”, “XBMLANGPATH”:“C:/Users/Administrator/Documents/maya/2024/prefs/icons;C:/Users/Administrator/Documents/maya/prefs/icons;C:/Program Files/Autodesk/Maya2024/icons;C:/Program Files/Autodesk/Maya2024/app-defaults;C:/Program Files/Autodesk/Maya2024/icons/paintEffects;C:/Program Files/Autodesk/Maya2024/icons/fluidEffects;C:/Program Files/Autodesk/Maya2024/icons/hair;C:/Program Files/Autodesk/Maya2024/icons/cloth;C:/Program Files/Autodesk/Maya2024/icons/live;C:/Program Files/Autodesk/Maya2024/icons/fur;C:/Program Files/Autodesk/Maya2024/icons/muscle;C:/Program Files/Autodesk/Maya2024/icons/turtle;C:/Program Files/Autodesk/Maya2024/icons/FBX;C:/Program Files/Autodesk/Maya2024/icons/mayaHIK”, “windir”:“C:\Windows”}}}]
2023-08-03 23:29:25.954 [T] CAdlsAdapter::IncomingAdlsMsg(): LaunchExe received
2023-08-03 23:29:25.972 [T] AdlSdk::CWinVerifyTrustOnFile::handleVerifyErrors: C:\Program Files (x86)\Common Files\Autodesk Shared\AdskLicensing\13.2.0.9150\AdskLicensingAgent/AdskLicensingAgent.exe is signed and the signature was verified
2023-08-03 23:29:25.972 [T] AdlSdk::CWinVerifyTrustOnFile::verifyPublisherInfo: Valid Autodesk publisher information found
2023-08-03 23:29:25.976 [D] CUtil::LaunchWinExe(): GetExitCodeProcess() succeeded with exit_code=[259] (STILL_ACTIVE) for pid=[9980]
2023-08-03 23:29:26.060 [D] CAdlsAdapter::ProcessIncomingMessage() [{“msgId”:“MSG_73629FED-41ED-4854-5865-BC9E3A0BB7AE”, “launchExe”:{“path”:“C:\Program Files (x86)\Common Files\Autodesk Shared\AdskLicensing\13.2.0.9150\AdskLicensingAgent/AdskLicensingAgent.exe”, “args”:“-r 0 -n /analytics/v1/connect?analyticsagentid=analytics-036c9126-76b1-40b9-6335-5b50286c0364 --no-gui -c 2 -i analytics-036c9126-76b1-40b9-6335-5b50286c0364”, “envVar”:{“ADLSDK_LOG_LEVEL”:“T”, “ALLUSERSPROFILE”:“C:\ProgramData”, “APPDATA”:“C:\Users\Administrator\AppData\Roaming”, “AWS_EXECUTION_ENV”:“EC2”, “CLIENTNAME”:“MacBook-Pro-de-”, “COMPUTERNAME”:“EC2AMAZ-LP7VUGK”, “ComSpec”:“C:\Windows\system32\cmd.exe”, “CommonProgramFiles”:“C:\Program Files\Common Files”, “CommonProgramFiles(x86)”:“C:\Program Files (x86)\Common Files”, “CommonProgramW6432”:“C:\Program Files\Common Files”, “DriverData”:“C:\Windows\System32\Drivers\DriverData”, “EC2LAUNCH_TELEMETRY”:“1”, “HOME”:“C:/Users/Administrator/Documents”, “HOMEDRIVE”:“C:”, “HOMEPATH”:“\Users\Administrator”, “LOCALAPPDATA”:“C:\Users\Administrator\AppData\Local”, “LOGONSERVER”:“\\EC2AMAZ-LP7VUGK”, “MAYA_APP_DIR”:“C:/Users/Administrator/Documents/maya”, “MAYA_CONTENT_PATH”:“C:/Program Files/Autodesk/Maya2024/Examples”, “MAYA_LOCATION”:“C:/Program Files/Autodesk/Maya2024”, “MAYA_MODULE_PATH”:“C:/Program Files/Autodesk/Maya2024/modules;C:/Users/Administrator/Documents/maya/2024/modules;C:/Users/Administrator/Documents/maya/modules;C:/Program Files/Common Files/Autodesk Shared/Modules/maya/2024”, “MAYA_PLUG_IN_PATH”:“C:/Users/Administrator/Documents/maya/2024/plug-ins;C:/Users/Administrator/Documents/maya/plug-ins;C:/Program Files/Autodesk/Maya2024/bin/plug-ins”, “MAYA_REVERSE_FILEFORMAT_EXT”:“1”, “MAYA_SCRIPT_BASE”:“C:/Program Files/Autodesk/Maya2024”, “MAYA_SCRIPT_PATH”:“C:/Users/Administrator/Documents/maya/2024/scripts;C:/Users/Administrator/Documents/maya/scripts;C:/Users/Administrator/Documents/maya/2024/presets;C:/Users/Administrator/Documents/maya/2024/prefs/shelves;C:/Users/Administrator/Documents/maya/2024/prefs/markingMenus;C:/Users/Administrator/Documents/maya/2024/prefs/scripts;C:/Program Files/Autodesk/Maya2024/scripts;C:/Program Files/Autodesk/Maya2024/scripts/startup;C:/Program Files/Autodesk/Maya2024/scripts/shelves;C:/Program Files/Autodesk/Maya2024/scripts/others;C:/Program Files/Autodesk/Maya2024/scripts/AETemplates;C:/Program Files/Autodesk/Maya2024/scripts/unsupported;C:/Program Files/Autodesk/Maya2024/scripts/paintEffects;C:/Program Files/Autodesk/Maya2024/scripts/fluidEffects;C:/Program Files/Autodesk/Maya2024/scripts/hair;C:/Program Files/Autodesk/Maya2024/scripts/cloth;C:/Program Files/Autodesk/Maya2024/scripts/live;C:/Program Files/Autodesk/Maya2024/scripts/fur;C:/Program Files/Autodesk/Maya2024/scripts/muscle;C:/Program Files/Autodesk/Maya2024/scripts/turtle;C:/Program Files/Autodesk/Maya2024/scripts/FBX;C:/Program Files/Autodesk/Maya2024/scripts/mayaHIK”, “NUMBER_OF_PROCESSORS”:“48”, “OS”:“Windows_NT”, “PATHEXT”:“.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC”, “PROCESSOR_ARCHITECTURE”:“AMD64”, “PROCESSOR_IDENTIFIER”:“Intel64 Family 6 Model 85 Stepping 7, GenuineIntel”, “PROCESSOR_LEVEL”:“6”, “PROCESSOR_REVISION”:“5507”, “PSModulePath”:“C:\Windows\system32\WindowsPowerShell\v1.0\Modules;C:\Program Files\WindowsPowerShell\Modules”, “PUBLIC”:“C:\Users\Public”, “Path”:“C:/Program Files/Autodesk/Maya2024/bin/Cg;C:/Program Files/Autodesk/Maya2024/bin;C:/Windows/system32;C:/Windows;C:/Windows/System32/Wbem;C:/Windows/System32/WindowsPowerShell/v1.0/;C:/Windows/System32/OpenSSH/;C:/Program Files/Amazon/cfn-bootstrap/;C:/Users/Administrator/AppData/Local/Microsoft/WindowsApps;”, “ProgramData”:“C:\ProgramData”, “ProgramFiles”:“C:\Program Files”, “ProgramFiles(x86)”:“C:\Program Files (x86)”, “ProgramW6432”:“C:\Program Files”, “SESSIONNAME”:“RDP-Tcp#0”, “SystemDrive”:“C:”, “SystemRoot”:“C:\Windows”, “TEMP”:“C:\Users\ADMINI~1\AppData\Local\Temp\2”, “TMP”:“C:\Users\ADMINI~1\AppData\Local\Temp\2”, “TMPDIR”:“C:\Users\ADMINI~1\AppData\Local\Temp\2”, “USER”:“Administrator”, “USERDOMAIN”:“EC2AMAZ-LP7VUGK”, “USERDOMAIN_ROAMINGPROFILE”:“EC2AMAZ-LP7VUGK”, “USERNAME”:“Administrator”, “USERPROFILE”:“C:\Users\Administrator”, “WF_IMF_CIN_CORRECTION”:“both”, “WF_IMF_CIN_WHITE_POINT”:“685”, “XBMLANGPATH”:“C:/Users/Administrator/Documents/maya/2024/prefs/icons;C:/Users/Administrator/Documents/maya/prefs/icons;C:/Program Files/Autodesk/Maya2024/icons;C:/Program Files/Autodesk/Maya2024/app-defaults;C:/Program Files/Autodesk/Maya2024/icons/paintEffects;C:/Program Files/Autodesk/Maya2024/icons/fluidEffects;C:/Program Files/Autodesk/Maya2024/icons/hair;C:/Program Files/Autodesk/Maya2024/icons/cloth;C:/Program Files/Autodesk/Maya2024/icons/live;C:/Program Files/Autodesk/Maya2024/icons/fur;C:/Program Files/Autodesk/Maya2024/icons/muscle;C:/Program Files/Autodesk/Maya2024/icons/turtle;C:/Program Files/Autodesk/Maya2024/icons/FBX;C:/Program Files/Autodesk/Maya2024/icons/mayaHIK”, “windir”:“C:\Windows”}}}]
2023-08-03 23:29:26.060 [T] CAdlsAdapter::IncomingAdlsMsg(): LaunchExe received
2023-08-03 23:29:26.076 [T] AdlSdk::CWinVerifyTrustOnFile::handleVerifyErrors: C:\Program Files (x86)\Common Files\Autodesk Shared\AdskLicensing\13.2.0.9150\AdskLicensingAgent/AdskLicensingAgent.exe is signed and the signature was verified
2023-08-03 23:29:26.076 [T] AdlSdk::CWinVerifyTrustOnFile::verifyPublisherInfo: Valid Autodesk publisher information found
2023-08-03 23:This is the most relevant line in my opinion:2023-08-03 23:29:44.998 [D] CUtil::LaunchWinExe(): GetExitCodeProcess() succeeded with exit_code=[259] (STILL_ACTIVE) for pid=[3272]Rings a bell?NVIDIA Driver version 536.25
4 tesla T4
Windows Server 2022 Datacenter
21H2
Build 20348.1787AMI IDvgpu16-nv-windows-server-2022-vWS-536.25-v202306270442 -prod-77u2eeb33lmrmami-0b1a9c7e04eae0510in us-east-1Powered by Discourse, best viewed with JavaScript enabled"
38,knowledge-base-contributing,"HowdyThis may be the wrong place to ask this, but figured I would try.My question is: Is there a place where end-users can contribute to a community knowledge base? I asking because I would like to contribute some installation information/steps on how to install the NVIDIA Licensing Server using Tomcat 10 and Java 18.0.1.1. The documentation provided in the .zip file is missing a bit of information on some of the issues I ran into while installing it. Below is a screen shot showing that I was able to get it working.If this not possible, than I appreciate any other alternative to share the steps and errors I ran in to while getting this done.Thanks!
image1235×375 56.2 KB
Powered by Discourse, best viewed with JavaScript enabled"
39,cant-find-vgpu-software-vgaming,"Hi,I am looking to build a gaming server capable of running AAA game titles at 1440p for 4 users concurrently. Thn clients will be used to stream the games from the server to the user/gamer.For the GPU hardware i have thought of using a single or two Quadro RTX 6000 alongside other mainstream computer hardware.I am trying to find information on vGaming vGPU Software for virtualization but couldn’t found any. Can you please help me on this ?vGaming is not an offical offering and therefore you won’t find it. You can try to test with QvDWS licenses instead to see if it would work as you would expect.regards
SimonThanks Simon for your replyOne think i would like to understand is the concept of Virtual Display Heads.Suppose a GPU supports 4 virtual display heads and 16 vGPUs in total. Does this mean that i can connect 16 thin clients with it or only 4 ?16 for sure.Powered by Discourse, best viewed with JavaScript enabled"
40,nvidia-vgpu-and-unified-memory,"Nvidia documentation states that unified memory is not supported from inside a VM with vGPU (only via pass-through mode).
I am trying to understand:Powered by Discourse, best viewed with JavaScript enabled"
41,grid-k2-linux-kvm-driver-proxmox-7-1-kernel-5-13,"Hi guys,
I have a server running proxmox 7.1 (debian os, kernel 5.13). I applied for the trial vgpu license but I am not able to install a driver. The latest driver refers to 367.xx linux legacy driver which I downloaded but crashes upon installation when trying to compile the kernel module.
Any hints how to make that work?The K2 GPU  you have reached its EOL and driver support ceased in 2018, the 367 branch was the latest to support this GPU.  I am not sure what is causing the crash you experiencing, however I would highly recommend you consider upgrading the GPU to a one which is still supported by our latest driver 470 branch. If then you still have any installation issues I will be able in a better position to help you.
Regards SimonHello @sschaberI just bought 2 pieces of K2 GRID, i’m facing this problem too in my lab, (PROXMOX 7.1, Debian)
I can’t find this driver version after a lot of research, can you help me to get this one?367 version, GRID K2Thanks!The is no kvm host driver available. You could use the GPU in Passthrough and try to run the public NV driver for K2. Keep in mind that this GPU is EOL for years now and same applies to the guest driver.Powered by Discourse, best viewed with JavaScript enabled"
42,grid-k1-dell-730-help,"Hi,I have a Dell 730 that i use for testing purposes and have acquired a cheap working Grid K1 GPU. Im running Windows 2016 Hyper-V Core and im wondering how i go about installing the drivers for this OS. I can`t seem to find anything although i found the two are compatible.If i can get it installed what would be my next steps to add it to a Windows 10 VM?Many thanksJamesHI James,As mentioned in a couple of other threads, NVIDIA GRID K1 and K2 GPU’s have been EOL for a couple or years now, so newer driver branches don’t support these cards anymore.
You could try searching for an older driver branch, for instance, see this (old) thread:
https://gridforums.nvidia.com/default/topic/1094/nvidia-grid-vgpu/nvidia-grid-k2-with-hyper-v-2016/post/3980/#3980Best,KoenraadHi,Thanks for the reply. I`ll take a look at the old threads and hopefully figure something out.Thanks for pointing me to the link.RegardsJamesPowered by Discourse, best viewed with JavaScript enabled"
43,rhel-8-not-booting-in-gui-mode,"I was updated install libelf-dev, libelf-devel or elfutils-libelf-devel packages .after that nvidia drivers installation completed.it not booting in GUI mode, it will run in CLI mode directly.i run below command it shows black screen only not showing anything.Dear Nvidia Team,After running the commandnvidia-xconfig -a --busid=PCI:59:0:0nvidia-xconfig -a --preserve-busidthen start x given after gpu card detected working but after restart the os get crash showinga start job is running for hold until boot process finishes up (14 minutes 5 seconds / no limit)waited fot 2 hours but no result not getting gui mode and command mode also .please resolve this attached screen shots .Dear Sir,I was done below steps today.1).restart the server with connecting gpu cable only, removed vga cable from server and check and same it will stopped at black screen only after restart2).changed power configuration to non-redundant in bois and restarted .same black screen comes after restart3).boot the server os into recovery mode as suggested steps from nvidia team and get gui screen comes with gpu card taken nvidia bug report and sos report copied
after restart it comes to same black screen comes not get cmd mode also we press ctrl+alt+f5 to get cmd mode.4).reloaded fresh os and loaded drivers as per nvidia team suggested from rhel site. after run below command it shows black screen only not showing anything.not get boot into gui modeplease find the attached report and resolve the problemPowered by Discourse, best viewed with JavaScript enabled"
44,a100-not-recognized-in-vm,"Hey everyone,we have two brand new Dell PowerEdge R7525 with one A100 each. We want to run VMware vSphere ESXi 7.0 Update 2 with MIG. We enabled SR-IOV in the BIOS, changed default graphics type to shared direct and installed NVIDIA-VMware_ESXi_7.0_Host_Driver  460.107-1OEM.700.0.0.15525992.
But after enabling MIG we aren’t able to get the GPU running inside the VM.
If we create a GPU and Compute instance using nvidia-smi on the ESXi and attach the GPU using the corresponding profil in the VM settings, the VM fails to start with the error message: "" vGPU ‘grid_a100-1-5c’ failed to create MIG GPU instance. Failed to start the virtual machine. Module DevicePowerOn power on failed. Could not initialize plugin ‘libnvidia-vgx.so’ for vGPU ‘grid_a100-1-5c’.""

image1018×301 28.9 KB
If we didn’t create the GPU and compute instance, we are able to boot the VM and see new GPU and Compute Instances on the ESXi, but if we try to install the GPU driver, the installer fails with the error message, that no compatible graphic card was found.What have we missed or are we doing wrong?Powered by Discourse, best viewed with JavaScript enabled"
45,gpu-in-chassis-not-being-seen-by-drivers,"We’ve been running two A100 GPUs in our system with no problem. We are now trying to get one of the GPUs to run in an extension chassis. The cards show up in lspci but the one in the chassis has no driver associated with it:The following is the nvidia-smi:The following is the dmesg output:Any recommendations at what to look at would be greatly appreciated. Please let me know if there is any other information that would be helpful.TonyThe following is a snippet from dmesg:Okay looks like the following solved my problem:You can swap the two GPU, if the nvidia-smi can show Tesla but no GT710, probably the GPU initialization is limited by BIOS configuration. No enough memory map space to support them.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
46,a5000-not-shows-mdev-supported-types-and-i-can-t-create-vgpus-instances,"I have installed the nVIDIA software in CentOS8.2 with kernel 5.10.131 with A5000  without problems;
I installed NVIDIA-Linux-x86_64-510.73.06-vgpu-kvm.run  ok, but when I list
/sys/bus/pci/devices/0000:86:00.0 there is not directory mdev_supported_types.
Some ideas? Can you help me?
I attempted /usr/lib/nvidia/sriov-manage -e 0000:86:00.0
but there is not directory mdev_supported_types.
I confirmed the iommu is on;

4a2047f3530a2db099b3f9ea5e20f512500×665 56.4 KB

and nouveau is forbidden;
lsmod |grep nouveau
the result is emptyAre you running the A5000 in the required mode (datacenter mode)?
Did you use the mode selector tool? If not, the GPU is still in workstation mode and won’t work as a vGPU device.NVIDIA Display Mode Selector Tool The NVIDIA Display Mode Selector Tool is a utility to set the desired display mode for NVIDIA A40, NVIDIA RTX A5000, NVIDIA RTX A5500, and NVIDIA RTX A6000 GPUs. Changing the display mode is supported for specific...Many thanks;
I changed the mode to  “physical_display_disabled”;

406bd5566e71728430073e646f0508c1381×628 21.6 KB

is correct?
but after reboot, there is not directory mdev_supported_types;Many thanks!
I changed the mode to “physical_display_disabled”;

406bd5566e71728430073e646f0508c1381×628 21.6 KB

is correct?
After reboot,but there is not directory mdev_supported_types.Powered by Discourse, best viewed with JavaScript enabled"
47,nvidia-gtx-1650-blackbox-squares-appear-in-game-cant-fix,"I have Asus G531 laptop and with Nvidia GTX 1650I try everything update lates driver, change thermal paste, format everything but still is same.Please I need help. I share videoNobady will answer ? Nvidia pls help. How i can contact ?Hi,Welcome to the NVIDIA Developer forums. You posted in the vGPU section of the developer forums, and your issue appears to be game related. I suggest posting in the GeForce forums where there are experts with gaming hardware.https://www.nvidia.com/en-us/geforce/forums/discover/Powered by Discourse, best viewed with JavaScript enabled"
48,using-a100-gpu-in-ubuntu-vm-vcs,"I have a server provided by IT with an A100 GPU. In the Ubuntu 22.04 VM I installed the according grid driver from nvidia, namely “NVIDIA-Linux-x86_64-460.106.00-grid”. The installation completes suceefully. I then configured the license server for vcs and all seems fine. I get below output from nvidia-smi.±----------------------------------------------------------------------------+
| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GRID A100-3-20C     On   | 00000000:02:00.0 Off |                  N/A |
| N/A   N/A    P0    N/A /  N/A |   1820MiB / 20475MiB |     N/A      Default |
|                               |                      |              Enabled |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| MIG devices:                                                                |
±-----------------±---------------------±----------±----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    0   0   0  |   1820MiB / 20475MiB | 42    N/A |  3   0    2    0    0 |
|                  |      4MiB /  4096MiB |           |                       |
±-----------------±---------------------±----------±----------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    0    0       4041      C   …conda/envs/tf2/bin/python       12MiB |
±----------------------------------------------------------------------------+Under  “Processes” you can see a tensorflow 2 process. And this is where the issue starts. I can load tensorflow and gpu is detected but as soon as I try any calculation, it just hangs forever and nothing happens. As can be seen a process is created in the GPU but nothing seems to happen.I also tried the official Nvidia docker container for tensorflow and it results in the exact same issue.I also get no error message or log entries therefore I have no idea how to trouble-shoot. I have reinstalled the Nvidia driver but that didn’t help at all.What could be the issue? How can I further troubleshoot?System: Lubuntu 22.04 on VSphere 7.0.3Hi, could you please try a newer driver? vGPU 12.x is already end of life and I doubt it works properly with Ampere.Reference the documentation for all releases of NVIDIA virtual GPU software.I would recommend to use at least the latest minor release from vGPU 13 branch.Best regards
SimonJust to confirm does the guest and host need to be matched? Or can I just update the guest?EDIT: A100 is pretty old so 12.x or 460 driver supports it:Release information for all users of NVIDIA virtual GPU software and hardware on VMware vSphere.But yeah doesn’t hurt to try with a never versionEDIT 2:According to the link you provided digging down further 13 and 14 does not support A100:So I think a never driver will work.And this kind of annoying as I don’t care about that whole AI enterprise thing in fact it is distracting and a bait and switch really as the card wasn’t purchased for what AI enterprise seems to target. So a simple driver install is what we would need.Unfortunately you are right. I overlooked the vSphere comment. Thought you are using KVM. You will need the NVAIE trial. No way to use vGPU as the .vib won’t support the A100.Powered by Discourse, best viewed with JavaScript enabled"
49,nlp-api-download,"Can someone help me find where the information is for how I use my API key to download software from NLP? I am trying to integrate it into my template building (vmware) using Packer, allowing for downloading of the stated version. I know how to create a API key but have nothing of how to use that in principal and download software.Powered by Discourse, best viewed with JavaScript enabled"
50,how-can-i-list-files-and-directories-using-nvcc-compiler,"I wanted to compile the cuda codes using NVCC for directory and file management. Specifically, I use dirent.h for directory management (to open the directory, list the files and so on). I tried to compile the C++ codes using NVCC compiler and run the executables on nvidia Jetson. I have lots of compilation errors. The main error message is below. Any idea to fix the compilation error? Can NVCC compile the direct.h and to use the directory management functions in the executable file running on Jetson?It seemed “filesystem” can not be compiled and used as well. Any idea how I manage the directory and files for the cuda using NVCC?dirent.h:413:28: error: missing binary operator before token “(”
#if WINAPI_FAMILY_PARTITION(WINAPI_PARTITION_DESKTOP)Powered by Discourse, best viewed with JavaScript enabled"
51,how-do-i-enable-cuda-or-opencl-on-the-m10,"I just got a vGPU Workstation license for a M10 card, but I’m not seeing either CUDA or OpenCL being enabled. I’m using the profile GRID M10-4Q, and VMWare ESXi 7.0. Do I need to make a change in vcenter or the VM?

image1047×545 98.8 KB
I have it set as Shared Direct in vcenterYou need to use a 8Q profile. CUDA is not working on smaller profiles with Maxwell generation.Ah ha, thank you, that worked.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
52,driver-to-vsphere-v6-7-430-27-tesla-m10,"Hi on the nVdia Product Download site, I did’t found the newest M10 driver (430.27) for vsphere V6.7 only for V6.5.
Where is it?Thanks to all!
Best regards
Novell1Powered by Discourse, best viewed with JavaScript enabled"
53,windows-10-1909,"According to all the NVidia documentation only Win 10 1809 and earlier is supported for nVidia vGPU. We are currently upgrading our Horizon to 7.11 and planning to roll out Win 10 1909. We are running Tesla M10 cards on VxRail. Is NVidia not going to support us if we roll out 1909, or even 1903? Is anyone using 1909 with nVidia vGPU? I was planning to use the latest LTSB of nVidia software. Any advice, comment appreciated.HiNot sure where you’re getting your documentation from, but it’s either out of date or wrong (or both :-) ).Both of the Current Releases (CR) support 1903 and the latest CR supports up to 1909: Supported Products :: NVIDIA Virtual GPU Software Documentation Obviously, if you’re going to run a CR, then you’d chose the latest version.Personally … don’t use the LTSR / LTSB software for any of your stack, and in fact if you want to run 1909, this isn’t an option anyway. Just my two cents: https://gridforums.nvidia.com/default/topic/10819/general-discussion/confused-on-versioning-/ but feel free to go whichever way suits your depoyment.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
54,pytorch-is-not-detecting-gpu,"Hi All,I was trying to use PyTorch with GPU in one VM installed with Ubuntu 18.04.GPU is displaying nvidia-smi.Thu Aug  4 23:12:19 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GRID RTX8000P-8Q    Off  | 00000000:02:00.0 Off |                  N/A |
| N/A   N/A    P8    N/A /  N/A |    550MiB /  8192MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+Installed following packages as wellconda list | grep -i cuda
cudatoolkit               11.3.1               h2bc3f7f_2
cudnn                     8.2.1                cuda11.3_0
pytorch                   1.12.0          py3.7_cuda11.3_cudnn8.3.2_0    pytorch
pytorch-mutex             1.0                        cuda    pytorchI am getting following error while running script.UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1656352464346/work/c10/cuda/CUDAFunctions.cpp:109.)
return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
File “test.py”, line 4, in 
torch.cuda.get_device_name(0)
File “/home/ubuntu/miniconda3/lib/python3.7/site-packages/torch/cuda/init.py”, line 329, in get_device_name
return get_device_properties(device).name
File “/home/ubuntu/miniconda3/lib/python3.7/site-packages/torch/cuda/init.py”, line 359, in get_device_properties
_lazy_init()  # will define _get_device_properties
File “/home/ubuntu/miniconda3/lib/python3.7/site-packages/torch/cuda/init.py”, line 217, in _lazy_init
torch._C._cuda_init()
RuntimeError: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.I have ran nvidia-bug-report.sh script as well but could interprept much from that.
Here I am attahced the result of the script.nvidia-bug-report.log (277.8 KB)Could any one please help to debug this ?Powered by Discourse, best viewed with JavaScript enabled"
55,cannot-find-the-download-for-vgpu-software-15,"According to NVIDIA Virtual GPU (vGPU) Software Documentatio , vGPU software 15.0 has been released. But I cannot find the download of the latest version. The latest vGPU software version in my applictaion hub is 14.2.
Could anyone give me a hint?
Many thanks.My platform is Linux KVM.Hi,
are you sure you still have a valid subscription?
If your entitlement is valid you should see the latest software downloads.regards
SimonMy subscription is out of date. I think that’s the reason.Thank you for your reply.Powered by Discourse, best viewed with JavaScript enabled"
56,domain-join-kills-nvidia-container-for-control-panel,"My Google FU has failed me :(
We have multiple RTX 8000 cards in Dell 940 servers running VMware 7.0.2 . Our Windows 10 vm’s work fine obtaining a license from the nvidia license server until we join them to our 2019 MS domain. The nvidia container starts then immediately stops which does not allow you to set the license server address, I have heard of a registry  edit that will fix the license server address problem but we need to have access to the Nvidia control panel.I assume you have GPO restrictions as soon as the VM joins the domain. Please check what kind of restrictions are assigned.I have been looking through the Domain settings have not really changed anything since the last working solution. only change was going to driver package NVIDIA-GRID_vSphere-7.0-460.91.03-462.96 for the esxi VIB and the windows 10 vm.Should have added that I can join the domain and the nvidia container will not start but I can take it back out of the domain and manually crank up the nvidia container and everything runs as expected. So it is definitely joining the domain which breaks it but it did not exhibit this behavior on the previous driver.Powered by Discourse, best viewed with JavaScript enabled"
57,strange-error-on-license-server,"Hi, everyone!I have Tesla V100 card on supermicro platform with vSphere hypervisor
The license server is running on VM with Win10 (on another machine)
I have VM with vGPU q-profile which can not receive any license from License Server.
Here is what I found in logs:What I also find in server API response (http://192.168.1.61:7070/api/1.0/instances/~/features):Looks like an error in license? Because feature will starts one year later (""starts"" : ""2020-12-29"")
OR I did something wrong???
Help please!Powered by Discourse, best viewed with JavaScript enabled"
58,problem-with-t4-2q,"Hi guys.I got 4 T4-2Q and want to host them in a Ruby Cloud.
I thought, I had it all set up, but my virtual GPU can’t fetch the license.
I am using Ubuntu 20.04, CUDA 11.2, CUDNN 8.1, I set the  server address to the correct server in gridd.conf, however, when I typeI get no licence.If I type in var/log/I get the following message:Jul  5 15:31:31 ds-lab-gpu-ubuntu-2004 nvidia-gridd: Calling load_byte_array(tra)
Jul  5 15:31:33 ds-lab-gpu-ubuntu-2004 nvidia-gridd: Failed to acquire/renew license from license server. (Info: http://10.38.224.110:7070/request; NVIDIA RTX Virtual Workstation - Error: [1,7E2,2,0[7000000B,0,702C7]]#012Requested feature was not found.)From my research, I found out, that I need a vWS license, yet in my license server, I got a NVIDIA Virtual Compute Server license.I would appreciate any help.Kind regards,
RobertHi,did you set the right feature type in gridd.conf? I assume not. Therefore the licserver expects to aquire a vWS license.regards
SimonHi Simon,thanks for answering.I tried all possible values in gridd.conf (1, 2, 4) and in every case, I could not acquire a license.Right now, I have the FeatureType 2.When I typeI get the following:ubuntu@ds-lab-gpu-ubuntu-2004:~$ nvidia-smi -q==============NVSMI LOG==============Timestamp                                 : Tue Jul  6 06:29:49 2021
Driver Version                            : 460.32.03
CUDA Version                              : 11.2Attached GPUs                             : 1
GPU 00000000:00:05.0
Product Name                          : GRID T4-2Q
Product Brand                         : NVIDIA RTX Virtual Workstation
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : N/A
GPU UUID                              : NoneOfYourBusiness
Minor Number                          : 0
VBIOS Version                         : 00.00.00.00.00
MultiGPU Board                        : No
Board ID                              : 0x5
GPU Part Number                       : N/A
Inforom Version
Image Version                     : N/A
OEM Object                        : N/A
ECC Object                        : N/A
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : VGPU
Host VGPU Mode                    : N/A
vGPU Software Licensed Product
Product Name                      : NVIDIA RTX Virtual Workstation
License Status                    : Unlicensed (Unrestricted)
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x00
Device                            : 0x05
Domain                            : 0x0000
Device Id                         : AlsoNoneOfYourBusiness
Bus Id                            : 00000000:00:05.0
Sub System Id                     : AgainNoneOfYourBusiness
GPU Link Info
PCIe Generation
Max                       : N/A
Current                   : N/A
Link Width
Max                       : N/A
Current                   : N/A
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : N/A
Replay Number Rollovers           : N/A
Tx Throughput                     : N/A
Rx Throughput                     : N/A
Fan Speed                             : N/A
Performance State                     : P8
Clocks Throttle Reasons               : N/A
FB Memory Usage
Total                             : 2048 MiB
Used                              : 288 MiB
Free                              : 1760 MiB
BAR1 Memory Usage
Total                             : 256 MiB
Used                              : 0 MiB
Free                              : 256 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Enabled
Pending                           : Enabled
ECC Errors
Volatile
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Aggregate
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Retired Pages
Single Bit ECC                    : 0
Double Bit ECC                    : 0
Pending Page Blacklist            : No
Remapped Rows                         : N/A
Temperature
GPU Current Temp                  : N/A
GPU Shutdown Temp                 : N/A
GPU Slowdown Temp                 : N/A
GPU Max Operating Temp            : N/A
GPU Target Temperature            : N/A
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : N/A
Power Draw                        : N/A
Power Limit                       : N/A
Default Power Limit               : N/A
Enforced Power Limit              : N/A
Min Power Limit                   : N/A
Max Power Limit                   : N/A
Clocks
Graphics                          : 300 MHz
SM                                : 300 MHz
Memory                            : 405 MHz
Video                             : 540 MHz
Applications Clocks
Graphics                          : N/A
Memory                            : N/A
Default Applications Clocks
Graphics                          : N/A
Memory                            : N/A
Max Clocks
Graphics                          : N/A
SM                                : N/A
Memory                            : N/A
Video                             : N/A
Max Customer Boost Clocks
Graphics                          : N/A
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes                             : NoneI pseudonymized certain data due to protect my company. Is it possible, that the GPU is not set up correctly? The amount of N/A-values worries me.Also, if you need any other information, please feel free to tell me, what you need (and, sadly, how I can acquire this information, since I am quite new to Linux and vGPUs).Hi,
forgot to mention you need to choose the right profile :) You can only use the C profile for your license type!!!
License assignment is based on the profile.regards
SimonHi Simon,I am amazed at how fast you react, that’s wonderful!In my license server, I have the following info:Feature Name:     NVIDIA-VirutalComputeServer
Version:  9.0
Total count:  4
Available:  4
Current Usage:  0
Reserved Count:  0
Vendor String:  NVIDIA-VirutalComputeServer-1
Feature Expiry:  Sadly,NoneOfYourBusinessYou still think, I should set up a C-profile?You need to. License aquisition is based on the profile type. Only vWS is a “superset” license type and can license different profile types.Thanks man, I am gonna try it.Hi Simon,I read a little documentation, and if I understand you correctly, we set up the GPUs wrongly.According tonvidia-smi -qI got a T4-2Q set up which needs a vWS license which I do not have.However, as I showed you before, I do have a vCS license, and I can use this license with T4-4C, T4-8C and T4-16C, right?This means, we have to uninstall the GPUs and install them anew with suiting options?Kind regards,
RobertCorrect. You can only use the C-profile which means starting with T4-4C as you stated above. Simply remove the Q profile and add the C profile to the VM.Sorry, I forgot to say “Thank you, Simon!”. Without you, I would have wasted weeks until I would have understood how to get this right. Thank you man!No worries. Happy I could assist :)This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
59,a100-vcs-mig-vm-i-can-run-cuda-example-but-not-able-to-run-cuda-gdb,"Hi guys,I need your help on virtual machine setup with A100 and vCS. I have MIG enabled and have a VM configured like this:I am able to run cuda example without any problem.
However when I try to use cuda-gdb. It throws error msg like:I didn’t see any documentation on this. Could somebody help me to solve this problem? Thanks!Hi,
CUDA debugging is not supported yet on vCS. Support is planned for future vGPU release. Please contact your Nvidia contact for getting more details on timing if necessary or send me a PM if you don’t have a direct contact person.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
60,doubt-with-licenses,"Hi, I have a vdi environment with horizon with pool with linked clones. vdi’s operating systems are windows 2016 datacenter. can i use vpc grid licenses with a tesla t4 for this environment? or the use of w10 is mandatory for this type of license.thanksHiYes, you can use Sever VDI in place of Windows 10 and use vPC licenses.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
61,problems-with-perfomance-vgpu-dell-r730-vmware-esxi-6-7-tesla-p40,"Hello.
Acquired NVIDIA Tesla P40 graphics card for use in virtualization.
Dell R730 Server, E5-2667v4, all-Flash, VMware ESXi hypervisor, 6.7.0, 17098360
We registered and received a 90-day trial license, installed the NVIDIA-GRID-vSphere-6.7-450.89-452.57 drivers. The licensing server runs on Windows Server 2012R2 x64 (License Client Manager version 2020.05.0.28406365 x64).
The problem is this:
Regardless of the selected profile (1…8q), the performance does not change in tests and in operation. The main work is related to CAD applications, performance measurement is carried out using the Red Turbine Demo and Solidworks 2020 Performance test. Are there performance limitations in the trial license? If there are not, how can we properly measure the performance for each profile?I’m assuming you’re using this in VGPU mode, can you cofirm what EUC you’re using? Horizon/Citrix?Also can you confirm thatAlso will note in testing once i got to a suitable profile (2b), using a better profile didn’t get me better performance, though to be fair i didn’t do synthetic testing, just real world loads that my users would hit.  To make sure though i did remove the gpu to see what a non accelerated load would perform.Last thing I’d note, double check the vGPU guide, they qualify certain vgpu/OS/Hypervisor combos, that if not matched will give you bad performance.Ah, not sure on benchmarks, I used real testing to get an idea of load per user and monitored that by directly monitoring gpu and framebuffer usage and scaling for our load.As for horizon, can’t help much there, FWIW we tried horizon before we went with citrix, as deployment seemed much simpler, and licensing would’ve saved us 30%, but we found vgpu performance in a greenfield deployment following all docs to a T to be the same as pure cpu.We’re sure there was something wrong with our setup but after spending for a vmware suggested consultant and them confirming our setup looked perfect, they referring us to support.  Vmware support then took ~6 weeks of throwing darts and requested we rebuild and collect diags before we finally asked for a refund and tried Citrix VAADS.  With VAADS we were up and with great performance inside of a day.Hi1Q >> 24Q vGPU Profiles all have identical performance, assuming the default (Best Effort) Scheduler is used and you are not Framebuffer limited. Unless you are Framebuffer limited, increasing the amount of Framebuffer with a bigger vGPU Profile will not change the performance of the GPU or your application. If you start playing with the Scheduler, that’s a different conversation, but you already have the maximum performance available to you.A far better test would be to use a relevant benchmarking utility (Redway Turbine is not) and use something from SPEC like their new SPECviewperf 2020 release. This is where you’ll clearly see the difference between all of the vGPU Profiles.You’ve mentioned CAD as a main workload … CAD is typically CPU limited, if you require better CAD performance, you need newer hardware so that you can run better (newer generation) CPUs, as the Intel v4 are an old architecture. Your Clock Speed is ok (faster is better), but the age of the CPU is really holding it back.If you can’t upgrade the Server to an R740XD / R7525, then there are a few things you can do to help improve things with what you have:1: Upgrade your virtualisation software. ESXi 6.7 is pretty old.
2: Make sure your Server Firmware, BIOS etc are all fully up to date.
3: Make sure your Server BIOS is tuned for Performance, and make sure ESXi can control it. Lots of tuning guides out there for this.
4: Make sure the ESXi Host its self is configured for Performance - not Balanced or other.
5: Make sure your CAD VMs are running on SSD / NVMe storage.
6: Make sure your VMs are running the latest supported version of Windows 10 (2004 at time of writing, even though H2 is now available) (or Server 2019 (currently 1809) if running Server VDI) and that you’ve tuned / optimised that Operating System using one of the many tools out there.
7: Make sure you’re running the latest VMTools and vGPU Software.As a starting point, you should be looking to configure your CAD VMs with the following Spec and optimize from there:vCPUs: 4-6 Cores @ 3.0Ghz+ (3.0Ghz minimum - Faster is better, adding more Cores won’t typically help)
System RAM: 12GB (or higher depending on usage)
vGPU: 4GB & QvDWS License (4GB at least or higher depending on model size, screen resolution etc)
Storage: SSD / NVMeIf you do that with your current platform, you’ve pretty much maxed it out. Any additional performance will need to come from optimizing your CAD models to suit your hardware, or newer hardware.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
62,deployment-guide-for-quadro-rtx-8000-on-vmware-vsphere,"Hi all,Help me please with Deployment Guide for Quadro RTX 8000 on VMware vSphere.
I want install Quadro RTX 8000 in HPE Proliant DL385 Gen10 and use VMware vSphere 6.7 for 10 VMs for AutoCAD, Solidworks and 3D Studio.I don’t want deploy Horizon completely because I think it’s overhead for my purpose. I want a minimal infrastructure for this purpose. Can I use only VMware vSphere for my purpose, without Horizon? Which software and licenses needed?Where described the installation process?Thank you!HiYou need vCenter Standard and vSphere Enterprise Plus. You’ll also need a connection protocol that’s good enough to support your specific workload and handle your users peripherals (3D Space Mice etc).If you were to use Horizon, vCenter and vSphere licenses are included, and it’s available in packs of 10, so it fits your use case perfectly. You could then use the Direct Connect option to save you having to deploy all the back end components.Alternatively, you could simply use something like Teradici Cloud Access Plus or Mechdyne TGX. These require no supporting backend infrastructure, however you’ll need to purchase vCenter Standard and vSphere Enterprise Plus licenses.Regardless of your choice, you’ll need NVIDIA QvDWS licensing for either deployment which is licensed per CCU, so you’ll need 10 of them.RegardsMGThank you for your answer, MG.Can you describe following information. What is the price of licenses. Which limitations will be if I don’t have the licenses?Regardless of your choice, you’ll need NVIDIA QvDWS licensing for either deployment which is licensed per CCU, so you’ll need 10 of them.HiWithout licensing the vGPU Software, you will not be able to use it. You’ll be limited to 1 user Per GPU in Passthrough. Or, you’ll need to run RDSH, again using the GPU in Passthrough and using the standard Quadro driver (not vGPU). You’ll still need a good connection protocol mentioned above.Speak to your local vGPU reseller for the best vGPU pricing. If you want individual VMs per user, you’ll need 10x QvDWS licenses (1 for each user).RegardsMGHi, I have small but little bit specific case where there is one 1 socket server, 0,5TB RAM with GPU: Nvidia Quadro RTX 8000. Does customer need to have ENT+ for that? If so why?Does he need vCenter? If so why? Would be Ess/Ess+ kit sufficient by any chance? Please could you provide email address to discuss more?Hi, you didn’t mention what you want to achieve so how should we answer your request?
For vGPU you always need Ent+ Licensing from VMWare so you could only do Passthrough with Std licensing.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
63,does-quadro-p4000-support-xenapp-7-15,"Hello! Can someone kindly advise how to make a QUADRO P4000 works in Windows Server 2016 for XenApp 7.15?HiInstall it as Passthrough (assuming you’re using a Hypervisor), use the standard Quadro driver from NVIDIA website.Enable the ""Use the hardware default graphics adapter for all Remote Desktop Services sessions"" Group Policy to enable the OS to use the GPU.Lastly, configure your Citrix Policies appropriately.RegardsMGThank you sir! Actually i don’t have any Hypervisor, i just install Windows Server 2016 as host O/S and want to use XenApp, does it work?HiSure, that will work just fine.Install the Windows OS > Install the NVIDIA Driver > Join the Domain > Install XenApp (this will automatically install the appropriate Server Roles (RDSH)) > Install all Windows Updates > Install the Applications > Check for Windows Updates again > Optimise and clean up the OS > Assign User access through Citrix Studio > Log in with Users and test … Easy ;-)Make sure you enable that Group Policy mentioned above. Without it, the XenApp Server won’t use the GPU.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
64,rds-2016-with-remotefx-vs-dda-on-ms-hypervisor,"Can someone steer me where Im trying to go here. There appears to be a sea of information here and my direction isn’t clear to me yet. Im building up a Dell r720 with Server 2016 for a hosted guest RDS Server. Im trying to get a video performance improvement and looking into a GPU that I can pass through to my RDS server. What cards should I be looking at for a server with 60 users and about 25 concurrent at a time? What hardware and what licensing fees can I expect to pay.If I use DDA, can all my concurrent users access the GPU if its dedicated to that VM? If my users aren’t engineers should I just go with remotefx?I understand remotefx is dead ending but this server will hopefully last another 4 years or so then get retired.Gratefulhmm no replies.HiWhat applications will you be running?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
65,gpu-cluster,"Hi , i have serveral grid k2, and i want to build a GPU cluster, but i meet a problem, i don’t konw if the k2 is supported the nvidia-container-toolkit or nvidia-docker2. Please help me!!!i had find serveral github projects to build the cluster, like Determined AI and OpenPAI, but both of them use the nvidia-docker, and i can’t run a container with my k2.Powered by Discourse, best viewed with JavaScript enabled"
66,tesla-k80-initital-setup-problem,"Hi all, I ma new to the Tesla community.  I recently set up a machine for CAD combined with CFD and FEA.  Machine specs are:Dual Xeon Silver 4216
128 GB Memory
Asus WS C621E SAGE main board
HDDs are all solid state NVMe
Asus GeForce RTX2070 video card
PSU: Corsair AX1600i (main) Corsair RX850 (for a little extra power)
Latest BIOS installedI bought three Tesla K80s of Amazon.  They were used and re-certified so I bought the insurance with them.I am having issues getting the machine to boot after installing the first card.  I have Above 4G Decoding enabled and my machine does POST and begins loading windows but hangs up and says it could not start windows.  so I am trying to narrow down what the issue could be.No NVIDIA Tesla drivers are loaded yet…cant load them until a TESLA is installed and windows startsLocation on main board…The GeForce RTX 2070 is in slot 7 (bottom) and I installed the first Tesla in slot 5.  the closest they can physically be located.  Other cards will go into slots 1 and 3 once the first card is workingNot compatible with mother board or combo of GeForce and Tesla on the same board (god I hope not)Thermal issue…the card was seriously hot. I have rad that these will heat up and need active cooling but it sounded like that’s only the case when you are really taxing them.   I know I have to add active cooling and I am 3D printing a duct to move allot of air but the duct is not done yetBad card?I have plenty of power and its wired up right, maybe I just have to wait until the air duct is done to cool it and try again if the heat is causing it to shut down.  I have not tried putting it into a different slot.Thanks
ScottHiUnfortunately I don’t think that’s going to work.You’re using a current generation GeForce GPU with a really old Tesla GPU and they have massively different driver requirements and they’re about as far apart in physical architecture as you can get.If you’re trying to benefit from Graphics and Compute, using 2 different GPU models is quite an old way of doing it. This used to be called NVIDIA Maximus, but it’s not used any more due to advancements in architecture. The last time I used this approach was back in 2015, but I was using a Quadro and Tesla, not GeForce. I was running an M6000 and K80 and that worked. Today, I’d just use a single, current generation GPU which would massively out perform that configuration.You 100% need a fan to cool the K80, it’s not optional. Whether you’re running workloads on it or it’s sat there idle, otherwise you’ll damage it. It needs very good air flow - just as any other Passive GPU does. Or, you need an appropriate chassis that’s designed for Passive GPUs. Your insurance is unlikely to cover thermal damage.Regardless of whether the system will boot or not, I don’t think this will work. I’m pretty sure that you need a Quadro driver to support the Tesla, and you can’t use that because you have GeForce in there.Being completely honest, to save you a lot of time, hassle, frustration and being underwhelmed at the K80s performance, here’s a bit of guidance … Return the RTX2070 and 3 K80s and get a refund. Purchase 1 Quadro GP100. These are based on the Pascal architecture. They have very good Graphics and Compute capability in a single GPU and will be much better for what you’re trying to do. It has 16GB of HBM2 memory and is a seriously powerful bit of kit!! It’s also an ""Active"" GPU (meaning it has a fan built in) so no need to mess around building your own, and it will use less power / generate less heat. You can purchase GP100s on eBay for a little over £1K if you shop around, which is probably not much more than the cost of all your existing GPUs (plus insurance) together. If you go down this path, make sure you go for the GP100, not the P100. The GP100 is Active and has display heads on the back of it so you can connect your monitors. It’s designed to go in a Workstation (just like you’re doing). The P100 on the other hand is headless and Passive, it’s designed to go in a Server. Performance between them is the same, but if you buy the P100, you won’t be able to use it unless you use virtualisation. Just something to be aware of.More modern GPUs are available like the GV100 which is built on Volta, but these are more expensive. You could use a Titan V (again Volta), but you’re then back to using using the GeForce gaming driver again, not Quadro, so I’d avoid this. The Titan V has less RAM than the GP100 (12GB), but it’s still HBM2, so is very fast! But if you’re doing CAD / CFD / FEA, then driver support is very important! For reference, NVIDIA’s Titan product line is classed as ""Prosumer"", so it’s a step up in terms of hardware from (Consumer) GeForce, but still uses the GeForce driver.The easiest, most cost effective way to do what you’re after is use the GP100.That’s the best bit of advice I can offer.RegardsMGThanks for responding.  I was a bit afraid this could be the case but also figured I could run the GPUs independently.  The GP100 is just about beyond what I’d like to invest in this machine right now.  in the states I’m looking at $2700 or so.  I have seen several posts on other forums where they were successful and satisfied with running a GTX1080 and K80 together so I figured there is a way to get an RTX2070 and K80 to run together.that was a recent post but if it doesn’t work for me I’ll rethink and see about going dow n the road you are suggesting.  I do appreciate your notes.Cooling: no doubt!  At 300W I expected that.  I have designed a duct that fits in my case and combines the flow from two 120mm fans to three ports to supply flow to all thee cards and dump about 20 percent to the board controller.  Just waiting to get it printed.HiIf you were planning to add all 3 K80s in there as well, then that’s going to be pretty expensive to cool and run! (unless you have a good electricity rate where you are :-) )I didn’t try with a GeForce GPU / GeForce driver, but if others are saying that they have it working, then it must work. The GP100 route would still be my recommendation, I just think longer term overall it will be better for you and if you wanted more performance at some point in the future, then you could purchase a second one and run them in NVLink. The route you’re going down with this setup is very limited and will be expensive to run due to the K80(s).Assuming you have it installed, you could try uninstalling the existing GeForce driver, make sure to install the RTX into the primary PCIe slot as this is what the system will be using for most of the time (as it will be providing the visuals). Install the K80 in the second PCIe slot, boot the system and if possible install the latest NVIDIA driver with the Clean Install box checked just to make sure it’s a clean install. I can’t think of anything else at this point, as your system gets past POST and starts booting.Try that and see how you get onRegardsMGHi, just found this while searching for answers to similar situation… .was told that Tesla is a GPU but apparently that is not fully accurate. I do not have any other cards but it sounds like the setup can work with Quadro plus Teslas? Should i return the Tesla… I thought wish 24 GB it would be pretty powerful.MG could you send me an email or call? I would be happy to discuss pay for your time as you seem extremely knowledgeable about this card and combination.Aaron G
aarong.2018@outlook.com
805-252-7753Powered by Discourse, best viewed with JavaScript enabled"
67,vgpu-one-v100-2-vms-using-cuda-at-the-same-time-is-it-possible,"Hi,my company is thinking about getting a cloud server for data science purposes (the computer scientists will run python scripts that will make use of CUDA).
We have been thinking about getting one cloud server running ESXi 6.7 with one V100 GPU, this would be our goal configuration:ESXi HOST (16 CORES XEON, 64GB RAM, V100)
|-------- VM1 Windows Server 2016 (8 CORES XEON, 32GB RAM, 50% V100) - running python scripts with CUDA
|-------- VM2 Windows Server 2016 (8 CORES XEON, 32GB RAM, 50% V100) - running python scripts with CUDAMy question is if it is possible to divide the CUDA GPU power, let’s say 50%-50% between the two virtual machines, and if one process launched in one of them could affect the other.And… any idea about how much could the licenses cost? (NVIDIA side)Thanks in advanceFor sure this is possible. Look at our vGPU vCS license type. You will need 1 license (50$/year).
With vGPU you have the choice between different schedulers so that you can make sure there is no interference between the two VMs (equal or fixed share) or you run the default scheduler (best effort).Powered by Discourse, best viewed with JavaScript enabled"
68,license-register-issues,"hi ,we face some issues to register license server
previously we have apply a trial license with account A
then now we have purchase the license and redeem the license with account B
when we want to add license server, it not allow where duplicate MAC address is being registered
any method to delete register MAC address from account A ? so that we can register to account BOpen a ticket with ESP (Enterprise Support).Hello,is it possible to move an NVIDIA license server from a 2008R2 virtual server to a 2019 virtual server?You can simply return the licenses on the vGPU portal and issue a new license file for the new license server.Powered by Discourse, best viewed with JavaScript enabled"
69,horizon-video-playback-performance,"Hello,I have performance problems with playback of videos in my VDI machines.  I’m using Blast Extreme accelerated by a Nvidia P40 GPU. Playback is always a little bit stuttering. I usually get a better result from my Linux VDI pool that isn’t GPU accelerated. If I check with youtube the problem seems to be related with encoding  since I don’t se dropped frames reported by the video player.What is your experience in fullscreen video playback with the P series?CristianoHi,I’m having no issues and super smooth playback even with 4k and Youtube with P40. Which browser are you using?
If you would using a Maxwell board I would assume the issue is related to decoding but Pascal already supports VP9 hardware decoding (used from Youtube) so that this cannot be the issue.
What OS and resolution are you using?RegardsSimonHello Simon,I’m using W10 64 1709 with 3 cpu and 5GB of Ram, storage is all flash. The profile is just a P40-1Q since I’m going for density. I’ve tried with edge firefox and chrome, aeme issue. Decoding the video from youtube shouldn’t be the issue, I don’t see dropped frames. The issue is not just youtube, every video app is a little bit jerky. I also tried the Nvidia lab, that is available with registration and playback is smooth there. I have also an SR open with VMware, so I’m working on multiple fronts.regardsCristianoHi Cristiano,could you please change the scheduler from default (equal share) to best effort for your deployment and test once again? I’m curious to hear if it makes any difference.Documentation for administrators that explains how to install and configure NVIDIA Virtual GPU manager, configure virtual GPU software in pass-through mode, and install drivers on guest operating systems.regardsSimonHello Simon,Wen I will upgrade to 5.2 I will try that, since it requires a restart. Right now is difficult for me to find a windows for downtimeRegardsCristianoHello Simon,didn’t switch mode, but GPU wise it seems ok, those are the statistics:GPU Session Process   Codec       H       V Average     Averageso it seems that encoding is fine. Are 80/90 FPS not a little too much?
Also decoding should be fine as youtube doesn’t report dropped frames.RegardsCristianoHi Cristiano,it depends on the scheduler. As default scheduler has no FRL it renders more than 60fps.
You can switch to best effort to have FRL=60fps which is more than sufficient. And I agree that the GPU cannot be the issue in your case as we render more than enough frames :)RegardsSimonTry using the GRID 5.1 drivers instead.I`m experiencing the same problem that Christiano mentioned before.We got Tesla P40 GPU`s in an Horizon environment in version 7.4.0 on ESXi Hosts (HPE DL380G10) in version 6.5U1.
I´ve already switched the scheduler to best effort, but did not see a difference.
I am using 2 full hd monitors and the blast extreme protocol.
The vGPU profile i am using is ""grid_p40-2q"".This is the output i get from the hypervisor shell when i run ""nvidia-smi vgpu -es"":
This output was generated while playing a YouTube video through firefox.
At the first ""7 fps"" lines the video was not startet, it startet later when those fps counters rose.
It seems like the GPU is rendering way too much frames, but i thought it is limited due to the best effort scheduler…Any advice on how to fix this?Hi prinz,could you run ""nvidia-smi encodersessions"" within the VM?For me it works as expected with P40-2Q and best effort playing a FullHD FULL screen youtube video:RegardsSimonI wonder about the effectiveness of the 1Q profile for full 4K video.  I’ve been looking at the difference between P6-1Q, P6-2Q and P6-4Q profiles and video performance.  4Q is super smooth, but with 2Q there is roughly a 25% drop in performance and with a 1Q profile a further 25% drop from there.I have default scheduler settings and have put this down to simple frame buffer capacity but something doesn’t sit right with me in that the software encoding engine (Blast in this case) is still doing the same number of pixels (the same video is being used) so why should the frame buffer make such a difference?Hello Simon,i ran the command ""nvidia-smi encodersessions"" within the VM while playing a YouTube 1080p video and got that output:If i connect to the desktop-pool with only one active monitor and watch the exact same video in fullscreen, i get that output:On the hypervisor it looks like this when i play the video with one active monitor:If i run ""nvidia-smi vgpu -q"" on the hypervisor, I can see the line ""Frame Rate Limit: 60FPS"", but it does not limit anything if i get this right…Regards,
DominikHi Dominik,I agree this looks like you don’t have FRL in place. Could you please double check that you’re running Best Effort scheduler? Try the latest GRID6.1 package and you should have Best Effort by default…RegardsSimonHi Simon,so I ran this command on the hypervisor to set the best effort scheduler and rebooted the hosts:
esxcli system module parameters set -m nvidia -p ""NVreg_RegistryDwords=RmPVMRL=0x00""But I dont see any difference. The frame rates are still way to high.
The question is, on which layer the problem occurs first.
It can be the hypervisor, the VM config, the Guest OS or the NVIDIA driver on the OS.
So i set the preference on the lowest layer, which should be fine.
I read the installation manual multiple times and I cant figure out any config errors done by me.
I have to correct that we are now on ESXi 6.5U2, maybe there is a known bug or problem?
We are on the latest GRID 6.1 software (host driver version: 390.57).UPDATE: I did further investigation and noticed a very interesting benchmark behaviour. This was tested with the Unigine Valley Benchmark. While the benchmark is running, the FPS-Counter in the application tells, that you are almost fixed at 67/68 sometimes 70FPS, while the hypervisor (nvidia-smi vgpu -es) tells you this:The benchmark feels like the frames are dropping very hard, but the FPS-Counter and the hypervisor tells you, that there are no frame-drops at all. Where/what can be the cause of this odd behaviour?ANOTHER UPDATE: I imported the View GPOs and set the MaxFPS-Blast GPO to 60 fps. It feels much much smoother now, but the frame rates are still pretty high and you can feel some sort of ""lag"" if you move windows quick or even in some video sequences, but no comparison to before (Max 30 FPS).So I think the main problem is found and stupid simple.
But for the fine tuning and the problem with the high fps I would be very pleased if I get further help here.Thank you for your helpful advice and effort!Regards,
DominikWhat are the min QP and max QP settings in the Blast Extreme session?
And are you using UDP or TCP?What are the min QP and max QP settings in the Blast Extreme session?
And are you using UDP or TCP?The QP settings are the default ones. We tried UDP and TCP, but there is no noticeable difference. I dont think, that this problem is a Blast setting. My guess is, that the frame rate limiter on the hypervisor is not working correctly. Blast displays only 60FPS due to the GPO I set, but the hypervisor renders way more frames than this. This is very bad for the user experience and of course also the user density, since one user could claim nearly all the performance of that physical GPU.Hi Prinz,I disagree. Let’s discuss this offline. Please send me a PM.regardsSimonI’m having the same results as others on this forum with Horizon blast (7.7) stuttering playback with H264 encoding enabled. We are using P40 cards, using 4Q and grid driver 412.16. Was this ever resolved?This sounds similar to my issue.Any solution?
I have the same issuePowered by Discourse, best viewed with JavaScript enabled"
70,jetson-agx-flash-devicetree-fail,"I’m making a customer board for Jetson AGX.So,I’m trying to change the devicetree with '$ sudu ./flash.sh -r -k kernel.dtb jetson-agx mmcblk0p1 ',but it doesn’t work , return ’ flash.sh command not found '.Powered by Discourse, best viewed with JavaScript enabled"
71,vgpu-of-2x-rtx8000-on-esx-7-0-low-utilization,"Hi,i getting low utilization on my test VM’s,I’m using VM Profile of :Cinebench R15 : OpenGL 59 +/- no more !!!
Does someone have the same problem ???NVSMI LOG:nvidia-smi -q==============NVSMI LOG==============Timestamp                                 : Wed Dec 23 09:04:45 2020
Driver Version                            : 450.89
CUDA Version                              : Not FoundAttached GPUs                             : 2
GPU 00000000:25:00.0
Product Name                          : Quadro RTX 8000
Product Brand                         : Tesla
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Enabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1325219085576
GPU UUID                              : GPU-9c213c49-3b61-10dc-4e1b-d32b2e9c1ae7
Minor Number                          : 0
VBIOS Version                         : 90.02.4E.00.03
MultiGPU Board                        : No
Board ID                              : 0x2500
GPU Part Number                       : 900-2G150-0150-030
Inforom Version
Image Version                     : G150.0231.00.02
OEM Object                        : 1.1
ECC Object                        : 5.0
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : Host VGPU
Host VGPU Mode                    : Non SR-IOV
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x25
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x1E7810DE
Bus Id                            : 00000000:25:00.0
Sub System Id                     : 0x13D810DE
GPU Link Info
PCIe Generation
Max                       : 3
Current                   : 1
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 46079 MiB
Used                              : 5995 MiB
Free                              : 40084 MiB
BAR1 Memory Usage
Total                             : 32768 MiB
Used                              : 45 MiB
Free                              : 32723 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Enabled
Pending                           : Enabled
ECC Errors
Volatile
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Aggregate
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Retired Pages
Single Bit ECC                    : 0
Double Bit ECC                    : 0
Pending Page Blacklist            : No
Remapped Rows                         : N/A
Temperature
GPU Current Temp                  : 31 C
GPU Shutdown Temp                 : 87 C
GPU Slowdown Temp                 : 84 C
GPU Max Operating Temp            : 82 C
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : Supported
Power Draw                        : 26.68 W
Power Limit                       : 250.00 W
Default Power Limit               : 250.00 W
Enforced Power Limit              : 250.00 W
Min Power Limit                   : 150.00 W
Max Power Limit                   : 250.00 W
Clocks
Graphics                          : 300 MHz
SM                                : 300 MHz
Memory                            : 405 MHz
Video                             : 540 MHz
Applications Clocks
Graphics                          : 1230 MHz
Memory                            : 6501 MHz
Default Applications Clocks
Graphics                          : 1230 MHz
Memory                            : 6501 MHz
Max Clocks
Graphics                          : 1620 MHz
SM                                : 1620 MHz
Memory                            : 6501 MHz
Video                             : 1500 MHz
Max Customer Boost Clocks
Graphics                          : 1620 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 2104744
Type                          : C+G
Name                          : GPU-TEST-1
Used GPU Memory               : 1900 MiB
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 2105231
Type                          : C+G
Name                          : GPU-TEST-2
Used GPU Memory               : 1900 MiB
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 2105630
Type                          : C+G
Name                          : GPU-TEST-5
Used GPU Memory               : 1900 MiBGPU 00000000:81:00.0
Product Name                          : Quadro RTX 8000
Product Brand                         : Tesla
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Enabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1325219085762
GPU UUID                              : GPU-20880b45-4e0e-bf33-ee89-9277cfe9e04c
Minor Number                          : 1
VBIOS Version                         : 90.02.4E.00.03
MultiGPU Board                        : No
Board ID                              : 0x8100
GPU Part Number                       : 900-2G150-0150-030
Inforom Version
Image Version                     : G150.0231.00.02
OEM Object                        : 1.1
ECC Object                        : 5.0
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : Host VGPU
Host VGPU Mode                    : Non SR-IOV
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x81
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x1E7810DE
Bus Id                            : 00000000:81:00.0
Sub System Id                     : 0x13D810DE
GPU Link Info
PCIe Generation
Max                       : 3
Current                   : 1
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 46079 MiB
Used                              : 7895 MiB
Free                              : 38184 MiB
BAR1 Memory Usage
Total                             : 32768 MiB
Used                              : 31 MiB
Free                              : 32737 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 1
Average FPS                       : 301
Average Latency                   : 3023
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Enabled
Pending                           : Enabled
ECC Errors
Volatile
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Aggregate
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Retired Pages
Single Bit ECC                    : 0
Double Bit ECC                    : 0
Pending Page Blacklist            : No
Remapped Rows                         : N/A
Temperature
GPU Current Temp                  : 31 C
GPU Shutdown Temp                 : 87 C
GPU Slowdown Temp                 : 84 C
GPU Max Operating Temp            : 82 C
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : Supported
Power Draw                        : 26.26 W
Power Limit                       : 250.00 W
Default Power Limit               : 250.00 W
Enforced Power Limit              : 250.00 W
Min Power Limit                   : 150.00 W
Max Power Limit                   : 250.00 W
Clocks
Graphics                          : 300 MHz
SM                                : 300 MHz
Memory                            : 405 MHz
Video                             : 540 MHz
Applications Clocks
Graphics                          : 1230 MHz
Memory                            : 6501 MHz
Default Applications Clocks
Graphics                          : 1230 MHz
Memory                            : 6501 MHz
Max Clocks
Graphics                          : 1620 MHz
SM                                : 1620 MHz
Memory                            : 6501 MHz
Video                             : 1500 MHz
Max Customer Boost Clocks
Graphics                          : 1620 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 2105606
Type                          : C+G
Name                          : GPU-TEST-3
Used GPU Memory               : 3800 MiB
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 2105645
Type                          : C+G
Name                          : GPU-TEST-4
Used GPU Memory               : 3800 MiBHiEither disable the frame rate limiter in the Hypervisor for each VM, or change the Scheduler on the GPU which will automatically remove the FRL.If you disable it individually for each VM, then remember to enable it again after running your benchmarks.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
72,vvtd-intel-virtualization-technology-for-directed-i-o-is-not-supported-on-a-virtual-machine-with-vgpu-device,"Hi, have T4 card in a UCSC-C240 on ESXi7.  VIB installed fine.  Under Hardware>Graphics>Edit Host Graphics I have “Shared Direct Vendor shared passthrough graphics” and “Spread VMs across GPUs” are set for all the hosts in vCenter.  I have looked over the quick start guide but don’t see a section that addresses this issue.  When I edit the VM and add a PCI device, I can see the option to choose between a “DirectPath IO” and the 'NVIDIA GRID vGPU"" radio buttons.  I choose the GRID device, choose an NVIDIA GRID vGPU Profile, and choose OK.  When I do, I get, “VVTD (Intel Virtualization Technology for Directed I/O) is not supported on a virtual machine with vGPU device”  I have gone into the host and disabled the “Intel VT for Directed I/O (VT-d)” setting in UEFI.  I powered down and powered up the host.  I then moved the VM to the updated host, but the error is presented every time I try to add/choose a vGPU on the VM.  What have I overlooked?  I also tried disabling VT entirely.  Thank you.Figured it out.  Power down the VM.  Then vi the .vmx file of the VM to which you’re adding the vGPU.
Find three line entries in the vmx file,
vhv.enable
vvtd.enable
windows.vbs.enable
Set all three lines to FALSE.
Power on the VM and power it off.
Now add the vGPU per Live installation of NVIDIA Virtual GPU - YouTubePowered by Discourse, best viewed with JavaScript enabled"
73,questions-on-vr-vs-autonomous-cars,"I don’t really have to much knowledge in regards to my question. In more or less words, I was wondering why don’t we push the VR controlled vehicles more? Wouldn’t it be more beneficial to put VR controlled vehicles in a similar market like Ride Share to gather billions of miles driven so our autonomous cars would already have the knowledge. Seems like the reason we are struggling to get full autonomous cars is because we are trying to skip tech step. Am I wrong? Maybe there is a bigger scope of things I am missing and potential dangers going VR, but wouldn’t full autonomous be in the same boat that we are trying to skip to?Powered by Discourse, best viewed with JavaScript enabled"
74,driver-is-not-initialised-when-using-nvidia-quadro-virtual-workstation-winserver-2019,"After launching an AWS instance with the ‘NVIDIA Quadro Virtual Workstation - WinServer 2019’ AMI on a g4dn.2xlarge instance, the Windows Device Manager shows the driver for the Tesla T4 as failed with the following error ‘Windows has stopped this device because it has reported problems. (Code 43)’. Its my understanding that this AMI should have the required drivers already installed?Any assistance is appreciated.Powered by Discourse, best viewed with JavaScript enabled"
75,problem-configuring-vgpu-access-using-kubevirt,"We try to configure OpenShift environment to use NVIDIA vGPU using the NVIDIA gpu operator. We followed the steps as described in this guide in NVIDIA vgpu documentation.I have a trail license from NVIDIA to use the vGPU software from their portal. I downloaded the Linux KVM all supported (should I install the RHEL drivers instaed?) version 13.7. As described in the tutorial, i extracted the NVIDIA-Linux-x86_64-470.182.02-vgpu-kvm.run and build the image using the drivers repository.I have also configured the ClusterPolicy, and all the pods, related to the GPU Operator, are in Running state.
I configured CNV (Kubevirt) on the cluster, I edited the HyperConverged to allow med device to allow using the use of the GPU for VMs (all the steps as described in NVIDIA GPU Operator guide)I try to deploy a new VM with RHEL 7.9 (looks like this version is supported in driver version 13.7 in the documentation)When I try to create the VM configured as follow:It fails to start and there are the warning in the VM events:In the VM virt-launcher pod I get the following errors:and finally the virt-launcher fails, and so does the VM.I can’t see any related logs in the Operator pods, only in the sandbox-device-plugin there is a log:The sandbox also showed this error when it started, but it’s in running state:In the Host itself using dmesg I can see the following error:Running nvidia-smi vgpu from nvidia-vgpu-manager-daemonset pod within openshift-driver-toolkit-ctrRunning nvidia-smi vgpu from nvidia-vgpu-manager-daemonset pod within openshift-driver-toolkit-ctrDo you have a suggestion why does this behavior happen?
Let me know if I can provide any additional information.Powered by Discourse, best viewed with JavaScript enabled"
76,cant-use-vgpu-manager-8-x-drivers-with-latest-centos-kernel,"Hi,I can’t use neither NVIDIA-vGPU-rhel-7.6-418.66.x86_64.rpm nor NVIDIA-vGPU-rhel-7.6-418.92.x86_64.rpm with the latest CentOS kernel (kernel-3.10.0-957.27.2.el7.x86_64). weak-modules complains about symbol versions (when enabling ""set -x"" in weak-modules):++ echo depmod: WARNING: /tmp/weak-modules.qqZEox/3.10.0-957.27.2.el7.x86_64/weak-updates/nvidia/nvidia-vgpu-vfio.ko disagrees about version of symbol vfio_pin_pages
++ echo depmod: WARNING: /tmp/weak-modules.qqZEox/3.10.0-957.27.2.el7.x86_64/weak-updates/nvidia/nvidia-vgpu-vfio.ko disagrees about version of symbol vfio_unpin_pages
++ echo depmod: WARNING: /tmp/weak-modules.qqZEox/3.10.0-957.27.2.el7.x86_64/weak-updates/nvidia/nvidia-vgpu-vfio.ko disagrees about version of symbol vfio_register_notifier
++ echo depmod: WARNING: /tmp/weak-modules.qqZEox/3.10.0-957.27.2.el7.x86_64/weak-updates/nvidia/nvidia-vgpu-vfio.ko disagrees about version of symbol vfio_unregister_notifierI only debugged this with 418.92, but it must have been the same with 418.66 (no symlinks created in /lib/modules/3.10.0-957.27.2.el7.x86_64/weak-updates/ directory).
kernel 3.10.0-957.21.3.el7.x86_64 is OK.
my hardware is
18:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100 PCIe 32GB] (rev a1)
3b:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100 PCIe 32GB] (rev a1)
86:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100 PCIe 32GB] (rev a1)
af:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100 PCIe 32GB] (rev a1)what can I do (besides booting an older kernel)?thx
matthiasPowered by Discourse, best viewed with JavaScript enabled"
77,rtx-6000-on-bare-metal-windows-suggestion,"Hi I have just got new customer, they are architect company and they have 10x I7 pc with 1080TI. They installed terminal server RDHS last year with following specs.Bare Metal Windows 2019 terminal server 15RDHS
1x MAINBOARD ASUS WS C621E SAGE
1x 1500 WATT power supply
4x64GB (256GB) ECC 2933mhz Samsung RDIMM RAM
1x INTEL VROC DIRECT CPU RAID 0
2x 4tb 4510 pro dc internet u.2 m.2 ssd
2x CPU Xeon Gold 6154  3.0GHz
1x NVIDIA GT 710
WATER COOLINGat the moment 10 person connect to terminal server which 3 of them use Autocad without gpu acceleration enabled, I guess because they have super fast vroc raid 0 and 2x cpu. these 3 Autocad users connect terminal server in and out of office when they go construction sites.They want me to install better graphic card hence I found this forum to solve this issue. 10 person will use Autocad in terminal server without having problem. I already suggest them VMware or any VM solution but they don’t want and strictly they want to use flexibility of having bare metal server.I have 2 suggestion in my mindoption a) 1x RTX 6000 and 10x Vapp ( I suppose even without VM I need this Vapp I don’t know what it is)
option b) 2x RTX 2080 TI with NVLINK and enable graphic acceleration on terminal server.Do you guys have any suggestion regarding option a or option b or any other option that I can’t think of ?
Do I really need RTX 6000 and vApp when I use baremetal ?Thanks in advance
RegardsHiWhichever version of AutoCAD is being used, increasing the CPU Clock Speed will improve the performance. 10 RDSH Users do not need 36 Physical Cores / 76 Threads, and as there are only 10 Users, they can get away with using a lower Core Count but with a much higher Clock Speed. 3.0Ghz is about the minimum you’d want for a good AutoCAD experience and faster is recommended if possible. The following would be my current choice for a 10 User AutoCAD deployment and these CPUs will provide a big increase in overall system performance and especially for AutoCAD:quick reference guide including specifications, features, pricing, compatibility, design documentation, ordering codes, spec codes and more.For the GPU, they should be using one that uses a Quadro driver, not a Consumer Gaming one. They may not need RTX 6000 levels of performance and a cheaper way to do it might be to use something like an RTX 4000 (8GB) or RTX 5000 (16GB). Neither of these will require a license and they will both use the Quadro driver. An RTX 6000 can be used if you think it necessary (there are multiple reasons for choosing this, including future proofing and flexibility), and if you use it with the publicly available Quadro driver (not the vGPU one) it won’t need a license either.Make sure you monitor the Users physical workstations for hardware utilisation before recommending a GPU. This is a great utility to use to capture those metrics: Releases · JeremyMain/GPUProfiler · GitHub You can then decide which GPU to go for once you’ve accounted for the combined utilisation.RegardsMGHi MrGRID,Thank you very much your valuable information and direct me to correct solution, since they already have 2x Xeon 6154 I am just thinking if I could change to 2x Xeon 6250 will there be any tangible outcome.I am thinking of getting a RTX 6000 with Quadro driver not vGPU for future proof. Is there any benefit of using vGPU on Bare metal anyway?  for example I have seen Vapps but I don’t know if I use that on bare metal is it going to be any difference. Do you think 1x RTX 6000 better than 2x Quadro RTX 5000 with NVLINK ?I will investigate utility you are referring and trying to understand it.Thank you
RegardsHiRegarding my CPU recommendation … An increase of nearly 1Ghz per Core for an application that is typically limited by CPU Clock Speed will give a notable performance boost! Usually, choosing the best CPU is a trade-off between Cores vs Clock Speed due to having to support multiple users, however, as your Customer only has 10 Users, there is no trade-off as the fastest Xeon CPUs have enough Cores to support the total user density. That’s a great position to be in! Don’t forget that will be a system wide performance boost, not just in AutoCAD.The CPUs they currently have are sub-optimal for this specific environment.If you use a Quadro GPU in Bare-metal or with a Hypervisor in Passthrough with the publicly available Quadro driver, there is no license to pay. Besides, you wouldn’t use vApps licensing with Autodesk products as the performance would be poor.The RTX 6000 is a better choice in my opinion because it can support vGPU if your Customer ever decided to make the switch to a virtualised environment. Anything in the Quadro line-up below an RTX 6000 does not support vGPU. Regarding NVLink, for this kind of workload I really wouldn’t bother.RegardsMGThank you MD,I am going to replace cpus the one you suggest.My last question is does it make any difference to have 1x or 2x GTX 6000? based on my bare metal server without using VM or vAPP but using just plain Quadro driver?thank youHiA single RTX 6000 is more than sufficient for this kind of deployment, if anything it’s too much. A Multi-GPU install would be a complete waste for this deployment, as it would be hugely over-spec’d and underutilised, not to mention Multi-GPU is not recommended for RDSH deployments.The reason I haven’t recommended a lower spec GPU for this deployment, is because you would then lose future proofing due to the next model down in the Quadro line being an RTX 5000 (even though from a performance perspective, it’s perfectly capable). If I were to suggest a T4 (from the Tesla line), then you would need an external vGPU License Server and you would then need QvDWS Licenses for every Concurrent User.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
78,unable-to-install-specific-nvidia-driver-on-google-cloud-t4-2-gpu,"Hi hope you al doing well.i had very bad  day i try whole day to install Nvidia driver on Ubuntu system that are host on Google Cloud Engine using T4 2 GPU
i use sudo apt install nvidia-driver-470
but upon reboot i got 525 version and cuda show 12.0in nvidia-smi
i purge all and
I tried different versions but did not work i am tired please help me.Powered by Discourse, best viewed with JavaScript enabled"
79,unable-to-use-tesla-p40-in-esx-7-0u3-in-windows-10-prod-22h2-or-windows-server-2019,"Server R730 2 x E5-2690 V4 384 GB memory using ESXi 7.0 U3.
Tesla P40 configured as Passthru.VM Guest Windows Server 2019 had no problem install Nvidia driver but when start display device Tesla P40 had yellow exclamation mark with this error when checking property in Device Manager:
This device cannot start. (Code 10)
Insufficient system resources exist to complete the API.VM Guest Windows 10 Prod 22H2 had same problem and same error message in Nvidia Tesla P40 in property manager:
This device cannot start. (Code 10)
Insufficient system resources exist to complete the API.Please help if anybody had experience using Tesla P40 in ESXiAs always: Which driver did you try to use? Keep in mind that you need a vGPU driver which requires licensing! You can use an eval to test the functionality and download the right driver from the vGPU portal.Regards SimonHi,This is version I used 527.41-data-center-tesla-desktop-winserver-2016-2019-2022-dch-international
This is only VM Passthru not using vGPU yet. I got the card in ebay for $300 and want to use in my server R730 using ESXi 7.0 U3. If this work I will configure as vGPU but maybe I will not used as vGPU because I have to pay license between $100-400 per year for perpetual just to use Davinci Resolve. It didn’t make sense.Unfortunately you are wrong. It doesn’t matter what type of deployment you are using. If you want WDDM support for DC GPUs like Tesla P40 you need a driver that supports it and this is only the vGPU driver. So you will need to buy a vGPU license no matter if you run vGPU, Passthrough or Baremetal.See also:Documentation for system administrators that describes NVIDIA Virtual GPU licensed products and how to configure licensing for them on supported hardware.Here you can see vDGA and Baremetal are also listed for vWS licensing…Maybe that the reason it got that error. It should be nice if the message mention fail to start because no license found. The bare metal is EULA only which mean is not enforced by software if I am not mistaken.
I did get trial license for 90 days yesterday and will try that. Actually the windows client driver from Grid for ESXi 7 is the same as the one I directly download from Nvidia public resource.
Do you know the latest documentation for vGPU other than this GA_vGPU_Deployment_Guide_TechPub_v04_c_final (nvidia.com)
Because this one written in 2015 for ESXi 6.1.
Another question let say I return this card and get RTX A4000 is that will only work if I get the license?
Thank you for your response anyway.Hi,
the driver is definitely not the same. Please use the vGPU driver and test again and you will see that it works.
We have a vGPU quick start guide available:Minimal instructions for installing and configuring NVIDIA virtual GPU software.RTX A4000 won’t require a license as this is a workstation GPU but could cause other issues as the RTX driver is not optimized for virtualization (virtual display support). These GPUs have display outputs and expect a monitor to handle proper resolution. Our vGPU driver instead has the mentioned virtual display support to create the resolution for VMs required dynamically.regards
SimonHi,I am stuck in configuring Nvidia License System. Please let me how can I get help.
In below step:
"" 3.9.2. Installing a License Server on a DLS InstanceI could not find Action that will download license_mm-dd-yyyy-hh-mm-ss.bin. I have open the page 10 times and click all Action and none of that will do that. Please help me if somebody know and resolve that problem.It doesn’t seem like Nvidia is providing support for Azure Windows VMs in this thread but in case it becomes a priority again I would like to understand what Windows Image + Nvidia hardware is required for Audio2Face.Windows 2019 and Windows 10 Pro didn’t seem to work.
Tesla M60 Doesn’t seem to work
Powered by Discourse, best viewed with JavaScript enabled"
80,connecting-to-a-nvidia-cloud-based-license-server-trough-a-authenticated-proxy,"I just watched your youtube video about setting up the NVIDIA Cloud Based Licensing server: Get your vGPU PoC running with NVIDIA Cloud Licensing Service - YouTube in order to license the VDI GPUs.Great Video!For me there some details are missing if someone would use a authenticated Proxy between clients (VDIs) and that cloud based license service.In order to get our VDIs to connect to this cloud service we would need to connect though an authenticated proxy. As Alternative we could ask for some proxy exception but then we would need a list of URLs to allow that which we could not find.The other way could be a possibility to add proxy credentials to the Client (VDI) so it can authenticate to our proxy. I checked already the documentation but could not find a way to do so.Can you help me?thanks a lot an have a great day.
cheers David.Hello David
Did you ever get a solution for your problem? I’m in front of the same.
THX
RogerHi Roger,could you please explain in more detail what is your issue? Proxy support for CLS is an upcoming feature but would be helpful to get the proxy server vendor for example.
If you need to exclude specific host names in the FW as a workaround you will get the necessary information from our documentation or support team.regards
SimonHello SimonThanxs for the answer. That mean at the moment its not possible to let talk the grid true a proxy with the cls?regards
RogerHello SimonAnd yes i need the host names, and they are not in any documentation i found. So i’ll contact the support team.regards
RogerHi Roger!Sorry for the late answer, we ended up installing the on premise Appliance (NLS) since it could not authenticate to our proxy. Now the Update for Version 15 is on my desk  and i think about moving to the Cloud Licensing Server. I saw in the release notes Proxys are now supported.Did you end up opening some URLs… or did you manage to run licensing through the proxy?Thanks a lotKind Regards DavidPowered by Discourse, best viewed with JavaScript enabled"
81,please-update-nvidia-driver-the-minimum-required-nvidia-driver-for-nvenc-is-522-25-or-newer-please-update-nvidia-driver-driver-does-not-support,"Hi,
I have NVIDIA quadro K 2100M video card end up trying to use Topaz
software and when I choose NVIDIA encoder I got this message:Please update Nvidia driver. The minimum required Nvidia driver for nvenc is 522.25 or newer.I have no idea how to do that and no clue is that even possible
Is there anybody can help me that issue and give me some instruction how to do it and where to go to do that.
Your help will be very appreciated
thank you very much
DanielPowered by Discourse, best viewed with JavaScript enabled"
82,graphics-card-for-an-hyper-v-rdp-server,"i have a tesla t4 card in a dell dell r740 server.  i’m trying to use dda to pass the graphics card to a hyper-v vm.  In the VM i can see the graphics card in the device manger.  However when i try to run something open gl it errors out.  If<a target=‘_blank’ rel=‘noopener noreferrer’ href=‘i run something via direct x the gpu isn’t doing anything according to perfmon.  Is there something i ne’>i run something via direct x the gpu isn’t doing anything according to perfmon.  Is there something i need to do to force the VM to use the new graphics card.HiFirstly, are you using the driver from the vGPU License Portal and does it have a license applied?Secondly, what type of VM is it? Windows 10 or RDSH?RegardsMGi’m just using the driver from nvidia’s website, is there a special licenced driver that i need?i’m trying to run RDSH on a windows server 2019.HiYou should be using the driver from here https://nvid.nvidia.com which requires an account and a license.As you’re not using vGPU (which you can’t with Hyper-V) you would be better off with a Quadro GPU and then use the standard Quadro driver from the NVIDIA website. That also wouldn’t require a license.As you’re running RDSH, you need to enable this GPO:Local Computer Policy > Computer Configuration > Administrative Templates > Windows Components > Remote Desktop Services > Remote Desktop Session Host > Remote Session Environment > Use hardware graphics adapter for all Remote Desktop Services sessionsRegardsMGis there a quadro driver that i could use w/ my tesla card?I’ve done the gpo thing.is there a better way to benchmark if i’m utilizing the tesla card other then the unreal heaven benchmark?  Every time i try running it using open gl I get an error!""GLAppWindow::create_context(): wglGetProcAddress():failed engin::video_restart    …""i’m not sure if that just an issue w/ the program or because it can’t access the proper hardware?HiQuadro GPUs use a Quadro driver, with the exception of the RTX 6000 and RTX 8000 which can use either Quadro or vGPU.Tesla GPUs use a Tesla driver for Passthrough / bare-metal Compute or a vGPU driver for virtualised workloads (Compute or Graphics).Yes. Unless your users run Heaven all day, it’s a pointless test and is only really for amusement as it proves nothing. Running benchmarks on VMs can be very misleading anyway as you really need to understand what it is you’re trying to prove, and isn’t really something that should factor into any technical decision too much, unless you’re trying to compare like for like with physical vs virtual, but even then, there are so many reason why it’s not a valid test. There are frame rate limiters built into the software layer so they all need to be turned off for bench marking otherwise the results will be limited, and it’s kind of pointless as when your users access the platform, it’s best to have those limiters enabled to balance the utilisation.If you want a more comprehensive test, you should be running one of the applicable ""SPEC"" benchmarks. They are industry standard for 3D workloads from the major ISVs (Dassault, PTC, Autodesk, Siemens etc etc) and will give your platform a proper workout! But again, you still need to disable the various limiters and then tweak settings throughout your entire stack right down to the Server BIOS to achieve the highest score, and it all just gets a bit unrealistic as you’ll never push the platform that hard in that way.You’re far better off using the applications you plan to actually use and testing with them, you’ll get much more realistic usable results.Out of interest, what do you plan to use the platform for and which remoting protocol are you using to access the VM?RegardsMGit’s an industry specific CAD software call Mitek Sapphire Structure  https://www.mitek-us.com/software/SAPPHIRE-Structure/we just plan on using RDP out the gate, we may look at citrix if we are having luck w/ RDP.I’m trying to use this in a passthough / bare-metal situation, how do i verify that it’s actually ""working""  So far just by watching perfom i’v seen no evidence it’s actually doing anything.HiThanks for the URL.In terms of performance, features, flexibility and management, Citrix will provide a much better experience overall.Do your users have any USB peripherals to consider? Things like a 3D SpaceMouse (3Dconnexion) etc? RDP won’t pass those through into the RDSH session.As it’s Passthrough and you want ""Graphics"" (not ""Compute"") you still need the Graphics driver. This is only available from within the NVIDIA Portal and needs to be licensed. You can register for a 90 day evaluation to gain access to it from here: Virtual GPU (vGPU) Software Free 90Days Trial | NVIDIAAs for validating whether the GPU is being used, you can use a GPU monitoring tool. My favourite is one called GPUProfiler. It’s created and maintained by a friend at NVIDIA and is available from here: Releases · JeremyMain/GPUProfiler · GitHubAs you’re focusing on one application, what’s the physical spec of the server? (CPU, RAM, Disk)RegardsMGgetting the licensed driver did the trick, thanks for the help!i’m just using the driver from nvidia’s website, is there a special licenced driver that i need?HiYes, there is a specific driver you need for vGPU. If you don’t already have access, you can register for an evaluation here: NVIDIA Enterprise Account RegistrationOnce approved, you’ll then be granted access to the Portal where you can download the License Server and vGPU Software.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
83,tesla-t4-vgpu-goes-k8s-problem-with-driver-image-container-generation,"Hi guys!I got 4 T4 and I want to offer their power to my colleagues using K8s and Docker. My boss said, that all the cool kids are using it, and that’s why we’re gonna start using it, because we are pretty cool as well.I got K8s running and followed the instructions from here. However, I ran into some problems with the Dockerfile. So I copied the Dockerfile from/home/ubuntu/driver/ubuntu20.04/Dockerfileto my home directory /home/ubuntu/ (I am on Ubuntu 20.04). Therefore, I had to modify the Dockerfile. Now, it looks like this:FROM ubuntu:20.04 as buildRUN echo ‘debconf debconf/frontend select Noninteractive’ | debconf-set-selectionsRUN apt-get update && apt-get install -y --no-install-recommends 
apt-utils 
build-essential 
ca-certificates 
curl 
git && 
rm -rf /var/lib/apt/lists/*ENV GOLANG_VERSION 1.15.5
RUN curl -fsSL https://storage.googleapis.com/golang/go${GOLANG_VERSION}.linux-amd64.tar.gz 
| tar -C /usr/local -xz
ENV PATH /usr/local/go/bin:$PATHWORKDIR /workRUN git clone nvidia / container-images / driver · GitLab && 
cd driver/vgpu/src && 
go build -o vgpu-util && 
mv vgpu-util /workFROM nvidia/cuda:11.4.1-base-ubuntu20.04ARG BASE_URL=http://us.download.nvidia.com/XFree86/Linux-x86_64
ARG BASE_URL=https://us.download.nvidia.com/tesla
ARG DRIVER_VERSION
ENV DRIVER_VERSION=$DRIVER_VERSION
ENV DEBIAN_FRONTEND=noninteractive#Arg to indicate if driver type is either of passthrough(baremetal) or vgpu
ARG DRIVER_TYPE=passthrough
ENV DRIVER_TYPE=$DRIVER_TYPE
ARG DRIVER_BRANCH=460
ENV DRIVER_BRANCH=$DRIVER_BRANCH
ARG VGPU_LICENSE_SERVER_TYPE=FNE
ENV VGPU_LICENSE_SERVER_TYPE=$VGPU_LICENSE_SERVER_TYPE
#Enable vGPU version compability check by default
ARG DISABLE_VGPU_VERSION_CHECK=false
ENV DISABLE_VGPU_VERSION_CHECK=$DISABLE_VGPU_VERSION_CHECK
ENV NVIDIA_VISIBLE_DEVICES=voidRUN echo ‘debconf debconf/frontend select Noninteractive’ | debconf-set-selectionsRUN dpkg --add-architecture i386 && 
apt-get update && apt-get install -y --no-install-recommends 
apt-utils 
build-essential 
ca-certificates 
curl 
kmod 
file 
libelf-dev 
libglvnd-dev 
pkg-config && 
rm -rf /var/lib/apt/lists/*RUN echo “deb [arch=amd64] Index of /ubuntu focal main universe” > /etc/apt/sources.list && 
echo “deb [arch=amd64] Index of /ubuntu focal-updates main universe” >> /etc/apt/sources.list && 
echo “deb [arch=amd64] Index of /ubuntu focal-security main universe” >> /etc/apt/sources.list && 
usermod -o -u 0 -g 0 _aptRUN curl -fsSL -o /usr/local/bin/donkey https://github.com/3XX0/donkey/releases/download/v1.1.0/donkey && 
chmod +x /usr/local/bin/donkeyCOPY ./driver/ubuntu20.04/nvidia-driver/ /usr/local/binCOPY --from=build /work/vgpu-util /usr/local/binADD ./driver/ubuntu20.04/drivers/NVIDIA-Linux-x86_64-470.63.01-grid.run drivers/
ADD ./driver/ubuntu20.04/drivers/README.md drivers/
ADD ./driver/ubuntu20.04/drivers/vgpuDriverCatalog.yaml drivers/#Fetch the installer automatically for passthrough/baremetal types
RUN if [ “$DRIVER_TYPE” != “vgpu” ]; then 
cd drivers && 
curl -fSsl -O $BASE_URL/$DRIVER_VERSION/NVIDIA-Linux-x86_64-$DRIVER_VERSION.run && 
chmod +x  NVIDIA-Linux-x86_64-$DRIVER_VERSION.run && 
apt-get update && 
apt-get install -y --no-install-recommends nvidia-fabricmanager-${DRIVER_BRANCH}=${DRIVER_VERSION}-1 
libnvidia-nscq-${DRIVER_BRANCH}=${DRIVER_VERSION}-1; fiWORKDIR  /driversARG PUBLIC_KEY=empty
COPY ${PUBLIC_KEY} kernel/pubkey.x509ENTRYPOINT [“nvidia-driver”, “init”]This file runs when I employsudo docker build   --build-arg DRIVER_TYPE=vgpu   --build-arg DRIVER_VERSION=$VGPU_DRIVER_VERSION   -t ${PRIVATE_REGISTRY}/driver:${VERSION}-${OS_TAG} .where I set the variables starting with $ as you suggested here. However, it breaks in step 35 whereCOPY ${PUBLIC_KEY} kernel/pubkey.x509is to be executed. Can you guys give me a hint how fix this? The error message readsStep 35/36 : COPY ${PUBLIC_KEY} kernel/pubkey.x509
COPY failed: file not found in build context or excluded by .dockerignore: stat empty: file does not existPlease note, that my Dockerfile is located at/home/ubuntu/DockerfileThanks in advance,
RobertHi persons.A colleague helped me out.In the end, we manipulated the lineARG PUBLIC_KEY=emptytoARG PUBLIC_KEY=./driver/ubuntu20.04/emptyand the driver container image was built successfully.Kind regards,
RobertPowered by Discourse, best viewed with JavaScript enabled"
84,raspberry-pi-v2-1-camera-red-black-crash-screen,"hello, I use Raspberry PI Camera V 2.1 on nano, * When the light is low, the camera displays a red and black screen。How to appear black  screen ??Powered by Discourse, best viewed with JavaScript enabled"
85,tesla-m10-hyper-v-2016-vdi-windows-10-not-working-vgpu,"HI All, I’d like to know if you can help me.I have 2 Hyper-V 2016 servers 386 RAM + 2 Processors 32cores + 2 nVIDIA tesla M10I have deployed on both, the NVidia Grid Software. On both servers I have set up the local policy to use hardware for remote desktop services. I have created a VM as the license server, I have activate it, register the MAC and downloaded the 90 trial license for 50 licenses from the Enterprise portal.The license server show me that 2 licenses were delivered, one for each Hyper-V hosts associated with one of the MACs that the servers have.I am deploying a VDI Windows 10 environment. I have tried with RemoteFX and without it but I am not getting the licensing from the server even I reserved the licenses by MAC.How can I get the full experience for my VDIs? what I am missing? do I need install any nvidia driver / software over the Windows 10 image? what other configuration I need to deploy to deliver graphics experience over my 10 VDI W10 pool?I have deleted and created the VDIs 15 times, trying all the options, configuring policies on the hosts… updating the last nVIDIA software realease… but…not working…Please, could you help me?Thank you very much for your help and time in advance.
PabloSo what’s the issue? Everything works as expected. Licensing is not fully enforced for RDSH or RemoteFX so there won’t be license aquisition as the licensing for RemoteFX is EULA based.See also here:Documentation for system administrators that describes NVIDIA Virtual GPU licensed products and how to configure licensing for them on supported hardware.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
86,cuda-and-nvidia-smi,"Hello all,
I am an amateur user, please forgive for possible omissions. I have EVGA GeForce RTX 2060 6GB GDDR6 KO Ultra Gaming GPU and a Linux Ubuntu 22.04 operating system.
I am running some chemistry simulations and calculations like these so i need the best performance of my hardware. The only driver version that gives me a response with nvidia-smi command is 470.
Insted of saying that my CUDA version is 11.4, when i type nvcc --version, the command is not found and when i install it with sudo apt install nvidia-cuda-toolkit, then i get not found when i type nvidia-smi.
Is it impossible to have both at the same time?
Thank you in advance
manos@manos:~/Desktop$ nvidia-smi
Sun Apr 30 13:21:13 2023
±----------------------------------------------------------------------------+
| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce …  Off  | 00000000:08:00.0  On |                  N/A |
|  0%   30C    P8    12W / 170W |    181MiB /  5912MiB |      1%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1756      G   /usr/lib/xorg/Xorg                 93MiB |
|    0   N/A  N/A      1891      G   /usr/bin/gnome-shell               86MiB |
±----------------------------------------------------------------------------+
manos@manos:~/Desktop$ nvcc --version
Command ‘nvcc’ not found, but can be installed with:
sudo apt install nvidia-cuda-toolkitPowered by Discourse, best viewed with JavaScript enabled"
87,vgpu-manager-on-flatcar-kubernetes-and-kubevirt-possible-or-not,"Hello,I’m permit to open a topic to know if it’s possible to run vGPU Manager on flatcar, along with kubernetes and kubevirt.For the context :  I’m currently testing kubevirt on flatcar bare metal servers. Working well for now.  I can manage VM inside kubevirt.But well the graphics part of KVM is a little too slow for virtual desktop. So we would like to try vGPU with Nvidia A2 cards to accelerate the remote display rendering.I manage to create an offline (air gapped) container with the nvidia driver for flatcar. Kernel modules are loading, nvidia-smi (inside the container) works ( return informations about the physical Nvidia A2 card).But, If I understand correctly the documentation and the Helm chart of GPU Operation, I need to build a container image “vgpu Manager”, right ?And I don’t see any dockerfile for flatcar. Is there any possibilities by the way ?
Or impossible ? (I’m not asking for official support of course, just the possibility to run and try it)For the driver container I use :
the Flatcar Dockerfile from the  nvida gitlab repod  with driver version 510.108.03 (support of cuda 11.7.1 as use in the Dockerfile and support nvidia A2 card as mentionned in grid release compat pages.But for vGPU manager only dockerfile for Ubuntu ? no FlatcarGitLab.comPerhaps with writing my own Dockerfile ? Or impossible ?Thank you in advancePlease feel free to ask for details or others informations.Regards,Powered by Discourse, best viewed with JavaScript enabled"
88,unbindlock-error-when-trying-to-create-vgpu,"We just upgraded one of our machines from V100s to A40s. I am attempting to run /usr/lib/nvidia/sriov-manage -e XX:XX:XXXX.X but every time I try I get the following error:
Cannot obtain unbindLock for XXXX:XX:XX.XThe vGPU host driver is up-to-date. I tried uninstalling and reinstalling the host driver but that didn’t fix the issue. The GPUs are not being used by anything. Assistance would be greatly appreciated.I would like to second this issue. In my case, it appears on a Linux (alma linux 8.5) system with an A5000 GPU.
(QEMU 4.2.0)Hello ,Were you ever able to resolve this? I am running in to the exact same error on a AMD EPYC system with A40s.
Ubuntu 20.04 is the OS.Thanks,SalvatorePowered by Discourse, best viewed with JavaScript enabled"
89,thinksystem-sr650-tesla-v100-server-2019-datacenter-help,"Good day.
There is test hardware ThinkSystem SR650 + Tesla 100 x32GB
Installed Windows Server 2019 datacenter, installed a hypervisor, created a virtual machine, how to assign this video card to a virtual machine?
Perhaps there is some kind of step by step manual.
Thank you.HiAll the documentation you need is available here: NVIDIA Virtual GPU Software DocumentationRegardsMGPowered by Discourse, best viewed with JavaScript enabled"
90,nvidia-and-vmware-drs-cluster,"Hey AllWe are running a Dell VX-Rail Cluster with 8 Nodes.
And we have Tesla M10 Cards in all the Nodes.
We have DRS disabled at the moment since Nvidia dont support VMWare DRS in the Cluster when Nvidia Cards are present.We are running Nvidia driver version = NVIDIA-GRID-vSphere-6.7-418.92-426.04When will Nvidia support this feature?
And the second question is, If we enabel DRS cluster in  VMWare, but we will let the VM`s that are running with GPU cards, be excluded from DRS, will that work?Just to be clear: VMWare doesn’t support DRS with GPUs. You should ask VMWare when the feature will be available. We cannot comment on features from 3rd party software.I can read in the Nvidia driver release documents, that the feature is not yet supported.
Can Nvidia tell when is will be supportet, or is it only VMWare that can give this information?HiAs Simon mentions above, you’ll need to raise this with VMware. You can either try with your VMware AM or try posting on the VMware forums to see if anyone there has some information on it.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
91,vgpu-of-telsa-t4-not-seen-on-esx-6-7,"Please run nvidia-smi without vgpu command and post the output.here you are…[root@localhost:~] nvidia-smi
Mon Mar 16 03:25:04 2020
±----------------------------------------------------------------------------+
| NVIDIA-SMI 440.53       Driver Version: 440.53       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:5E:00.0 Off |                    0 |
| N/A   38C    P8    17W /  70W |     92MiB / 15359MiB |      0%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0   2100302      G   Xorg                                           5MiB |
±----------------------------------------------------------------------------+One other point:
Due to pandemic situation in France we experiment som difficulties to comunicate and then obtain some information concerning that problem, wich is starting to be urgent (!).Also I should notice that I tried the 440.53 version of the driver, and also the 430.83 (which is more recent than the 440 (according to NVIDIA’s site), with exactly the same results !the result of the nvidia-smi -a command is: (which says that the cGPU mode is VSGA wich is not what we want (!))==============NVSMI LOG==============Timestamp                           : Mon Mar 16 17:24:11 2020
Driver Version                      : 430.83
CUDA Version                        : Not FoundAttached GPUs                       : 1
GPU 00000000:5E:00.0
Product Name                    : Tesla T4
Product Brand                   : Tesla
Display Mode                    : Enabled
Display Active                  : Disabled
Persistence Mode                : Enabled
Accounting Mode                 : Enabled
Accounting Mode Buffer Size     : 4000
Driver Model
Current                     : N/A
Pending                     : N/A
Serial Number                   : 1322419111424
GPU UUID                        : GPU-34d6d925-61d7-ca33-9c9b-34420d8614c9
Minor Number                    : 0
VBIOS Version                   : 90.04.38.00.03
MultiGPU Board                  : No
Board ID                        : 0x5e00
GPU Part Number                 : 900-2G183-0000-001
Inforom Version
Image Version               : G183.0200.00.02
OEM Object                  : 1.1
ECC Object                  : 5.0
Power Management Object     : N/A
GPU Operation Mode
Current                     : N/A
Pending                     : N/A
GPU Virtualization Mode
Virtualization Mode         : Host VSGA
Host VGPU Mode              : N/A
IBMNPU
Relaxed Ordering Mode       : N/A
PCI
Bus                         : 0x5E
Device                      : 0x00
Domain                      : 0x0000
Device Id                   : 0x1EB810DE
Bus Id                      : 00000000:5E:00.0
Sub System Id               : 0x12A210DE
GPU Link Info
PCIe Generation
Max                 : 3
Current             : 1
Link Width
Max                 : 16x
Current             : 16x
Bridge Chip
Type                    : N/A
Firmware                : N/A
Replays Since Reset         : 0
Replay Number Rollovers     : 0
Tx Throughput               : 0 KB/s
Rx Throughput               : 0 KB/s
Fan Speed                       : N/A
Performance State               : P8
Clocks Throttle Reasons
Idle                        : Active
Applications Clocks Setting : Not Active
SW Power Cap                : Not Active
HW Slowdown                 : Not Active
HW Thermal Slowdown     : Not Active
HW Power Brake Slowdown : Not Active
Sync Boost                  : Not Active
SW Thermal Slowdown         : Not Active
Display Clock Setting       : Not Active
FB Memory Usage
Total                       : 15359 MiB
Used                        : 92 MiB
Free                        : 15267 MiB
BAR1 Memory Usage
Total                       : 256 MiB
Used                        : 2 MiB
Free                        : 254 MiB
Compute Mode                    : Default
Utilization
Gpu                         : 0 %
Memory                      : 0 %
Encoder                     : 0 %
Decoder                     : 0 %
Encoder Stats
Active Sessions             : 0
Average FPS                 : 0
Average Latency             : 0
FBC Stats
Active Sessions             : 0
Average FPS                 : 0
Average Latency             : 0
Ecc Mode
Current                     : Enabled
Pending                     : Enabled
ECC Errors
Volatile
SRAM Correctable        : 0
SRAM Uncorrectable      : 0
DRAM Correctable        : 0
DRAM Uncorrectable      : 0
Aggregate
SRAM Correctable        : 0
SRAM Uncorrectable      : 0
DRAM Correctable        : 0
DRAM Uncorrectable      : 0
Retired Pages
Single Bit ECC              : 0
Double Bit ECC              : 0
Pending Page Blacklist      : No
Temperature
GPU Current Temp            : 39 C
GPU Shutdown Temp           : 96 C
GPU Slowdown Temp           : 93 C
GPU Max Operating Temp      : 85 C
Memory Current Temp         : N/A
Memory Max Operating Temp   : N/A
Power Readings
Power Management            : Supported
Power Draw                  : 17.41 W
Power Limit                 : 70.00 W
Default Power Limit         : 70.00 W
Enforced Power Limit        : 70.00 W
Min Power Limit             : 60.00 W
Max Power Limit             : 70.00 W
Clocks
Graphics                    : 300 MHz
SM                          : 300 MHz
Memory                      : 405 MHz
Video                       : 540 MHz
Applications Clocks
Graphics                    : 585 MHz
Memory                      : 5001 MHz
Default Applications Clocks
Graphics                    : 585 MHz
Memory                      : 5001 MHz
Max Clocks
Graphics                    : 1590 MHz
SM                          : 1590 MHz
Memory                      : 5001 MHz
Video                       : 1470 MHz
Max Customer Boost Clocks
Graphics                    : 1590 MHz
Clock Policy
Auto Boost                  : N/A
Auto Boost Default          : N/A
Processes
Process ID                  : 2100900
Type                    : G
Name                    : Xorg
Used GPU Memory         : 5 MiBPlease we will apreciate some quick help in that matter !
ThanxHi JohnIt’s not a problem with the driver.On your vSphere Host, uninstall the 430.83 (don’t upgrade), reboot the Host and re-install 440.53 so you’re running the most up to date version. That takes care of that.Once the driver has been reinstalled, make sure vCenter is still configured to ""Shared Direct"". Now that side of the install is taken care of and there’s no need to revisit it.Have you made any changes to the Server BIOS? If no, please review these articles to make sure your BIOS is configured correctly:NVIDIA Support Article: Incorrect BIOS settings on a server when used with a hypervisor can cause MMIO address issues that result in GRID GPUs failing to be recognized. | NVIDIAUse Page 23: https://images.nvidia.com/content/pdf/vgpu/guides/vgpu-deployment-guide-horizon-on-vsphere-final.pdfPlease also confirm that you are running Enterprise Plus licensing on your vSphere Hosts? (vCenter is fine with Standard licensing) …Let us know how you get onRegardsMGHi MG,It’s still not working…I read the bios link of your post but, because of the confinement of peapole in France (COVID-19), I’m not able to go to my work place in front of the server that time and I don’t know when I will be able to do so…I can for sure confirm I’m using the Enterprise Plus version of ESX
"" VMware vSphere with Operations Management 6 Enterprise Plus ""But stil:
[root@localhost:~] nvidia-smi
Mon Mar 16 21:06:43 2020
±----------------------------------------------------------------------------+
| NVIDIA-SMI 440.53       Driver Version: 440.53       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:5E:00.0 Off |                    0 |
| N/A   37C    P8    17W /  70W |     92MiB / 15359MiB |      0%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0   2100312      G   Xorg                                           5MiB |
±----------------------------------------------------------------------------+
means still no GRID !and also:
[root@localhost:~] nvidia-smi vgpu
Not supported devices in vGPU modeI’m lost !! Help…
RegardsHiOk, great. So you’re running the correct vGPU driver and you’re running the correct vSphere licensing. There’s no need to change anything there again. Forget about them and look at other areas.The BIOS is a really important step. I’m not saying it’s the issue, but it could certainly cause an issue and does need to be set correctly if it isn’t already. Do you not have any out of band management for the Server hardware? Is there no way to remotely get to the BIOS on server boot? How do you remotely power it on? No remote management Console to watch it’s progress?Regarding vCenter, first I want you to double check something …1: Log into vCenter as administrator.
2: Locate the vSphere Host that has the T4 installed and select it.
3: In the centre, click Configure, under Hardware select PCI Devices.
4: In the tab that says Passthrough-enabled devices, make sure the T4 is not listed here.
5: If it is listed here, it must be removed. Click All PCI devices and Configure Passthrough. Scroll down and unselect the T4 (there are multiple T4 options in here, none of them should be selected).
6: Reboot the Host afterwards.
7: Once rebooted, using the above steps ensure that the T4 is no longer showing in the Passthrough-enabled devices.Now follow these steps:1: Log into vCenter as administrator (if you aren’t already).
2: Locate the vSphere Host that has the T4 installed and select it.
3: In the centre, click Configure, under Hardware select Graphics.
4: You now have 2 Tabs (Graphics Devices and Host Graphics), select Host Graphics.
5: Select the Edit tab to the right.
6: In the Window that opens there are 2 sets of 2 options, at the moment you’re only interested in the tops ones (Shared and Shared Direct). You must select Shared Direct.
7: Reboot the vSphere Host. Once it comes back up, using the steps above make sure that Shared Direct has been accepted and is still set.
8: Connect to the Host using SSH and run nvidia-smi vgpu. If vGPU is available, it will list the T4.Try that and see how you get onRegardsMGHi MG,This project is in POC stage and then, unfortunetly, I don’t have the IPMI (supermicro) or IDRAC (HP) to remotely get the bios.For the other point, I don’t have vcenter (I won’t be able to install it on my windows 10). Then I just can use the hypervisor web-UI and then, I didn’t find with that interface, the way to configure hardware PCI-device (that was what I said when I told about the shared direct; I’m not sure to have activated later…).Is there a way to do so using the web-UI ? And if not, how can I install vCenter on my windows 10 ?Thanx
RegardsJohnapparently, vSphere client is no longer available for ESX later than 6.0 and I’m using 6.7 version…only the web-UI version…HiYou need vCenter for vGPU.I don’t mean any offence, but it sounds like you’ve not used VMware before, or at the very least are not familiar with it or its components. With that in mind, as you’ve mentioned this is urgent, I would strongly advise that you forget about using vGPU and just use the T4 in Passthrough to a single RDSH VM and give all users access to that. That’s the quickest way to build a usable VM and give multiple users a platform to work from (if that is your objective). You can get vCenter installed and look at vGPU after that’s done when your users are working.Passthrough doesn’t need vCenter and you can configure that directly on the vSphere Host. If this is an acceptable alternative, then reverse the steps I mentioned above about checking for Passthrough-enabled devices. Please note, that the T4 will still require a license in Passthrough, so make sure you have the NVIDIA License Server up and running.If you still want to go down the vGPU route, then you will need vCenter. In which case, deploy it on another physical Server in your environment. Download the vCenter .iso, this will then allow you to deploy a vCenter VSA to your other Server, but you’ll need to know how to configure it.As you’re unfamiliar with VMware and you’ve stated this is a priority, I would advise you just run the T4 in Passthrough and go down that route for the time being, unless there is a specific reason for wanting vGPU in the current situation.RegardsMGHi MG,To be perfectly clear, the POC was already done but using a KVM hypervisor. Before to deploy it in production stage, the company-IT ask us to do the same but with VMWare. We have to create a windows 10 vm, using vGPU, give the result to IT-team which will configure it in term of security group compliance for the next deployment (we are planing to deploy 15 vm on theses 3 ESX server). As you say, I’m not familiar with vmware (and actualy our ESX experts have just litle knowledge on grid and vGPU, unfortunetely…).
But I don’t want to give up this project. The goal is to give the oportunity to our coleague to start specific applications (gaz industry) and to use kind of VNC (DCV actually) to see the screen on their computers.I will try the vCenter way… Many thanx for your advises.JohnHi, I already advised to check your vCenter settings in my first post. If you are not familiar with VMWare it is very hard to give you proper advise.HiThe reason I suggested using Passthrough for now, is because as you’re unfamiliar with VMware (which is no problem at all, there’s plenty of technologies I’m unfamiliar with) it will be the quickest way to give your users access to a GPU accelerated desktop and allow them to work, albeit from the same RDSH VM. While they’re working on that RDSH VM, you can then look at how you install and set up vCenter and then in the background, build the Windows 10 VMs that you’ll migrate them to, rather than give them nothing in the short term until you’ve resolved this issue.This approach is the easiest and quickest way to bring up service :-)When you say ""gaz industry"", which Applications are your users running? Petrel? Kingdom? …RegardsMGPetrel, Techlog, eclipse, gocad … (Petrel is a very graphical consuming !)HiVery interesting …Depending on how your testing goes, you may want to seriously consider looking at other GPUs. Although it may work, the T4 isn’t really suited to seismic interpretation or eclipse runs, and certainly not with multiple users running on it.Personally, I’ve found Petrel to be CPU limited, so it’s worth making sure you have plenty of high speed CPU Cores for each VM as well, but I guess this depends on your workflow and which modules you’re using.The minimum GPU I’d be looking at for these type of workloads would be a P40, then either an RTX 6000 or 8000 if you need more performance than that. If you’re doing more Computational processing than 3D, then a V100 / V100S may be a better option than an RTX (although a V100 / V100S will do a great job with 3D as well if needed, and an RTX will do a great job with Computational, but they do have their more specific use cases). Obviously once vCenter is sorted and you’re able to use vGPU, you can put multiple users on all of those so they’re not a 1:1 relationship.How are you testing the performance? Seagull?RegardsMGHi all,Thanx for the advices M.G !News:
I deployed a vCenter on my ESX-1 using a windows vm and, I’m now able to configure the Shared Direct and, I now access to the vGPU on my vms (!)Many thanks to both of you !
All the Best
JohnHi.Im running ESX 6.7 on QuantaGrid D52G-4U which is compatible with Tesla T4 installed on it.
I tried all the steps mentioned in the thread, but still can’t make it work properly.Errors that I have:Theis is also missing PCI Devices menu item in the vCenter esx host Configure Tab.Do you have any idea what could be wrong?HiNot sure what you plan on using the 1A profile for?, but have you enabled SRIOV in the BIOS and enabled Above 4G decoding?RegardsMGHi.Yes, SRIOV and 4G decoding are enabled.You need to enable IOMMU (AMD) or VT-d (Intel) in the BIOS; SRIOV is for something else.Powered by Discourse, best viewed with JavaScript enabled"
92,esxi-6-7-tesla-v100-430-27-not-working,"Hello,we have a ESXi 6.7 installed on our Server. Now i wanted to passthrough the Tesla V100 to one VM.I installed the latest Host Driver for ESXi:
NVIDIA-VMware_ESXi_6.7_Host_Driver-430.27-1OEM.670.0.0.8169922.x86_64.vib and reboot the machine.But when i run the nvidia-smi comes an error:NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.Can anybody help?HiIf you’re using Passthrough you don’t need to install the .vib in the ESXi Host.Remove the GPU from running in Passthrough, and use a vGPU Profile instead. Then run nvidia-smi again.RegardsMGHello thank you for your reply,maybe ""passthrough"" was not the correct word. I want to ""attach"" the vGPU to more than one VM like the Document430.27-430.30-431.02-grid-software-quick-start-guide.pdf
Chapter 3. INSTALLING AND CONFIGURING NVIDIA VGPU MANAGER AND THE GUEST DRIVER describes.I register me in nvidia license portal, download the package NVIDIA-GRID-vSphere-6.7-430.27-430.30-431.02.zip for ESXi 6.7.The installation with ""esxcli software vib install –v NVIDIA-VMware_ESXi_6.7_Host_Driver-430.27-1OEM.670.0.0.8169922.x86_64.vib"" was also successful.But nvidia-smi throw the error:NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.Would be helpful to know which server hardware you are using. If it is Dell you need to modify your BIOS to restrict MMIO.
You should also run ""dmesg"" to get more information on the host what might be the issueThe machine is a Dell PowerEdge R740xd.dmesg | grep NVIDIA shows:2019-07-15T11:46:44.718Z cpu94:2101167)ALERT: NVIDIA: module load failed during VIB install/upgrade.
2019-07-15T11:46:44.722Z cpu109:2101168)NVIDIA: Starting vGPU Services.
2019-07-15T11:46:44.728Z cpu0:2101171)NVIDIA: Starting Xorg service.
2019-07-15T11:46:45.225Z cpu39:2101248)NVIDIA: Starting the DCGM node engine.It looks like the installation with VIB was not correct.I can not find information about ""BIOS restrict MMIO"". Is it what this nvidia support site describe?
https://nvidia.custhelp.com/app/answers/detail/a_id/4119/~/incorrect-bios-settings-on-a-server-when-used-with-a-hypervisor-can-cause-mmioOk i found the solution. Passthrough was enabled in in ESXi. I disabled it and can see now information about my GPU with nvidia-smi.Okay it still not works.I disabled the passthrough setting in ESXi Host by PCI-Devices.
I change with vSphere Web Client the Settings for the Host Graphics and Graphics Devices to shared direct.
Restart the ESXi Host.Now nvidia-smi works:vmkload_mod works:and dmesg has no errors:But i still can’t attach the graphic card. The menu option for Adding PCI-Devices is grey:
https://www.directupload.net/file/d/5518/ejz8rkxv_png.htmAny ideas?ECC memory disabled? Correct license present (Enterprise Plus) on vSphere?It was the License, we have only the Standard License in ESXi. I try it with passthrough in one VM till we have the right licenses.Powered by Discourse, best viewed with JavaScript enabled"
93,critical-condition-nvidia-graphics-driver-is-not-compatible-with-this-version-of-windows,"To Whom It May Concern,Good evening.
I have a problem regarding the malfunction of my graphics card to my laptop. It seems that my “Version of Windows” cannot detect my current graphics card which I’m using for several years now. It’s only this time that I updated my Windows and afterwards the graphics card isn’t working already. I tried to play one of my games and I kinda noticed that I’m not playing it the way it was supposed to be smooth back then. Then I checked that the only CPU/GPU that was named after is “Intel” which isn’t my graphics card.I checked my Device Manager and found out that my Display Adapter only shows Intel. When I ticked “Show Hidden Devices” I saw that my NVIDIA graphics card appeared but isn’t enabled. I right clicked it and it only shows Update Driver or Uninstall. There isn’t any option of Enable/Disable. I tried to press the “Update Driver” and it does nothing so what I did was, I uninstalled the device from Device Manager and tried to download the same driver that I know. Then soon after, upon installing, it says that it isn’t compatible with the version of Windows.I tried almost everything that I found from the internet. My recent activity was I used DDU (Display Driver Uninstaller) via Safe Mode and tried to reinstall the driver. But it still hasn’t solve the problem. So I tried to reach out to NVIDIA customer service but then I found this forum. I’ve been stressed out for weeks just for my graphics card to work again. I hope you could help me out. And sorry for my bad English. I did my best to express it with how I can explain it thoroughly. Hopefully you could help me out. Thank you! crying emojiPowered by Discourse, best viewed with JavaScript enabled"
94,failed-to-attach-multiple-vgpu-to-a-vm,"Currently, I am trying to add multiple ""vGPU "" in Ubuntu VM. But fails with the following error.Added following content in virsh edit <vm-name>Following is the environment configuration
GPU model: “NVIDIA RTX A6000”
OS: “Ubuntu 20.04.3 LTS (Focal Fossa)”
Kernel: “5.11.0-41-generic”
Server: SYS-740GP-TNRTWhile adding 1 vGPU to VM it’s a success, but fails during multiple vGPU.
Whether multiple vGPU supported in Ubuntu host hypervisor or something wrong in config?Hi shan_8992,I am facing the same issue, do you have any luck so far?Cheers,According to NVIDIA RTX A6000, its A6000-48Q/A6000-48C. For our use case, it’s not our target.
Screen Shot 2022-02-02 at 21.13.561698×860 121 KB
Is there any progress?Hi,what kind of progress do you mean? If we work on enabling smaller vGPU profiles for multi-vGPU?regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
95,virtual-machines-cannot-be-started-after-graphics-passthrough-is-configured,"I use a tesla T4 graphics card, the server system is centos7.8.2003, and the kvm virtual machine system is windows10.
I’m trying to do graphics card passthrough, my virtual machine installation command is:

微信图片_202305241709161664×118 6.78 KB

It is found that the virtual machine cannot be created. The specific performance is that it has been stopped at the beginning of the installation process and cannot be installed normally, but it can be installed normally after removing --host-device=5e:00.0.
Next, I first installed the kvm virtual machine normally. After the installation was successful, I used virt-mananger to add the graphics card to the virtual machine. The virtual machine that could start normally could not be started. I want to know if you guys have a solutionPowered by Discourse, best viewed with JavaScript enabled"
96,aws-g4dn-xlarge-with-nvidia-rtx-virtual-workstation-vws,"We would like to use NVIDIA RTX Virtual Workstation with G4dn.xlarge as a node in EKS cluster.
Planning to create T4-4C x 4 vGPUs and utilize them to deploy 4 pods integrating with vGPU.I would like to know whether vGPUs can be created on NVIDIA RTX Virtual Workstation and use it as worker node in EKS cluster?Powered by Discourse, best viewed with JavaScript enabled"
97,getting-cannot-obtain-unbindlock-for-000000-0-when-trying-to-enable-vgpu,"Hello,I am having trouble getting vGPU setup for some of our newer systems. Specifically these are Dell PowerEdge R7525 with AMD EPYC processors and 3x Nvidia A40 GPUs.The OS is Ubuntu 20.04 and I am using the latest NVidia vGPU driver: 510.108.03I am following the guide that comes with the driver and  when I try to enable them with the sriov-manage utility I get the following error:I verified that srv-io and iommu are enabled in the BIOS and I used the displaymodeselector --gpumode and disabled the display ports.I am stumped here.Any help would be greatly appreciated.Thank you,SalvatorePowered by Discourse, best viewed with JavaScript enabled"
98,vmotion-between-v100-pcie-and-v100-pcie-32-gb,"It’s possible to vmotion VMs between hosts with V100 PCIe and V100 PCIe 32GB?
Why are vGPU profiles different between these 2 cards? They are the same but one has 2x RAM than the other.vMotion is not possible between these GPUs as these have different deviceIDs so vMotion is not possible.I see. But, what’s the logic of assign different profiles to these cards if they are essentialy the same?Unfortunately vMotion is restricted to same deviceIDs. Migrating to different GPUs would be nice but the effort to make this possible would be really big.I can understand this on cards with different GPUs but not in this case as the GPUs are the same, and only amount of RAM is different.Powered by Discourse, best viewed with JavaScript enabled"
99,nvidia-grid-t4-1b,"The NVIDIA GRID T4-1B is compatible with the guestwindonws 10 systemHi,Welcome to the NVIDIA Developer forums! Your question belongs in the Virtual GPU category. I will move it over for you.Best,
Tom KCorrect. 1B is a vPC profile, meant for Win10 knowledgeworkers.THX.
But can I use CUDA?No. CUDA ist not supported with vPC. Then you would need 1Q profile and vWS license.Powered by Discourse, best viewed with JavaScript enabled"
100,vsphere-6-7-u2-nvidia-driver-430-27-0-00b-memory-on-some-cores,"Have 2 M10 cards per server.  ESXi 6.7 U2 upgraded driver to 430.27 and now some cores on the M10 show 0.00B memory allocated in the Graphics config on the host via vSphere Web Client.  All cores show as Shared Direct however xorg is not loading for some of the cores.Any ideas?This is what fixed it for me.We applied ESXi 6.7 patches as well as upgraded from 410 to 430 driver during the same maint window.  One of those clearly caused the xOrg config to get fried.  Going through the above steps put everything back in order for us.That sucked!Powered by Discourse, best viewed with JavaScript enabled"
101,rtxgi-patch-gives-error,"when applying RTXGI nvidia branch patch this is what im greeted with, please help me solve this. Im not a pro programmer but really need this to work…error: patch failed: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.cpp:272
error: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.cpp: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.h:32
error: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.h: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/IndirectLightRendering.cpp:342
error: Engine/Source/Runtime/Renderer/Private/IndirectLightRendering.cpp: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/RayTracing/RayTracingLighting.h:14
error: Engine/Source/Runtime/Renderer/Private/RayTracing/RayTracingLighting.h: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/SystemTextures.h:11
error: Engine/Source/Runtime/Renderer/Private/SystemTextures.h: patch does not applyThis worked for me
“open the patch file in Notepad++, go to Edit->EOL Conversions, select Unix (LF), save the file, and then try to apply the patch.”https://github.com/NVIDIAGameWorks/RTXGI/issues/35Powered by Discourse, best viewed with JavaScript enabled"
102,gtc-conference-date,"I attended GTC 2021 in April, but why now I see a GTC 2021 in November? What is the difference between these two conferences? Is GTC holding for twice per year? If I want to present my stuff related to GPU, which conference should I target for? ThanksPowered by Discourse, best viewed with JavaScript enabled"
103,assigning-multiple-vgpus-to-one-vm,"Hi All,I’ve got a Tesla M10 on my Windows Server 2019 VM, with a vDWS license installed.I was under the impression I could assign 2 vGPU’s to 1 VM so as to allocate extra resources for Solidworks when the vDWS license was used.However, the 2nd vGPU has an ! on it in Device Manager with an error on it ""This device cannot find enough free resources that it can use. (Code 12)If you want to use this device, you will need to disable one of the other devices on this system.""The only other device is the other M10.  I’ve disabled the Hyper-V Video Driver.I can install the driver again, then reboot and then the behaviour is the same.Have I done something silly?Thanks in advance for your help.HiNot sure why you’d want to do that … Solidworks can’t use more than 1 GPU.Solidworks is typically CPU limited (not GPU). So if you need more performance, you mainly need a faster CPU. Also, it’s single threaded, not multi-threaded so hopefully you have a CPU that at the very minimum has a 3.0Ghz base clock. If Solidworks is your main application, then 3.3Ghz or above would be a better choice.Which version of Solidworks are you using? Reason for asking, I believe it was Solidworks 2019 that had a bit of a rework to improve performance, so make sure you’re running the latest version if possible :-)RegardsMGHi sorry for the delay.  We’re running SW 2020.OK I must have misunderstood a different article about it.  I was under the impression you could basically utilise the resources of 2 vGPU’s as 1, thus increasing the power.We’re running AMD EPYC 7351 CPU’s at a clock speed of 2.9Mhz.  Maybe that’s the cause of the lagging.HiYou can run more than 1 vGPU, but the application needs to support it. Also, there are different ways of presenting more than 1 GPU to a system / application. As you’re running Hyper-V, you’re not actually using vGPU anyway, you’re using Passthrough (referred to by Microsoft as DDA (where a whole GPU is allocated to a VM, rather than a portion of it)).Application lag can be caused by many things. BIOS, choice in Hardware, Hypervisor settings, Storage, Network, Protocol, Operating System, Application Configuration, Data Size etc etc.What is it in Solidworks that’s laggy?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
104,help-setting-up-a-linux-vm-with-passtrouth-enabled-gpu,"Hi all,I’m having some issues running a docker container (triton inference server) on a vm using the host gpu (passthrough)My setup is the following:Host:
Linux ubuntu 20.04
NVIDIA RTX P4000
16GB RAM
800 GB Disk
16 coresVM:
Linux Ubuntu 20.04
10GB RAM
48 GB Disk
8 Cores
Virualized using qemuI believe the passthrouth is configured well since I can see the graphics card using lspci and nvidia-smi identifies it correctly.I’ve installed the nvidia-docker2 and configured it as docker default runtime. I’ve also installed kernel headers and development packages and CUDA drivers 470.103.01-1.When i run a container that uses gpu (such as triton inference server) the container freezes not only itself but also the whole VM (it is not possible to docker stop or docker rm it.I’m not sure if I need a nvidia license server or if my graphics card is not compatible with gpu passthrough/iommu.Any help is welcome. thanks!HowdyYou may need to configure your container to allow access and pass through the proper device files.See link. Powered by Discourse, best viewed with JavaScript enabled"
105,tesla-v100-16gb-and-unreal-engine-5-and-games,"Hello. Can Tesla V100 be used to develop games in Anrial Engine 5 and play games? We have a vGPU Tesla V100 16 GB. It has been forwarded to Windows Server 2019. Development is underway in Blender. Everything is fine there. But if you run the Anrial Engine editor, then it becomes impossible to work because of the jerking of the image, there is no smoothness.40 processors are assigned to the server via the Windows Hyper-V Server 2019 hypervisor, Tesla V100 16GB video card is forwardedPowered by Discourse, best viewed with JavaScript enabled"
106,help-with-m10-on-esxi-6-7,"The graphics profiles are not being populated.
when i add a shared pci device to my VMwhen i run esxcli software vib list | grep -i nvidiaNVIDIA-VMware_ESXi_6.7_Host_Driver  390.72-1OEM.670.0.0.8169922           NVIDIA                                                                                                                                                                           VMwareAccepted    2018-08-15    <----------- this gets returnnvidia-smi commands returns all the m10 GPUHey, did you move your VM to the correct host?Powered by Discourse, best viewed with JavaScript enabled"
107,licenses-not-being-released,"Hello all,Since last week we see that some of our machines randomly do not release their licenses, we first thought it was our new montly disk but now we’ve tested with multiple images and multiple versions of the nvidia software we still see this issue, we’re now lowering the lease period as a workaround.Anyone seeing similar problems?Powered by Discourse, best viewed with JavaScript enabled"
108,bar1-memory-is-65gb-on-rtx-a6000-correct,"Hello!We are trying to get vGPU running with two A6000 in vSphere 7.0.3 Enterprise Plus and have completed installation. Now our VMs do not boot with the following error:Could not initialize plugin ‘libnvidia-vgx.so’ for vGPU ‘nvidia_rtxa6000-12q’.We’ve investigated all things, SR-IOV enabled, IOMMU enabled and switched the displaymode. Verifying the displaymode with nvidia-qmi -q shows this info for the two GPUs:Is that indicating that the displaymode is set correctly for vGPU? It seems off, as the A6000 does not have 64GB of memory.Greetings
DominiqueMode is correct but I assume a VMWare parameter for the VM us still missing. How much sysmem is assigned?The VM has 4GB of RAM and 12GB of VRAM (-12q). Should we give it more ram?Also, we see that enabling SR-IOV does not succeed in ESXi for the GPUs, even after reboot the settings stays on “Needs reboot”. As this step is not mentioned in any documentation for vGPU, we are not sure if it is needed.
SR-IOV1573×333 51.5 KB
PS: SR-IOV is enabled in BIOS, these are the settings:

BiosSettingBox704×498 97.7 KB
We could fix the issue. Now we have received RTX 6000 Ada Generation and have a different problem - BAR1 shows 256MB for this card and we can’t change its display mode with the displaymodeselector tool. Is Bar1 of 256MB ok for using a RTX 6000 Ada for vGPU? If not, how do we change it?@sschaberPowered by Discourse, best viewed with JavaScript enabled"
109,since-changing-to-ubuntu-22-04-the-system-does-not-detect-external-screens-anymore,"With windows everything was working fine (external monitor (dell) connected by an hdmi-dvi adaptercable)
I installed Ubuntu Jammy on my Asus Rog zephyrus. At the beginning it recognized my external screen, but it was not possible to “connect” with it properly. When chosing the screen in display settings, it stayed black. Then i installed newer nvidia driver, 525 made my system crash so i sticked to 510. but it didnt recognize the external monitor. downgrading to 470 didn’t help either.
other things i tried:maybe install drivers for displayports or anything? I’m out of ideas…thank you in advance.greetingswhen the site lets me upload my nvidia-bug-report.sh then i will do. but it uploads for 15 min (400kb)
dont know what the problem is therePowered by Discourse, best viewed with JavaScript enabled"
110,nvidia-vgpu-license-server-issues-only-two-licenses,"Hello,sorry for my bad english.
We are currently supplying one of our customers with an RDHS-Windowsserver22-Enviroment which accesses GPU ressources.
We have ESXi Hosts with the NVIDIA A40.
We issue the licenses cia CLS. We have 70 vApp licenses.
In the beginning the licenses were obtained successfully by the user sessions. But now since some days we there are only 2 licenses requested althoug there are more user sessions. Per server one license instead of per user one license, so to say.
I tried to troubleshoot the problem by looking at the Nvidia Licensing Log.
It says that the licenses can be obtained etc. But still there are only 2 vApp licenses issued.
Before the problem occured, u could see down right a message which says nVidia license successfully obtained.
But now this message does not show up.
I checked network-connections etc.
Everything looks fine.
And also there are 2 licenses which are obtained. One per Server (We have 2 RDSH which accesses nVidia Ressources)
I also restarted the service. Without any success.
any ideas ?Hi,
it works exactly as it is designed to work and it is impossible that it ever worked the way you described.
vApps licensing is not license enforced (EULA based) so only the host itself gets a license as we cannot count the CCU at this stage.Best regards
SimonHello,thanks for your reply. That might be true it is some weeks ago.
BUt still, there should be more used licenses than this, right ?
There are right now at least +20 User-Sessions per host and still, only 2 licenses were obtained:

image1201×96 5.51 KB
The vPC License was never used. I swear whenever i loggend in with an test-account, i saw the message down right that a nvidia license was obtained.
And as shown in the screenshot, a lot more licenses were obtained. Now i have only 2 that are in use while +30 user are logged in. I my understanding somewhere wrong ?If you have 2 hosts (RDSH) then you should have 2 licenses assigned as only the host acquires a license.
You will need the CCU count to properly license the use case but as I said already this is EULA enforced.You will need the CCU count to properly license the use casewe assigned all the licenses to the CLS instance:

image1116×140 7.95 KB

And again, more license-usage was shown in the past.
Is the CCU count a feature that i accidently disabled or didn’t enable at all?
Because licenses were allocated successfully in the past.
It might be right that only two licenses are obtained, one per RDHS host. But again the usage should be way more (depending on logged in users).
Do you understand what i am trying to explain (english not good)? If my understanding is correct, your statement is that my described scenario is a feature and not a bug.
I also opened a NVIDIA ticket.
Thanks again for your time.Powered by Discourse, best viewed with JavaScript enabled"
111,430-30-grid-vgpu-driver-fails-to-load-on-linux-tesla-t4-x2,"Guest:
$ lspci | grep -i nvidia
02:02.0 VGA compatible controller: NVIDIA Corporation Device 1eb8 (rev a1)$ tail /var/log/nvidia-installer.log
ERROR: Unable to load the ‘nvidia-drm’ kernel module.
ERROR: Installation has failed.  Please see the file ‘/var/log/nvidia-installer.log’ for details.  You may find suggestions on fixing installation problems in the README available on the Linux driver download page at www.nvidia.com.$ dmesg | tail
[  585.162303] nvidia-nvlink: Nvlink Core is being initialized, major device number 241
[  585.163241] vgaarb: device changed decodes: PCI:0000:02:02.0,olddecodes=none,decodes=none:owns=none
[  585.163387] NVRM: The NVIDIA GPU 0000:02:02.0 (PCI ID: 10de:1eb8)
NVRM: installed in this system is not supported by the
NVRM: NVIDIA 430.30 driver release.
NVRM: Please see ‘Appendix A - Supported NVIDIA GPU Products’
NVRM: in this release’s README, available on the operating system
NVRM: specific graphics driver download page at www.nvidia.com.
[  585.163715] nvidia: probe of 0000:02:02.0 failed with error -1
[  585.163733] NVRM: The NVIDIA probe routine failed for 1 device(s).
[  585.163734] NVRM: None of the NVIDIA devices were initialized.
[  585.163946] nvidia-nvlink: Unregistered the Nvlink Core, major device number 241$ uname -a
Linux <REMOVED> 3.10.0-957.12.1.el7.x86_64 #1 SMP Tue Apr 23 12:06:18 PDT 2019 x86_64 x86_64 x86_64 GNU/Linux$ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.5/lto-wrapper
Target: x86_64-redhat-linux
Configured with: …/configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux
Thread model: posix
gcc version 4.8.5 20150623 (Red Hat 4.8.5-36.0.1) (GCC)Host:
uname -a
VMkernel <REMOVED> 6.7.0 #1 SMP Release build-11675023 Jan  7 2019 19:29:34 x86_64 x86_64 x86_64 ESXiesxcli software vib list | grep -i nvidia
NVIDIA-VMware_ESXi_6.7_Host_Driver  430.27-1OEM.670.0.0.8169922           NVIDIA   VMwareAccepted    2019-07-22nvidia-sminvidia-smi vgpu
Thu Jul 25 17:36:07 2019PowerCLI:
( get-vmhost ).ExtensionData.Config | select GraphicsInfo, SharedPassthruGpuTypesGraphicsInfo                     SharedPassthruGpuTypes{NVIDIATesla T4, NVIDIATesla T4} {grid_t4-8q, grid_t4-8c, grid_t4-8a, grid_t4-4q…}( get-vmhost ).ExtensionData.Config.GraphicsConfigHostDefaultGraphicsType SharedPassthruAssignmentPolicy DeviceTypesharedDirect            performance                    {0000:05:00.0, 0000:07:00.0}( ( $myvm | get-view ).Config.Hardware.Device | where-object Key -eq 13000 ).Backinggrid_t4-8aApparently the Linux driver does not like the ‘a’ profile. Switched to ‘q’ profile and the driver now loads, although I have not finished testing, fully.Powered by Discourse, best viewed with JavaScript enabled"
112,feature-request-release-image-from-govcloud-to-publiccloud,"Nvidia has lots of useful Virtual Workstation AWS ami on the GovCloud. Would be extraordinary if those could be released on the public cloud to complement the already existing solution on the public cloud.Deploy an Omniverse Virtual Workstation on AWS — Omniverse Nucleus documentation
https://cloudstation-public-dev-us-west-2.s3.us-west-2.amazonaws.com/templates/cloudstation-cfn.jsonPowered by Discourse, best viewed with JavaScript enabled"
113,tesla-v100-sxm3-32gb-driver-install-failed,"Hello
I cant find driver for my TESLA V100 SXM3-32GB
My system: Windows 2019, update, cuda 11.
For first i try to download latest driver for Tesla V100 but i have message ""This graphics driver could not find compatible graphics hardware"" i check *.inf files from DisplayDriver path and dont find my 1DB8 supported card, i try many others version for Tesla V100 but no one support 1DB8 device, only 1DB6.
My device id: PCI\VEN_10DE&DEV_1DB8&SUBSYS_12AB10DEDid you resolve this issue?Powered by Discourse, best viewed with JavaScript enabled"
114,vray-6-and-enscape-issues-with-rtx3070,"I bought a Intel i7 with RTX3070 to work with Sketchup + Vray or Sketchup + Enscape. In both cases I’m having trouble. With VRay, if the quality is above medium, the computer suddenly crashes with the blue screen, with many different stop codes (Power state failure, Store Exception, Memory management, etc). In order to deliver my projects, I’m rendering the images in parts and it’s taking more than 3 hours to render each image.
With Enscape, Sketchup crashes with bug splat closing the file whenever I try to activate ray tracing.
Can anyone please help me solve my problem?Regards,Powered by Discourse, best viewed with JavaScript enabled"
115,greetings-nvidia-cisco-community,"My name is Shawn and I work for Cisco Systems specifically in the Virtualization/VDI space.  This includes a ton of work with Nvidia GRID GPU’s.  Glad to see the community set up here, I’ll try to comment/view the forum as often as possible.Thanks!Hi Shawn, can you comment on the hardware compatability matrix for C240M4, 2008R2 and Grid K1? I’m having trouble getting the driver installed and I think it’s because it’s not supported, Thanks!Hi Shawn,Great to have you and your input!Thanks,
SarahPowered by Discourse, best viewed with JavaScript enabled"
116,tesla-p40-in-vmware-esxi-6-7-is-not-working-in-passthrough-mode-for-created-vms-dell-r730,"Setup Details :GPU Card - Tesla P40VMWare ESXI -  6.7Server - Dell PowerEdge R730CPU

image1130×136 22.5 KB
Memory

image1131×402 31.4 KB
Issue : After installing and configuring the ESXI and VCenter in the Dell server with Tesla P40 GPU card I am not able to start any created VM attached with GPU as PCI in passthrough  mode.Below is the Vcenter settings for graphics for GPU passthrough,

image1365×441 61.3 KB
Below is the VM Setting with the added GPU (passthrough) as PCI device,

image635×541 30.3 KB
After applying the setting when I try to start the VM it doesnot start and pops up an error as follows,

image1400×797 163 KB

Operation Failed : Device poweron failed.But when I tried starting the VM after removing the GPU it boots up normally.Can anyone please help on this issue.?There are some settings you need to do for passthrough of GPU in ESXi. Please review your settings as per this link: Using GPUs with Virtual Machines on vSphere - Part 2: VMDirectPath I/O - Virtualize ApplicationsThe VM needs to boot in EFI mode, and you need to also set the pciPassthru.use64bitMMIO=”TRUE” and pciPassthru.64bitMMIOSizeGB= (In the case of P40, 64 should do).Does anybody noticed problems with max resolution used in a windows10 Pro VM using a P40 in Passthrough mode? I’m trying to access using VNC or Teradici and I can only set it to 1440x900 max resolution. In shared mode using part of a P40 as a vGPU I can use 3840x2160 (as native) resolution without any problem.How can I increase the max resolution supported for a TERA DEFAULT monitor when using the P40 in passthrough mode?Thank you in advance,
Òscar CalafHi,
not aware of any resolution issues with P40 in PT. You could try to fake the EDID file to get your desired 4k resolution.regards
SimonThis topic was automatically closed 60 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
117,grid-vgpu-and-blender-compatibility,"I am using the nvidia grid VGPU (RTX6000) on the Exsi 7.0 hypervisor. However, blender and a dose of OpenGL software such as Rviz and Cloudcompare do not seem to work properly with the VGPU. All these applications only use the SVGA device. I have tried disabling the SVGA device in the VM setting, but that doesn’t make a difference. nvidia-smi shows that even teamviewer is using the GPU in this setting, but not other applications. However, UE4 works smoothly. What might be the causes? thanks for any tips! Merry Xmas!Powered by Discourse, best viewed with JavaScript enabled"
118,testing-nvidia-graphics-cards-using-nvidia-virtual-machine-service,"Hi,I think, It would be very useful for all NVIDIA Developing Community and also for not Developing Community to have a NVIDIA Virtual Machine Service where we can test an Application with all the Graphics Cards or at least a big subset of the GPUs that NVIDIA offers. I would like that I could test that App at least with Windows 10 (or future Windows OS version) and also the most important OS.I think this would improve all the NVIDIA developer community testing system and customers could receive a very accurate list of all the NVIDIA GPUs that are working with a release version of an App.( There are more interesting ideas in using NVIDIA virtual machines, as for anyone who doesn’t want to buy a new machine and wants to do something with the NVIDIA GPU for a little while or doesn’t want to worry about the machine itself. )I know that this service does not exist because I asked to NVIDIA agent earlier.I know that Amazon, Microsoft and Google offer some VMs compatible with NVIDIA GPUS, but that is not enough to test a big set.Thanks.Hi lbdalmendray1,Appreciate the suggestion.  Do you have a specific area of interest for applications that you want to test - i.e. computing (CUDA), Deep learning, Professional Visualization, video gaming etc.NVIDIA provides a number of developer programs for our developers.  You can read more about them here: NVIDIA Developer Program | NVIDIA DeveloperIn terms of testing NVIDIA GPUs online then there is a number of CSPs that provide access to GPUs - GPU Cloud Computing Solutions from NVIDIAFor our customers looking to test vGPU we do provide an online test drive facility - NVIDIA & VMware Free Test Drive | NVIDIAFor customers looking to test AI solutions, we launched AI launchpad - LaunchPad: The End-to-End AI Platform | NVIDIAFor everyone, we continue to try and make the cost of entry to develop on NVIDIA GPUs as low as possible.  You can develop a CUDA application, run AI frameworks, etc on consumer gaming hardware or Jetson SOCs.Thank you and other developers who read this post for developing your applications using NVIDIA hardware and SDKs.:D:Powered by Discourse, best viewed with JavaScript enabled"
119,nvidia-quadro-virtual-workstation-oracle-cloud,"Hello my VM does not detect the vGPU:
This Hardware Device is Not Connected to The Computer (Code 45),Oracle support told me that I should contact you since everything was working correctly, that the error is at the operating system level, is there anything that can be done to make it work?https://drive.google.com/drive/folders/1yehdqdFqdldXkVxga_1xMVQDDSZrYuQ_?usp=share_linkPowered by Discourse, best viewed with JavaScript enabled"
120,cannot-access-gui-after-kernel-update-problem-with-nvidia-drivers-on-ubuntu,"Dear Nvidia community,After a recent Kernel update on my Workstation, the nvidia graphics drivers stopped working. Unfortunately some attempts at fixing the issues were done in my absence but were not documented so I’m not entirely sure of some of the changes that were done.My setup:
nvidia-bug-report.log.gz (567.2 KB)

IMG_20210716_1213549364640×3472 1.77 MB
OS : Linux-5.4.0-77-generic-x86_64-with-debian-buster-sid - Ubuntu 18.04
GPUS : dual Quadro RTX 6000 - driver version 460.84Description of the issue:
The machine boots and then freezes on a blue login screen with with unresponsive mouse and keyboard (see image). I emphasize that my machine has ubuntu 18.04 installed so I would expect the usual purple background to be visible.
The driver seems to be installed correctly as ‘nvidia-smi’ yields the expected output.What I tried so far:I’ll attach the nvidia-bug report,I am deeply grateful for any advice/help,AdrianoPowered by Discourse, best viewed with JavaScript enabled"
121,problems-install-grid-driver-on-windows-10,"Hey,Specs:
VMware ESXi 7.0.1
vSphere 7.0.1
Windows 10 Pro for WS 20H2 build 19042.631 VM
Tesla T4I’ve installed the VIB on my hypervisor and it’s able to detect my graphics card.I installed the 461.33 vGPU driver on VM and it’s successful. But when I reboot, I get a BSOD saying VIDEO TDR Failure for nvlddmkm.sys. I can’t figure out the solution for the problem. I’ve tried disabling all of the default VMware display drivers thinking there might be a conflict but that didn’t work.HI, See more:
SYMPTOM OR ERRORS
When user tries to install vGPU drivers an error is seen “NVIDIA Installer cannot continue” with the details “The NVIDIA graphics driver is not compatible with this version of Windows. This graphics driver could not find compatible graphics hardware.”ROOT CAUSE
It is very likely that the user has downloaded the wrong driver for their VM’s operating system. For example: this error will occur if a user is using a Win 8.1 32bits but attempting to install the 64-bit NVIDIA driver, cookie clicker!SOLUTION
Ensure correct driver is used for the Operating system. The driver naming e.g. 362.13_grid_win8_win7_64bit_english should make it clear which version is installed.RELEVANT PRODUCTS
NVIDIA GRID vGPU including K1, K2, M60, M6 GPUsWindows Operating systems including 7.0, 8.0, 8.1, 10.0, server OSsI have the correct driver. 461.33_grid_win10… and the installation runs successfully. It’s just when I reboot to fully complete the installation, the BSOD happens.EDIT: 4/1/2021, so I really have gotten vDGA working. I was able to install the GRID vGPU driver and license it, etc and able to use it with my camera client. So it seems like the driver isn’t the problem, but maybe the hypervisor and VIB. I’m not sure. I believe I can use vDGA as a workaround for my use case.Some other troubleshooting stuff: I’ve attempted doing vDGA and from what it looks like, everything is working. I don’t get a BSOD. I’m off network so I can’t really test it, but nvidia-smi recognizes the card.So it seems like there’s something wrong with my implementation of vGPU. I’m not sure what though.Log files attached.nvidia-bug-report.log (4.4 MB)It sucks I can’t edit previous posts after a while…but I don’t think I can use vDGA as a workaround for my use case. I need multiple users to be able to use the gfx card at once, so I need to use vGPU. If anyone knows a solution, please please reach out. As you can see, I’ve been working on this for a week+ straight.Hi ybaker613,Sorry you are having issues.  Can you check that you have set the Host Graphics Setting to “Shared Direct” - Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software DocumentationDI have verified that it’s set to Shared Direct. I can send a pic if needed.Can you confirm that your T4 is installed in a compatible server for vGPU and VMWARE.  A list of compatible servers are here: Virtual GPU Certified Servers | NVIDIA GRIDIt’s not, but does it matter that much? vDGA and everything else for VMware works.It matters because it is not clear if the issue is because of a incompatibility between your hardware; the T4 and the vGPU software.  We work with OEMs/VMware etc to give buyers confidence that their hardware platform is compatible with vGPU and the T4 will run without error.Powered by Discourse, best viewed with JavaScript enabled"
122,error-unable-to-load-the-kernel-module-nvidia-ko,"On a new Amazon EC2 g2.2xlarge GPU instance running Ubuntu Server 14.04 LTS, I cannot install the latest NVIDIA GRID driver. When trying to install the driver, I encounter the following error:ERROR: Unable to load the kernel module ‘nvidia.ko’.  This happens most
frequently when this kernel module was built against the wrong or
improperly configured kernel sources, with a version of gcc that
differs from the one used to build the target kernel, or if a driver
such as rivafb, nvidiafb, or nouveau is present and prevents the
NVIDIA kernel module from obtaining ownership of the NVIDIA graphics
device(s), or no NVIDIA GPU installed in this system is supported by
this NVIDIA Linux graphics driver release.How can I resolve this error and proceed with installing the driver? The output below shows the OS version on the EC2 instance.Here’s the nvidia-installer.log mentioned in the error message.Can’t read the .log the connection times out.Have you disabled the nouveau driver?have you checked the gcc version used by the driver package (installed on the Server)  is the same one used to create the server kernel?You may need to change the version of gcc in the VM to match.You may also find this usefulUsing a pre-built public AMI Based on the instructions in this blog post, I’ve created an AMI and shared it publicly. So the easiest thing to …Hey, I have the same issue when trying to install cuda
$sudo sh cuda_11.0.2_450.51.05_linux.runKernel module compilation complete.
 → Unable to determine if Secure Boot is enabled: No such file or directory
ERROR: Unable to load the kernel module ‘nvidia.ko’.  This happens most frequently when this kernel module was built against the wrong or improperly configured kernel sources, with a version of gcc that differs from the one used to build the target kernel, or if another driver, such as nouveau, is present and prevents the NVIDIA kernel module from obtaining ownership of the NVIDIA GPU(s), or no NVIDIA GPU installed in this system is supported by this NVIDIA Linux graphics driver release.Please see the log entries ‘Kernel module load error’ and ‘Kernel messages’ at the end of the file ‘/var/log/nvidia-installer.log’ for more information.
 → Kernel module load error: No such device
 → Kernel messages:
[    2.803910] Decoding supported only on Scalable MCA processors.
[    2.812952] Decoding supported only on Scalable MCA processors.
[    2.818914] Decoding supported only on Scalable MCA processors.
[    2.831118] Decoding supported only on Scalable MCA processors.
[    2.838982] Decoding supported only on Scalable MCA processors.
[    2.846096] Decoding supported only on Scalable MCA processors.
[  502.947087] VFIO - User Level meta-driver version: 0.3
[  502.962436] IPMI message handler: version 39.2
[  502.964542] ipmi device interface
[  502.977726] nvidia: loading out-of-tree module taints kernel.
[  502.977735] nvidia: module license ‘NVIDIA’ taints kernel.
[  502.977736] Disabling lock debugging due to kernel taint
[  503.052876] nvidia: module verification failed: signature and/or required key missing - tainting kernel
[  503.133478] nvidia-nvlink: Nvlink Core is being initialized, major device number 242
[  503.149763] ACPI: PCI Interrupt Link [LNKB] enabled at IRQ 11
[  503.150178] NVRM: The NVIDIA GPU 0000:00:06.0 (PCI ID: 10de:2230)
NVRM: installed in this system is not supported by the
NVRM: NVIDIA 450.51.05 driver release.
NVRM: Please see ‘Appendix A - Supported NVIDIA GPU Products’
NVRM: in this release’s README, available on the operating system
NVRM: specific graphics driver download page at www.nvidia.com.
[  503.165935] nvidia: probe of 0000:00:06.0 failed with error -1
[  503.165952] NVRM: The NVIDIA probe routine failed for 1 device(s).
[  503.165953] NVRM: None of the NVIDIA devices were initialized.
[  503.166267] nvidia-nvlink: Unregistered the Nvlink Core, major device number 242I did the following to resolve it but it didn’t work$ vi /etc/default/grub
GRUB_TIMEOUT=1
GRUB_DISTRIBUTOR=“$(sed ‘s, release .*$,g’ /etc/system-release)”
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL=“serial console”
GRUB_SERIAL_COMMAND=“serial”
GRUB_CMDLINE_LINUX=“console=tty0 crashkernel=auto net.ifnames=0 console=ttyS0 nouveau.modeset=0”
GRUB_DISABLE_RECOVERY=“true”$ vi /etc/modprobe.d/blacklist-nouveau.conf
blacklist nouveau
blacklist lbm-nouveau
options nouveau modeset=0
alias nouveau off
alias lbm-nouveau off
blacklist vfio-pci$ update-initramfs -u doesn’t work for me since I an running centos 7
So I did this instead
$ sudo dracut -v -f$ rpm -qa kernel* |sort
kernel-3.10.0-1160.45.1.el7.x86_64
kernel-3.10.0-957.1.3.el7.x86_64
kernel-debug-devel-3.10.0-1160.45.1.el7.x86_64
kernel-devel-3.10.0-1160.45.1.el7.x86_64
kernel-headers-3.10.0-1160.45.1.el7.x86_64
kernel-tools-3.10.0-1160.45.1.el7.x86_64
kernel-tools-libs-3.10.0-1160.45.1.el7.x86_64$rebootI hope I can get some advice how to resolve this issue.
Thanks in advance!Powered by Discourse, best viewed with JavaScript enabled"
123,holiday-mystery-v100-vgpu-grid-proveout-fails-cannot-create-cuda-contexts-alloc-memory-on-most-cuda-sample-kit-entries-vmware-rhel-cuda10-2,"Interesting holiday mystery: We are helping an org prove out GPUs in their data center, and while nvidia-smi successfully runs, any basic creation of a CUDA context / cudaMalloc fails.  We suspect it’s around the vGPU  setup, as our reference setup works on a google cloud RHEL 8.x node w/ similar install flow.We’re unsure where to go from here, so any ideas welcome! It’s hard for us to move non-docker / packaged items to host, so if diagnostics ideas, ideally ones we can containerize. (Ex: we got cuda sample tests running via nvidia docker, but hard outside docker b/c rhel makes it hard to get the old gcc7 installed.)Some lingering ideas:
– maybe 2Q is the wrong size? or we’re using the wrong license type?
– are there bios settings we need to check/tweak?
– maybe there is a way to test the cuda context at the hypervisor/rhel level that isn’t hard (e.g., no need for porting gcc toolchain)?=====It’s a tricky yet standard enterprise env, so we’d like to get this figured out as a template for future apps:
– V100 GPU
– esxi 6.7
– rhel 8.3
– vGPU 10.4 driver bundle (=> 440.121 vGPU manager +  440.118 linux driver)
– testing vGPU partition of size 2Q for headless compute tasks (CUDA → nvidia rapids)
– license manager is still being setup: we tried setting as Type 0 (unlicensed) and 1, 2
– docker w/ nvidia runtime set as default (docker 19.04, same versions as work on another rhel 8.3 gpu node)Some diagnostics so far:Errors are generally:440.118.02 / 440.118.02 / 10.2
0 GRID V100-2QP0, 2GB partition w/ 160MB allocated, but missing temp/wattage  we see in the hypervisor’s nvidia-smiMore nvidia-smi details:display mode enabled
display active disabled
persistence mode enabled
accounting mode disabled
driver model: current/pending n/a n/a
vbios 00.00.00.00.00
multigpu board: no (single gpu test node)
gpu part: n/a
gpu virt mode: vgpu
host vgpu mode: n/a
product name: quadro virtual data center workstation
license status: unlicensed
pci bus 0x02
gpu link info n/a
ecc mode enableddocker run --rm --runtime=nvidia --gpus all nvidia/cuda:10.2 nvidia-smi./bandwidthTest
Starting…
Running on…
Device 0:…
Quick ModeCUDA error at bandwidthTest.cu:686 code=46 (cudaErrorDevicesUnavailable) “cudaEventCreate(&start)”./reduction
./reduction Starting…
GPU Device 0: “Volta” with compute capability 7.0
Using Device 0: GRID V100-2Q
Reducing array of type int
16777216 elements
256 threads (max)
64 blocksCUDA error at reduction.cpp:492 code=46 ) cudaErrorDevicesUnavailable) “cudaMallo((void**)&d_idata, bytes)”b) numba/cupy/cudf/etc fail on context / memory creation:from numba import cuda
cuda.current_context() #failsHiThe “Q” Profiles (QvDWS (Quadro Virtual Datacenter Workstation)) are the highest license tier and give the maximum functionality available. However you may also want to use the “C” Profiles (vCS (Virtual Compute Server)) as these are specifically for Compute focused workloads. They’re considerably cheaper and they’re licensed per GPU, not Per User like all other licenses. You can run up to 8x VMs on the same GPU with a single vCS license and they may be more appropriate for your workloads. However for the time being “Q” will be fine.I’m not sure why you’re running vGPU 10.4? The 10.x branch is only supported until December 2020, meaning you have 3 days (at time of writing) of potential support remaining. If you use the current branch of 11.x (11.2 is most recent), this is an LTSB that runs to 2023 (not that you’d want to stay on the same driver for that long mind). 11.x also supports CUDA 11.0.What you’re experiencing is correct, the CUDA version is not listed in the Hypervisor as CUDA workloads aren’t run from there. You’re installing a GPU manager in the Hypervisor, not an actual driver (of sorts), which is why you can see the CUDA version within the VM, as the VM driver contains CUDA.The 2Q (2GB) Profile … You can of course use a 2GB Profile (if 2GB framebuffer is sufficient for your workload), however, depending on how many VMs you plan to run, you may benefit from changing the Scheduler mode to one that allows more consistent resource scheduling. Compute workloads are typically quite intensive, the Default Scheduler (Best Effort) will try and service all processing requests as they come in and for 3D / Graphical workloads it does a pretty good job, however it can easily become overloaded with multiple consistently high processing requests which will lead to inconsistent processing times, so perhaps switch to “Fixed” or “Equal” share mode to give more predicable performance. If you were running an A100, then this would be a different conversation due to MIG and SR-IOV.Regarding CUDA performance, again, what you’re experiencing is correct. You need to get it licensed and then it will start to work. There is a severe drop off in functionality when the vGPUs are not licensed. Licensing should be the first element that is completed when deploying a vGPU environment as obtaining production licenses can sometimes take a while and cause delays. Evaluation licenses on the other hand are pretty quick to get hold of and if you are facing delays, you can get those yourself by signing up for a 90 day evaluation here: NVIDIA Enterprise Account Registration.Hope that helpsRegardsMGWanted to report we’re good now, this helped. It looked like the base issue was misunderstanding what it meant for degraded performance for unlicensed mode during setup. The app uses CUDA, and unlicensed mode full disables CUDA, vs degrading it, hence failed context creation. It was fine once we got licensing up!Powered by Discourse, best viewed with JavaScript enabled"
124,nvidia-grid-vgpu-mouse-problems,"We are trialling NVIDIA Grid vGPU applications using VMWare (7) and Citrix vAPPS (1808). When running a VDA based on windows 10 (which we have to do for a supported engineering environment) the mouse only lines up if you set local resolution to 800x600 - all other resolutions do not line up. This isn’t an issue with windows server 2016/2019 VDAs and is also not an issue with the Windows 10 VDA when we don’t use the NVIDIA card.The issue is present with single and multi-monitor setups.NVIDIA Driver version is 462.31
RTX Desktop manager 201.66
NVIDIA WMI 2.36.0Has anybody got any advice to resolve the issue?Which vGPU profile do you use? Does it also happen with RDP? Never seen such an issue yet.Regards SimonI’m having this same issue as well, setting the endpoint to a lower resolution like 1280 x 1024 corrects the mouse alignment issue, but that isn’t a permanent fix.  It seems there is a scaling issue when using vApps licensing on Windows 10, did you find a solution to your issue?  I have also testing the same scenario with Windows Server 2019 and it does not have this issue, it seems isolated to Windows 10 current and older builds (21H2, 21H1, 20H2)Hi, this is pretty simple to explain. You are not allowed to use vApps on Win10. You need to use vPC for client OS. The vApps profile is preventing misusage and therefore has the 1280x1024 restriction on the console session.Regards SimonI can confirm my issue was resolved when we used the correct license.Kind regardsBenPowered by Discourse, best viewed with JavaScript enabled"
125,nvidia-tesla-t4-memory-bandwidth,"Hi everyone,We have consider NVIDIA Tesla T4 for our server.
I find that there is difference about memory bandwidth in NVIDIA document:In product brief: 320 GBytes/s1232.63 KBIn datasheet: 300 GB/sec414.27 KBWhat is the correct maximum memory bandwidth?Thanks,320 GB/s should be correct as peak bandwidthDear sschaber
Thanks for your information.Powered by Discourse, best viewed with JavaScript enabled"
126,azure-n-series-ubuntu-vm-nvidia-failing-at-boot,"Size: Standard NV36ads A10 v5 (36 vcpus, 440 GiB memory)
OS: Ubuntu 22_04-lts-gen2Added the NVIDIA GPU Driver Extension for Linux extension per: NVIDIA GPU Driver Extension - Azure Linux VMs - Azure Virtual Machines | Microsoft DocsUpon boot I see:[FAILED] Failed to start LSB: Micro…ension for nVidia GPU Drivers.
See ‘systemctl status nvidia-vmext-service.service’ for details.nvidia log file shows:
234951-image847×660 20.8 KB
Tried installing via article: How do I add NVIDIA GPU to a Linux virtual machine? - Microsoft Q&ABut then get this boot loop failure, which after about 30 minutes I can get back to a login screen, purge, and boot normally again:
235228-image755×459 10.4 KB
Powered by Discourse, best viewed with JavaScript enabled"
127,nvidia-gtc-21-access-technical-training-and-sessions-built-for-developers,"Access technical training and sessions built for developers.
Register for Free - GTC 2022: #1 AI ConferencePowered by Discourse, best viewed with JavaScript enabled"
128,what-is-the-difference-between-screen-card-and-vgpu,"Hi,
I need to know what is the difference between screen card and vGPU. And what is the type of the products below ?1- Nividia Grid Cards K1 & K2
2- Nividia Tesla Grid Cards  M series and  N series1-Grid K1 and K2 are EOL - no relevance any more
2-Tesla boards are datacenter GPUs without diplay head and enabled for vGPU with software license.There is no N series. M = Maxwell, P= Pascal, V= Volta and T= Turing (latest generation)regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
129,looking-for-nutanix-guest-drivers-v471-68-unable-to-find-them-anywhere,"Hi All,I’ve just installed Nutanix AHV 13.0 host drivers but I’m unable to find the Windows guest drivers anywhere, any ideas??Many Thanks
HenryAs described in the Nutanix documentation you can only download the guest drivers from the NV licensing portal. If you have bought licenses already you should have access to the portal. Otherwise you can request a trial license and create an account.
This is the link to request a trial: https://www.nvidia.com/object/vgpu-evaluation.htmlregards
SimonPowered by Discourse, best viewed with JavaScript enabled"
130,nvidia-driver-error-booting-on-linux-rminitadapter-failed-0x30874,"Hello,
Since the last update of nvidia driver on Linux, I get a freezing error booting Linux. The following error repeats endlessly and freeze the boot process :[   41.341777] NVRM: GPU 0000:06:00.0: Failed to copy vbios to system memory.
[   41.341996] NVRM: GPU 0000:06:00.0: RmInitAdapter failed! (0x30:0xffff:874)
[   41.342046] NVRM: GPU 0000:06:00.0: rm_init_adapter failed, device minor number 0
[   43.076696] NVRM: GPU 0000:06:00.0: Failed to copy vbios to system memory.
[   43.076920] NVRM: GPU 0000:06:00.0: RmInitAdapter failed! (0x30:0xffff:874)
[   43.076970] NVRM: GPU 0000:06:00.0: rm_init_adapter failed, device minor number 0
[   45.267751] NVRM: GPU 0000:06:00.0: Failed to copy vbios to system memory.
[   45.267959] NVRM: GPU 0000:06:00.0: RmInitAdapter failed! (0x30:0xffff:874)
[   45.268004] NVRM: GPU 0000:06:00.0: rm_init_adapter failed, device minor number 0
[   47.002711] NVRM: GPU 0000:06:00.0: Failed to copy vbios to system memory.
[   47.002837] NVRM: GPU 0000:06:00.0: RmInitAdapter failed! (0x30:0xffff:874)
[   47.002888] NVRM: GPU 0000:06:00.0: rm_init_adapter failed, device minor number 0
[   49.360182] NVRM: GPU 0000:06:00.0: Failed to copy vbios to system memory.
[   49.360354] NVRM: GPU 0000:06:00.0: RmInitAdapter failed! (0x30:0xffff:874)
[   49.360382] NVRM: GPU 0000:06:00.0: rm_init_adapter failed, device minor number 0
[   51.095810] NVRM: GPU 0000:06:00.0: Failed to copy vbios to system memory.
[   51.095940] NVRM: GPU 0000:06:00.0: RmInitAdapter failed! (0x30:0xffff:874)
[   51.095965] NVRM: GPU 0000:06:00.0: rm_init_adapter failed, device minor number 0
…
…
…My confignvidia-smi -L
GPU 0: NVIDIA GeForce GTX 650 Ti (UUID: GPU-e517d20a-4ddb-da11-cf33-0a46716e9897)idia-smi
Thu Nov 11 14:43:21 2021
±----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce …  Off  | 00000000:06:00.0 N/A |                  N/A |
| 30%   43C    P0    N/A /  N/A |    663MiB /   979MiB |     N/A      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+All previous version of NVIDIA driver worked fine.
The error come with the update to NVRM version: NVIDIA UNIX x86_64 Kernel Module  470.82.00
Do I need to use a legacy driver for NVIDIA GeForce GTX 650 Ti ?
Why this error ?Thanks for your help.OlivierPowered by Discourse, best viewed with JavaScript enabled"
131,nvidia-smi-has-failed-because-it-couldnt-communicate-with-the-nvidia-driver-make-sure-that-the-latest-nvidia-driver-is-installed-and-running,"In Vmware sphere 7(Evaluation version) trying Multi-Instance GPUs (MIG) on the NVIDIA A30.
Things done1- Global SR-IOV Enabled in BIOS
2-esxcli graphics host set –-default-type SharedPassthru
3-Install the ESXi Host Driver for MIG Support
- esxcli system maintenanceMode set –enable=true
- esxcli software vib install -v NVIDIA_bootbank_NVIDIA-VMware_ESXi_7.0_Host_Driver_460.107-1OEM.700.0.0.15525992.vib
- esxcli system maintenanceMode set –enable=false
4-RebootProblem :1-I dont see driver being loaded[localadmin@localhost:~] vmkload_mod -l | grep -i nvidia
[localadmin@localhost:~]2-[localadmin@localhost:~] nvidia-smi
NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.[localadmin@localhost:~]hey @rahul.anand , were you able to solve it? I seem to have exactly the same problem and i’ve followed the same setup as you.Powered by Discourse, best viewed with JavaScript enabled"
132,compatibility-between-esxi-7-0u2-and-6-7-vib,"Hello,Just wondering would  Nvidia Tesla M10 vib for 6.7 be compatible with esxi to 7.0u2? Just trying to figure out if both should be updated together or if it could wait.ThanksHi,
You always need to update the appropriate vib for the ESX version given. ESX 7 needs a different vibPowered by Discourse, best viewed with JavaScript enabled"
133,nvidia-vgpu-tech-tips,"Technical resources for NVIDIA Virtual GPU projects. Whether you want introductory videos, installation walk-throughs or tips for success:   NVIDIA vGPU Tech Tips - YouTubePowered by Discourse, best viewed with JavaScript enabled"
134,t4-vgpu-remote-vedio-display-with-bad-experence,"HiI am a PhD student from Xian jiaotong university.In a project we need provide hight quality remote vedio play.And Our technique stack are:1.T4 card with inspure server in nvidia support list2.redhat 8.2 enterprise with kvm qemu3.vgpu software package is 13.x4.vw flavor is 8u 16G. with 40 storage. vgpu license is vpc ,and vgpu is B-2bOur problem is that when we play the 4k vedio and connect it from local host server or remote server.the screen will appear tear out in Vertical direction.We have try most parameter setting we can find on nividia offical web .Pls help us with this issue.ps we also tried V100 card.ThanksPowered by Discourse, best viewed with JavaScript enabled"
135,linux-kvm-live-migration-for-tesla-t4-problem,"HelloI can live migrate on the NVIDIA T4 graphics card, but after the migration is completed, the Linux kernel reports the following error. What is the reason?Nov 24 19:30:38 VM-0-76-centos nvidia-vgpu-mgr[23405]: notice: vmiop_log: (0x0): Finish restoring vGPU state …Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: NVOS status 0x19Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: Assertion Failed at 0xe7c0bd31:150Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: 5 frames returned by backtraceNov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: /lib64/libnvidia-vgpu.so(_nv004938vgpu+0x26) [0x7fa50af0de76]Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: /lib64/libnvidia-vgpu.so(+0x7a901) [0x7fa50aeab901]Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: vgpu(+0x10d31) [0x55b8e7c0bd31]Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: /lib64/libpthread.so.0(+0x814a) [0x7fa50ba3314a]Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: /lib64/libc.so.6(clone+0x43) [0x7fa50b356dc3]Nov 24 19:30:39 VM-0-76-centos nvidia-vgpu-mgr[23405]: error: vmiop_log: (0x0): Failed to create local Memory handle (error: 0x19)Dev environment
Linux Host ：CentOS 8.3
Nvidia Grid： 12.2
Guest OS ：Window 10ThksHi,you may try the current vGPU version for this branch. Apart from that there is not much we can do as you are running a not supported configuration (CentOS) so you won’t be able to open a support ticket with NVES.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
136,gpu-a40-passthrough-poor-performance,"Hello everyone,I am facing some issues with my A40 GPU while gaming. Currently, I have set up a vGPU with flavor A40-8Q, but the performance is quite poor. It appears that the FPS is capped. I’ve tried changing the vGPU flavor, but it did not improve the performance. I’ve also used ‘frame_rate_limiter=0’ to uncap the frame rate, but it did not help.To address this, I decided to pass the entire GPU to a Windows 11 VM. However, I’m encountering problems while installing the driver. The installation process does not complete, and after a forced reboot, the VM fails to boot up.At this point, I’m not sure what to do to either enhance the vGPU’s performance or successfully pass the GPU to the VM.If anyone has any suggestions, I would greatly appreciate them. Thank you.Hi,
which Hypervisor is in use? FRL off should do the trick. I guess something didn’t work with the FRL off otherwise you should see >60fps. Please simply try to run a benchmark like Unigene Heaven to check if the GPU renders more that 60 fps.regards
SimonHi.Thank you for your reply. It sent me down a new rabbithole of testing.
I am using Ubuntu 22.04,  qemu:7.0, nvidia: 510.108.03.After running the benchmarks like you suggested, I saw an increase of almost 2x fps.
Exactly the result I was expecting. I’ve updated qemu and nvidia driver between the tests. This could have had the desired effect.I’ve been playing around with different schedulers.
Could you tell me what is the difference between EQUAL_SHARE and FIXED_SHARE schedulers?
I see a drop to ~20fps during benchmarks. I’ve used both the default values and 1ms time slices.Also is there a way to slice cuda cores to vGPU. I mean just like vram, is there a way to have a dedicated number of cuda cores for each vGPU?Powered by Discourse, best viewed with JavaScript enabled"
137,touch-monitor-support-with-p40-and-horizon-view,"vSphere 6.5 U3 - Horizon View 7.12 - vGPU 10.2 (P40) - Win 10 1803 - Wyse 3040 (PCoIP) - Dell P2418HT MonitorWe have a niche project the requires the use of two Dell P2418HT Touchscreen Monitors with our Win 10 1803 Image, but we are having issues getting just one monitor to calibrate properly. We have a 1GB vGPU profile attached to a Win 10 1803 Image while connected to a Dell P2418HT monitor and try to perform a screen calibration the sensor is noticeable off by about an inch up. We are unable to touch the corners of the screen to properly complete the calibration in Windows. If we add an additional non-touch screen monitor and set it use the Nvidia card and move the touchscreen to use the Horizon View/sVGA for the second display I can sometimes get the calibration to complete. When we removed the Nvidia card from the VM and used the Horizon View Display driver everything calibrates fine with one monitor.Are touchscreen supported with vGPU or am I missing something?Are multiple touchscreens supported with a extended Win 10 desktop using vGPU?Powered by Discourse, best viewed with JavaScript enabled"
138,hyper-v-ms-server-2016-2019-vm-gpu-via-dda,"Hello everybody,
In a (Hyper-V) VM Gen 2 with Win10 Pro I want to set exclusive access to a graphics card via Discrete Device Assignment (DDA).
The Hyper-V host is a Server2016. (eventually 2019)
Unfortunately, I have not found a current entry.
Basically, it seems loud >> https://blog.workinghardinit.work/2016/04/11/discrete-device-assignment-in-windows-server-2016-hyper-v/ << (video description >> https : //vimeo.com/161800097 <<) to go with a NVIDIA GRID K1.
That was 2016. What is the situation at the moment?
Is there an overview of which graphics types support the DDA feature under Hyper-V incl. Drivers?
Can I, for example, to use a P620?
Thanks in advance.PS: Sorry for the bad englishFor a single VM you can use a Quadro board >2000er series. Only Quadro and Tesla supports Passthrough/Virtualization.I’m trying to DDA my Quadro P2200, but have not been able to, getting errors when starting the VM, it says that an object cannot be found.
I bought that card exclusively to DDA it to a VM.
I would really appreciate if anybody is willing to help me troubleshooting the issue, I’ve gone thru numerous guides and posts with no luck. Not sure if I need to modify anything in my BIOS or the host.Thanks in advanceI am running into the same issue with my Quadro K2200.  Passthru with DDA worked fine in 2016 and now that I’ve upgraded that server to 2019 my VM will not start.  Stating that the device is in use by another VM.Powered by Discourse, best viewed with JavaScript enabled"
139,which-gpu-licenses-setup-for-rdsh,"Hi!Could anyone recommend a setup for delivering 6 to 10 concurrent graphics-accelerated RDSH Desktop Sessions (Windows Server 2019) which are intended to watch 720p videos with media player from the WAN. No cinema quality is needed; the users should be able to understand what’s happening. Videos show 2 people sitting and talking in a room, no big movements.e.g.Are the vApps licenses the right choice, even if desktops have > 1280×1024 resolution?Or One
3. Bare-Metal RDSH with Quadro P4000 or M4000 (no licenses?)Your help is very much appreciated as I didn’t quite get the answer from the other topics.HiYes, vApps licenses are the correct choice for the M10 and T4.If it were me, I’d use the T4 in Passthrough. It’s a much more modern GPU with better encoding / decoding capabilities, and has plenty of Framebuffer for a single VM with multiple users.If you wanted to skip the vApps licensing (not that it’s expensive anyway), you could use an RTX4000 (instead of the M4000 or P4000). It has the same benefits of being a more modern GPU with better capabilities than the earlier architectures. No need to do that bare-metal, you can still run that in a VM as Passthrough. The downside to those GPUs, is they only have 8GB of Framebuffer, whereas the T4 has 16GB if you ever needed it.Framebuffer is typically the limiting factor when running RDSH when maximum user density is reached.RegardsMGHi MrGrid,thank you very much!I have one more question concerning CPU requirements when using GPU in this case:Is it better to use more cores with lower speed (e.g. Xeon-Gold 6240, 2.6 GHz) or less cores with higher speed (e.g. Xeon-Gold 6234, 3.3Ghz)?We would prefer lower speed / more coresHow many vCPUs would you assign to the T4-assigned VM with 10 video users?(I know the question does not directly concern the GPU but this might be the best place to ask anyway…)Thanks!RegardsWaleHi WaleTypically you’d want a higher Clock as that helps the entire platform, not just the VM, but you also need to take into account what else is running on the VM and also Hypervisor, so it’s always a trade off. If your system isn’t fully loaded, you could always populate just a single CPU Socket and use a Xeon Gold 6254 which has 18 Cores @ 3.1Ghz. Then if you need more CPU at some stage, buy another and scale up.Start with 8 vCPUs, 16GB RAM and a T4 and scale resources up / down accordingly. Storage wise, you should be running Flash, not spinning disk. If you wanted a cheap, fast, storage solution, you can run M.2 drives on a PCIe carrier board.RegardsMGHi, MrGRID
Could you be so pleasure to explain how to divide one T4 onto 8 vGPU under Windows Datacenter Server 2019 with Hyper-V role installed to passthrough them into VMs under such server?
License server is installed.HiHyper-V doesn’t support vGPU. Passthrough (DDA) is your only option.Depending on how many and also the type of graphics workloads you may want to run in the future, you would do well to look at changing your Hypervisor for those workloads. If you only have RDSH workloads, then sticking with Hyper-V and Passthrough may be sufficient, but if you need to do anything more than that, then you’ll need to change Hypervisors.Hyper-V is currently the least favourable Hypervisor for graphics workloads. vSphere, XenServer, Acropolis and even KVM would all be a more suitable choice at the moment should you wish to look at changing.RegardsMGWhen enabled on Tesla GPUs, licensed editions of GRID Virtual Workstation or Virtual PC are activated by obtaining a license over the network from an NVIDIA GRID License Server. The license is “checked out” or “borrowed” at the time the Virtual Machine (VM) is booted, and returned when the VM is shut down.Powered by Discourse, best viewed with JavaScript enabled"
140,vsphere-7-0-3-esxi-with-nvidia-a40-gpu-nvidia-smi-has-failed-because,"Hi Nvidia Team,I can´t get a Supermicro AS-2114GT-DNR with a NVIDIA A40 up and running.
I set the BIOS Options:
SR-IOV = Enable
Above 4G Decoding = Enable
IOMMU = EnableOn vSphere Client I set the Graphic Device Settings to shared Direct.I installed the driver from nvid.nvidia.com → Version 11.9 vSphere 7esxcli software component apply -d <path-to-the-NVIDIA-vGPU-Manager-.zip>After rebooting and adding the PCI Devices to the VMX → there is no profile availible:

Bildschirmfoto 2022-10-31 um 13.40.101602×474 43.4 KB
On the ESXi host the NVIDIA-SMI shows only: NVIDIA-SMI hast failed because it clouldn´t comm…is this the right driver?
On the docs I can find a driver with 14.2 → not 11.9?Thanks a lotOliverWhy did to take 11.9? This LTSB version is not supporting A40.
You will need at least the 13.x LTSB driver branch.regards
SimonHi Simon,
there is no other option in my nvid portal. Where can I get the right Version?
Bildschirmfoto 2022-10-31 um 13.35.571475×272 76.8 KB
It seems you have a filter active. You should see multiple different versions.Hi simon,fixed. I don´t know how, but i got finally (chrome privacy tab) the latest version.
Thanks a lot!OliverPowered by Discourse, best viewed with JavaScript enabled"
141,a100-cannot-create-vgpu-with-sr-vio,"Hello,
We have A100 card a try to enable sr-vio on CentOS 7.9 with latest driver 510.47.03-511.65 for vGPU:/usr/lib/nvidia/sriov-manage -e 00:19:0000.0
modprobe: FATAL: Module pci-pf-stub not found.Documentation is not clear, standard vGPU with SR-VIO requires driver removal and use pci-stub?Can we use in one host A100 and V100 for vGPU purposes?Regards,
PiotrHi @PiotrP ,Could you please check whether IOMMU enabled and blacklisted nouveau? If not please do so first, reboot and then give a try.Regards,
ArifPowered by Discourse, best viewed with JavaScript enabled"
142,a100-vgpu-vs-mig-in-kvm,"We are running A100 PCIe 40GB in MIG mode in KVM (Ubuntu 22.04).
GPU is partitioned smallest size possible (1g.5g) and partitions are allocated as mdev links to virtual machines.Now end users want that VM’s would compete for whole GPU resource.
There are some VM’s which need more GPU time to time.
My understanding is that this is not possible with MIG mode as partitions are fixed.
Then I found this article:To improve NVIDIA GPU utilization in K8s clusters, we offer new GPU time-slicing APIs, enabling multiple GPU-accelerated workloads to time-slice and run on a single NVIDIA GPU.Article suggests about “Virtualization with vGPU” would be solution for this.
I haven’t just found any documentation how this should be configured and how it’s possible in KVM environment.
Is there any documentation how to configure A100 with vGPU but without MIG mode in KVM?Powered by Discourse, best viewed with JavaScript enabled"
143,cuda-initialization-failed-for-pytorch-using-nvidia-tesla-m6-on-esxi-6-7,"We are trying to run Tesla M6 GPU on VMware vSphere Hypervisor (ESXi) 6.7.
The Operating System used on VM is RHEL 8.6.We have installed the following Nvidia GPU driver:Download the English (US) Data Center Driver for Linux RHEL 8 for  Linux 64-bit RHEL 8 systems. Released 2022.5.16Version:	470.129.06
Release Date:	2022.5.16
Operating System:	Linux 64-bit RHEL 8
CUDA Toolkit:	11.4The driver is installed successfully, and gives the following output when we run
$ nvidia-smiWe also installed the compatible CUDA version i.e 11.4 from the below link:Resources CUDA Documentation/Release NotesMacOS Tools Training Sample Code Forums Archive of Previous CUDA Releases FAQ Open Source PackagesSubmit a BugBoth GPU and CUDA drivers were installed succesfully, we verified CUDA by running:
$ nvcc --versionnvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Wed_Jun__2_19:15:15_PDT_2021
Cuda compilation tools, release 11.4, V11.4.48
Build cuda_11.4.r11.4/compiler.30033411_0But when we verify if CUDA is working fine or not by testing the CUDA Samples 11.4 deviceQuery, the test fails:
$./deviceQuery
./deviceQuery Starting…
CUDA Device Query (Runtime API) version (CUDART static linking)
cudaGetDeviceCount returned 3
 → initialization error Result = FAILWe tried to check if ther is any error using dmesg:
$dmesg | grep  -E “NVRM|nvidia”
[    2.827680] nvidia: loading out-of-tree module taints kernel.
[    2.827693] nvidia: module license ‘NVIDIA’ taints kernel.
[    2.840425] nvidia: module verification failed: signature and/or required key missing - tainting kernel
[    2.850492] nvidia-nvlink: Nvlink Core is being initialized, major device number 242
[    2.851684] nvidia 0000:02:01.0: enabling device (0300 → 0302)
[    2.853120] nvidia 0000:02:01.0: vgaarb: changed VGA decodes: olddecodes=io+mem,decodes=none:owns=none
[    2.853420] NVRM: loading NVIDIA UNIX x86_64 Kernel Module  470.129.06  Thu May 12 22:52:02 UTC 2022
[    2.900185] nvidia-modeset: Loading NVIDIA Kernel Mode Setting Driver for UNIX platforms  470.129.06  Thu May 12 22:42:45 UTC 2022
[    2.904634] [drm] [nvidia-drm] [GPU ID 0x00000201] Loading driver
[    2.904637] [drm] Initialized nvidia-drm 0.0.0 20160202 for 0000:02:01.0 on minor 1
[   57.834904] nvidia-uvm: Loaded the UVM driver, major device number 240.Another way to verify if CUDA was working fine or not by checking with pytorch:
$python3.8We also tried to change the compute mode and virtual mode using nvidia-smi commands, but it was not supported.#nvidia-smi -i 0 -c 0
Setting compute mode to DEFAULT is not supported.
Unable to set the compute mode for GPU 00000000:02:01.0: Not Supported
Treating as warning and moving on.
All done.#nvidia-smi -i 0 -vm 3
Setting virtualization mode is not supported for GPU 00000000:02:01.0.
Treating as warning and moving on.
All done.#nvidia-smi -i 0 --virt-mode=3
Setting virtualization mode is not supported for GPU 00000000:02:01.0.
Treating as warning and moving on.
All done.We have tried various versions of GPU as well as CUDA drivers(11.2 to 11.4) but still the issue persists.
The main question arises is whether Tesla M6 can run on Virtual Machine or does it need Physical Machine only?
Also, its not clear from the documentation at:Release information for all users of NVIDIA virtual GPU software and hardware on VMware vSphere.
In section 2.1 Supported NVIDIA GPUs and Validated ServerPlatforms, it’s not mentioned whether Tesla M6 supports Virtual Machine or not.
It mentions :What’s difference between a Virtual Machine and Nvidia Virtual Compute Server? Will Tesla M6 work on ESXi 6.7 for computation?ThanksHi, Have you gotten it working? I am having the same issue but unsure what to do with it?Thanks!Powered by Discourse, best viewed with JavaScript enabled"
144,vgpu-on-aws,"hi,
has anyone done VGPU with AWS ec2?thank you
P.Powered by Discourse, best viewed with JavaScript enabled"
145,vgpu-dls-license-cluster-monitoring-user,"Hello together,
recently we’ve installed a DLS-Cluster for upgrading our old flex era licenses leasing of our vGPU environment.
Now in the new NLS system there is an Rest API included, where I should be able to implement a external monitoring (Nagios) for the leasing (amout of licenses, how many woul be used or are free ect.), reading the JSON output. Is it possible to create or use another user than the dls_admin for the check? Otherwise, is there an step-by-step user guide that explains the use of auth token shown in the https://dls-vm-ip-address/auth/v1/login page?
I don’t want to use the dls_admin user for a monitoring script. Actually I want to have an user with limited privileges, cutted down to the real necessary requirements.
Do you have such a guide or maybay helpful hints for such an implementation?kind regards
SvenPowered by Discourse, best viewed with JavaScript enabled"
146,script-to-get-grid-driver-suitable-for-host,"Hello,the host/hypervisor and grid driver in a VM are bound together.
I cannot install an newer grid driver on an older host.How can I check, within the VM which grid driver is necessary?
Something like this:Another option is do take a closer look in the nvidia driver, there must be
a way to test this with some C-source, because the newer nvidia driver,
somehow knows that it does not work together with the host version.Powered by Discourse, best viewed with JavaScript enabled"
147,m10-vgpu-8q-profile-on-linux-unable-to-create-cuda-profile-code-999,"Hi all,Nvidia-smi on guest:Nvidia-smi on host says:When I try to run anything of tests from CUDA toolkit, I got an error:~$ ./EGLStream_CUDA_Interop
Found 1 cuda devices
Found EGL-CUDA Capable device with CUDA Device id = 0
Created EGLStream 0x55cd70ab2911
EGLStream initialized
CUDA Producer on GPU Device 0: ""GRID M10-8Q"" with compute capability 5.0failed to create CUDA context (0x3E7)
&&&& EGLStream interop test FAILEDAt first test run, there is a log in dmesg:[43311.987240] nvidia-uvm: Loaded the UVM driver in 8 mode, major device number 240I tried more recent driver versions but no luck, so is it with P100 12GB too.Where am I wrong? Can I somehow get more detailed debug?Thank you in advance!HiHas the VM picked up a license ok?RegardsMGNo, it hasn’t. But is active license mandatory for CUDA to work? I could get similar configuration working in beginning of this year – since I use nvenc, I remember that just image was choppy (3fps) but there weren’t problems with CUDA. nvidia-smi dmon showed encoder usage. I just can’t figure out what changed since then :(HiNo, it hasn’t. But is active license mandatory for CUDA to work?License the Software and see if that helps.RegardsMGMrGRID, you was right. I’m very very confused now about how could I see nvenc working on unlicensed card. Thank you a lot for a straight way :)NVENC has nothing to do with CUDA. CUDA is not enabled without a licenseYes, you are right. In Gstreamer nvh264enc plugin NVENC uses CUDA and I thought that it’s the only method to use it, sorry.Powered by Discourse, best viewed with JavaScript enabled"
148,alterative-methods-for-unsupported-gpus,"My laptop’s GPU is not supported by Nvidia’s vGPU manager, and loading GPUs is no longer naturally supported by hyper-v if I want to use it on a virtual machine. I’ve tried deploying it using Discrete Device Assignment, but that doesn’t let the virtual machine boot at all. Any suggestions on how to get my GPU (RTX 2060 Max-Q) working on a virtual machine?Have you resolved why DDA does let your VM boot at all?No, I found somewhere that it is not compatible with some GPUs such as Nvidia GPUs (not sure if all of them, or just less powerful ones, but it is irrelevant for the powerful ones in all cases). I think this is done on purpose for security concerns.Powered by Discourse, best viewed with JavaScript enabled"
149,nvidia-smi-file-location-on-linux,"I am using Ubuntu version 18.04 and what I am looking for is to locate where the GPU stats are saved locally on the machine.I know I can execute the following command on the terminal:
nvidia-smiBut what I am looking for, is to actually locate the file and read it manually instead of using the above command.
Can someone help out.Powered by Discourse, best viewed with JavaScript enabled"
150,rtx4000-quadro-on-single-vm,"I everyone, i have a question.i have 1 quadro rtx4000 on dell t430, i try to passtrough pci but it doesn’t work, on hadware screen esxi 7 i recive the flashing screen and not activate passtroughPowered by Discourse, best viewed with JavaScript enabled"
151,vsphere-7-a40-gpu-driver-for-windows-server-2019,"Greetings,  I have a VMWare box with a A40 GPU, the card is seen in vSphere with the right profiles, I’ve assigned the VM with a prebuilt profile, when I start Windows 2019, it’ll crash with “page fault in nonpaged area”.  I’m testing SolidWorks Web2 setup and it requires a supported Nvidia driver.  Any help will be appreciated.  I’ve tried various drivers from the Licensing Portal.Powered by Discourse, best viewed with JavaScript enabled"
152,citrix-vdi-grey-screen-at-logon,"Hi guys,Here is my set up (fresh installation):
Windows 10 1809 LTSC (Fully patched)
Citrix VDA 1912
VMWare ESXi 6.7U3
VMware Tools v11.0.5-15389592 (SVGA Driver not installed)
Microsoft Basic Display Driver Adapter (disabled)
NVIDIA-GRID-vSphere-6.7-440.53-440.56-442.06 - v10.1
GPU: NVIDIA Tesla M10
vGPU profile: M10-1BWhen the Citrix VDI session is initiated a grey screen is all the user can see. Please refer to the screen shot below:https://ibb.co/G5zpvqnCitrix Policies:https://ibb.co/8YjCpL7Surprisingly, if a master image, same setup specified above, but running Citrix VDA 7.15 LTSR CU5 is upgraded to Citrix VDA 1912 LTSR, the issue goes away and the VDIs work wonders.Any thoughts?Thank youHi vianneyjscan you try to resize the window? Does the grey screen goes away? I have this issue on some clients for example my home pc aswell. It seems that the video stream freezes and when i resize the window it gets refreshed, i only have this issue on the start and not while connected.Br
MatSo you already have a solution?! Why should you stay with 7.15? This is the worst release for GPU enabled VDIs and really makes sense to go with 1912Hi guys,@Gormat
Resizing the window does not help.@sschaber
No, we have not found a solution yet. We are willing to use vGPU enabled VDIs with VDA 1912, no with VDA 7.15.HiHave you tried an up to date version of Windows? Your version is from 2018, give a clean build 1909 a try and see how you get on.RegardsMGHi MrGRID.I will give a shot to Windows 10 1909.The reason we are using Windows 10 1809 LTSC, which is supported by MS for 10 years, is because it does not come with all the crapware and modern apps, what consequently makes it lightweight and ideal for a VDI environment.HiIf removing the default rubbish is the sole reason you’re running an older OS, then a better option may be Server VDI.You could also use the Citrix Optimiser or VMware OS Optimization Tool to remove that default rubbish, and of course there are plenty of custom Powershell options to remove it as well if that helps give you more options.RegardsMGHello,@MrGRIDI created a new master image with Windows 10 1909, surprisingly the issue is reproducible as well.That’s very odd, what do you think?HiThat’s strange.Something else you can quickly try … Can you remove / disable all of the Citrix Policies applied to that specific VM (or Delivery Group) and try again. More of a sanity check really.Just out of interest, are your Delivery Controllers upgraded to 1912, or are they an earlier version?As for what I think … I think I’m going to bring up my Lab and have a test for you to see if I can replicate it … :-)RegardsMG@MrGrid.We use Citrix Cloud Service, so the Delivery controllers should be running the latest version available.Let me rephrase this comment from my original post above:If a master image, same setup specified above, but running Citrix VDA 7.15 LTSR CU5, and then upgraded to Citrix VDA 1912 LTSR, the issue goes away…but there is a nasty memory leak with the CtxGfx driver.HiThanks for the info.What’s your image build process? It should be:Install Windows > Install VMTools (Without vSGA Driver) > Install vGPU Driver > Install Citrix VDAWhen you upgrade the VDA from 7.15 to 1912, do you just run the upgrade or do you do anything with the vGPU driver?RegardsMG@MrGRID""Something else you can quickly try … Can you remove / disable all of the Citrix Policies applied to that specific VM (or Delivery Group) and try again. More of a sanity check really.""Removed the Citrix Policies mentioned above:…from the VDIs’ OU and the user I am using for testing, but it is still reproducible.@MrGRIDInstall Windows > Install VMTools (Without vSGA Driver) > Install vGPU Driver > Install Citrix VDA
Yes, I did it in that order without without vSGA Driver.When you upgrade the VDA from 7.15 to 1912, do you just run the upgrade or do you do anything with the vGPU driver?
I just run the upgrade, nothing else.HiThanks, just seeing if this is something I can replicate …RegardsMG@MrGRIDThank you so much, I appreciate that.HiUnfortunately I can’t replicate it. 1912 works without any issues for me out the box.Win 10 1909 clean build from .iso and fully patched as of this morning > VMTools 11.0.1 > vGPU 10.1 > VDA 1912It’s a clean build Citrix environment (reinstalled this morning) consolidated onto a single VM (DDC, Storefront, Director, SQL Express). No Citrix Policies have been created and only the default ones are applied.Which version of Workspace App are you using?RegardsMGHi @MrGRIDI already figured it out, I was applying some ctxhooks via a reg file I gathered a while ago from a master image with VDA 7.15 installed.That being said, the grey screen issue is already resolved.Thanks a lot for the follow up and support.Any thoughts on the high memory consumption by the ctxgfx service?HiApply your registry settings via GPO, it’s easier to review and keep track of what’s being applied when you upgrade your VDA or Operating System.Regarding the memory leaks, the only advice I can offer is to make sure you’re running the latest software throughout your stack. The 2003 VDA is now available, upgrade to that in combination with vGPU 10.1 and see if that helps.RegardsMGHi @MrGRID,Quick question…As I mentioned earlier, we are assigning M10-1B vGPU profiles to these Windows 10 VDIs.These users are using Windows-based thin clients with 2 x monitor @1080p. They are office power users that pretty much use enterprise apps, but they rarely run multimedia stuff such as YouTube, video conferences, and video training. On top of that, we use Pi-Hole to block ads and push ad-blockers extensions/add-ons to their browsers.I used the following guide as a reference:
http://images.nvidia.com/conten  t/pdf/grid/guides/vgpu-profile-sizing-guidance-for-windows-10.pdfBased on your experience, would it make sense to upgrade their vGPU profiles to M10-2B?HiUnfortunately this isn’t an answer anyone else can give you, as your environment specifications, applications, user working habits and therefore overall utilisation will vary to anyone else’s. You’ll need to monitor the utilisation on a subset of your VMs and decide what’s appropriate. Here’s my favourite utility for this kind of thing: Releases · JeremyMain/GPUProfiler · GitHub It’s nice and easy to understand, just capture the metrics for a group of users (the more the better) and take appropriate action based on the results. Other tools are available if you wanted to dive a bit deeper.If you increase the vGPU Profile size, at best, you halve the density of the GPU potentially doubling your overall Server hardware requirement, unless you have some headroom built-in.This is why it’s absolutely critical to run well defined POCs before the hardware specifications that will be used are finalised. If unsure, it’s far better to over-spec than under-spec the environment. I’ve seen it happen before in an environment where the customer used the the wrong vGPU Profile and it worked out very, very expensive for them to put right.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
153,chromebooks-and-nvidia-grid,"Hello everyone,I come here because Citrix and NVidia have both been struggling to provide me with any concrete information. We’re trying to get dual monitors working for chromebooks, with hardware encoding enabled for our GPU setup. We are hoping to utilize hardware encoding for the entire screen, rather than selective h.264. This works fine when launching a single monitor Citrix session, however if we full screen it across 2 or more monitors it does not work. They are simple 1080p monitors and this issue happens across multiple chrome devices including i5 cpu chromebooks, chromeboxes, etc.Our setup:
Delivery controller: LTSR 7.15.300
VDA: 1906
Windows OS: 1809 x64
Nvidia driver version: 9.1 on both host and guest
Imaging: Image created through app layering, and published with MCS (static persistent desktops). I am using the platform layer for nvidia drivers, then installing the vda afterwards. There is an app layering nvidia fix we also perform prior to installing the drivers (regarding unifiltr) registry key.
GPU: Tesla T4 Turing 16gb GPU, 2 in each host.I am at a loss as to what to try. We have played with google policy and used the chrome configuration utility from citrix:Citrix Workspace app (earlier known as Citrix Receiver) for Chrome and HTML5 Configuration UtilityThis works fine from a windows endpoint, but dual monitors I cannot get working from any kind of chrome device. This is really preventing us from moving forward with our POC and any help would be greatly appreciated.So what should NV do there? As you already mentioned it works fine on fat client so not a NV issue. Citrix receiver has not the same feature set for different platforms so I assume it is a limitation with Citrix receiver. At least there is nothing from NV side that would prevent dual screen on Chrome.regards
SImonHiIn addition to Simons answer (which is correct), the issues you’re experiencing are why it’s so important to run POCs before rolling out a new environment or set of technologies. Trying different configurations of hardware, software etc until you find what works and what’s acceptable for your support teams and more importantly end users. This is where you find the various limitations of each technology or combination of technologies and it’s all part of the process. You can then either accept those limitations and carry on, or decide if you go down another route substituting different technologies until you get the functionality that you need.For example:Is using the GPU for encoding the protocol critical to the success of the POC at this time? If no, try using the CPU (server side) by changing the Citrix Policies appropriately and see if that works for your users.If hardware encoding is critical, is having multiple monitors? How about removing a pair of low resolution 1080P monitors and replacing them with a single 4K monitor? This will free up desk space, remove cables and free up power sockets as well as giving your users much more screen estate to work with. It will also give you some future proofing, which 1080P doesn’t. And as you’ve already confirmed, your POC works with a single monitor …You’ve already mentioned that other non-Chrome devices work, are you locked in to using Chrome as an OS?This is 100% a Citrix limitation or Citrix / Chrome configuration issue. The GPU is more than capable of encoding multiple monitors (or a single 4K monitor ;-) ). There is nothing on the NVIDIA side that can be done here.Have you posted on the Citrix Forums? If no, you should be posting under these categories:https://discussions.citrix.com/forum/1316-xendesktop-7x/https://discussions.citrix.com/forum/523-gpu-technologies/Lastly, I haven’t used XenDesktop 7.15 for a long time, I always run the CR to take advantage of the latest settings, but it may be worth checking which Citrix Policies are available in the LTSR vs CR in case there’s something in there that helps. Unrelated, but whenever I’m working with customers and they’re using vGPU / GPU technologies, I always recommend running CR, not LTSR. It may or may not be applicable in your case, but worth having a look just in case.RegardsMGUnderstood and thanks for the feedback. Yes, we’re still in the POC phase luckily. I think what I’m most disappointed with is the fact that neither Nvidia nor Citrix can definitively say where the limitation is. No one has given us any advice other than the standard documentation, no one can say whether it is a limitation of chromebooks, Receiver for Chrome, or anything else. I can see where it would be easy for Nvidia to say that it works on a fat client, so it isn’t an Nvidia issue. It makes sense, and I understand that.We’re really hoping to get the NVENC offloading working as that seems to be the best use of the GPU’s. When the hardware encoding isn’t working, the performance when watching even a simple youtube video is on par with that of a regular VDI VM. There isn’t much benefit for buying these fancy video cards if they can’t offload CPU tasks to the GPU.Regarding what should NV do, it would be helpful if they atleast added this to their documentation so the next person that tries to do dual monitors on a chrome device, they can say it is a known limitation. Or perhaps NV could work with Google or Citrix to get this implemented if it is a limitation of Citrix or Chrome OS.I’m sure there is a number of things they could do, whether they will do them to try to sell hardware is another story. We’re an extremely large customer looking at buying easily 40-50 high end GPU’s, and anywhere from 4000-6000+ per user licenses, but I suppose this isn’t incentive enough to get any support beyond ""this is a citrix issue"".I suppose I’ll post on the Citrix forums to see what they can offer.HiThe GPUs and vGPU software are doing what they’re sposed to. They have the functionality and performance to encode multiple monitors (way more than two) per session or Client. The issue is with the combination of Citrix WorkspaceApp and Chrome, and that’s nothing to do with NVIDIA. You could use AMD GPUs and it still wouldn’t work, as it isn’t an AMD limitation either. You can see this because as you’ve mentioned above, the solution works with a Windows Operating System on a Client instead of Chrome. It isn’t because of NVIDIA that it works with Windows as the GPU is located in the datacenter so has zero visibility of the Client or its Operating System being used, it’s because of Citrix and Microsoft. Windows being the most popular Operating System globally moves it to the top of Citrix’s priority queue for feature development and support.Unfortunately, in this instance, an Operating System that isn’t widely used in enterprise environments (compared to something like Windows) is being used on the Client side, therefore feature development and configuration support will be lacking by comparison. There really isn’t anything NVIDIA can do here, their GPUs are working perfectly, are in no way at fault and there’s no need for NVIDIA to add it to any of their documentation, as it isn’t their limitation.Do you have the model number of a Chromebook you’ve selected for this POC that I can look at?… neither Nvidia nor Citrix can definitively say where the limitation is.I can understand the frustration when vendors are bouncing customers around. However, I will definitively say that it’s a Citrix WorkspaceApp & Chrome configuration or functionality issue.RegardsMGHey TylerMy company isn’t setup exactly like you are but we are running Chromebooks connected to Plugable USB-C docking stations running up to 3 monitors from a single Chromebook.  Our hardware consists of Dual Nvidia M10 Cards in our hosts and Asus C434, HP X360 14 G1, and PixelBooks.  What chromebooks are you trying this from?
Also are you using the Citrix Workspaces from Chrome Web Store vs the playstore.Citrix Workspace app for Chrome OS
We are currently on 7.15 CU4  and 1909 for the VDAs.And just read you post a for a second time and noticed we are setup different.  We have our graphics policies set to ""Use video codec when preferred.""  I will test with changing it to  ""For the entire screen"" and will get back with you on our results.Hey TylerWelp…you are correct.  I get the same results as you.  If we change the Video Codec to ""For the Entire Screen to Optimize"" our Plugable USBC docks no longer work with our Chromebooks.  The Workspaces trys to open and then immediately closes.  If I unplug it from the dock the native screen works.  But then says Hardware Encode ""disabled""  Our default policy was set to ""For Actively Changing Regions.""  If I set this to ""Use Video Codec when Preferred""  I get the same result as above.  If I set if to ""For Actively Changing Regions"" everything works again.  And this is only on Chromebooks.  I tested on a couple Mac Books and a couple Windows 10 machines and ""For the Entire Screen to Optimize"" works fine and hardware encode says ""Enabled"" with 4 monitors connected.  So looks like just chromebooks are not working.  We are actually finishing up a test environment that is running 1909.  This is to prepare for the next LTSR.  Maybe the behavior is fixed since 7.15 is a few years old now.Powered by Discourse, best viewed with JavaScript enabled"
154,quadro-rtx6000-passthrough,"Setup: Dell7525 2x EPYC 7F72 and a Quadro RTX6000 - Proxmox 6.4 on the bare metal with PCI passthrough enabled.VM running linuxmint20 with the rtx6000 passthrough and nvidia-driver-470 installed.  nvidia-smi loads and shows processes loaded on the GPU, but no utilization.
My test app is obs-studio (snap) with all the built in nvenc support.  OBS shows loaded on the GPU, but no utilization. All the rendering is still taking place on the CPU.Is there something limiting the performance of the GTX6000?Hello @bass1957 and welcome to the NVIDIA Developer forums!Can you try running
nvidia-smi encodersessions
specifically to check if nvidia-smi reports NvEnc being used?  As a next step to verify the GPU as such works as expected you should try to use different rendering applications that utilize different features from the GPU than NvEnc as OBS does.
Maybe run an example Deep Learning docker image or some OpenGL samples?That could help distinguish what exactly is and is not working for your setup.Thanks,
MarkusBubkis…
I can send the whole GPU to this VM w/o any paid licensing, correct?I don’t think I am able to help you further at this point, but I moved your topic into a better suited category where I am sure there will be someone who can give you some suggestions.MarkusHi @bass1957Are you still having issues with this setup.  Quadro RTX6000 is supported in pass-through and you don’t need any additional software - such as vGPU to make it work.I am not familiar with Proxmax and how that works for virtual environments.  However, assuming that nvidia-smi is detecting the GPU correctly I assume the NVIDIA driver is working correctly.I suspect that your application is based on GLX and however you are remoting into the server is defaulting to CPU rendering.  I recommend running X11VNC on the server and see if that helps.:D:Yes, still trying to work this out.  Had some other issue pop-up but will be getting back to it shortly.I suspect that your application is based on GLX and however you are remoting into the server is defaulting to CPU rendering. I recommend running X11VNC on the server and see if that helps.That’s what I’m beginning to realize and looking for a way to run heavy graphic apps (like OBS) but use the GPU to render the desktop and the encoding work.  I was using Proxmox’s built in remote desktop (spice or novnc).  So, yeah, I guess all the desktop rendering was done on the host’s CPU. :/That said, I’m moving to try and use an LXC arrangement on proxmox rather than QEMU VM’s so I can have multiple, different apps/processes use the GPU simultaneously.
(eg. spin up a quick VM for someone to render a backlog of video content into more suitable formats, while other regular use LXC’s are using the gpu for object detection and what not…)I’ve got the drivers loaded on the host and I can spin up an LXC and install the same version of the drivers and SMI is happy.  Now I’m working on the apps part of the equation.But just so I’m clear, if I’m running a desktop environment (like Mate) in an LXC, can I have that desktop rendered/processed on the quadro?     (using a different remote desktop solution like X11VNC)
What are the tricks or need to knows?I’ve already found out the snaps don’t work well in LXC’s so not snap ffmpeg or OBS :(.  I’ll have to build my own ffmpeg.
Lots of questions, sorry, but thanks in advance for your advise.
LHAs an update…
Passthrough is working great in LXC containers.  Running 2 different instances of OBS sharing the Quadro and it turns out it’s rendering the desktop as well.  I’m using NoMachine to initiate and access the required GUI Desktop.  That was a tricky setup but the Ubuntu-Studio distro has nearly all the pieces put together.
Also, not necessarily for this forum, but a ray of hope, got the SNAP’s of ffmpeg to work in the containers so I didn’t have to compile from source.Now I’m moving on to adding object detection to the NVR (Zoneminder) running in a different container.  I need to get CUDA up and cuDNN.  So it looks like I’ll be starting over installing the CUDA toolkit on the host and containers as it includes the drivers needed to match throughout the whole system (host and containers).Powered by Discourse, best viewed with JavaScript enabled"
155,win-7-64bit-pro-can-not-install-driver,"Xenserver 7.0 installs the grid driver normally, nvidia-smi displays normally
But I installed a matching version of win 7 64bit windows driver can not be installed
Display failure
I tried to install using the upgrade driver in Device Manager.
After the VM is restarted, the VGPU graphics card in the vm is still not installed.
Right click on the desktop and the nvidia control panel icon is not displayed properly.Powered by Discourse, best viewed with JavaScript enabled"
156,legacy-vgpu-software-image-running-on-a-version-13-2-vib-updated-vmware-host-pointing-at-legacy-license-servers,"Hi, we are planning a migration and have an important question. Currently we have the Legacy VGPU License Servers and Version 11.5 Software. We have succesffully built our new DLS Servers and they work. But we have to migrate 146 Hosts to the updated VIBs. My customer noticed that the old image with Version 11.5 Software pointing at the old License Servers is successfully running on an updated host that is using the new Version 13.2 VIB. Is this a possible migration path? It would be much easier to be able to migrate hosts in small groups instead of all at once overnight. Updating 146 Linux hosts with VIBs is a serious bottleneck. They want to know if we can update the hosts ahead of the all the software on the images and the License server registry entries?   Otherwise we have to update everything in one night.Powered by Discourse, best viewed with JavaScript enabled"
157,in-ubuntu18-nvidia-driver-install-failed,"I am a new to GPU setting. I will set up nvidia-driver on Ubuntu18. But many try has failed for unknown reason.envI think nvidia-driver-455 and cuda11.1.1 are right version from many website. I reinstalled Ubuntu, and tried NVIDIA official install flow on https://developer.nvidia.com/cuda-11.1.1-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocalAfter rebooting, the command “nvidia-driver” results onNVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.I saw /var/lib/dkms/nvidia/455.32.00/build/make.log written belowPlease tell me what happened and solution.ThanksKnown bug. Happens with kernel 5.8. Will be fixed soonIf there is no output, then your installation has probably failed . It is also possible that the driver is not available in your system’s driver database. You can run the following command to check if your system is running on the open-source driver nouveau. … This is my terminal output of Nvidia Drivers .Sorry, I forget to note result.The error is caused by hardware problem. My CPU had unfortunately initial failure, so cuda error happened.After changing to new one, no error happend following official set up instruction.Thank you, every one.Powered by Discourse, best viewed with JavaScript enabled"
158,nv-license-server-log4j,"Hi,cant find anything on this topic, altough it should be here:UPDATE: Revenera’s response to Apache Log4j vulnerabilities CVE-2021-45105, CVE-2021-45046, CVE-2021-44228, and CVE-2021-4104 (as of 14-Jan 10:20 CST) A critical vulnerability in Apache Log4j 2 impacting versions from 2.0-beta9 to...The License Server is effected correct? Any mitigations done?Security Notice: NVIDIA Response to Log4j Vulnerability (CVE-2021-44228) - December 2021 | NVIDIA (custhelp.com)Additionally:
Log4j Java Vulnerability (CVE-2021-44228) for Legacy vGPU Software License Server (nvidia.com)You’ll also need to follow their instructions to remove the JNDILookup class in the following files.
C:\NVIDIA\LicenseServer\Tomcat\webapps\licserver.war
C:\NVIDIA\LicenseServer\ui\licserver.warAny information on where I can find docs for removal of the JNDILookup class from licserver.war files?Log4j Java Vulnerabilities for Legacy vGPU Software License Server (nvidia.com)From the article -Note: Mitigation steps are updated on Dec 23rd, 2021 to address recently reported new CVE-2021-45105, so if you used the previous mitigation steps (deleting JndiLookup class), it does not address CVE-2021-45105.Hi,I have already follow ESPCommunityupgrade the log4j to 2.17.1But whenI use log4shell tool (Release v1.0.0-log4shell · lunasec-io/lunasec · GitHub)to check log4j，the result shows that the path argument in /opt/flexnetls/nvidia/
still include log4j 2.14
image900×427 21.4 KB
I have already search my license server, there is no log4j-core-2.14.0.jar
Is this path still work?or in which way I can fix this?thanks for the help.Powered by Discourse, best viewed with JavaScript enabled"
159,license-for-share-gpu-in-3-linux-vm-at-the-same-time,"Hi all,I want to share the GPU between 3 Ubuntu VM concurrently. I want to know which type of license I need for this purpose.
Right now I have one Quadro vDWS license with one vSphere 7 Enterprise Plus.Regards,
AshkanHiIf you want to use 3 VMs concurrently, then you’ll need 3 licenses. The type of license will depend on the workload you’re running.If you only use 1 VM at a time, then you only need 1 license. Note that the other 2 VMs will need to be powered off, as the license is allocated when the VM starts, not when the user logs in.RegardsMGThank you for your response, could you please tell me where can I find the list of license based on the workload?Regards,
AshkanHiThe best reference I can give you is here: https://docs.nvidia.com/grid/11.0/grid-vgpu-user-guide/index.html#virtual-gpu-types-grid-referenceYou’ll need to assess your environment and the workload you’ll be running. I assume you already know what your application requirements are, because you’ve already installed it. Then make the appropriate choice regarding the vGPU license or how you’d like to use the platform.QvDWS covers everything, so using the license you already have, you can experiment with different workloads and configurations and workout what you need. Or you can just purchase 2 more QvDWS licenses knowing that you’ll be covered for any workload, or you can just have 1 VM powered on at any one time and continue as you are. But there’s lots of information in the link I sent you that should point you in the right direction.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
160,3d-software-not-using-gpu,"Hi everybody,
I finally managed to get my Windows 2012 R2 vm working on proxmox, with GPU passthrough enbaled and licenced GRID vWS drivers up and and running using a TESLA T4 card.
Server is a poweredge R740
I am trying a BIM software which is using 3D modeling and performances are awfull. It looks like the vgpu is not used.
Any Tips from experienced users would be great==============NVSMI LOG==============Timestamp                                 : Wed Feb  9 17:54:06 2022
Driver Version                            : 472.98
CUDA Version                              : 11.4Attached GPUs                             : 1
GPU 00000000:01:00.0
Product Name                          : GRID T4-4Q
Product Brand                         : NVIDIA RTX Virtual Workstation
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : N/A
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : WDDM
Pending                           : WDDM
Serial Number                         : N/A
GPU UUID                              : GPU-98745397-89c0-11ec-8b3e-387adb41f841
Minor Number                          : N/A
VBIOS Version                         : 00.00.00.00.00
MultiGPU Board                        : No
Board ID                              : 0x100
GPU Part Number                       : N/A
Module ID                             : N/A
Inforom Version
Image Version                     : N/A
OEM Object                        : N/A
ECC Object                        : N/A
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GSP Firmware Version                  : N/A
GPU Virtualization Mode
Virtualization Mode               : VGPU
Host VGPU Mode                    : N/A
vGPU Software Licensed Product
Product Name                      : NVIDIA RTX Virtual Workstation
License Status                    : Licensed (Expiry: 2022-2-10 16:8:5 GMT)
Hi,if this is for RDS sessions. Did you set the policy (GPO) → se the hardware default graphics adapter for all Remote Desktop Services sessions ?This policy setting enables system administrators to change the graphics rendering for all Remote Desktop Services sessions on a Remote Desktop Session Host (RD Session Host) server.
vApps license is needed for this usecase only, but RTX Virtual Workstation will do, although not needed.Cheers,
Ron.RDS sessions. Did you set the policy (GPO) → se the hardware default graphics adapter for all Remote Desktop Services sessions ?Use the hardware default graphics adapter for all Remote Desktop Services sessionsThanks for your answer,
Yes, it is a RDS session environment, and the GPO is enabled.Hi,have you tried different apps i.e. free benchmarks (Unigine Heaven etc) to check GPU acceleration is working in general even if not for your BIM software.
You can try OpenGL and Direct3D in Unigine for example but there is a lot of other tools available and you may want check with nvidia-smi or for better usability GPUProfiler  (Releases · JeremyMain/GPUProfiler · GitHub) in your RDS sessions. Don’t have any WS2012R2 running anymore, just WS2019 and WS2022 but if GPU/vGPU is recognized in general this should work just fine.Ron.BTW: I think your eval license period ends todayHi,
Token have a 1 day validity, then I have to regenerate a new one :-)
I am actually using GPUProfiler.
Thing is, when I use the BIM software, perfs are awfull and it looks like it is using almost nothing from the GPU.
If I start testing with href=“HTML5 Fish Bowl” the GPU goes up normally.
The card is recognised by the software and I asked the company who told me that as long as the software recognised it there is nos issue.
We have to stick with WS2012R2 for the moment as the DC is a linux samba which AD/FOREST is not compatible with upper AD/FOREST. It sucks but no choice from what I knowhere is the output of nvidi-smi:PS C:\Program Files\NVIDIA Corporation\NVSMI> ./nvidia-smi
Thu Feb 10 15:54:35 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 472.98       Driver Version: 472.98       CUDA Version: 11.4     |
|-------------------------------±---------------------±---------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GRID T4-4Q         WDDM  | 00000000:01:00.0 Off |                    0 |
| N/A   N/A    P0    N/A /  N/A |   4018MiB /  4096MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A       504    C+G   …dows\system32\LogonUI.exe    N/A      |
|    0   N/A  N/A       564    C+G   C:\Windows\system32\dwm.exe     N/A      |
|    0   N/A  N/A      3844    C+G   …tic\Windesc\ImportIFC.exe    N/A      |
|    0   N/A  N/A      4052    C+G   C:\Windows\system32\dwm.exe     N/A      |
|    0   N/A  N/A      4440    C+G   …Attic\Windesc\windesc.exe    N/A      |
|    0   N/A  N/A      5876    C+G   C:\Windows\Explorer.EXE         N/A      |
±----------------------------------------------------------------------------+WS2019 did the job.
Thanks for the helpPowered by Discourse, best viewed with JavaScript enabled"
161,vmware-vgpu-add-vvtd,"Hi
I have problems on adding a vgpu on a vmware vm. The vm had enabled VBS (Virtual Based Security). I have disabled it, but anyway I get the message, that VVTD (Intel Virtualization Technology for Directed I/0) is not supported.
On a fresh clean vm I can add the vpu.
How could I disable that VVTD on that vm?Cheers
LukasSolved:shutdown vm
disable VBS
delete following lines in vmx-file:vvtd.enable = ""TRUE""
vhv.enable = ""TRUE""Thanks, I disabled Intel VT-D in BIOS but still got this message. So I searched the setting in the VM settings via the vSphere Client but found nothing. The vmx file can be found using “find /vmfs/volumes/ | grep vmx$” on the vSphere server command line.Update: Do not disable VT-D in BIOS! Just remove the lines or set vvtd.enable to “FALSE” in the vmx file. VT-D is actually needed by the vGPUs.Powered by Discourse, best viewed with JavaScript enabled"
162,horizon-7-9-windows-10-freezing,"Hope I am in the right forum for this.My environment is Horizon 7.9, Vsphere 6.7, Nvidia Tesla M10, GPU Driver v 431.02 on a Windows 10 1903 desktop (Windows 1809 does the same)  and when I log in using HTML or Client I get a desktop and as soon as a license for the GPU is received, the desktop completely freezes.
The Master image does not have this issue. Only the Instant Clones.Thanks in advance.I have exactly the same issue. Could you resolve it?thxCheck @vdiguywi’s solution at https://gridforums.nvidia.com/default/topic/9657/nvidia-virtual-gpu-technology/vdi-machines-with-nvidia-tesla-t4-profile-are-stuck-when-using-horizon-client/?offset=10#15490Powered by Discourse, best viewed with JavaScript enabled"
163,nlc-license-server,"Hello. How to create a new NLS server without migrating the old Legacy server?And it need a DLS server typePowered by Discourse, best viewed with JavaScript enabled"
164,error-installing-license-server,"Hi
After installing Java 64bit, seting path and java_home I have successfully installed nvidia llcense server.
But then the Service ""FlexNet License Server - nvidia"" is not avaiable.
In the log-file I find:C:\NVIDIA\LicenseServer\server>flexnetls.bat -install
Error writing service configuration : Der Prozess kann nicht auf die Datei zugreifen, da sie von einem anderen Prozess verwendet wird.Pre-install failedAlso trying to manually install it failes.Starting manually is ok.What could be the problem?Windows Server 2019Solved:Deaktivate TrendMicro VirusScan –> Successfully installed.Powered by Discourse, best viewed with JavaScript enabled"
165,p40-not-detected-by-bios,"Hello,I cant seem to get any of the 4 Tesla P40 detected by our HP ProLiant DL580 Gen9. I have checked the power and confirmed the slots are all x16 wideThanks in advanceAdamPowered by Discourse, best viewed with JavaScript enabled"
166,grid-forums-functionality,"Hi NVIDIA,Is it possible to add the functionality to the GRID Forums to receive e-mails for updates to previous posts?   Currently, I maintain a list of active threads.  It would be nice to receive an e-mail when they are updated.Thanks for considering this!RichardHi Richard,I’ve highlighted the request to the forum infrastructure guys. Hope you enjoyed yesterday’s webinar.Best wishes,
RachelI’ve been requesting this one for several years on the GeForce Forums - at the moment the only option is an RSS feed.The webinar was very interesting - is there a specific discussion thread anywhere?I’ve heard from the IT guys - ""It’s actually been in use for a short while on the DevTalk forums already, and we do have plans to roll it out to GeForce forums and GRID forums in the near term."" :-Dwe directed folks to discuss the webinar on the VMware-VMware user group as both teams agreed to monitor it - but you are free to post a new thread on this forum about the NVidia stuff… but if you want the VMware perspective the joint community group probably best: Submit FormThanks Rachel!  I’m glad to hear it’s in-progress.Cheers,RichardWe have moved the GRID (vGPU) forums to a new modern day platform.
For a list of new features and functions, please read this guide Getting to Know the New NVIDIA Developer ForumsCheers,
TomPowered by Discourse, best viewed with JavaScript enabled"
167,vm-reboot-cause-server-reboot,"Hi all,
I’ve a SUPERMICRO server with a M10 GPU (at the moment i’ve a free-trial license) and as virtualization platform i’m using oVirt 4.4.2.
My issue is very strange and it seems to be a bug because i can reproduce it:All NVIDIA driver’s are update at the 2020-09-30 latest release (11.0).The VM works very well and the vGPU too. This is my very first test with vGPU and i can’t understand the reason of this issue.Could someone help me?
Thank you in advance.Powered by Discourse, best viewed with JavaScript enabled"
168,how-to-fix-the-error,"Hello! Please tell me what to do with this “NoMachine authentication failed, please try again” Error. I’m getting this error, I’ve made several attempts to connect, but I keep getting the error. Perhaps someone else has experienced this, I would be grateful for your help!I also recently received an error message from Nomachine. In my case, the problem was with the firewall on the client machine. But you have a different error to solve you can find the answer here https://www.helpwire.app/blog/nomachine-not-working/ This article describes the most common problems and solutions.Powered by Discourse, best viewed with JavaScript enabled"
169,updating-drivers-on-appstream-instance-in-aws,"Hi,
Does anybody have any tips on updating Nvidia tesla drivers on a windows server 2019 image for graphics pro instance type?The initial one is 412.16 and has Cuda 10.0 but I need at least Cuda 10.1. I’ve tried to install 419.69 but the display adapter changes to Microsoft Basic Display Driver and I get only a few small resolutions (1280x1024, 1024 x 768, 800x600) and aspect ration seems to get stuck on 4:3 or similar.I also tried with the newest driver, I just don’t remember the number. Same issue.It’s Tesla M60, I tried both Windows 2019 and 2012R2Some screenshots: [Issue with Nvidia Testla on Appstream - Album on Imgur]Powered by Discourse, best viewed with JavaScript enabled"
170,weird-guest-state-unable-to-run-workloads-without-reinstalling-drivers-mig-kvm-passthrough,"Hello everyone,I was doing some resiliency tests on the A30 using this implementation of MaxFlops, in a system configured with the vGPU (vgpu-ubuntu-525_525.85.07) host driver, KVM and 4 VMs with MIG pass-through each. I maxed out the number of blocks in MaxFlops. Individually the workloads ran fine, but when I tried running them concurrently, the system kinda crashed, each VM displayed a different error: (and this is using the gpuAssert/cudaGetErrorString in the aforementioned MaxFlops implementation)After which I couldn’t run any CUDA workloads in the VM’s. Upon restarting the VM’s, the “CUDA-capable device(s) is/are busy or unavailable” error persevered, and I was still unable to run any CUDA workloads. Reinstalling the guest drivers and rebooting one more time solved the issue.Has this behavior been observed before, or is my system just wonky?Thanks.Powered by Discourse, best viewed with JavaScript enabled"
171,tesla-p40,"Hello, I have an Xserver running on a P40 and it’s working fine except when I run glxgears the fps go up to 9 or 10 thousand and and the whole desktop becomes unusable. I’v been trying everything I can think of to the the fps to be 60 but nothing seems to work. An ideas how to get the fps down to 60? Thank You.Powered by Discourse, best viewed with JavaScript enabled"
172,passthrough-vs-vgpu-licensing,"Hello all,i know thats a repeating topic, but i didnt find a satisfactory answer to this.We want to use two RTX8000 in Passthrough mode with VMware ESXi.
For passthrough i need only vSphere Standard and no additional licenses from nVidia? I have to use “non-grid” drivers?For a later POC we will use these cards for vGPU (perhaps). So i will need vSphere Enterprise Plus und nVidia vGPU license? vPC or vWS dependent from use case. And we will have to use grid drivers, which are different from those mentioned above?thank you for your answers
regardsCorrect!Powered by Discourse, best viewed with JavaScript enabled"
173,can-you-please-fizx-the-licensing-server-mess,"Hi, new vgpu user here.
so I both installed the legacy and the “contemporary” licensing server.
Both are an insult to the end user admin who has to deal with this SH$$. they are cumbersome in a way that is unacceptable.
Please invest a few $ in a summer intern to fix the mess.thank you
ChrisPowered by Discourse, best viewed with JavaScript enabled"
174,qemu-5-0-unsupport-vgpu-migration-after-applying-add-migration-support-for-vfio-devices-patch,"From the patch of “Add-migration-support-for-VFIO-devices.patch”, It seems that it may have possible to support nvidia vgpu migration in qemu-5.0. But after I apply this patch, the qemu monitor still show me “Error: VFIO device doesn’t support migration”.
This problem is caused by the migration blocker, which is set due to vfio_get_dev_region_info return non-zero. So, I wonder if I or the patch have missed something.
Thanks.Hi, which distri are you using? Migration is supported for example for KVM from Nutanix (AHV). I really doubt that this feature was added in 2018 as referenced in your link above.The linux kernel distro is 4.18.0-167.el8.x86_64.
Qemu version is 5.0.Right now there is no support for migration for RedHat or Ubuntu KVM. Only specific KVM reference partners are already providing migration support as mentioned above (AHV as example).
Sorry that I cannot be of better help.regards
SimonThanks for your reply. If possible, I hope nvidia can support vgpu migration feature for CentOS8 with Qemu-KVM as soon as possible.Powered by Discourse, best viewed with JavaScript enabled"
175,add-nvidia-vgpu-to-master-mcs-image,"HelloI was wondering if there are any issues involved with leaving the NVidia VGPU still attached to my master image for XenDesktop using MCS ?  Using the profile M10-1B.  In some of the old citrix documentation it says to remove the VGPU from the image before using it as a template.  And new instructions do not mention removing the VGPU.  If we are creating several hundred VDIs I would seem a pain to add the VGPU after they are created.Below is some info on what we are usingDual NVidia Grid M10
VSphere 6.7
Citrix 7.15 LTSR CU4HiPersonally, I’ve never removed the vGPU from the image before using MCS in any of my deployments.If all of your VMs will be the same (which is one of the points of MCS / PVS) then there’s no reason in doing it.Just build the VM, install VMTools, install the vGPU driver, install your Apps and Windows Updates, clean up and optimise the image, shut the VM down, take a snapshot as it is and let MCS do what it does best.You are fine to proceed as you are :-)RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
176,nvfbchwencode-exe-cannot-find-hid-device,"I try run NvFBCHWEncode.exe. Its not working. Windows 10Powered by Discourse, best viewed with JavaScript enabled"
177,nvidia-a40-paththrough-opengl-is-stuck-at-1-1,"Hello Everyone.It has been a week I am struggling with making the 4x A40s that I have to work on ESXi 7. based on VMWare, the model of the server and board that I have supports ESXi7 and 6.7U3. yet, even when installed ESXi7 and windows server 2019 is prepared, it shows supported OpenGL1.1 .
Summary:
ESXi 8 was installed and it was showing OpenGL3.1
Installed other ESXi versions, all of them were showing OpenGL1.1  when checking with GPU-Z.
PathThrough is enabled for PCIE devices.
Boot option: efi
pciPassthru.64bitMMIOSizeGB=128
pciPassthru.use64bitMMIO=TRUE
hypervisor.cpuid.v0=FALSE
The VM boots normally, and the GPU driver is installed.
Has anyone experienced this issue?…all of them were showing OpenGL1.1 when checking with GPU-ZCheck device manager for code 43 or similar.Hello I have a similar problem. I’m working with an HPE server that has an Nvidia Quadro A4 GPU that runs under windows server 2022. I connect to the server trough RemoteDesktopProtocol of microsoft.
When I try to run programs that requiere OpenGL I have this same error. I have the impression that the OS doesn’t recognize the OpenGL of the graphic card. Please could you give us some insight on how to solve this issue?
Thank you.
This is a screenshot of Blender:

This is the detailed description of the setup:
Nvidia a40 setup.txt (1.7 KB)Powered by Discourse, best viewed with JavaScript enabled"
178,esxi-6-7-vgpu-vm-cannot-start-if-large-memory-vm-with-vgpu-already-started,"I have an ESXi 6.7 host with 2 x V100 GPUs. There is 384 GB RAM on the host. I have two VMs with vGPU profiles: grid_v100d-8c. Machine A has 16 GB RAM allocated and machine B has 256 GB RAM.If A is running, B can be started and both operate fine. However if B is running first, A cannot start and will give the error:The amount of graphics resource available in the parent resource pool is insufficient for the operation.It does not make sense as there is plenty of graphics resource available and adequate RAM.While this might not seem like a problem as both machines can be made to boot, I cannot then add any further machines without stopping the larger one. So am only able to use 16/64GB of GPU memory.We’re currently running 460.73.02. Any advice would be greatly appreciated.Hi Ben,Please see this article - vGPU VMs might fail to boot on ESXi 6.5 and 6.7 with multiple GPUs even if the graphics type is Shared Direct (nvidia.com).  Please upgrade to ESXi 6.7 Update 3 to resolve the issue.If this doesn’t resolve your problem - let me know.
DHi Doug,Many thanks for your response. We are running ESXi 6.7 P05 (so more recent than U3). I have checked the article but the memory is being reported correctly on our system:
image1199×175 8.07 KB
Hi Ben,Can you open a support ticket and our customer support team will be able to assist you further.thanks
DPowered by Discourse, best viewed with JavaScript enabled"
179,nvidia-opengl-driver-issue-error-code-3-nvidia-grid-k2,"Hello,we are experiencing the following issue when having opened a cad application (e.g. SolidWorks or Catia) and then producing cpu load by unpacking a large Zip file or even copying a large Zip file
and simultaneously rotating a model in the opened cad application.
The rotation is very sticky and after few seconds the screen is freezing and the following error appears.NVIDIA OpenGL Driver
Unable to recover from a kernel exception. The application must close
Error code: 3 (subcode 2)The issue is reproducable and started with upgrade from XenDesktop to version 7.15 CU1 and Nvidia Grid K2 driver to version 367.124/370.21 in February 2018.
But as the issue was happening not frequently (perhaps one time a month) it has not been tracked further. This changed in April 2020. After upgrading to XenDesktop to version 7.15 CU5 and Nvidia Grid K2 driver to 367.134/370.41 the issue got even worse. From since we have experiencing the issue several times a day.XenDesktop Configuiration:
Windows 7 x64
4 vCPU
40 GB RAM
VDA 7.15 CU5 (formerly 7.15 CU1)
Nvidia driver 370.41 (formerly 370.21)XenServer Configuration
XenServer 7.1 CU2 (formerly 7.1)
Nvidia Grid Profile K260Q (issue happening with all profiles)
Nvidia driver 367.134 (formerly 367.124)The Citrix support has investigated the issue by case number 79895362 and came to conclusion that this is a Nvidia issue. Please see the following section from Citrix log files, provided by Citrix Support:281739,0,2020/07/31 14:43:21:40207,8656,1792,1,Hd3dProvidersApollo,MontereyD3D9Capture.cpp,47,CMontereyD3D9Capture::CaptureFrame,14,EntryExit,""CMontereyD3D9Capture::CaptureFrame: Entry"",""""
281740,0,2020/07/31 14:43:21:40208,8656,1792,1,Hd3dProvidersApollo,MontereyD3D9Capture.cpp,52,CMontereyD3D9Capture::CaptureFrame,9,Information,""CMontereyD3D9Capture::CaptureFrame: Time Spent in Monterey (D3D9) API Capture = 4.66685863197776E+18"",""""
281741,0,2020/07/31 14:43:21:40211,8656,1792,1,Hd3dProvidersApollo,Hd3dProvidersApollo.cpp,102,ReportMessageHandlerCdf,9,Error,""CMontereyD3D9Capture::CaptureFrame :: MONTEREY # monitor = 1 # NvFBC NvFBCToDx9VidGrabFrame Failed. error: 0xffffffed"",""""
281742,0,2020/07/31 14:43:21:40211,8656,1792,1,Hd3dProvidersApollo,Hd3dProvidersApollo.cpp,102,ReportMessageHandlerCdf,9,Error,""CMontereyD3D9Capture::CaptureFrame :: MONTEREY # monitor = 1 # NvFBC Fall back to GDI."",""""
281743,0,2020/07/31 14:43:21:40212,8656,1792,1,Hd3dProvidersApollo,MontereyD3D9Capture.cpp,146,CMontereyD3D9Capture::CaptureFrame,14,EntryExit,""CMontereyD3D9Capture::CaptureFrame: Exit (bRetVal = 0)"",""""
281744,0,2020/07/31 14:43:21:40212,8656,1792,1,Hd3dProvidersApollo,ScraperThread.cpp,1925,ScraperThread::ThreadMain,9,Error,""ScraperThread::ThreadMain: NVIDIA NVFBC capture failed and fall back to GDIScraper."",""""Thanks for your help.Best Regards,
Frank WagnerHello Frank, I am currently getting the same error. Did you get a resolution?
MattPowered by Discourse, best viewed with JavaScript enabled"
180,how-much-video-memory,"Hello,how can i find out, how much video memory is the right for my applications?I created vms with the m60-1b profil. It has 1024 MB video memory.My users are working fine with this profile, but i took a look into the performance counters and see, that the available video memory is sometimes only 12 MB. But never lower.What happens, if the applications has not enough video memory? does it swap to VM RAM ? Or will the application crash?Today, 4GB of VRAM is more than enough for 1080p gaming. However, if you are planning on gaming in QHD and UHD resolutions any time soon, going with 8GB is the safer bet. VRAM, or video RAM, is one of the more standout specifications of a graphics card. For downloading movie use Tubemate download is an android application that gives you the ease of downloading online videos with fast speed and resume facilityI don’t want to play games. Our users are working with AutoCAD and inventor.So my question was, what happens if the framebuffer is not enough.Swap in Sysmem. 1B might not be enough for AutoCAD or Inventor, especially for multi monitor deployments. You can use GPUProfiler to check the FB load. 12MB already shows that there is a swap in sysmem happening as it starts with 95% saturation.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
181,headless-egl-contexts-dont-seem-to-work-with-capture-sdk,"Title, pretty much, says it all.Is there some reason that a headless EGL context on an Amazon G2 isn’t registering as current when the NvIFROGLCreateSession method is called ???Right now, I ALWAYS get a ""There is no OpenGL context current."" back from the NvIFROGLGetError call.If others are able to make this work, I will dig into the matter further…
but right now I’m a little puzzled as to why an EGL context is not as good as a GLX context ???Aren’t they all, essentially, supposed to be the same thing ???OK. The entire libnvidia-ifr shared object is completely dependent on GLX. Is there a reason GLX was the only context management api implemented for NVIFR ?Also, are there any plans to implement support for the EGL api ? Looking at what you did for the GLX api… it seems a not so difficult task, as EGL mirrors GLX in many respects.Hi Flavius,The SDK team have been made aware of this thread and are investigating/discussing.Best wishes,
RachelWow.
Had given up hope on you guys to even see that post. Let alone looking into the matter.
Thanks much Rachel.I came across this topic which exactly what I am currently looking. I’m wondering if there has been any further update to this?it’s deprecated now – here is a piece of fresh Nvidia Capture SDK README:Use of NvIFR is deprecated. The NvIFR header file and sample applications
are removed from the NVIDIA Capture SDK. Existing applications that use NvIFR
will continue to work on supported devices. Please refer to section 6 of
Release notes.NVIFR interface will not be supported on future GPU architectures.Applications using NvIFR ToHWEnc interface can instead use
Nvidia Video Codec SDK directly.Powered by Discourse, best viewed with JavaScript enabled"
182,dls-data-privacy,"Hi at all, we have a customer where asks about what kind of data will be send between Nivida Cloud  and onPremise DLS Instance? In Documantion i can see a communcation flow with some notice about offline reporting but what does this mean?Powered by Discourse, best viewed with JavaScript enabled"
183,issues-installing-virtualbox-vmware-player-on-vdi-with-vgpu-profile,"I’m trying to install a type 2 hypervisor within our VDI environment. I’ve gone ahead and enabled nested virtualization in the CPU settings of the VM, but upon startup i’m prompted with the a failed error message that states ""PCI passthrough devices cannot be added when Nested Hardware-Assisted Virtualization is enabled"" We’re currently using NVIDIA vGPUs in our VDI environment. Do you guys know of any workarounds to get virtualbox or vmware player installed on the VDI’s that use vGPU shared graphics?We’re using Horizon 7.7, vCenter 6.7u3, and ESXI 6.7 by the way. Graphics cards are Nvidia T4s and we’re using GRID drivers version 10.Powered by Discourse, best viewed with JavaScript enabled"
184,nvidia-dls-monitoring,"Hi all,
I installed on the last days the new Nvidia License Server Appliance 2.1.0 as VM.
I want to also install our CheckMK monitoring agent to get more infos when something is wrong with this machine but I couldn’t find a user which have enough permissions to install the DEB package.
I also could’t find any SNMP information?Thanks in advance,
VM_MasterPlease use our Enterprise Support. They might be of help. Not sure if the DLS appliance is intended to install additional software packages.Best regards
SimonThink you need to create a sudo user to be able to do that, see release notes https://docs.nvidia.com/license-system/latest/nvidia-license-system-release-notes/index.html#creating-dls-sudo-userPowered by Discourse, best viewed with JavaScript enabled"
185,jetson-nano-module-with-lora-4g-embeded,"hi
we are development  .and
we  need  ,   JETSON NANO  / XAVIER , with 4G  + , LORA gateway embeded.just one board.pls  advise , any informations .  about this  board .when sale ?
where can i find .tks a lotPowered by Discourse, best viewed with JavaScript enabled"
186,how-to-set-vertical-resolution,"Hi,I’m running a Windows 10 ent 1909 VM on a ESX 6.7 host. The Host has a TESLA T4 board with the latest drivers installed on host and VM (11.1). The Grid_t4-2b profile is attached to the VM.I have 2 types of VM’s and both are used with a VNC session.Type 1 = VM with 2 displays / both landscape mode
Type 2 = VM with 1 display but Portrait modeType 1 is working fine. I attached the second display with the fakeEDID powershell script via nvwmi. The script creates all the time 4 displays, but I then disable the 2 displays via nvidia control panel.My problem is the type 2 VM. I tried like everything in my opinion but no Portrait mode resolutions. Is there a way to fix this? I know this can be done with RDP, Horizon etc. But VNC for this type of VMs is the only option because of screen sharing.Please Help!Powered by Discourse, best viewed with JavaScript enabled"
187,how-to-install-drivers-on-rtx-virtual-workstation-azure-w-ubuntu,"I tried listing the devices with lscpi but the graphics card does not show up. NVIDIA-SMI is preinstalled but cannot communicate with the driver.Powered by Discourse, best viewed with JavaScript enabled"
188,false-positive-license-error-after-upgrading-to-nvidia-grid-driver-451-48,"After upgrading my golden image to Nvidia grid driver 451.48 I notice now that every user receives a balloon pop-up stating ""NVIDIA license not present. However, this message is false since when you click the balloon and look at the license manager you see that the license server is present and valid.https://imgur.com/a/4jlGyzvaddendum: this happens when the user logs in and the system tray icons are loading. Perhaps this could be some sort of timing issue where the balloon checks too fast.Is there any way I could maybe remove the system tray icon completely as a workaround ?Hi ProfundidoIf you’re sure it’s getting a license, then you can create and set the following Registry Key to disable the Pop-up:HKEY_LOCAL_MACHINE\SOFTWARE\NVIDIA Corporation\Global\GridLicensingType = REG_DWORD
Key = DisableSpecificPopups
Value = 1Use a GPO to set the Key so it’s easy to track and revoke if needed.RegardsMGKnown issue. Will be fixed in the next release. Be aware that this is only a ""cosmetic"" issue as the VM is properly licensed. As workaround you can use the Regkey mention by MrGRIDregards
SimonThx guys. I will try the workaround. I noticed indeed that functionality wise there are no problems but I cannot release a build update in which this balloon message happens since it will rain tickets with end user questions about it the next day.By the way, I had been wanting to disable the Nvidia system tray icon all together already before this license error because:The license management console seems not to be multi-user aware. If I click it -even as admin- another end user on the same Citrix server will typically get the actual management console to pop up in their Citrix Xenapp session where I won’t get to see it (unless I’m the only user on that server)End users are typically curious and tend to click this system tray icon in their Citrix Xenapp session, causing popup’s for someone else on the server to happen.Update: I set the reg key manually in the build (since it’s Hkey local) rather than through GPO and rebooted the machine but upon next login I saw the error again. This doesn’t seem to work. I rebooted the server twice to make sure my test was valid and doublechecked the key:https://imgur.com/a/08BLde0Hi ProfundidoI’m using the setting I listed in some of my deployments with vGPU 11 and it does work. Not sure why it’s not working for you though. Looks like you have it configured as required.Just for reference, there’s a list of useful vGPU registry settings available from here, including the removal of the license component from the Control Panel:https://docs.nvidia.com/grid/11.0/grid-licensing-user-guide/index.html#windows-registry-grid-license-settings__windows-registry-grid-license-settings-summaryRegardsMGThanks. That’s a useful overview of available switches.I had already tested using the fix from the other 2year old thread where we remove the icon completely and after testing that part seems to work. First login after rebooting I still saw a short flash after which the icon dissappeared but subsequent logins don’t see anything at all.I think I’ll use that for now as full workaround so I can release this build and experiment with other switches later.We are seeing the same issue as well and reg key to hide notifications does not work. NVIDIA, can you guys release some sort of intermediate client patch or workaround as its generating support calls?We are seeing the same issue as well and reg key to hide notifications does not work. NVIDIA, can you guys release some sort of intermediate client patch or workaround as its generating support calls?This exact value below in a build update of your golden image (or deploy through gpo) did the trick for me:[HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\nvlddmkm\NvTray]
""StartOnLogin""=dword:00000000Reboot after implementing or make your build go live and then test with multiple logins from different usersI have this set under current user SOFTWARE\NVIDIA Corporation\NvTray StartOnLoginThis seems to shorten duration of the message. It is still there, however, for the first user to logon to the machine.Havent tried disabling tray for the entire machine yet.Update: After I put my build in production today I too noticed that the error message still appears very briefly for the first person that logs in to that server (not for subsequent user logons) but since the icon is immediately removed it’s harmless now. People don’t have the time to even try clicking on it.For me personally that’s sufficient as a workaround. Note though that this is still using the workaround of completely removing the system tray icon for everyone. The original reg value that is supposed to only prevent the balloon popup message (without removing the system tray icon completely) doesn’t work for me either.Hi,we have the same error in our environment. Please get the fixed version released quickly.
I opened a support case about this and nobody told me that this is a known issue.Thanksfor anyone that follows this: I can confirm that since the latest drivers (452) that I just installed solved the problem for me. There no more license error popups during first logon on a server.Powered by Discourse, best viewed with JavaScript enabled"
189,how-i-try-nvidia-vgpu-on-desktop-pc,"Hello guys,I need to do research about virtual GPUs and I need to run it on my PC so I can test and get screenshots to experiment and get results.So I got a free 90-day license from NVIDIA vGPU to do this, but as I read, I found it maybe needs to servers and the like. I’m weak in this area. I’ve already installed VMware Workstation and VirtualBox before on my PC, but not servers and so on.So I’m almost confused.I’m still a beginner to know servers, including virtualization, and I need to use the NVIDIA Virtual GPU license on my desktop (Windows 10), which in turn needs VMware, but I do not know how to set it on my device.Please Help. Thank you in advance,Tamer,HiTalk about running before you can walk … :-)This URL will get you started: NVIDIA & VMware Free Test Drive | NVIDIAClick on the ""Get Started"" tab and complete the required details. You’ll then receive an email and will be able to access a GPU accelerated VM that’s cloud hosted.For the evaluation, you don’t need any licenses or VMWorkstation. Simply follow the instructions once you’ve completed the ""Get Started"" form.Benfor FREE TEST DRIVE, you don’t need to download anything.
you will be provided access to a virtual machine(server/a computer running somewhere else and you can connect to that system with your pc) which will have GPU.goto the Nvidia’s free trial page and get started. You will understand everything.So we have a ~200 user office which operates on Microsoft VDI (virtual desktop infrastructure) using HyperV and Remote Desktop brokering and virtualization hosts.Relevant to this query, we have 3x Virtualization hosts supporting the ~200 VM’s for VDI use. They do NOT have a GPU in them. VidMate Teatv ShareitIncreasingly, users are running more and more applications (and even browsers with videos/interactive content) that is lagging due to the alk of GPU acceleration. This is offloaded to the CPU’s, which is causing an increasing trend in CPU usage and more and more spikes that affect the whole userbase.I’ve been tasked with looking at GPU acceleration for the VDI environment. Which is fine, there is quite the range of Tesla GPU’s that I can use in my env with carying specs etc.However… Management are insisting that the cost of the Tesla GPU’s is too high, and its not feasible to offload that cost increase onto the client. I argue that that’s not really my problem, lol. But management insist that it MUST be possible to sue consumer grade GPU’s in the servers to provide acceleration.I told them this is not possible and to use nvidia vgpu management software, you need to have a tesla core’d GPU.We are at an impasse, and I’m stuck scratching my head, becuase they still believe we can use consumer cards.So, please clarify for me, can you, or can you not, use consumer grade GPU’s (read as RTX2080’s, RTX2070’s etc) in a server and then have nvidia vgpu manager successfully segment those GPU’s into devices mapped to VDI VM’s.Thanks.HiThe quick answer for your management team is no, it’s not possible to use GeForce GPUs with vGPU. They are not designed to work together or supported to do so.Certain Quadro and Tesla GPUs are designed for Professional and Enterprise use with vGPU. However, as you are using Hyper-V, unfortunately you can’t use vGPU at all (Hyper-V doesn’t support it), so you would have to use DDA (Passthrough) with the GPUs instead. This is ok for RDSH deployments, but for VDI, a different combination of technologies would be required.RegardsMGhi
in my opinion it’s not possible to use GeForce GPUs with vGPUSo we have a ~200 user office which operates on Microsoft VDI (virtual desktop infrastructure) using HyperV and Remote Desktop brokering and virtualization hosts.Relevant to this query, we have 3x Virtualization hosts supporting the ~200 VM’s for VDI use. They do NOT have a GPU in them. VidMate Momix VidMate App Increasingly, users are running more and more applications (and even browsers with videos/interactive content) that is lagging due to the alk of GPU acceleration. This is offloaded to the CPU’s, which is causing an increasing trend in CPU usage and more and more spikes that affect the whole userbase.I’ve been tasked with looking at GPU acceleration for the VDI environment. Which is fine, there is quite the range of Tesla GPU’s that I can use in my env with carying specs etc.However… Management are insisting that the cost of the Tesla GPU’s is too high, and its not feasible to offload that cost increase onto the client. I argue that that’s not really my problem, lol. But management insist that it MUST be possible to sue consumer grade GPU’s in the servers to provide acceleration.I told them this is not possible and to use nvidia vgpu management software, you need to have a tesla core’d GPU.We are at an impasse, and I’m stuck scratching my head, becuase they still believe we can use consumer cards.So, please clarify for me, can you, or can you not, use consumer grade GPU’s (read as RTX2080’s, RTX2070’s etc) in a server and then have nvidia vgpu manager successfully segment those GPU’s into devices mapped to VDI VM’s.Thanks.no reply?Geforce GPUs don’t support vGPU. But datacenter GPUs won’t support it either with Hyper-V. You would need to run ESX, Nutanix or KVM or use Azure Stack HCI which is currently the only “on prem” option from MSFT to support  GPU-P which is the MSFT implementation to slice GPUsPowered by Discourse, best viewed with JavaScript enabled"
190,nvidia-smi-shows-err-on-both-fan-and-power-usage,"Hi, I am using the Gforce GTX and have run several DL jobs on it. Suddenly it is showing an error on the nvidia-smi, “ERR!” shown in both the fan and powerusage from the nvidia-smi. I have driver version 515.65 and running on CUDA 11.7. Any idea what’s going on?Below is the output of nvidia-smi:±----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA TITAN X …  On   | 00000000:03:00.0 Off |                  N/A |
|ERR!   87C    P0   ERR! / 250W |      8MiB / 12288MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
±----------------------------------------------------------------------------+nvidia-bug-report.sh command output:
nvidia-bug-report.log.gz (379.5 KB)Powered by Discourse, best viewed with JavaScript enabled"
191,aws-gpu-with-a-centos-7-ami,"Tried to install latest driver using Ansible Role nvidia.nvidia_driver . Failed to install the driver although no error during installation. Attaching the debug output.nvidia-bug-report.log.gz (31.0 KB)Powered by Discourse, best viewed with JavaScript enabled"
192,cloud-rendering-with-aws-nvidia-for-octane-2021,"Hi,In my current job, I work in a studio that specializes in 3D and VFX.
Our goal is to render scenes from our pipeline on an AWS virtual machine with the best GPU configuration.
We use the following software in our pipeline:
Maya Autodesk 2021 (using Octane 2021) , After Effects 2020.Thank you,
MesThank you,You may try 100k Cuda core in single Cloud Render FarmPowered by Discourse, best viewed with JavaScript enabled"
193,nvidia-smi-has-failed-because-it-couldnt-communicate-with-the-nvidia-driver-rhel-8-4,"I’m trying set up a VMware virtual environment for my developers to work in. I have ten ESXi hosts clustered together with A10 graphics cards. I’ve been following the steps in Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software Documentation and am currently on part 4.2.After I install the NVIDIA graphics driver on Linux and try to run the nvidia-smi command to confirm it’s working I get the following message: NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.When I check the status of the nvidia-grid service I get this:
nvidia-gridd.service - NVIDIA Grid Daemon
Loaded: loaded (/usr/lib/systemd/syste/nvidia-gridd.service; enabled; vendor present: disabled)
Active: failed (Result: exit-code) since Mon 2021-11-29 08:08:46 EST; 28min ago
Process: 1342 ExecStopPost=/bin/rm -rf /var/run/nvidia-gridd (code=exited, status=0/SUCCESS)
Process: 1107 ExecStart=/usr/bin/nvidia-gridd (code=exited, status=0/SUCCESS)
Main PID: 1125 (code=exited, status=1/FAILURE)Nov 29 08:08:45 rhel8vdi systemd[1]: Starting NVIDIA Grid Daemon…
Nov 29 08:08:45 rhel8vdi nvidia-gridd[1125]: Started (1125)
Nov 29 08:08:45 rhel8vdi systemd[1]: Started NVIDIA Grid Daemon.
Nov 29 08:08:46 rhel8vdi nvidia-gridd[1125]: Failed to initialize RM client
Nov 29 08:08:46 rhel8vdi nvidia-gridd[1125]: Failed to initialize RM client
Nov 29 08:08:46 rhel8vdi nvidia-gridd[1125]: Failed to unlock PID file: Bad file descriptor
Nov 29 08:08:46 rhel8vdi nvidia-gridd[1125]: Failed to close PID file: Bad file descriptor
Nov 29 08:08:46 rhel8vdi nvidia-gridd[1125]: Shutdown (1125)
Nov 29 08:08:46 rhel8vdi systemd[1]: nvidia-gridd.service: Main process exited, code=exited, status=1/FAILURE
Nov 29 08:08:46 rhel8vdi systemd[1]: nvidia-gridd.service: Failed with result ‘exit-code’.I have tried uninstalling and reinstalling the driver, purging the install, installing an earlier version of the driver, using different VM PCI profiles, and installing on a clean install of RHEL 8. I know the VIB is installed correctly on the ESXi hosts because I’ve successfully created a Windows 10 Desktop Pool and Licensing Server with GRID vGPUs in the same environment.nvidia-bug-report.sh returns an empty file except for the opening statement, nvidia-settings returns ERROR: Unable to find display on any available system.I am using:
Hypervisor: VMware vSphere 7.0.2
OS: RedHat Enterprise Linux 8.4
Driver: NVIDIA-Linux-x86_64-470-82-01-grid.run
Graphics Card: A10 Tensor Core
GPU Profile: NVIDIA GRID vGPU nvidia_a10-24qTurning off Secure Boot in the VM Settings worked for me - had the same issue. I tried to install the certs with no luck.Powered by Discourse, best viewed with JavaScript enabled"
194,omniverse-audio2face-environment,"I installed it via NVIDIA Omniverse Launcher to run Omniverse Audio2Face.
However, the GPU specification says it is possible in RTX, so when you run it, an error appears in the console window.
It doesn’t seem to be working properly. So should I buy an RTX GPU and use it as a StandAlone?
I wonder if it is possible to use a server with RTX GPU as a network.
I have a server with Titan RTX installed and I was wondering if there is a way I can use it.
I found RTX Virtual Workstation (vWS), and I was wondering if it would be possible to use it.
I also know it costs money, but I’m curious what it’s going to cost. You can also point us to a site where you can find information about costs.
Finally, I wonder if there is a way to use NVIDIA-managed cloud servers instead of the servers we have.
If so, I would also like to know about the cost.Powered by Discourse, best viewed with JavaScript enabled"
195,quadro-rtx-5000-and-vgpu-help,"Hi,
There is a new Quadro RTX 5000 installed in a DELL R730 server with two processors and 256GB memory. Installed Windows Server 2022
It is necessary to provide remote access for three engineers who will work in a professional program for calculating acoustic reverberations (the program needs OpenGL).
Can you tell me how you can configure so that they can simultaneously run and use the Quadro RTX 5000? I did not see this model in the documentation for using vGPU.What you are trying to do is not a vGPU use case. You simply need to enable the default GPU fof RDP (local policy) in Windows Server OS. For better remoting Performance I would also recommend to enable the H264 policies.Regards SimonHi Sschaber,Thanks for the quick response!Microsoft has removed the RemoteFX feature from all versions due to security issues - Deploy graphics devices using RemoteFX vGPU | Microsoft Docs.""Because of security concerns, RemoteFX vGPU is disabled by default on all versions of Windows starting with the July 14, 2020 Security Update and removed starting with the April 13, 2021 Security Update. To learn more, see [KB 4570006] KB4570006: Update to disable and remove the RemoteFX vGPU component in Windows ""They want to make a new GPU-P technology, but this is not yet known.What other options are there? I hate to believe that buying a GPU for $ 2800 can’t make it work for three people.Ok, so I assume that you want to virtualize with Server 2022 and have 3 Win10 VMs as guest OS. Wasn’ t clear from your current description. Unfortunately there is no other option if you want to virtualize. So why not using Server 2022 without virtualization? The problem is not the RTX5000 but the OS. If you want to use vGPU you need to use a working hypervisor like ESX or XenServer. MSFT may support GPU-P for Server 2022 in a future release but currently there is no option…hi,I am not suggesting anything. I asked how to be in such a situation and what I need to buy to make it work.It just doesn’t work via RDP - a black screen on the remote desktop if you enable RemoteFX via RDP.I’m guessing because Microsoft RemoteFX is no longer supported in any way at all.ESX or XenServer - what should be installed, what drivers, etc., to make it work in the described scheme? If possible in more detail, since I first encountered such a task.Hi,
I still don’t know yet what you are trying to achieve. Please describe first the intended use case. RDSH or Win10 VDI. Without more details there is no way to give you proper advise.
If you are OK with Server 2022 and baremetal then it should work already with just installing the Nvidia Quadro driver. Forget the RemoteFX approach as this won’t work…Have a DELL R730 + GPU Quadro RTX 5000 + Windows Server 2022
I need office workers (2-3 people) to log into Windows Server via RDP at the same time for simple office tasks. And at the same time, three engineers could work remotely while using of the RTX 5000 resources while working in a professional acoustic modeling program. I need the simplest, most convenient and 100% working solution without a headache. As you advise, we will do it. Thank you in advance for responding quickly!Ok, thanks for clarification. So I would just enable RHSH role on Server 2022, install NV driver, set local policy to use GPU for RDP sessions and that’s it. The 3 users will share the GPU resources but that should be fine.Thank you!Powered by Discourse, best viewed with JavaScript enabled"
196,unable-to-use-single-32gb-profile-on-v100s,"Hello there,We have some v100s for compute and have an issue whereby we can use all profiles except 32gb profiles. When we try use a 32gb profile we cant install the drivers in Ubuntu and in Windows nvidia-smi doesnt detect the card.But this works fine on smaller profiles…dTo use NVIDIA vGPU software drivers for a bare-metal deployment, complete these tasks:Install the driver on the physical host.For instructions, see Installing the NVIDIA vGPU Software Graphics Driver.License any NVIDIA vGPU software that you are using.For instructions, see Virtual GPU Client Licensing User Guide.Configure the platform for remote access.To use graphics features with Tesla GPUs, you must use a supported remoting solution, for example, RemoteFX, Citrix Virtual Apps and Desktops, VNC, or similar technology.Use the display settings feature of the host OS to configure the Tesla GPU as the primary display.NVIDIA Tesla generally operates as a secondary device on bare-metal platforms.If the system has multiple display adapters, disable display devices connected through adapters that are not from NVIDIA.You can use the display settings feature of the host OS or the remoting solution for this purpose. On NVIDIA GPUs, including Tesla GPUs, a default display device is enabled.Users can launch applications that require NVIDIA GPU technology for enhanced user experience only after displays that are driven by NVIDIA adapters are enabled.Powered by Discourse, best viewed with JavaScript enabled"
197,tesla-t4-on-hpe-gen-10-and-windows-server-2019-gpu-doesn-t-appear-in-task-manager,"Hello, We have a ProLiant DL380 Gen10 Plus with a NVIDIA Tesla T4.
In the iLO, Nvidia is displaying in green with status “Enabled” and in Windows in the  Device Manager Control Panel is listed and well installed, but I can´t see the GPU in the Task Manager.
I don´t be sure if the GPU is working or not.
Why doesn´t appear GPU in the task manager? How can i know if GPU is working?
ThanksPowered by Discourse, best viewed with JavaScript enabled"
198,tesla-t4-on-hpe-gen-10-not-active,"hello everyone, I have installed in a remote Data center an HPE ProLiant DL380 Gen10 with Windows Server 2016 64 Bit, to that we have inserted an Tesla T4. the problem is that when i connect remotely i dont see the GPU working. More precisely the GPU shows in device manager but when i run the 3d modeling tool the GPU appears as “Inactive”, also the GPU does not appear to run the task manager. I tried to select the Tesla GPU as preferred one from the NVidia Control Panel setting but i dont have the 3d setting options. can someone help to solve this as the whole purpose on the server was to use the GPU and we can’t use that. thank you
image979×843 138 KB
Hi,did you check the following:
Steps are as below:BTW: You won’t see the GPU in task manager with WinServer2016. Just not implemented. Works starting with 2019regards
Simonthank you, i tried the suggested steps and still not working, i tried again to select it as the prefered  one but when opening the nvidia control panel i have the following message even if i can see the gpu in device manager
image1177×398 189 KB
Which Nvidia (vGPU driver) do you use?
Please stay or use the vGPU 13.x path. NVIDIA Virtual GPU (vGPU) Software DocumentatioPlease check the device manager first. Looks like there is no GPU detected at all in your setup.regards
SimonHello again,Let me explain the whole context.
we have installed in a DC an HPE ProLiant DL380 Gen10 with Windows Server 2016 64 Bit, to that we added NVIDIA T4 16GB GPU. We use the servers remotely, so we log in from different location and when we run our 3d tool the server is working only on the integrated GPU, not the NVIDIA and this make the whole process verry slow. On the other hand, we can see the NVIDIA GPU in Device Manager, that means is properly installed (see screen)

Image 1495×596 170 KB
I have tried to set the NVIDIA GPU to be the preferred one, both from Bios ( i can’t find the VIDEO Option as in the image), for some reason it is missing)

image 2879×345 132 KB
also, i could not find the 3d setting when right click on NVIDIA Control Pannel.
i have no idea what might be the problem.Sorry for the late reply.
You need to set the right Windows local policy to use the GPU for RDS sessions:
snip
On Windows Server 20xx, Remote Desktop Services (RDS) sessions on the RD Session Host server use the Microsoft Basic Render Driver as the default adapter. To use the GPU in RDS sessions on Windows Server 20xx, enable the Use the hardware default graphics adapter for all Remote Desktop Services sessions setting in the group policy Local Computer Policy > Computer Configuration > Administrative Templates > Windows Components > Remote Desktop Services > Remote Desktop Session Host > Remote Session Environment
snipWas a solution ever found for this?
I have an Azure VM with a Tesla T4 but no matter what I do, I cant get applications to use it.
Ive made my changes to group policy. Ive tried manually installing the drivers and using the nvidia extensions in Azure.
The status in Nvidia control panel is perpetually as shown below:
(There are no applications running on this GPU.)In my case, Ive tried a number of OS. Not sure how to use this T4.Powered by Discourse, best viewed with JavaScript enabled"
199,gpu-passthrough,"This is a Feature request. i tried to get GPU partitioning on my HP Gaming laptop with Hyper-V And when i installed the driver it gave me a driver install error:NVIDIA Installer cannot continue the graphics driver could not find compatible graphics hardware.We Need GPU Passthrough NVIDIA Made it compatible with QEMU KVM on Laptops but not Hyper-V??? It Works fine with QEMU KVM but not Hyper-V.NVIDIA. Please Fix This.Powered by Discourse, best viewed with JavaScript enabled"
200,unable-to-install-grid-driver,"Hello,I have a Windows 10 21H2 with a vGPU A4000-2b. I’m trying to install the nvidia grid driver 472.98 that I installed on another vm 3 months ago and now, it’s failing at the driver installation with error 0xe0e00059.I tried googling but I can’t find what’s going one.On VMware ESXi 7.0 U2.Thank you!Powered by Discourse, best viewed with JavaScript enabled"
201,esri-arcgis-pro,"How do I use the app mentioned in the heading of the topic if I am using Quadro vWS on Google Cloud Platform.? I was not able to locate how to fire up the app.
Reference: Quick Start Guide :: NVIDIA Quadro Virtual Workstation DocumentationHiThe App is not included with the VM. You need to register for an evaluation with ESRI, then if approved download the App and install it. You register for the evaluation from here:Try ArcGIS Pro free for 21 days. Get access to ArcGIS Pro desktop software; ArcGIS Online; a suite of apps for the office, field & community; and more with this free trial.The GCP trial is generic, it would be exactly the same for any Autodesk products you wanted to try. ESRI and Adobe are just random examples of applications you can use with a GPU.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
202,increase-performance-of-rdsh,"Hi all!How could to increase performance graphics of RDSH Desktop Sessions?I have a server with VMware ESXi 6.7 and many VMs of Windows Server 2019.
One of this I have enable RDSH services for connect 10/15 concurrent users (not VDI, simple RDP session).How is the best solution of buy?Example:Your help is very much appreciated
Have a nice day.HiYes, use the T4 with vApps licenses. You can either run 1x RDSH VM with the full 16A vGPU Profile, or you could run 2x RDSH VMs each with an 8A vGPU Profile depending on your requirements.vApps licenses are Per CCU, so you’ll need 10-15 vApps licenses (whichever is the total CCU you end up with).RegardsMGHi MrGRID, thank you for the answer !
It’s all clear… I have another question:ThankHiSorry, I’m not sure I understand your question? Could you write it in a different way please?RegardsMGI bougth an Tesla T4 and I installed in a Supermicro server with ESXi 6.7.Configuring in passthrough:

Cattura1853×160 16.7 KB
And assign to a virtual Windows Server 2016 with RDSH services:

Cattura2780×265 14.3 KB
In the server I installed only “452.39_grid_win10_server2016_server2019_64bit_international.exe”.
I would to continue with installation of the license server but I have a problem with nvidia control panel, it’s impossibile to assign an ip of license server for vApp:
Where am I doing wrong ?Powered by Discourse, best viewed with JavaScript enabled"
203,cc-vms-licensing-terminology,"Hi,I’ve received separate quotes for NVIDIA Virtual Compute Server Subscriptions that have the following:In the Virtual-GPU-Packaging-and-Licensing-Guide.pdf document, I don’t see CC VMs mentioned anywhere.Can someone confirm what “CC VMs” mean? I’m guessing “CC” is short for “concurrent” and not related to CCU (i.e. Concurrent User Licensing).Correct. vCS is licensed per GPU and you can run 8 or 10 concurrent VMs per GPU.Powered by Discourse, best viewed with JavaScript enabled"
204,a100-support-on-vsphere-6-7-or-7,"Hi to all,
I’ve got a configuration problem in our laboratory that involves the NVIDIA A100 with ESXI 7u1.
I’ve followed vmware blog(https://blogs.vmware.com/apps/2020/09/vsphere-7-0-u1-with-multi-instance-gpus-mig-on-the-nvidia-a100-for-machine-learning-applications-part-1-introduction.html) and also the NVIDIA MIG deployment guideon the vSphere 7.0 U1 host I’ve tried MIG-backed and time-sliced vGPU profiles. Neither of the two seems to work correctly.
After enabling MIG Feature on the GPU, creating a GPU Instance, a Compute Instance and applying the vGPU profile to a virtual machine, during the power on procedure VMware reports that error:
could not initialize plugin /usr/lib64/vmware/plugin/libnvidia-vgx.so for vGPU grid_a100-10cRunning nvidia-smi on the VMware host after the error shows the following message:unable to determine the device handel for gpu 0000:3b:00:0 gpu is lost. reboot the system to recover this gpuWe must reboot the host to make the GPU “operational” again.I’ve also done same test creating only the GPU Instance and not the Compute Instance.
The same applies to time sliced vGPU profiles (disabling MIG feature and using “normal” vGPU).I’ve used all the latest vGPU driver: 11.2 and 12.0, same result.
The VMware version is ESXi 7.0 U1 build 17325551.
the SRV-IO feature in the BIOS is enabled. Dell r740 host server is in use.
I’ve tried 2 different cards but the result is the same. Also tried the passtrought, but the card always go in unrecoverable state
Any one can help?Do you have adequate cooling for the GPU?A100 is simply not supported on vSphere 7 yet. Support should come with the next U2 release.Hi Adam,I am having the same issiu as you too, only with a HPE DL385 Gen10+.
I read the same post and ran into the same results using ESXi-7.0U1d-17551050.Currently only RHEL 8.2/8.3 support MIG and KVM for the A100.
Fun fact, it dosen’t! Even fresh out of the box RHEL with KVM will not start the “nvidia_vgpu_vfio“. The install of the driver works with no errors, but after a reboot with “lsmod | grep vfio” no  “nvidia_vgpu_vfio“ an no way to access “nvidia-smi”Maybe sschaber has an idea what to do with THEL or a info when vmware will release U2.I am not able to install the vgpu drivers on vSpeher 7.0 U2. Can somebody confirm me that A100 80 GB will work on vSpehere 7.0 U2?Powered by Discourse, best viewed with JavaScript enabled"
205,adding-gpu-to-existing-ucs-cluste,"Hi Everyone,We currently have a UCS cluster of 8 HX220 servers running VMware Vsphere with Citrix for our VDI. The servers are a couple years old and recently I asked Cisco for a design to expand the cluster so we can add M10 cards. Every design they’ve come back with is a ""new"" cluster. When I asked why can’t I just add the GPU capabilities to the existing I was told it won’t work. The last design we had was adding 10 nodes with 2 M10 cards in each, so I would have to have one cluster for non-gpu workloads and the other for GPU. I mentioned well I could reduce the number of M10’s needed and I’ll purchase T4 cards for the exiting servers even if they don’t scale as well at least I’d have some GPU for the existing desktops on the existing cluster.I was advised that the hypervisor that virtualized the desktop (not the server) is where there is a limitation. This doesn’t make sense to me, has anyone any similar experience in this with Cisco UCS servers?Thanks for any insight if anyone can help.HiIf you’re using the M4 architecture then you’re completely out of luck, as the HX220 doesn’t support any GPUs, you’d need to use HX240, but be hugely limited on GPU options. If you’re using the M5 architecture then the HX220 will support either 1 or 2 T4s, so you could run 4 GPU accelerated XenApp Servers (splitting the T4s in half) or up to 32 XenDesktop VMs (assuming 1GB is enough framebuffer).As a heads up, unless M10s are already deployed in an environment and you’re looking to add additional GPU capacity with the same architecture (regardless of the OEM Server), I would strongly advise you (and anyone else) avoid purchasing them for a production environment at this point of their lifecycle and look at current generation GPUs. The T4 will scale as well as the M10, it’s just that the T4 has half the amount of Framebuffer, so you need 2 of them to equal a single M10s.If you’re going to retro fit GPUs into a Server, unless you’ve previously accounted for this with the specification when purchasing (which I’m assuming wasn’t done, otherwise the HX240 would have been used), it’s best to start clean. Installing GPUs typically requires larger PSUs and GPU enablement Kits (low profile CPU heat-syncs and custom power cables (as (certainly with Cisco) the GPUs have to be Passively cooled)) and sometimes different PCIe Riser configurations. CPU and Memory configuration is also a huge consideration due to the way in which the GPU changes the way resources are allocated. Although it can obviously be done, retro fitting GPUs into Servers that weren’t originally spec’d to run them is something I always try and avoid, and I’ll never recommend it (unless as mentioned, the Server had been correctly spec’d to accommodate GPUs after purchasing).My advice, take this opportunity and create a new Cluster with Servers that were correctly spec’d to support GPUs from the outset. A HX240 M5 will support up to 6 T4s, 3 times the density of the HX220 M5. One reason that Cisco may have come back with a 10 Server design, is because their 2U Servers only support 2 double wide GPUs, where as other OEMs support at least 3, which can make a huge difference to user density, architecture, licensing and overall cost.""The Hypervisor that virtualised the desktop"" … So VMware then? I’m not sure which limitation they’re referring to, but ideally your Hosts in that type of Cluster should be the same GPU hardware. I’m assuming you’re using MCS / PVS?RegardsMGThank you very much for the detailed reply much appreciated. We are using the M5 architecture so our HX220’s can take 2 - T4’s each. We are going to try and run mostly hosted shared desktops off of Server 2016/2019 and only in use pooled desktops in use cases that absolutely need them.We use MCS, and Cisco’s designs are all M5 HX240 nodes for the ""new"" cluster and again I simply thought it would be a matter of adding the HX240’s into the existing cluster that would then allow us to provision GPU resources within. We thought even if our existing non-GPU ""task worker"" and moving some of those to the citrix cloud to free up CPU, RAM, and Storage if needed again just to add GPU. It is at this point that Cisco is saying there is a limitation of the desktop hypervisor, so they haven’t said it isn’t possible. I feel like I’m being oversold a bit, and although I understand a new cluster is a preferred design I’m trying to squeak as much ROI out the existing cluster thats all.We don’t know what size of frame buffer will work, we are post secondary institution so we are making assumptions based off of the physical spec’s of those programs that use software that requires GPU (AutoCad, Revit, ArcGIS). So we’re not entirely sure of the total amount of GPU horse power they’ll need for learning outcomes. We plan to start small and then scale if the user experience and performance demands it, but we need to start somewhere.So I didn’t want to retro-fit I completely ok with adding new nodes I just wanted to attach them to the existing cluster is all so to expand some GPU potentially those that already exist. Some of the existing use cases do have some small measure of application where GPU allocation may benefit their outcomes.Just for record the expansion we are planning going from starter assumptions is about 250 CCU that may end up with a 2GB FB and 200 CCU at 1GB. Because so many things are unknown of where this will need to scale that’s sort of our starting point in the expansion. Cisco has been very good and trying to respond based on requirements provided but I still feel I’m missing pieces to explain it to our management properly.One last thing, the M10’s are they due for a new generation or is the T4 that ? I understand the T4 2:1 ratio compared to M10’s I just thought it was more bang for the buck going with the M10 for density. However if they are going out soon then ya buying them now might make scaling in a year or 2 become tricky (new clusters again lol) if they are no longer available for sure.Again thank you for your reply it’s very helpful in helping me understand and additional comments are much welcomed.HiIs there an issue with creating a new Cluster? Apart from the requirement for a minimum amount of Hosts (I’m assuming you’re running Hyperflex) but you have that covered with Ciscos recommendation. The existing vCenter will run multiple Clusters so no complication there. Citrix will work across Clusters, just add the new location into Studio. I’m assuming you already have the correct vSphere licenses (Enterprise Plus) for your existing Cluster, but you’ll obviously need additional vSphere Enterprise Plus licenses for the new Cluster, unless you’re running (vSphere for Desktop). So I’m not initially sure what the issue is with creating a new Cluster, and it’s actually not a bad idea to have more than one …What are the Specs of your existing HX220 Hosts? (PSU Rating / CPU (Cores and Clock (or model number and I’ll look it up) / RAM / Disk / Network). Have you checked to see if you can fit 2 T4s in them (just to make sure 2 PCIe slots are available)?What’s meant by the ""desktop Hypervisor""? Are they referring to VMware? I don’t see the relevance unless it’s out of date? Which version of vSphere / vCenter are you running?Which version of Citrix are you running? (MCS is my preferred method of deployment, glad you’re using it).Hosted Shared Desktops (XenApp) - Don’t use Windows 2016, it’s really old! If you’re building these XenApp VMs from scratch, then you should be using the latest version of Windows 2019. If you’re running “Microsoft Volume Licensing” then there’s an April 2020 fully patched version sitting on the VLSC Portal ready for use. Regarding XenApp VM specs, now that you’ve mentioned which applications you’re running, the M10 is no longer an option for you regardless of any Server. The Applications you’ve listed are also reliant on CPU Clockspeed, the higher the better and typically nothing less than 3.0Ghz, so make sure any new Server purchases have a 3.0Ghz+ Clock. You should be looking at the T4 at a minimum. Using vGPU, you’ll need the 8Q Profile (Not 8A) for each XenApp VM and you’ll get 2 of those per T4. This will require QvDWS licensing (because of your Applications), but as you’re an Educational facility, speak to your IT distributor and you will be able to get EDU pricing for the vGPU licenses (it makes a HUGE difference). The reason this is important, is that vGPU is licensed per CCU, so if you have 250 CCU, you’ll need 250 QvDWS licenses. And yes, you need QvDWS licensing with these applications, vApps won’t give the performance needed. Regarding CPU and RAM, assuming you have adequate resources and can retro fit 2 T4s into the HX220, you’re effectively splitting the Server into quarters to support 4 XenApp VMs. Start with the following specs for each VM and then modify 8 vCPU / 32GB RAM / T4-8Q. This spec will typically support 20 – 25 Users (sometimes more / less), but this is application dependant and the applications you’re planning to run are typically delivered using XenDesktop (Not XenApp) to give consistent performance, so your XenApp density will probably be lower, but it depends how the Applications are used. Start with those specs and see how you get on. The only vGPU options you have with XenApp are 8Q or 16Q. You wouldn’t go lower than 8Q due to Framebuffer limits, and 16Q would mean only 1 VM per T4.Pooled Desktops (XenDesktop) – Start with 4 vCPU, 8GB RAM and T4-2Q per VM. Scale up resources from there depending on requirements.I assume you know about the hard RAM allocation when running vGPUs? It’s fixed per VM and the entire amount is hard allocated on boot. This is one reason it’s important to spec the Servers correctly when purchasing with GPUs as it changes the way in which resources are used.Rather than let Cisco talk you into a new purchase at this point, you should be looking to run a POC for the XenApp and XenDesktop VMs so you know what size profiles you need (CPU / RAM / vGPU). Then you can spec your new Servers correctly to fit the maximum amount of Users on them and allowing a little headroom for future performance and additional application requirements. There’s nothing worse than buying a new platform to meet your current requirements, then in 6 months or a year later when new applications are installed, realising that you didn’t allow enough performance headroom to support them.What is your total planned CCU density for XenApp & XenDesktop? 10 servers sounds a lot just to support 250 CCU …Unless you have reasons for not wanting to, it actually makes sense to run multiple Clusters if you have the resources to do so, one for your XenApp VMs the other for your XenDesktop VMs. That way you keep better control of the resource allocation from each vSphere Host for a more consistent experience.Unfortunately I can’t comment on GPU EOL / EOS. All I’ll say is that it’s not a good idea to buy and build a new Server platform around a GPU that’s 4 years old. There are technical reasons why you wouldn’t want to use them as well due to their architecture. Basically, stick with the T4 as a minimum, design around that and you won’t go too far wrong.RegardsMGNo after your explanation I think that better sells the idea of a new cluster a little better. The original thought process I was under was basically in 2 pieces 1) KISS keep it simple, less provisioning of new VM hosts etc., 2) I wanted to understand why when sold a ""scalable"" solution originally how it could be so complex to access that original scalability model (that’s my own OCD kicking in there).The existing vCenter will run multiple Clusters so no complication there. Citrix will work across Clusters, just add the new location into Studio. I’m assuming you already have the correct vSphere licenses (Enterprise Plus) for your existing Cluster, but you’ll obviously need additional vSphere Enterprise Plus licenses for the new Cluster, unless you’re running (vSphere for Desktop). So I’m not initially sure what the issue is with creating a new Cluster, and it’s actually not a bad idea to have more than one …Good call we have standard licensing on the existing nodes right now so we’ll upgrade to Enterprise Plus. Your explanation makes sense to me and the idea of a new cluster based on that is no longer a bottle neck in my mind now.What are the Specs of your existing HX220 Hosts? (PSU Rating / CPU (Cores and Clock (or model number and I’ll look it up) / RAM / Disk / Network). Have you checked to see if you can fit 2 T4s in them (just to make sure 2 PCIe slots are available)?Each node is HX220c-M5sx, dual 2.6 6132 processors, 756GB (766) max ram, 6 x 1.8TB drives. I looked up the specs here https://www.nvidia.com/en-us/data-center/resources/vgpu-certified-servers/#utm_source=shorturl&utm_medium=referrer&utm_campaign=grid-certified-serversSo its good for 2x T4 per node, and it looks like the HX240x M5 can take 6x per node ?Hosted Shared Desktops (XenApp) - Don’t use Windows 2016, it’s really old! If you’re building these XenApp VMs from scratch, then you should be using the latest version of Windows 2019. If you’re running “Microsoft Volume Licensing” then there’s an April 2020 fully patched version sitting on the VLSC Portal ready for use. Regarding XenApp VM specs, now that you’ve mentioned which applications you’re running, the M10 is no longer an option for you regardless of any Server. The Applications you’ve listed are also reliant on CPU Clockspeed, the higher the better and typically nothing less than 3.0Ghz, so make sure any new Server purchases have a 3.0Ghz+ Clock. You should be looking at the T4 at a minimum. Using vGPU, you’ll need the 8Q Profile (Not 8A) for each XenApp VM and you’ll get 2 of those per T4. This will require QvDWS licensing (because of your Applications), but as you’re an Educational facility, speak to your IT distributor and you will be able to get EDU pricing for the vGPU licenses (it makes a HUGE difference). The reason this is important, is that vGPU is licensed per CCU, so if you have 250 CCU, you’ll need 250 QvDWS licenses. And yes, you need QvDWS licensing with these applications, vApps won’t give the performance needed. Regarding CPU and RAM, assuming you have adequate resources and can retro fit 2 T4s into the HX220, you’re effectively splitting the Server into quarters to support 4 XenApp VMs.We are definitely looking at server 2019 for brand new builds.Start with the following specs for each VM and then modify 8 vCPU / 32GB RAM / T4-8Q. This spec will typically support 20 – 25 Users (sometimes more / less), but this is application dependant and the applications you’re planning to run are typically delivered using XenDesktop (Not XenApp) to give consistent performance, so your XenApp density will probably be lower, but it depends how the Applications are used. Start with those specs and see how you get on.Those are spec’s now, except we are at 36GB RAM and don’t have a vGPU profile. Same mindset as you suggest need to try it and see what the real user experience is like and so on.you should be looking to run a POC for the XenApp and XenDesktop VMs so you know what size profiles you need (CPU / RAM / vGPU). Then you can spec your new Servers correctly to fit the maximum amount of Users on them and allowing a little headroom for future performance and additional application requirements. There’s nothing worse than buying a new platform to meet your current requirements, then in 6 months or a year later when new applications are installed, realising that you didn’t allow enough performance headroom to support them.What is your total planned CCU density for XenApp & XenDesktop? 10 servers sounds a lot just to support 250 CCU …I think this is solid advice, running a PoC with some T4’s is the way to go and then make expansion plans based on outcomes from that we’ll have a better idea. We really don’t know our CCU count, we have around 500 physical workstations currently but the number of unique users is 4x times that amount but they are not all using them at the same time so this expansion to measure actual usage patterns is somewhat of a guessing game for us at this point as well.Unfortunately I can’t comment on GPU EOL / EOS. All I’ll say is that it’s not a good idea to buy and build a new Server platform around a GPU that’s 4 years old. There are technical reasons why you wouldn’t want to use them as well due to their architecture. Basically, stick with the T4 as a minimum, design around that and you won’t go too far wrong.I think you sold me, if the M10 is 4 years old it’s pretty sure it will be discontinued or replaced in short order vs the T4 which is from 2018.HiIf your HX240 Nodes are only running XenApp / XenDesktop VMs, then you can use ""vSphere for Desktop"" licensing, which is cheaper than Enterprise Plus, but you can only run desktop workloads on those vSphere Hosts. With vCenter you can use Standard licensing.The HX220 with a T4 will be ok for a small, controlled POC to understand initial utilisation and configuration and will give you a rough idea about what your new VM specs and Cluster configuration will look like. It may be that you decide to scale up, not out, in which case you might use the 16Q profile with 1 XenApp VM, making the XenApp VMs have a higher density but have fewer to manage over all. Framebuffer is typically what you’ll run out of first when sizing with 8Q vGPU profiles on XenApp, but you obviously have 2 of them compared to 1 16Q profile. It’s the same amount of physical resource, you’re just distributing it in a different way and it can impact user density so it’s worth investigating whether 2x 8Q VMs vs 1x 16Q VM works for you. The other advantage of having less VMs is Windows licensing, just something to be aware of depending on which Microsoft licensing model you use.The HX240 will support 6 T4s, but this obviously depends on PCIe Riser configuration and whether you’re running anything else in those PCIe slots. Another benefit of the HX240 are the additional storage configurations you can use due to having more onboard disk capacity.Regarding platform usage … If you look through (Citrix) Director history it will tell you your loadings. You’ll then have an idea of how many and when people use the platform. The other thing is how many Citrix licenses you have, that’s your Max CCU limit and will give you a hard number to work with. You could have a look through the Citrix User Profiles (I assume you’re running UPM), and see when the people last logged on, obviously making calculations to accommodate the way in which people are currently working (COVID).RegardsMGI really appreciate your advice, its been a good sounding board for me to figure my way through this initial decision. Yes we’re going to PoC, its about learning what we need to know then to expand up or out whichever makes sense.Thanks again, I’m sure I’ll have more questions in the future :)HiNo problem at all, glad it’s been a useful discussionBest of luck with the POC, please let us know how you get on!RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
206,quadro-rtx-a4000-as-vgpu-in-rdsh-vm,"Hello everyone,i am trying to get a Quadro RTX A4000 working properly as a vGPU for a newly set up RDSH.The GPU runs inside a Dell R740 Host-System and is passed through via DDA to the RDSH, which runs as a Hyper-V VM.The GPU is doing it’s job fine until more than 15 Users connect to the RDSH, dwm.exe starts crashing instantly if User 16 tries to connect, giving the User only a blackscreen.Error Infos:
Name der fehlerhaften Anwendung: dwm.exe, Version: 10.0.17763.831, Zeitstempel: 0xd5c9fdea
Name des fehlerhaften Moduls: udwm.dll, Version: 10.0.17763.1852, Zeitstempel: 0x6f3c3f5d
Ausnahmecode: 0xc00001ad
Fehleroffset: 0x00000000000b15d5
ID des fehlerhaften Prozesses: 0x4344
Startzeit der fehlerhaften Anwendung: 0x01d87db83505be01
Pfad der fehlerhaften Anwendung: C:\Windows\system32\dwm.exe
Pfad des fehlerhaften Moduls: C:\Windows\SYSTEM32\udwm.dll
Berichtskennung: afed10c4-e78d-4753-a9dd-00ae4d92b896
Vollständiger Name des fehlerhaften Pakets:
Anwendungs-ID, die relativ zum fehlerhaften Paket ist:So i’m wondering if the A4000 is supported for what I am trying to do. Drivers and Windows Updates are all up to date.Any help would be appreciated!How is your framebuffer saturated when the 16th user tries to connect?
A4000 is not vGPU capable but doesn’t matter as you run just Passthrough. I doubt that Dell supports the A4000 in server systems at all.
What you are seeing always happens sooner or later on every RDSH installation. But CCU count us different. For most customers this happens with almost 50 CCUs instead of that early.framebufferHey, thanks for your reply.Thats how the workload on the  GPU looks with 15 Users signed in on the RDSH and User 16 trying to sign in.
image2018×1004 60.2 KB
On the other RDSHs we currently use Quadro P4000 without problems, we had one A4000 laying around so I decided to test it.Hmm, really strange. Could you test an older driver based on R470 branch? 473.47 for example. Looks like a resource issue but there are so many GPU resources left that I don’ t understand why this is happeningUnfortunately I already tried these drivers with the same results:Could try even older drivers but I’m pessimistic ^^Powered by Discourse, best viewed with JavaScript enabled"
207,hyper-v-server-2019-rdsh-farm,"HiWe currently run a server 2019 RDSH farm and would like to start implementing dedicated graphics cards into our HPE ProLiant DL380’s.Requirements are to increase the user count on each VM by offloading load from the CPU for Chrome and Office applications, along with improving the look and feel of the RDSH session.These requirements might be unattainable as I have seen reference to max users/licenses on the M10 of 64, is this the case?Ideally we would be running 5-6 RDSH VMs ok each host, currently we average 20 users per RDSH.Our supplier is a bit un clear on how much and what we need to licence as well, so any help on that would be appreciated.Many thanksHiAs an example, depending on the type of applications and how they’re used, you should expect about 15-25 users per GPU on an M10 before framebuffer exhaustion. The M10 has 4x 8GB GPUs on it and you’d allocate 1 GPU per RDSH VM. The user density varies between deployments as applications and how they’re used vary, not to mention environment optimisations, monitors and resolutions etc all vary and they all impact framebuffer usage. 15-25 users per GPU would give you between 60-100 users per M10 which should be achievable.However, in any new GPU / vGPU deployment, I’d recommend the T4 GPU over the M10 due to the stage of their lifecycle (M10s were released in 2016). As has been shown many times and also with feedback on here to support it, it’s the 8GB of framebuffer that is typically the limiting factor when it comes to RDSH deployments, not the encoding or processing, meaning that the 8GB on the M10 isn’t really sufficient for modern and more importantly future RDSH deployments forcing customers to scale out their deployments and not up, hence my recommendation to avoid it for new installations, and go for the T4.As you’re using Hyper-V, you’ll need to use Passthrough (it doesn’t support vGPU), so if you went with the T4, you’d need multiple GPUs per DL380.Regarding licensing, you’d want to use ""vApps"". This is licensed per Concurrent User (not total user), so match it to your CALs and you should be fine.Which generation of DL380 do you have?How many concurrent users do you support in you RDSH environment?RegardsMGHiThanks for the reply.We have a mixture but predominently Gen10.Across the farm currently we are at around 1,000 users, with aspirations for 2,000 within two years.Ideally 30 - 40 users per RDSH VM, for this exercise to be worthwhile.So Host wise if running 5 x RDSH VM’s, based on 30 users per session would be 150 users per ProLiant DL380 host.We currently have 2 x 10GB NIC’s in the chassis as well.I had seen mentioned advice to look at Quadro GPU’s, as they don’t require licensing?HiGreat, thanks for the information!Depending on your Riser configuration, you can physically fit up to 3x M10s or 7x T4s per DL380 G10. Here’s NVIDIAs Certified Server URL that collates information from the Server OEMs: Virtual GPU Certified Servers | NVIDIA GRIDRetro fitting GPUs into any Server can raise complications with the original Server configuration. These can be things like CPU choice, PSU choice (of which there are prerequisites that must be met) and RAM, so you need to make sure you have all the requirements met before installing the GPUs. You will also need a GPU enablement Kit which is typically a pair of low profile CPU heatsinks (to provide adequate cooling for the GPUs as they’re Passive) and additional Power Cables for the GPUs that need them (depending on which GPUs you go for (M10s need one, T4s do not)).The licensing for vApps really isn’t expensive, and for your environment, I’m pretty sure you can’t avoid it due to the options available. Basically, the Quadro options you have won’t give you the density you need. The largest single slot Quadro is an RTX4000 (8GB), if you move to a 16GB Quadro then you’re looking at the RTX5000 which is dual slot, so you halve the density in your server vs a T4 which has the same amount of Framebuffer and much lower power requirements. If you go above that, you’re into RTX6000 / 8000 which is not suitable for this type of deployment.5x T4s per DL380 with 30+ users per RDSH should be very achievable (pending a small POC for application validation of course).When purchasing your new DL380s as you scale later, you may want to revise the specification (CPU / RAM / GPU) so that you can install more T4s to further improve that density.RegardsMGBrilliant advice MG, I will look into the T4’s, any ceiling (Max users) on users for T4’s or is it purely based on usage requirements? Trial and error.HiUnfortunately there are too many variables to give an accurate answer on that, and there is no hard limit with RDSH (a VDI deployment is obviously different). Things like the amount of monitors a user has and the resolution of those monitors make a huge difference (1080P vs 4K) both to Framebuffer utilisation but also encoding as well. The type (and version) of applications installed and how they are used (we’ve all seen users with many multiples of tabs open in a browser before) makes a big difference too. Operating System configuration and optimisation all plays a part.I’ve heard of RDSH numbers of 10 - 11 users maxing out 8GB on an M10 due to sub-optimal applications being used, and then others right up to 30 users on single 8GB M10. Everyone’s environment is different, so the end results are usually different.As an estimate in terms of absolute numbers, if you have the right type of applications installed, with a well optimised Operating System and users that behave themselves, then I’d be expecting over 40 users on a single T4. It’s also important to leave a little headroom on all components to give a consistent experience and level of performance. No environment runs well when it’s running at maximum utilisation, so find your maximum then dial it back about 10 - 15% per GPU / RDSH. Also, when you purchase new servers to scale your environment, I would be expecting better density due to a more optimised selection of components being chosen to work together (CPU / RAM / GPU / Storage).The numbers you’re asking for are very realistic, and a small POC is always the best way to make sure you’re making a positive change to the environment, and you only need 1x T4 to test initially which means the initial cost of the POC should be very low.RegardsMGUnderstood, appreciate the feedback.Will go for a T4 and see how we get on ???Powered by Discourse, best viewed with JavaScript enabled"
208,gcp-vm-with-4-nvidia-t4-no-sli-mode-shown-cinema-4d-redshift,"Hello,
we’re trying to run Cinema 4D with Redshift on 4 T4 - we get the error shown in the screenshot.Redshift tells us to Disable Multi-GPU mode, unfortunately that is not shown in the Nvidia Control Center on our Google Cloud Platform Virtual Machine. What can we do? Any help is appreciated! Thanks!
image (1)798×167 16.7 KB
Here’s the error message from Redshift in Cinema 4DFYI, unfortunately Redshift RT (RealTime) also does not work - maybe a connected issue?As far as I know, it might be changed via BIOS/UEFI? How could that be accessed via the VM?Powered by Discourse, best viewed with JavaScript enabled"
209,horizon-with-t4-resolution-limited,"I am deploying a new Horizon environment currently on Horizon 7.9 with ESXi 6.7 U2
the NVDIDA T4 cards are functional but we are limited to 2560 x 1600 screen resolution.I have the profile set to grid_t4-1b, with one display this should be able to do 3840×2160 upto  5120×2880.how do you enable the higher resolution options? hi high resolution screens such as a Surface we get a black boarder.Powered by Discourse, best viewed with JavaScript enabled"
210,nvidia-vgpu-and-geforce-experience,"Hello all
Could anyone help with question - does Nvidia Grid vGPUs driver support GeForce Experience?Idea to make high performance stream some applications over network from virtual machines with nvidia gridPowered by Discourse, best viewed with JavaScript enabled"
211,nvidia-knowlegebase,"First stop for any support issueshttp://nvidia.custhelp.com/app/answers/list/st/5/kw/grid/page/1Articles are being added all the time, so strongly recommend searching here first.Powered by Discourse, best viewed with JavaScript enabled"
212,aws-cloudxr,"I am attempting to set up the CloudXR Server on the NVIDIA Quadro Virtual Workstation - WinServer 2019. I have verified that the vGPU Tesla T4 [g4dn.xlarge]
exists on the VM and the driver version is 452.39.Although the vGPU meets the criteria for CloudXR [“For the server, NVIDIA CloudXR SDK requires any VR-Ready model of NVIDIA GPU, including Quadro® GPUs, based on the NVIDIA PascalTM GPU architecture or later architectures.”] and the driver version is “NVIDIA Graphics driver 440.97 or later” I am still received the following error: “No cloudXR capable GPU found”I seem to be having the same issue with a Tesla T4 on Google Cloud (with driver 461.09). It seems this GPU may not be supported with CloudXR?Update: worked when I installed the GRID driver. (thanks to the answer here: [SOLVED] CloudXR install fails due to ""no compatible GPU"" - #2 by niclas.voda)Powered by Discourse, best viewed with JavaScript enabled"
213,vgpu-package-for-vmware-vsphere-8,"Hi,
does anybody know when the new vGPU package with drivers will be available for  VMware vSphere 8?
Thank you,JiriHi,there will be support for vSphere 8 with the next upcoming major release. Should be available in a few weeks.regards
SimonHi Simon,
Any update?
Thank you for the previous information. We have been waiting for vSphere 8 support and postponing the implementation of vGPU solution on our customer’s hardware. And the customer keeps asking when the new version will be. :-)Thanks,JiriHi Jiri,please be patient for a few more days :) We are almost there…regards
SimonHi,
Great!!! Thanks a lot!JiriHi, please check the latest release :)
https://docs.nvidia.com/grid/latest/index.htmlregards
SimonWhere can i download the latest release for VMware v15.x?As always: Go to the Nvidia Licensing Portal. You need to have a valid entitlement.I do not see the latest, I do have a valid entitlement. The latest I see is from March 2023 and is v11.x. Thank you.EDIT. I found it. Thank you!Just wanted to mention to do a filtering:

image1651×383 40.9 KB
Powered by Discourse, best viewed with JavaScript enabled"
214,telsa-p40-remotefx,"How i can enable RemoteFX in Windows 2016 server Operating system ( Hyper-V) to use NVIDIA Telsa P40 card. In Hyper-V Physical GPU setting i am getting this error "" Summary-This Computer doesn’t have any Physical graphics Processing unit(GPU).Use of a RemoteFX 3D video adapter requires at least one Physical GPU that supports RemoteFX""First of all you should tell us what you want to achieve. Then we may give you a proper advise.I am adding this server to the RDS setup and want to assign GPU Graphics to the VDI machines . We need to run \ Test 3D applications in the VDI Machines.So are you talking about Win10 VDI or Server 2016 RDSH?Host machine is Windows 2016 enabled with RDSH & we are having Windows 10 VDIUnfortunately I have no experience with RemoteFX and Tesla P40. As RemoteFX is deprecated technology I never had a customer really using it. Server 2019 fully removed the RemoteFX functionality.
I could only help with DDA but Passthrough won’t help in your scenario.Powered by Discourse, best viewed with JavaScript enabled"
215,nvidia-license-server-issues,"Hi all,I fighting still weeks with the nvidia support about issues with the nvidia license server.
I use the latest version from november 2020.I have a primary node and also a failover/backup node. Both installed on windows server 2016.
I can see the replication works between primary and backup license sever.But something is wrong here…
The database files grows on the secondary site each day. The database file on the primary is not larger than 10MB. On the secondary site it is already 120MB after one week. I reinstalled the license server on the secondary site multiple times.I can also see in the log files of the secondary following errors:17:34:41,213 INFO  Scheduled-pool-9-thread-7 [sync-session=6YDPLL5LK8KM] Return for feature GRID-Virtual-PC 2.0, count=-1 failed.
17:34:41,213 INFO  Scheduled-pool-9-thread-7 [sync-session=6YDPLL5LK8KM] Return for feature GRID-Virtual-PC 2.0, count=-1 failed.Can anyone of you confirm that they have the same issue?Thanks in advance,
EricHiI’ve not experienced this before, however all my License Servers are run on Server 2019.A few options to investigate …Try a clean install of Server 2019 (fully patched)
Try a different version of Java / OpenJDK
Try using Linux for the License ServerAre you running anything else on these License Servers apart from the NVIDIA Licensing? Any other Server Roles etc?Just looking for anything at this stage that would give an indication of what’s causing the issue, as NVIDIA Support are pretty good and the License Server components are fairly basic.RegardsMGYou have also failover license server configuration?
The license db file has on your primary and backup server nearly the same size?I already built two new license servers on 2019 but same issue here.Can you check if you see on the backup license server the correct number of assigned licenses in the license overview?Thanks!HiJust checked on both Servers …They are totally in sync with each other. They even have the same amount of space remaining / consumed on the HDD.For reference, here are the version details of OS, License Server and Java:
image757×290 73.9 KB
RegardsMGThanks for checking.
It looks like you don‘t use the lastet release of the license server from november 2020?
You also use oracle java version? We switched to openjdk because of oracle license policy.NVIDIA removed today this latest version of the license server because of some major bugs!Powered by Discourse, best viewed with JavaScript enabled"
216,nvidia-rtx-workstation-with-a40-on-vsphere-7-0,"I have two servers Dell R740 with one A40 on every sever. There is infrastructure Vsphere7.0. I would like to install RTX workstantion software to have VM’s for Cuda Compute. Can I use RTX without VMware Horisont for that?Thanks.Powered by Discourse, best viewed with JavaScript enabled"
217,cuda-11-x-and-vs2017,"Hello, I want to use the latest CUDA version with VS 2017 and I’m having strange behavior.  I opened the VS2017 samples project or solution that came with CUDA and had the following issues.  One issue is that the code samples have undefined variables which I suspect is due to an incompatible SDK.  The other is that when I tried to undock one of the code editor panels the entire project crashed and I received an error message that files were not recoverable.  Any assistance would be appreciated.Powered by Discourse, best viewed with JavaScript enabled"
218,hype-v-virtualization-windows-server-2019-host-ubuntu-linux-1804-lts-64bit-guest-quadro-rtx-6000,"Hello,I have the following concern and would appreciate help very much:We are running a Windows Server 2019 (Version 1809 with Hyper-V role) as host. The machine has 4 Quadro RTX 6000 cards. We want to create a setup that serves 4 virtualized guest systems that each have a dedicated GPU to their disposal (pass-through). Those guests shall run either Windows or Linux.We got it to work with the Windows guests (DDA). We followed the Microsoft manual by dismounting the cards from the host and adding the assignable devices to the guests. Everything works fine.However, we do not get it to work with the Linux guests. We followed the same procedure. As long as the GPU is not added, the guest OS starts fine. But when we add the device Linux is not booting. It got stuck before starting the graphical output. We already tried installing the NVidia device drivers. That did not solve the problem.So my questions from general to specific are:Thank you very much for your time,
MarcelPowered by Discourse, best viewed with JavaScript enabled"
219,computer-vision-solutions-page-refreshed,"Computer Vision Developers:We have updated the Computer Vision Solutions Landing Page, particularly for beginners and those new to NVIDIA software. In short, here are some high-level updates:If you have feedback on the Computer Vision Solutions Landing Page, NVIDIA computer vision software, or anything-related to computer vision, please reach out. Our team would be happy to hear from you.Best,
MikeB_NVPowered by Discourse, best viewed with JavaScript enabled"
220,does-multi-instance-gpus-supported-by-a100-allow-users-to-set-clock,"Does anybody know whether the A100 GPU with Multi-Instance GPU (MIG)  allow user to set the application clock (graphic or memory) for a specific GPU instance? Or when we set the application clock via Nvidia-smi, it applies to all instances within the GPU.
More information about MIG:  NVIDIA MULTI-INSTANCE GPUClocks are set per GPU - so are applied to all the MIG instances.Powered by Discourse, best viewed with JavaScript enabled"
221,problems-with-citrix-server2016-vgpu-10-1,"Hi,
we are running in issues with vGPU on VMware 6.7 on 2016 XenApp Servers.
Single Sessions get disconnected and the Users are unable to reconnect. We are also unable to end the Sessions on the RDSH or in Citrix Studio/Director.This is what we see in the eventlog:<Event xmlns=""Error;and a few seconds before Citrix Session reliability is taking the session:""Session reliability has suspended the connection for user domain.com\username, session 5Event xmlns=""Error;Systems without vGPU never experienced that Problem:
We are running T4 Cards wich vGPU Software 10.1Any suggestions?
Thanks,
AlexHi Alex,sounds like you should open a support ticket with Nvidia and Citrix to work on this.Regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
222,how-can-i-program-code-to-use-vgpu-on-the-grid-m60-1q,"i installed NVIDIA-Linux-x86_64-390.75-grid.run and i found ""No running processes found "" after command “nvidia-smi”
i try to install TensorFlow and cuda, but i found GRID M60-1Q doesn’t support cuda.
so i don’t know how to program code to use vgpu so that there are processes running on the command “nvidia-smi”.thanksPowered by Discourse, best viewed with JavaScript enabled"
223,setting-up-nvidia-with-nas-and-plex,"Ok, I am new to all of this and I need your expert advice. So i have a Qnap 453a, the Shield 16gb and three tvs. my router and modem is located in my living room, along with the 4k Ultra HDR Tv. The 2nd tv is in the kids room with an xbox 360, and the last Tv is my room. I have a Lg 1080 non smart tv.If I mount the NAS to the Shield, and they both need to be connected to the router do I need to purchase an additional piece of equipment like the fire stick in order to stream to the TV in my room?What is the best way to connect all of this to stream media throughout my home. Also should I run the Plex server from the Shield?any help I would appreciate so much, including anything i didn’t know to ask…  THANKSHi,This is the NVIDIA Developer forum. Unfortunately, you will not find Shield support here. I suggest posting questions related to Shield in the GeForce forums.The world's most advanced graphics cards, gaming solutions, and gaming technology - from NVIDIA GeForce. Download drivers, automate your optimal playable settings with GeForce Experience.Best,
TomPowered by Discourse, best viewed with JavaScript enabled"
224,oracle-cloud-nvidia-market-place-image-not-working,"Hi,I tried the following image via Oracle cloud
marketplace / application / 76105157/ usageInformation?region=eu-frankfurt-1
and it does not work.
When I access my machine, I cannot see any Nvidia driver.
No Nvidia driver/card is available following desktop/nvidia driver
or via nvidia-smi.exe I receive no card installed.What do I need to do?Powered by Discourse, best viewed with JavaScript enabled"
225,how-to-install-a-custom-application,"Hey I need to install blender and try the performance. As soon as I download the installer and give permission nothing happens. Help!!!Hi Neenjo,It is not possible to install your own apps. We had problems with abuse people trying to install bitcoin miners and some very odd things. If you contact an NVIDIA partner they may be able to offer you a trial.Best wishes,
RachelTo provide the best performance and prevent any misuse of Trial, users are not allowed to install or run any software on their own.If you need to install and run other than ready to use apps, add Custom Virtual Private Server.
People kept installing Cryptocurrency minors. So to protect the system from such abuse. you are now allowed to install new apps on your own.I am also looking for the answer to How to install a custom application. Anyone with a perfect idea.Thank you. The answer from Rachelberry answers it allhi
you can’t install a custom applicationPowered by Discourse, best viewed with JavaScript enabled"
226,wrong-license-edition-is-displayed-in-the-nvidia-control-panel,"Hello Team,I have P40-1b profile assigned to a VM and installed with 412.31 driver version. The vDWS license is acquired but the nvidia control panel shows ""Your system is licensed for GRID Virtual PC""
Kindly help me to reoslve this issueRegards,
SanjeevHi SanjeevThat’s as expected. You have a vPC profile allocated to the VM at the moment.If you’d like to use Quadro features, shutdown your VM, on your Hypervisor, change the vGPU profile on the VM to 1Q and power it on again. The NVIDIA Control Panel will then report that you’re using a Quadro profile.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
227,windows-2008r2-win-7-to-win-2016-win-10-rdp-remotefx-upgrade,"Dear,For a upgrade of a control room I want to make a POC to integrate follow systems.We currently have following setup:We want to integrate all in a Hyper-V cluster. I was looking to add two P2000’s to the Win 2016 cluster and make 3 Win 10 test guests using Remote FX to show all camera content on a videowall using thin clients controlled by  thinmanager. The current thin client is only RDP 8, so we’ll also test with Win 10 IOT thin clients supporting RDP 10.Questions:regards,
PascalPowered by Discourse, best viewed with JavaScript enabled"
228,nvidia-container-cli-initialization-error-cuda-error-unknown-error,"Installed nvidia kmod driver on centos 7.5 machine with A100 GPUs and getting the nvidia-container-cli: initialization error: cuda error: unknown error
I see  NVRM: installed in this system is not supported by the NVIDIA 396.82 driver release. in dmesg logs.
Can you advise which version should we go with or if there is a way to fix this error.nvidia-container information: nvidia-container-cli -k -d /dev/tty info
– WARNING, the following logs are for debugging purposes only –I0520 21:14:52.146938 87864 nvc.c:281] initializing library context (version=1.0.1, build=038fb92d00c94f97d61492d4ed1f82e981129b74)
I0520 21:14:52.147026 87864 nvc.c:255] using root /
I0520 21:14:52.147030 87864 nvc.c:256] using ldcache /etc/ld.so.cache
I0520 21:14:52.147034 87864 nvc.c:257] using unprivileged user 10041:10042
W0520 21:14:52.149093 87865 nvc.c:186] failed to set inheritable capabilities
W0520 21:14:52.149171 87865 nvc.c:187] skipping kernel modules load due to failure
I0520 21:14:52.149785 87866 driver.c:133] starting driver service
I0520 21:14:52.161217 87864 driver.c:233] driver service terminated with signal 15
nvidia-container-cli: initialization error: cuda error: unknown errorKernel version from uname -a
Linux datasciairflowa100gpuworkerc1-dsm1-1 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/LinuxAny relevant kernel output lines from dmesgNVRM: installed in this system is not supported by the NVIDIA 396.82 driver release.Driver information from nvidia-smi -a==============NVSMI LOG==============Timestamp                                 : Thu May 20 11:58:52 2021
Driver Version                            : 460.73.01
CUDA Version                              : 11.2Attached GPUs                             : 8
GPU 00000000:00:04.0
Product Name                          : A100-SXM4-40GB
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Disabled
MIG Mode
Current                           : Disabled
Pending                           : Disabled
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1323820022403
GPU UUID                              : GPU-5c2da4bc-dc76-ea02-156e-00422cb46cab
Minor Number                          : 0
VBIOS Version                         : 92.00.36.00.04
MultiGPU Board                        : No
Board ID                              : 0x4
GPU Part Number                       : 692-2G506-0200-002
Inforom Version
Image Version                     : G506.0200.00.04
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : Pass-Through
Host VGPU Mode                    : N/A
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x00
Device                            : 0x04
Domain                            : 0x0000
Device Id                         : 0x20B010DE
Bus Id                            : 00000000:00:04.0
Sub System Id                     : 0x134F10DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 4
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P0
Clocks Throttle Reasons
Idle                              : Not Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 40536 MiB
Used                              : 0 MiB
Free                              : 40536 MiB
BAR1 Memory Usage
Total                             : 65536 MiB
Used                              : 1 MiB
Free                              : 65535 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Enabled
Pending                           : Enabled
ECC Errors
Volatile
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Aggregate
SRAM Correctable              : 0
SRAM Uncorrectable            : 0
DRAM Correctable              : 0
DRAM Uncorrectable            : 0
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 640 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 37 C
GPU Shutdown Temp                 : 92 C
GPU Slowdown Temp                 : 89 C
GPU Max Operating Temp            : 85 C
GPU Target Temperature            : N/A
Memory Current Temp               : 37 C
Memory Max Operating Temp         : 95 C
Power Readings
Power Management                  : Supported
Power Draw                        : 61.62 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 400.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 W
Clocks
Graphics                          : 1095 MHz
SM                                : 1095 MHz
Memory                            : 1215 MHz
Video                             : 990 MHz
Applications Clocks
Graphics                          : 1095 MHz
Memory                            : 1215 MHz
Default Applications Clocks
Graphics                          : 1095 MHz
Memory                            : 1215 MHz
Max Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1215 MHz
Video                             : 1290 MHz
Max Customer Boost Clocks
Graphics                          : 1410 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes                             : NoneDocker version from docker version
Client:
Version:           18.09.1
API version:       1.39
Go version:        go1.10.6
Git commit:        4c52b90
Built:             Wed Jan  9 19:35:01 2019
OS/Arch:           linux/amd64
Experimental:      falseServer: Docker Engine - Community
Engine:
Version:          18.09.1
API version:      1.39 (minimum version 1.12)
Go version:       go1.10.6
Git commit:       4c52b90
Built:            Wed Jan  9 19:06:30 2019
OS/Arch:          linux/amd64
Experimental:     falseNVIDIA packages version from dpkg -l ‘nvidia’ or rpm -qa ‘nvidia’
xorg-x11-drv-nvidia-libs-396.82-1.el7.x86_64
libnvidia-container1-1.0.1-1.x86_64
nvidia-docker2-2.0.3-1.docker18.09.1.ce.noarch
nvidia-container-runtime-2.0.0-1.docker18.09.1.x86_64
xorg-x11-drv-nvidia-devel-396.82-1.el7.x86_64
nvidia-container-toolkit-1.0.5-2.x86_64
nvidia-kmod-396.82-2.el7.x86_64
xorg-x11-drv-nvidia-396.82-1.el7.x86_64
xorg-x11-drv-nvidia-gl-396.82-1.el7.x86_64
libnvidia-container-tools-1.0.1-1.x86_64NVIDIA container library version from nvidia-container-cli -V
version: 1.0.1
build date: 2019-01-15T23:26+0000
build revision: 038fb92d00c94f97d61492d4ed1f82e981129b74
build compiler: gcc 4.8.5 20150623 (Red Hat 4.8.5-36)
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,–gc-sectionsPowered by Discourse, best viewed with JavaScript enabled"
229,quadro-p400-direct-access-under-esx-6-7,"I am struggling to get my servers up and running.
Y want a CAO /rendering VM benefit from direct Access to the QUADRO P400 GPUMy conf is the following
Lenovo System x3100 M5: 32G RAM, intel(R) Xeon(R) CPU E3-1220 v3 @ 3.10GHz
Running ESX 6.7 build 8169922I do not find the proper ESX 6.7 Vib/ driver to download because the Esx is not a listed OS in the  driver selection list on NVIDIA Support site.
Any clue ??ThksHi,short answer: Not working. You cannot Passthrough a Quadro P400 GPU. You need at least a Quadro P2000.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
230,esx-6-7-update-3-with-vib-version-nvidia-bootbank-nvidia-vmware-esxi-6-7-host-driver-450-80-1oem,"Hello,I have 4 esxi hosts with Tesla M10 GPU on each host.
I enabled Hot GPU migration on vcenterwhen migrating a VM, I get a warning ""A warning or error occurred when migrating the virtual machine.
Virtual machine relocation, or power on after relocation or cloning can fail if vGPU resources are not available on the destination host.""What am I missing?Also, when I put a host in Maintenane Mode, the VMs will NOT migrate automatically even though I have available GPU resources.I have to manually Migrate each powered ON VM.on the Guest OSPCI device 0 = NVIDIA GRID VGPU
GPU Profile = grid_m10-1qPowered by Discourse, best viewed with JavaScript enabled"
231,vmware-horizon-7-9-instant-clone-and-nvidia-license,"Hi Guys,VMware Horizon 7.9 instant clone pool, 180 users. We have issues, VM get license but license stay in the license pool because VM doesn’t get shutdown and then we run out of license.
on logout or re-logon Nvidia license doesnt get release, license get release on proper VM shutdown, as suppose.
Is there a way to release nvidia grid license on user logout in instant clone pool?Thanks,
IgorHiThe license is allocated when the VM powers on. Not when the User logs in. This cannot be changed and is by design.Adjust your Power settings in the Resource Pool so that the VMs are Powered Off until needed and you’ll get your licenses back (and also improve your GPU performance).How many Concurrent Users do you have and how many vGPU licenses do you have?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
232,driver-for-nvidia-6200tc,"I installed this GPU in PC and don’t know what driver to download, when I search in Google there is a million drivers but none of them are on official Nvidia website so I don’t know which one to chose.I did a search on that model, and found that card was released in 2004, nearly 18 years ago. That is an eternity in the computer hardware world. Unfortunately that card is no longer supported as far as I can tell.Powered by Discourse, best viewed with JavaScript enabled"
233,gpu-benchmark-error,"I am working on a virtual machine on the Azure Microsoft service.
The virtual machine is running windows 10 and I have a Tesla T4 GPU.
I downloaded all the latest Nvidia drivers.
My problem occurs when I try to run a GPU benchmark software, I am running the benchmark software Heaven Benchmark 4.0.
When I run the benchmark software I am getting the following error:
image1920×1080 215 KB
Sometimes the benchmark software just getting stuck.
I tried to run it as a sanity check to see that everything is working fine (I am pretty new to working in this environment).
I also tried running an online benchmark at the url: https://web.basemark.com/, and it is just getting stuck.
When I run nvidia-smi.exe it recognize my GPU and driver version.Get GPU Caps Viewer to check your GPU’s capabilities and try the built-in demosIt turns out I had to download a GRID driver and it fix everything.
The link for the driver is here: Azure N-series NVIDIA GPU driver setup for Windows - Azure Virtual Machines | Microsoft LearnPowered by Discourse, best viewed with JavaScript enabled"
234,gpu-for-multiple-hyper-v-vms,"Hi all, vGPU newbie here.  I have an HP DL380 thats running 13 high spec Visual Studio development VM’s, each one assigned to a developer who uses Remote Desktop to connect to.  They are all saying that the UI is laggy, is there a GPU, or similar tech I can use in order for the VM’s to access better performing GPU for a snappier RDP UI?Hi,Unfortunately there is not much you can do with Hyper-v as it doesn’t support vGPU. You would need a different Hypervisor first like ESX, KVM, Citrix or AHV.Regards SimonThanks Simon, much appreciated.Powered by Discourse, best viewed with JavaScript enabled"
235,size-of-standard-persisent-disk-problem,"In Google cloud console, under VM instances market place I chose NVIDIA Quadro Virtual Workstation - Windows Server 2019 as my compute engine and in it I chose standard persisent disk to be 200gb and created virtual machine. But when I open the VM the disk size is 50gb only. Please helpHi MaraleeePlease use Windows Disk Management console to extend the partition size to 200GB.You can add space to an existing volume in Windows, extending it into empty space on the drive, but only if the empty space doesn't have a volume on it (it's unallocated) and comes immediately after the volume you want to extend, with no other...NVMRPowered by Discourse, best viewed with JavaScript enabled"
236,segmentation-fault,"Hi, I am new to the Jetson tx2 and trying to deploy a TRT model on Jetson TX2 and i am getting segmentation fault during inferencePowered by Discourse, best viewed with JavaScript enabled"
237,using-in-openstack,"Hello, I have a question about vGPU.
in (Supported Products :: NVIDIA Virtual GPU Software Documentation) there is no normal openstack.
Can I use vGPU in normal openstack not RedHat OpenStack Platform?
And is there installation guide about vGPU in normal openstack?
I’m a beginner. Please Help me
God bless you!p.s. in (OpenStack Docs: Attaching virtual GPU devices to guests) is it a guide for normal openstack vGPU?Powered by Discourse, best viewed with JavaScript enabled"
238,designers-or-rds-sessions-do-not-use-the-gpu,"Hi.
We’ve an Tesla M60 on a HPE DL380 G9 with Vmware Vsphere 7, Vcenter 7 and we’ve updated our driver to Vgpu 11.1; so that’s all about server side.
Also we have the latest linux license server (2020.05) and it’s working.
So we have tested on RDSH (A windows server 2019), we installed apps, assigned gpu profile in vcenter and attached license to RDSH. All seems correct; license server shows that license is delivered and RDSH shows it too; drivers are all up to date and from latest package for vsphere 7 and version 11.1 and are installed on both ESX and RDSH; licenses for programs that are used are obtained; but
RDSH SHOWS NO ADVANTAGE VERSUS VMWARE BUILTIN GRAPHIC CARD AND ALL USERS DIDN’T SENSE ANY DIFFERENCE.
So we have tested the second scenario for having many machines instead of one RDSH.
We disconnected Vgpu from RDSH and dedicated it to one or two machines and done all above, but NOTHING CHANGED.
We’re really out of idea.Note: months ago, we had multiple machines with windows 8 (or 8.1) and they were working fine. Users want us to rollback but downgrades are hard and we have not decided to do this bad job.
We really need your help urgently and we’re in emergency as our designers are using VMware graphics with very low performance.HiHave you configured the ""Use hardware default graphics adapter for all Remote Desktop Services sessions"" setting in the group policy: Computer Configuration > Administrative Templates > Windows Components > Remote Desktop Services > Remote Desktop Session Host > Remote Session EnvironmentHave you monitored the GPU on the RDSH VM to see if it’s being used and what applications are you using?I’m assuming that the Windows VMs you recently tested on were Windows 10, not Windows 8, because vGPU 11.x doesn’t support anything older than 10.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
239,is-any-nvidia-product-officially-supported-for-pci-passthrough-with-qubes,"I’m interested in doing video production work in a Qubes VM (Qubes being a high-security operating system based on Xen), to have a high degree of isolation between video production software (SynthEyes; DaVinci Resolve Studio; various BorisFX products) and other tools on the system.As nVidia’s consumer-grade products are not intended for virtualized use (even when passing the entire GPU through to a single VM rather than segmenting), I’m interested in determining what offerings nVidia has that are suitable to my use case.If I were going to be using consumer-focused products, I would be satisfied with self-supporting; but for the premium associated with business-segment cards, I’m looking for something where customer support is available.Powered by Discourse, best viewed with JavaScript enabled"
240,vgpu-11-error-during-vm-start-vsphere,"Hello,during the start of a VM on vSphere 6.7 and latest NVIDIA vGPU 11.0 the tasks fails: Could not initialize plugin ‘/usr/lib64/vmware/plugin/libnvidia-vgx.so’ for vGPU ‘grid_t4-8q’.
The host is fresh installed and configured the same way as the other hosts in the cluster (where everything is working).
Same issue with vGPU 10.3. Version 10.2 is working.The 3 things I’d look for isAre there other vm’s on the host with a differentHi Korbinian,we run into the same issue when updating our 4 ESXI hosts from 10.2 to 11.0. Only one host got the same issue. we resolved it by uninstalling and re-installing grid manager on this machine. please also note that ECC has to be disabled. before 11.0 it was a known issue from nvidia that some machines cannot start (this was the reason we upgraded). hope this helps!regards,
sandroPowered by Discourse, best viewed with JavaScript enabled"
241,is-it-possible-to-present-multiple-vgpus-to-a-single-vm-from-a-tesla-t4-card-on-esxi-6-7,"Hi guy’s anyone know why I cant present more than one vGPU to my VM Server 2019 (VM hardware version 15)?I can only load 1 and the VM will start fine, if I load a second vGPU the VM fails to start with error: Could not initialize plugin ‘/usr/lib64/vmware/plugin/libnvidia-vgx.so’ for vGPU ‘grid_t4-4c’.Spec background: 1 X Tesla T4 16GB card in Dell vXrail V570, vCenter 6.7 Enterprise plus license running single 64GB Mem VM (server 2019). The GRID driver installed successfully. Host Graphics device is using Shared Direct Vendor shared passthrough graphics.Host ECC has been disabled. The VM has these two settings on/off makes no difference pciPassthru.use64bitMMIO=TRUE
pciPassthru.64bitMMIOSizeGB=64Below is the output of a few of our favourite commands.[root@vxesxi5:~] nvidia-smi -i 00000000:3B:00.0 -e 0
ECC support is already Disabled for GPU 00000000:3B:00.0.
All done.
[root@vxesxi5:~] nvidia-smi
Wed Jul  8 09:56:45 2020
±----------------------------------------------------------------------------+
| NVIDIA-SMI 440.87       Driver Version: 440.87       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:3B:00.0 Off |                  Off |
| N/A   38C    P8    17W /  70W |     79MiB / 16383MiB |      0%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+
[root@vxesxi5:~] esxcli software vib list | grep -i nvidia
NVIDIA-VMware_ESXi_6.7_Host_Driver  440.87-1OEM.670.0.0.8169922           NVIDIA  VMwareAccepted    2020-07-08
[root@vxesxi5:~] lspci -n | grep 10de
0000:3b:00.0 Class 0302: 10de:1eb8 [vmgfx0]Any help appreciated, this is doing my head in!! I understood this card could present up to 4 vGPU’s to a single VM.[root@vxesxi5:~] nvidia-smi -q==============NVSMI LOG==============Timestamp                           : Wed Jul  8 11:36:19 2020
Driver Version                      : 440.87
CUDA Version                        : Not FoundAttached GPUs                       : 1
GPU 00000000:3B:00.0
Product Name                    : Tesla T4
Product Brand                   : Tesla
Display Mode                    : Enabled
Display Active                  : Disabled
Persistence Mode                : Enabled
Accounting Mode                 : Enabled
Accounting Mode Buffer Size     : 4000
Driver Model
Current                     : N/A
Pending                     : N/A
Serial Number                   : 1561120009254
GPU UUID                        : GPU-166df7a5-7a83-f1ac-bc58-313305b331d5
Minor Number                    : 0
VBIOS Version                   : 90.04.38.00.03
MultiGPU Board                  : No
Board ID                        : 0x3b00
GPU Part Number                 : 900-2G183-0100-001
Inforom Version
Image Version               : G183.0200.00.02
OEM Object                  : 1.1
ECC Object                  : 5.0
Power Management Object     : N/A
GPU Operation Mode
Current                     : N/A
Pending                     : N/A
GPU Virtualization Mode
Virtualization Mode         : Host VGPU
Host VGPU Mode              : Non SR-IOV
IBMNPU
Relaxed Ordering Mode       : N/A
PCI
Bus                         : 0x3B
Device                      : 0x00
Domain                      : 0x0000
Device Id                   : 0x1EB810DE
Bus Id                      : 00000000:3B:00.0
Sub System Id               : 0x12A210DE
GPU Link Info
PCIe Generation
Max                 : 3
Current             : 1
Link Width
Max                 : 16x
Current             : 16x
Bridge Chip
Type                    : N/A
Firmware                : N/A
Replays Since Reset         : 0
Replay Number Rollovers     : 0
Tx Throughput               : 0 KB/s
Rx Throughput               : 0 KB/s
Fan Speed                       : N/A
Performance State               : P8
Clocks Throttle Reasons
Idle                        : Active
Applications Clocks Setting : Not Active
SW Power Cap                : Not Active
HW Slowdown                 : Not Active
HW Thermal Slowdown     : Not Active
HW Power Brake Slowdown : Not Active
Sync Boost                  : Not Active
SW Thermal Slowdown         : Not Active
Display Clock Setting       : Not Active
FB Memory Usage
Total                       : 16383 MiB
Used                        : 86 MiB
Free                        : 16297 MiB
BAR1 Memory Usage
Total                       : 256 MiB
Used                        : 2 MiB
Free                        : 254 MiB
Compute Mode                    : Default
Utilization
Gpu                         : 0 %
Memory                      : 0 %
Encoder                     : 0 %
Decoder                     : 0 %
Encoder Stats
Active Sessions             : 0
Average FPS                 : 0
Average Latency             : 0
FBC Stats
Active Sessions             : 0
Average FPS                 : 0
Average Latency             : 0
Ecc Mode
Current                     : Disabled
Pending                     : Disabled
ECC Errors
Volatile
SRAM Correctable        : N/A
SRAM Uncorrectable      : N/A
DRAM Correctable        : N/A
DRAM Uncorrectable      : N/A
Aggregate
SRAM Correctable        : N/A
SRAM Uncorrectable      : N/A
DRAM Correctable        : N/A
DRAM Uncorrectable      : N/A
Retired Pages
Single Bit ECC              : 0
Double Bit ECC              : 0
Pending Page Blacklist      : No
Temperature
GPU Current Temp            : 38 C
GPU Shutdown Temp           : 96 C
GPU Slowdown Temp           : 93 C
GPU Max Operating Temp      : 85 C
Memory Current Temp         : N/A
Memory Max Operating Temp   : N/A
Power Readings
Power Management            : Supported
Power Draw                  : 17.26 W
Power Limit                 : 70.00 W
Default Power Limit         : 70.00 W
Enforced Power Limit        : 70.00 W
Min Power Limit             : 60.00 W
Max Power Limit             : 70.00 W
Clocks
Graphics                    : 300 MHz
SM                          : 300 MHz
Memory                      : 405 MHz
Video                       : 540 MHz
Applications Clocks
Graphics                    : 585 MHz
Memory                      : 5001 MHz
Default Applications Clocks
Graphics                    : 585 MHz
Memory                      : 5001 MHz
Max Clocks
Graphics                    : 1590 MHz
SM                          : 1590 MHz
Memory                      : 5001 MHz
Video                       : 1470 MHz
Max Customer Boost Clocks
Graphics                    : 1590 MHz
Clock Policy
Auto Boost                  : N/A
Auto Boost Default          : N/A
Processes                       : NoneHi SSDYou need to have multiple (physical) GPUs to be able to use Multi-vGPU. So in your case, you’d need more than 1 T4 in your Server. You could then allocate 2, 3, 4 etc … T4-16* Profiles to a single VM.Even if it were possible, adding more than 1 vGPU from the same physical GPU wouldn’t do anything, as it’s the same physical GPU.Make sure you’re not confusing having Multiple GPUs on a single VM, vs Multiple VMs on a single GPU …RegardsMGAh ok, I’m used to the GRID K1 cards having multiple GPUs.So this solution we have bought cant present multiple vGPU’s to a single VM then, so this means we either buy more T4 cards to split up the processing or try to present other VMs to share the GPU, but as you say they will fight for contention/resources if both VM’s are hitting it at the same time correcct?So sounds like its not the preferred GPU card for this solution then, can you recommend card that would do what I’m asking of it?Hi MG, so the solution for us is to replace the single Tesla T4 card with 2 X RTX-5000 cards in the Host and simply do a direct pasthrough assignment presenting them to the 1 VM.Thanks for your assistance to date.Regards,
SSDPowered by Discourse, best viewed with JavaScript enabled"
242,a40-enable-displayport,"Hi,How do I enable the display port at the back of the GPU?
Manual says the physical outputs are disabled and in “virtualisation mode”.ThanksPowered by Discourse, best viewed with JavaScript enabled"
243,slow-performance-on-azure-vm-nvs12v3-with-nvidia-tesla-m60-8gb,"Hello forum,looks like i´m very stuck here. I´m trying to run a VM in Azure with a Nvidia Tesla M60. The performance is hell (i think about 1-4 frames per second). I followed the Guidelines on how to enable the dedicated GPU but with no effort. I´m using Citrix Workspace (2109) to access the Windows 10 multisession. Wether i use RDP or bastion the problem stays, i did run a test on WebGL water, the performance is very low. Even on my Laptop with non-dedicated graphics the perfomance is compared to the VM very well.I´m using the Nvidia GRID driver from microsoft (471.83 for Server 2019), dxdiag shows the correct adapter (NVIDIA Tesla M60 instead of the Indirect Display Adapter).What is the problem here? I wanted to run some 3D, CAD-Application - but i have no luck using the M60. The Graphics utilization monitor always shows (Inactive), it seems that the dedicated GPU is not used at all.Can you post the output from nvidia-smi -q from within the VM? I’m wondering if the VM is properly licensed…==============NVSMI LOG==============Timestamp                                 : Thu Dec  2 12:30:06 2021
Driver Version                            : 471.68
CUDA Version                              : 11.4Attached GPUs                             : 1
GPU 00000001:00:00.0
Product Name                          : Tesla M60
Product Brand                         : Quadro
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : N/A
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : WDDM
Pending                           : WDDM
Serial Number                         : 0322718043881
GPU UUID                              : GPU-e69f6e29-27d2-14ae-1ed2-4e1eefeb37ef
Minor Number                          : N/A
VBIOS Version                         : 84.04.9f.00.12
MultiGPU Board                        : No
Board ID                              : 0x10000
GPU Part Number                       : 900-2G402-0000-000
Module ID                             : 0
Inforom Version
Image Version                     : G402.0040.00.04
OEM Object                        : 1.1
ECC Object                        : 3.0
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GSP Firmware Version                  : N/A
GPU Virtualization Mode
Virtualization Mode               : Pass-Through
Host VGPU Mode                    : N/A
vGPU Software Licensed Product
Product Name                      : NVIDIA RTX Virtual Workstation
License Status                    : Licensed (Expiry: N/A)
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x00
Device                            : 0x00
Domain                            : 0x0001
Device Id                         : 0x13F210DE
Bus Id                            : 00000001:00:00.0
Sub System Id                     : 0x113A10DE
GPU Link Info
PCIe Generation
Max                       : 3
Current                   : 3
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : N/A
HW Power Brake Slowdown       : N/A
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 8192 MiB
Used                              : 206 MiB
Free                              : 7986 MiB
BAR1 Memory Usage
Total                             : 256 MiB
Used                              : 2 MiB
Free                              : 254 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
Single Bit
Device Memory             : N/A
Register File             : N/A
L1 Cache                  : N/A
L2 Cache                  : N/A
Texture Memory            : N/A
Texture Shared            : N/A
CBU                       : N/A
Total                     : N/A
Double Bit
Device Memory             : N/A
Register File             : N/A
L1 Cache                  : N/A
L2 Cache                  : N/A
Texture Memory            : N/A
Texture Shared            : N/A
CBU                       : N/A
Total                     : N/A
Aggregate
Single Bit
Device Memory             : N/A
Register File             : N/A
L1 Cache                  : N/A
L2 Cache                  : N/A
Texture Memory            : N/A
Texture Shared            : N/A
CBU                       : N/A
Total                     : N/A
Double Bit
Device Memory             : N/A
Register File             : N/A
L1 Cache                  : N/A
L2 Cache                  : N/A
Texture Memory            : N/A
Texture Shared            : N/A
CBU                       : N/A
Total                     : N/A
Retired Pages
Single Bit ECC                    : 0
Double Bit ECC                    : 0
Pending Page Blacklist            : No
Remapped Rows                         : N/A
Temperature
GPU Current Temp                  : 26 C
GPU Shutdown Temp                 : 91 C
GPU Slowdown Temp                 : 88 C
GPU Max Operating Temp            : N/A
GPU Target Temperature            : 85 C
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : Supported
Power Draw                        : 16.14 W
Power Limit                       : 150.00 W
Default Power Limit               : 150.00 W
Enforced Power Limit              : 150.00 W
Min Power Limit                   : 112.50 W
Max Power Limit                   : 162.00 W
Clocks
Graphics                          : 405 MHz
SM                                : 405 MHz
Memory                            : 324 MHz
Video                             : 405 MHz
Applications Clocks
Graphics                          : 557 MHz
Memory                            : 2505 MHz
Default Applications Clocks
Graphics                          : 557 MHz
Memory                            : 2505 MHz
Max Clocks
Graphics                          : 1177 MHz
SM                                : 1177 MHz
Memory                            : 2505 MHz
Video                             : 1083 MHz
Max Customer Boost Clocks
Graphics                          : N/A
Clock Policy
Auto Boost                        : On
Auto Boost Default                : On
Voltage
Graphics                          : N/A
Processes
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 2596
Type                          : C+G
Name                          : Insufficient Permissions
Used GPU Memory               : Not available in WDDM driver model
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 2712
Type                          : C+G
Name                          : Insufficient Permissions
Used GPU Memory               : Not available in WDDM driver model
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 8348
Type                          : C+G
Name                          : C:\Windows\explorer.exe
Used GPU Memory               : Not available in WDDM driver model
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 12800
Type                          : C+G
Name                          : Insufficient Permissions
Used GPU Memory               : Not available in WDDM driver model
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 13008
Type                          : C+G
Name                          : C:\Windows\SystemApps\Microsoft.Windows.Search_cw5n1h2txyewy\SearchApp.exe
Used GPU Memory               : Not available in WDDM driver model
GPU instance ID                   : N/A
Compute instance ID               : N/A
Process ID                        : 13988
Type                          : C+G
Name                          : C:\Program Files (x86)\Autodesk\Autodesk Desktop App\AutodeskDesktopApp.exe
Used GPU Memory               : Not available in WDDM driver modelGPU is licesend properly. I’m wondering if you enabled the GPU as default graphics adapter for RDSH? You need to configure a local policy. Otherwise you won’t see GPU utilization in RDP sessions.Hello Simon,i don´t intent to use rdp - i´m using Citrix Workspace App to connect remote to my VM.But i guess you meant this setting:
image1200×538 108 KB
Correct :)Right now, i´m reading your article about setting up the right configuration for citrix… (choosing the right remoting protocol…)i found it somewhere on the nvidia-website.In addition I wouldn’t disable the WDDM driver policy in your screenshot above. Never did this and I don’t really know how this affects the OS.The Citrix-Support told me to disable it, but i see it´s for VDAs 2006 or later. I´m disabling it now.I´m using WDDM now. I look at the graphic status bar now, shouldn´t it say GPU:Nvidia?No idea. Never used that indicator bar :) Why not simply check with nvidia-smi if you see GPU load ?
Or use a tool like GPUProfiler to make sure everything works as expected.Powered by Discourse, best viewed with JavaScript enabled"
244,nvidia-license-server-build-and-migration,"I have a deployed Legacy On-Premise License Server. I want to build the new License Server. If I do not touch the old deployment and I go to the NVIDIA Portal and build my new DLS Server and reassign my licenses to it. That should not break my old deployment correct? I should not be able to build a new parallel License Server and import the Licenses. My old lIcense server is version 11.5. I believe I read this means my vCPU software is not compatble with new License server. So I would need a new image with the new vGPU vWS software that is compatible. Once I test my new image and certify it. I would then update the software on my old images and repoint my old environment to the new servers. Does this sound correct?Correct, you should be able to deploy the new license server without touching the old environment.
Keep in mind that we currently only deprecated the legacy license server with vGPU 14. So starting with vGPU 15 you will need to move to the new license server appliance. CLS/DLS works with vGPU 13 and upwards. Which vGPU version do you run currently?11.5 . Yes I know we will need to update our image software. You gotta do what you gotta do…Thanks!Powered by Discourse, best viewed with JavaScript enabled"
245,changing-wddm-mode-to-tcc-for-p4000-and-p2200-in-esxi,"We have a customer project that requires using P4000 and P2200 as pass-through devices, passed to Windows VMs running on vSphere. Both cards come with WDDM as default operating modes. Since they are pass-through devices there is no driver installed on ESXi. Its a project requirement that when VMs come up the card is already in TCC mode. I know gpumodeswitch utility is only supported for M60 and M6 cards and Nvidia-smi is only installed on esxi along with the driver. If there a way or another utility we can use to change the WDDM mode to TCC in ESXi, instead of using nvidia-smi in Windows ?Powered by Discourse, best viewed with JavaScript enabled"
246,server-2019-gpu-acceleration-slow-p4000,"Hello, we have 3x Hyper-V Server 2019 with Nvidia Quadro P4000 Cards.So we will migrate to W10 1909 (4x vCPU, Dynamic Memory) VDI Environment, so i will test some GPU SettingsGPOs active on Hypervisor & Windows 10 1909:Use HardwaregraphicapterH.264 / AVC 444 - Graphicmode priorizeH.264 / AVC 444 - Activiate Hardware encodingOn W10 VDI i see AVC 444 Mode in eventlog Nr. 162:Der Client unterstüzt Version 0xA0600 des RDP-Grafikprotokolls, Clientmodus: 0, AVC aktiviert 1. Anfangsprofil: 2048I make some test with Paint 3D, its very slow and the cpu usage will raise till 50-80% (for example my Notebook 5%?).On the hypervisor i will see eventlog 170
""Encodername: NVIDIA H.264 Encoder MFT. Server: Servername"", but not the VM Name.Maybe AVC 444 Mode is active, but not the Hardware encoding on the VMDo i forgot some settings, do i need other drivers, maybe cuda toolkit?Thanks
Regards PascalHiIf you switch to 4.2.0 does that help with the experience?Which remoting protocol are you using?RegardsMGHi,
4.2.0 does not help.RDP 10 Protocol.So what i tested, i installed Windows 10 1809, setting up remotefx und what did happen?remotefx works, its an old feature, but gold.Graphicpower is available!On Windows 10 1909 i got RDP error, maybe i need new Nvidia Driver on HypervisorPowered by Discourse, best viewed with JavaScript enabled"
247,quadro-vdws-profiles-together-with-vcs-profiles-on-same-gpu,"Hi,Is it possible to use both Quadro vDWS profiles together with vCS profiles simultaneously on the same GPU? Or can these not be mixed on the same GPU?Best,KoenraadHiOnly a single Profile can be run on any GPU concurrently.That said, the vDWS license covers vCS, so you could if you wanted to use the vDWS license to run a vCS workload.Running Compute and Graphical workloads simultaneously on the same GPU would not be the best choice due to the nature of each workload. They would typically require different Scheduler configurations for optimal performance, and unless you ran ""Fixed"" or ""Equal"", the Compute workload would more than likely impact the Graphical workload. However, even this would still not be optimal due to different workloads and the standard Scheduler configuration (which would typically be ""tweaked"" for a specific workload).RegardsMGMakes sense Ben, thanks!KoenraadPowered by Discourse, best viewed with JavaScript enabled"
248,autorun-scripts-run-program-make-it-cant-run-based-on-the-cuda,"Hi,
I run my autorun script on Ubuntu 18.04,
and my program using cuda for OCR,
if I run the .sh script manually, it will cost around 10000MB of GPU (nvidia-smi)
if run it by autorun script, (autorun.sh → program.sh), then it only cost 155MB of GPU,
is there anything should I modified for my autorun script? it feels like my program didnt run based cuda and GPU…
ThanksPowered by Discourse, best viewed with JavaScript enabled"
249,deployment-failed-with-nvidia-quadro-vws-on-azure,"Hello team,I’m following the document below,Getting started information for all users of NVIDIA Quadro Virtual Workstation on Microsoft Azure.Release information for all users of NVIDIA Quadro Virtual Workstation on Microsoft Azure.and tried to deploy the Nvidia Quadro vWS Windows Server 2016 image, with NC12s_v3 VM on Azure, but got the following error. Same error occured when trying with ND series, which is also indicated supported from above doc.{""code"":""MarketplacePurchaseEligibilityFailed"",""message"":""Marketplace purchase eligibilty check returned errors. See inner errors for details. "",""details"":[{""code"":""BadRequest"",""message"":""Offer with PublisherId: ‘nvidia’, OfferId: ‘nvidia-quadro-vws-win2016’ cannot be purchased due to validation errors. For more information see details. Correlation Id: ‘xxxxxx’ The ‘unknown’ payment instrument(s) is not supported for offer with OfferId: ‘nvidia-quadro-vws-win2016’, PlanId ‘win2016-19-12-grid11-1’. Correlation Id ‘xxxxxx’.[{&quot;The ‘unknown’ payment instrument(s) is not supported for offer with OfferId: ‘nvidia-quadro-vws-win2016’, PlanId ‘win2016-19-12-grid11-1’. Correlation Id ‘xxxxxx’.&quot;:&quot;StoreApi&quot;}]""}]}“Marketplace purchase eligibilty check returned errors. See inner errors for details.
… The ‘unknown’ payment instrument(s) is not supported for offer with…”Your issue is in the error message plain as day.“The ‘unknown’ payment instrument(s) is not supported for offer with…”Please correct the payment issue and try again.If you need support with Troubleshooting Azure payment issues, I found this via Google:Resolving an issue when updating payment information account in the Azure portal.Please do come back and let us know if this resolved your issue or not. I know it’s been a long time, but I’m genuinely wanting to know you were successful.Powered by Discourse, best viewed with JavaScript enabled"
250,graphics-card-twin-monitor-total-control,"I have recently purchased an MSI NVIDIA GEFORCE GTX 1660 Super, VENTUS XS OC EDITION, graphics card. It seems to be working well.It is the case that the card has one HDMI port at the back, and that my (MSI) motherboard has one HDMI port at the back of it. I am running two monitors at the same time.-Is it the case that the NVIDIA graphics card has assumed total control of both monitors? The graphics card itself only has one HDMI slot, not two of them. If the NVIDIA graphics card has not assumed total control of both monitors, is there a setting that I can alter to make that happen? And if so, could someone issue a reply to my question here talking me through/showing me how to alter the appropriate setting so that I don’t have onboard motherboard graphics controlling my twin (2) screens, but that the NVIDIA card does so, despite that one screen remains plugged into the motherboard HDMI port?Powered by Discourse, best viewed with JavaScript enabled"
251,quadro-vdws-license-for-multi-os,"Hi all,We have a ""Quadro vDWS"" license. I have two questions:1- Is it possible to share GPU with this license between to deferent OS at the same time (Windows & Linux or Redhat and non-Redhat distro)? If yes please let me know how should we enable the license.2- If I want to share GPU for CentOS should I use the ""Linux KVM"" license?Thank you in advanceBest Regards,
AshkanHi AshkanYes, you can use Windows and Linux on the same GPU. If both VMs are powered on and in use at the same time, then you’ll need 2 QvDWS licenses. If you only have 1 license, then the VM that acquires the license first will be the only one that can be used with the GPU.There is no Operating System specific vGPU license, so you can use the vGPU license to support all Operating Systems.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
252,dell-7920-loops-on-bios-setting-after-using-nvidia-mode-selector-on-rtx-a5000,"Hello,I’m setting up a system for VDI solution with :DELL Precision 7920NVIDIA RTX A5000VMWARE ESX 7.0.2VMWARE Horizon 8To enable VGPU on the RTXA5000 for VmWare, I read in you support forum that I should use nvidia mode selector to turn the display mode OFFA6000 in vGPU 13.0 and ESXi 7.0u2 : Failed to start vGPU instance - Virtual GPU Forums / General Discussion - NVIDIA Developer ForumsI did it. But now my DELL 7920 Workstation doesn’t boot.It loops on entering setup.I tried to reset to factory settings, to upgrade the BIOS firmware to the latest version.But it is still not booting.Is there any specific action to do in BIOS setup to make it boot ?Thanks in advance,Best Regards,I have the same problemHi Boris,The Dell workstation does not support the RTX A5000 in SR-IOV mode.  You may need to add a second GPU that supports display output to enable the workstation to boot.Recommend you contact Dell about BIOS settings to support the GPU in SR-IOV mode.-D-Powered by Discourse, best viewed with JavaScript enabled"
253,gpu-passthrough-on-windows-10,"I want GPU access in Virtual Machine(Guest OS - Ubuntu).
The Host OS is Windows 10 and GPU is Nvidia T400.Powered by Discourse, best viewed with JavaScript enabled"
254,nvidia-smi-and-nvidia-persistenced-hangs-with-nvidia-driver-issue-on-a100,"Hi,We are running hosts on AWS p4d.24xlarge with Nvidia A100 GPUs that initialize nvidia-persistenced and prime GPUs before running a workload.We’re using Nvidia driver version 470.57.02 on Amazon Linux 1 (Linux 4.14.248-129.473.amzn1.x86_64).For a fraction of our workloads, we either observe nvidia-persistenced to fail with the error nvidia-persistenced failed to initialize. Check syslog for more details., or otherwise outright hang. In the cases where a hang occurs, we also observe nvidia-smi to hang in a similar fashion. nvidia-bug-report.sh also hangs, prior to generating any meaningful log (even with --safe-mode). In /var/log/messages, we observe the following stack trace:Any help would be appreciated!Powered by Discourse, best viewed with JavaScript enabled"
255,aws-nvidia-gaming-pc-windows-server-2019-updating-driver-to-442-59-lost-license,"Using an AWS EC2 g4dn.xlarge instance. When I try to update the NVIDIA gaming drivers according to the directions in section 4 of Install NVIDIA drivers on Windows instances - Amazon Elastic Compute Cloud the GRID license goes from GRID vGaming to GRID Virtual Applications and is limited to a resolution of about 1280x1024-1366x768. Without updates it was freezing in gameplay of Borderlands 2 at 1920x1080 and I wanted to see if driver updates might fix it. Any way to fix the GRID licensing?Powered by Discourse, best viewed with JavaScript enabled"
256,vgpu-license-portal-upgrade,"HiJust a heads up for those running vGPU …The vGPU License Portal has just undergone a large upgrade to the UI. It’s now much easier to use and there are additional features that have been requested as well regarding License Server manageability.Check it out here … https://nvid.nvidia.com/siteminderagent/forms/login.fccRegardsMGHi MrGrid,Can you point me to the part of the site that allows me to add a new entitlement? The old site was awkward but at least I could eventually do what I wanted, there is nowhere in this new portal where I can enter an order number or entitlement id to add newly purchased licenses to my enterprise account. Hoping you can help!–
LucasHi LucasFor first time customers the PAK is now hardcoded into their registration form. They redeem it as a function of the registration process.For current customers who purchase additional licenses, the new entitlement will be available when they log into the portal.Basically, the days of manually adding PAK keys are now behind us and this is (or should be) a system automated process. So when purchasing additional licenses from your vGPU license partner, please ensure they use the correct details so that the licenses / PAK appears in the correct account. They should not be providing you with a PAK any more.As this is a system automated task, I believe it takes up to 24hrs for the PAK to appear so you can draw down licenses against it.Hope that helps!RegardsMGHi MG,Thanks for your reply. I’ll go back to the vendor and try to figure out what the issue is. Can you clarify if the link between the vendor (we use Dell Digital Locker) and the NVIDIA License Portal is just the email addresses? I can’t see anything else that links the two sites.LucasHi LucasYes, your email should be enough for the License Distributor to locate you (as it will be unique within the NVIDIA Portal) and allocate the additional purchases.I don’t have any personal experience using Dell Digital Locker, but I’ve heard of a few issues previously. Whether these issues have been caused by Dells system, customer error with supplying incorrect details, an understanding of the system or a combination of all of them, I’m unsure.Although this is an older post, it’s worth just having a look here for reference. Simon (from NVIDIA) details the steps required for the Dell Digital Locker, although this was when the PAK method was being used so there will be a difference here, but they should help guide you in the right direction and set expectations around processing time.https://gridforums.nvidia.com/default/topic/1176/nvidia-virtual-gpu-drivers/tesla-m60-vib-drivers-for-esxi-host-/If you have a look and are still unsure about the process, it’s always worth speaking to Dell directly to help offer guidance this first time. Obviously if you have any issues or comments about the process after that, then come back to us on here and we’ll see what we can do.RegardsMGWell this is likely the issue seeing as the person who manages the license servers (me) is different from the person who buys the licenses (my boss). We’ll try to sort it out with Dell. Really appreciate your replies MG.LucasHi LucasThat shouldn’t be an issue. If the licenses are tied to you your Bosses email through Dell, then they may appear under that email address in the NVIDIA Portal (I’ve not used the Dell process so can’t comment on personal experience) … In the NVIDIA Portal, there is a Tab on the left called ""User Management"" where other members can be added to that account via email and you can be a ""Super User"" or ""Base User"". You should then be able to gain access to purchased licenses via your Bosses email.RegardsMGI login to the new portal site, I have nothing to Click to Access
1389×787 113 KB
HiDo you already have vGPU licenses allocated to that email account (Either 90 Day evaluation or already purchased)?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
257,dell-r740-with-tesla-m10-nvidia-smi-failed-to-initialize-nvml-unknown-error,"Server: Dell R740 - 384GB RAM, Tesla M10
OS: ESXi 6.5U3
nVidia Driver: 460.73.02
GPU: nVidia Tesla M10In the BIOS,
Memory Mapped I/O Above 4GB: Enabled
Memory Mapped I/O Base: 512GB
https://www.dell.com/support/kbdoc/en-ca/000144038/dell-poweredge-14g-esxi-returns-failed-to-initialize-nvml-unknown-error-with-nvidia-gpuhttps://kb.vmware.com/s/article/2064775
# esxcli hardware pci list –c 0x0300 –m 0xf
0000:40:00.0
Address: 0000:40:00.0
Segment: 0x0000
Bus: 0x40
Slot: 0x00
Function: 0x0
VMkernel Name: vmgfx3
Vendor Name: NVIDIA Corporation
Device Name: NVIDIATesla  M10
Configured Owner: Unknown
Current Owner: VMkernel
Vendor ID: 0x10de
Device ID: 0x13bd
SubVendor ID: 0x10de
SubDevice ID: 0x1160
Device Class: 0x0300
Device Class Name: VGA compatible controller
Programming Interface: 0x00
Revision ID: 0xa2
Interrupt Line: 0xff
IRQ: 255
Interrupt Vector: 0x00
PCI Pin: 0x00
Spawned Bus: 0x00
Flags: 0x3201
Module ID: -1
Module Name: None
Chassis: 0
Physical Slot: 4294967295
Slot Description: PCIe Slot 1; relative bdf 04:00.0
Passthru Capable: true
Parent Device: PCI 0:60:17:0
Dependent Device: PCI 0:64:0:0
Reset Method: Bridge reset
FPT Sharable: trueAs shown above, Module Name: None is not correct.  It should be Module Name: nVidiaDoes anyone know what could be causing the Failed to intialize NVML: Unknown Error?On my ESXi server, does xorg need to be started?  I still get this error whether xorg is started or not started.dmesgAs shown in DMESG, the nVidia module failed to load.Ok.  I solved it.The version of ESXi 6.5U3 that I was using is the latest from Dell but it’s still from Dec 2019.  I downloaded the latest patch updates (Feb 2021) for ESXi 6.5U3 from VMWare and patched the server.  Now the nVidia drivers work properly.From a quick google search, one of the patches fixes the maximum size allowed for VIBs.Powered by Discourse, best viewed with JavaScript enabled"
258,will-vgpu-release-13-2-include-support-for-rhel-8-5,"I’m running RHEL 8.5 with KVM, and it looks like the current release (13.1 from Nov 2021) only supports RHEL 8.4.What’s the likelihood that 13.2 will include support for RHEL 8.5?  I’m trying to decide if I should just wait, or if I should downgrade to RHEL 8.4.It seems that nvidia does minor version releases of the vGPU software every 2-3 months, so does that mean we might see 13.2 around Jan or Feb of 2022?Thanks!If you want to test RHEL with KVM today I would recommend downgrading to RHEL 8.4 and use vGPU 13.1.Unfortunately, I cannot comment on future releases of vGPU software and what OSes they will or will not support.:D:Understood, thanksPowered by Discourse, best viewed with JavaScript enabled"
259,c-series-vgpu-profile-in-vmware-vsphere,"Hi,Using nvidia vgpu software in version 13, are C-series vpgu type profiles supported in vmware vsphere ? The license is vWS.ThanksHi,I don’t get the full intention of this question. Which GPU are you using? vWS licensing is a superset of all the others, so why would you need C profile?
Would only be relevant for compute only GPUs (A30/A100/H100) where no vWS license is available as these GPUs don’t support graphics.regards
SimonC profiles are optimized for certain usages, such as compute-intensive server workloads, such as artificial intelligence (AI), deep learning, or high-performance computing (HPC). This profile better meets the requirements for our users.Could you please mention which GPU. I’m sorry to say that your assumption is wrong. vWS license contains all the C - profile features. You can even license a VM with a C- profile when you have only a vWS license in your licserverIt is A40. I did not say vWS does not contain C profiles. It does. But why C profiles do not appear in the selection menu, in the settings of the virtual machine, in vmware sphere ?Have same problem here, C-series Profile not appear on the list, any update for solving this? thanksHi,vSphere doesn’t contain C-profiles any more for vGPU as this is a new offering (Nvidia AI Enterprise) that contains the C-profiles.Powered by Discourse, best viewed with JavaScript enabled"
260,adobe-photoshop-crashing-when-using-tesla-p4,"Hi to allI have recently installed a bunch of VDAs which will be used to work with Adobe creative Cloud products. I recognized when I triy to open a various picture (BMP, PNG or JPG…), adobe keeps crashing. I have found out that disabling hardware GPU usage for Photoshop makes this problem disappear.I have tested Photoshop on my local Windows 10 with an older Quadro, and the problem didn’t occur.Specs:I hope to find help here.Thanks in AdvanceHi,we have the same problem with NVIDIA T4s.
Also 12.2 driver, VDA 2103 and ESXi 7.0 U2a.ThanksThanks for your feedback. Can you tell me if you had this problem before GRID 12?
My deployment is pretty new, so I cannot compare to earlier versions.I think it started with an Photoshop update. vGPU 12.2 worked.Did you ever solve this? I have a feeling that later Drivers don’t have this problem. But what I also found is that disabling the VMware sVGA graphics adapter should solve the problem. I am doing more tests right now to be sure.Powered by Discourse, best viewed with JavaScript enabled"
261,google-cloud-vms-failing,"I am trying to spin up NVIDIA provided images for google cloud VMs, such as nvidia-quadro-vws-win2019-1 and nvidia-gaming-windows-server-2019-2, but after choosing them from the marketplace and selecting ‘Launch’ I get a message: The reference ‘id’ is not found, reason: The resource ‘nvidia-gaming-windows-server-2019-2-vm’ exists, but the reference value does not.This is the product advertised here: Google Cloud console
image1736×912 72.9 KB
I am experiencing a similar issue.Powered by Discourse, best viewed with JavaScript enabled"
262,how-to-get-grid-release-installed-on-hypervisor-from-vm-running-on-that-hypervisor,"Hi,Is there a way of detecting what GRID drivers version is installed on hypervisor that a vm is running on? A way of doing that with no nvidia drivers installed on guest vm would be preferred, in case it can’t be done - with nvidia drivers installed then.The goal is to write a script that installs nvidia drivers automatically and, as guest driver version depends on hypervisor driver version, guest must detect hypervisor version somehow to know which guest drivers version to install.Regards,WladyslawPretty easy: simply run nvidia-smi on the hostThis is right response but my question was not precise enough. How to detect what GRID version is installed on hypervisor from within guest vm with vgpu assigned?Well, I guess you would need to run hypervisor CLI in order to be able to get the required host output. I don’t see another way to get the host context from VM guest.Powered by Discourse, best viewed with JavaScript enabled"
263,vgpu-nvidia-not-seen-by-windows-server-2016,"Running XenServer Hypervisor. When we boot old Windows 2012 Server, the Server sees the vGPU Nvidia GRID K260 - Result! BUT newly built Windows 2016 Server, just sees the Basic Microsoft Display Adapter.
Physically, the vGPU isn’t being passed. Help ?Which driver did you install? Screenshot from Device Manager?Installed NVidia GRID K2 but want to use GRID K260
image1083×502 87 KB
Just to add… DRIVER WON’T INSTALL on Windows 2016 Server because it can’t see it. We get “no compatible hardware detected”.
XenServer Hypervisor has the vGPU because on starting up old Windows Server 2012 VM on same Hypervisor Host…we see the GPU in Device Manager on Windows 2012 Server and therefore install of NVidia Driver works,Well, there is no GPU assigened to the VM otherwise the device manager would show a device. Please first assign the K260Q profile to the VM and try againGPU is assigned. It’s just not “seeing” it
image948×550 93 KB
GPU Assigned but NVidia still not visibleDid you find a solution to your issue?
We have the same issue with Citrix Hypervisor 8.2, NVidia Tesla-M10 and Windows Server 2016.Powered by Discourse, best viewed with JavaScript enabled"
264,nvidia-a2-video-card-on-a-dell-poweredge-t550-questions,"I come from a RemoteFX background before Microsoft retired it.Our goal is to have GPU acceleration for simple CAD applications inside a Microsoft HyperV environment.
Basically Parts Rendering, flat shaded, no Fluid dynamics, not advanced Physics of any kind.I had set up Discrete Device Assignment (DDA) with the NVIDIA A2 adapter. The Video card is visible inside the virtual machine (Windows 2022 Standard Server acting as the Remote Desktop Server) but when I try to run any benchmarks like Heaven, it throws out errors that there is no Direct X 11 support, etc. etc.I contacted Dell support and thus far, no response. NVIDIA Enterprise sales redirected me to this forum.My question is: Does the NVIDIA A2 support 3D graphics acceleration DirectX, OpenGL, Vulcan, or is it ONLY for AI Inference workloads and I am out of luck?I thank you in advance for any assistance you can provide.Thank you,
RichardYou are using the right GPU but you need also the right driver which is the vGPU driver.  So you need have vGPU licensing in place.
You can register for a vGPU evaluation to get the vGPU driver.90 Day Eval: Virtual GPU (vGPU) Software Free 90Days Trial | NVIDIABest regards
SimonSimon,Thank you for the response and I apologize in advance for all the newbie questions.Assuming I download the vGPU driver, is there an additional subscription cost
for the vGPU license? If the trial expires and there are vGPU driver updates will
there be an additional cost involved even though I may not need support?I am trying to set up a personal knowledgebase so I do not have to reinvent the wheel
with each server.In addition, all the youtube videos do not mention vGPU license. Two Gamers, One GPU from your Windows PC! Hyper-V Paravirtualization Build and Tutorial - YouTubeAgain, I am not interested in trying to get gaming cards to work in Hyper-V for a server.
My goal is always have Quadro levels of business cards so as to minimize any McGuyverish actions that need to be taken.On that note, does NVIDIA have a rough set of video cards that can work with SERVER HYPER-V DDA or GPU-P?Is it the new way to require vGPU driver for all server installations as, say, compared to the RemoteFX days where a WHQL or a Studio driver would suffice.Addendum: Given that I would not need AI acceleration currently, Would the NVIDIA T400 and T600 be less of an overkill? Would they still need VGPU drivers?Thank you again,
Richard.Addendum #2:Not interested in VDI. Only interested in Remote Desktop Session mode.Hi,please don’t mix-up workstation/gamer GPUs and datacenter GPUs.
vGPU is an enterprise grade product and therefore requires licensing but you also get enterprise support.
For RDSH deployment you will need such called vApps licenses for your CCU count. 20 concurrent users means 20 vApps licenses.
More details and list pricing you can find in our documentation:319.41 KBA2 is the cheapest datacenter GPU atm so I wouldn’t call it overkill :)
In general you need a GPU that supports Passthrough to run DDA. Quadro GPUs starting with >2000 range support PT and don’t require vGPU licensing but won’t be cheaper compared to A2 and there is still a difference in terms of virtual display support. vGPU drivers are made for this use case and fully support VGX, quadro drivers expect a physical display as these GPUs always have a physical display head which can cause issues if there is no monitor attached.
T400 or T600 won’t work at all.Best regards
SimonSimon,Thank you again and I apologize for being a pest:
Microsoft DDA instructions back from 2022 mention  no vGPU driver requirements.Learn how to use DDA to deploy graphics devices in Windows ServerAgain, I am not trying to be difficult here, but the whole point of the exercise is for it to be cheaper than buying 2K laptops for Fusion360 cad programs. when I hear Enterprise grade
my pockets squeal.We can get a physical dongle for a few $ that fixes the external monitor requirement.Again, I apologize for being all over the place, but Microsoft says one thing, NVIDIA another, Some testers something else, and it is hard to nail it down.Thank you,
HarryMAgain: It really depends on your requirements. You can use DDA with the available datacenter driver with no extra cost but as you have already seen, this driver is meant for DC usage (AI/ML) workloads and therefore doesn’t support graphics (pure TTC mode (tesla compute cluster)).
Anyways, there are different options to achieve your requirements. Feel free to decide whatever you wanna deploy. I don’t think the 25$ for a vApps user license is expensive for the value you get.Honestly speaking, deploying RDSH for CAD users with the intention to save money is the wrong approach and won’t work properly. You would also need to invest in proper remoting stacks like Citrix or VMWare to get the given remoting performance necessary. Even with VDI (which would be a much better approach) you won’t get the baremetal performance.
If you don’t have other arguments like simplfied management or flexibility, I would stick with the laptops.Best regards
SimonSimon,Thank you again. I will list some scenarios below and expectations and please tell me if my understanding is correct:Assuming the same A2 video card.In regards to the A2 video card, getting a VAPP license will allow it to be used for CAD Graphics work?VApp license: If I have a Remote Desktop Session host that serves 10 users and of those
users only 2 will be using the CAD program, do I need to get vAPP license for all 10 or can the vApp be activated for specific users and be transferable?Second scenario:  Remote Desktop Session host. Users would need basic 2D acceleration and basic 3D acceleration just for faster screen refreshes and to offload Chrome graphics rendering from the CPU.If I assume 1080p at 16-bit color for each monitor with each user having 4 screens, if I calculate total number of users will that be good starting point for GPU Vram requirements or will I need to reserve or account more GPU VRAM?GPU Paravirtualization. Microsoft has been unclear on support. What is NVIDIA’s stance and requirements on sharing a GPU with say 2 Remote desktop session host servers? What are the requirements and other considerations like MMIO space? Where is the MMIO space of say 32GB come from for some cards and is it reserved by the HOSTS RAM that I have to account for?What NVIDIA licensing considerations come into play with GPU-P?Thank you again,
HarryMIn regards to the A2 video card, getting a VAPP license will allow it to be used for CAD Graphics work?
-Depends on the CAD requirements. As I said, RDSH is always difficult. But yes, most applications should workVApp license: If I have a Remote Desktop Session host that serves 10 users and of those
users only 2 will be using the CAD program, do I need to get vAPP license for all 10 or can the vApp be activated for specific users and be transferable?
-For sure every CCU needs a license. You cannot prevent a user on a RDSH host with GPU to use the GPU therefore should be pretty clear that all users need to be licensedSecond scenario: Remote Desktop Session host. Users would need basic 2D acceleration and basic 3D acceleration just for faster screen refreshes and to offload Chrome graphics rendering from the CPU.
-Same license. Really makes no difference.If I assume 1080p at 16-bit color for each monitor with each user having 4 screens, if I calculate total number of users will that be good starting point for GPU Vram requirements or will I need to reserve or account more GPU VRAM?
-No, you need ~8GB FB for 15 CCU as a baseline. Depending on the use case (CAD apps) you might end up with way less users on the host.GPU Paravirtualization. Microsoft has been unclear on support. What is NVIDIA’s stance and requirements on sharing a GPU with say 2 Remote desktop session host servers? What are the requirements and other considerations like MMIO space? Where is the MMIO space of say 32GB come from for some cards and is it reserved by the HOSTS RAM that I have to account for?What NVIDIA licensing considerations come into play with GPU-P?See my comments inlineThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
265,nvidia-nvector-download-and-documentation,"Hello,Where can I download nVidia’s nVector benchmarking tool from?
Or is this for nVidia internal use only?Neither of the writeups below provide any links to download;655.33 KBIf you’re supporting the recent influx in remote work, you’ve probably noticed that business applications are more graphics-heavy than ever before. Applications such as Microsoft Office, Google Chrome…ThanksPowered by Discourse, best viewed with JavaScript enabled"
266,does-nvidia-dcgm-support-elasticsearch,"Does Nvidia DCGM support elasticsearch ?
We want to ship the metrics to elasticsearch. Please clarify.Powered by Discourse, best viewed with JavaScript enabled"
267,nvidia-vmware-vsphere-6-5,"We have upgraded a esxi host to 6.5 and the VIB to the supported NVIDIA-kepler-vSphere-6.5-367.64-369.71 downloaded from Nvidia’s website but the base machine will not start with the GPU (PCI shared device) enabled complaining about not enough GPU memory. When running ‘nvidia-smi’ on the host, it shows the cards:nvidia-smi
Thu Nov 24 00:04:52 2016
±----------------------------------------------------------------------------+
| NVIDIA-SMI 367.64                 Driver Version: 367.64                    |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GRID K2             On   | 0000:05:00.0     Off |                  Off |
| N/A   25C    P8    28W / 117W |     18MiB /  4095MiB |      0%      Default |
±------------------------------±---------------------±---------------------+
|   1  GRID K2             On   | 0000:06:00.0     Off |                  Off |
| N/A   23C    P8    27W / 117W |     18MiB /  4095MiB |      0%      Default |
±------------------------------±---------------------±---------------------+
|   2  GRID K2             On   | 0000:84:00.0     Off |                  Off |
| N/A   26C    P8    28W / 117W |     18MiB /  4095MiB |      0%      Default |
±------------------------------±---------------------±---------------------+
|   3  GRID K2             On   | 0000:85:00.0     Off |                  Off |
| N/A   24C    P8    27W / 117W |     18MiB /  4095MiB |      0%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0     68574    G   Xorg                                             7MiB |
|    1     68600    G   Xorg                                             7MiB |
|    2     68641    G   Xorg                                             7MiB |
|    3     68660    G   Xorg                                             7MiB |
±----------------------------------------------------------------------------+
[root@k2-3:~]Um, Xorg? The older esxi host down’t show that. Output from ‘gpuvm’gpuvm
Xserver unix:0, PCI ID 0:5:0:0, vSGA mode, GPU maximum memory 4173824KB
GPU memory left 4173824KB.
Xserver unix:1, PCI ID 0:6:0:0, vSGA mode, GPU maximum memory 4173824KB
GPU memory left 4173824KB.
Xserver unix:2, PCI ID 0:132:0:0, vSGA mode, GPU maximum memory 4173824KB
GPU memory left 4173824KB.
Xserver unix:3, PCI ID 0:133:0:0, vSGA mode, GPU maximum memory 4173824KB
GPU memory left 4173824KB.To me, something implies the VIB is not correct but that is the only 1 available via Nvidia’s website. Downgrading to NVIDIA-GRID-vGPU-kepler-vSphere-6.0-367.64-369.71 on the esxi host allows the base machine to start with GPU enabled, but View won’t compose a pool as it does not recognize the older GPU.Anyway, has anyone else upgraded their Vsphere to 6.5 and run into this issue or are we missing something simple?Thanks.Nevermind, the host graphics settings on each esxi that had been updated to 6.5 had reverted back to Shared and not Shared Direct. Once setting the host to ""Shared Direct"" and restarting xorg, all is well.This this exactly the problem I was running into, thanks for sharing the solution.vSphere 6.5 and November 2016 GRID drivers (both Kepler and Maxwell) require changing the default GPU mode from “Shared” (vSGA) to “Shared Direct” (vGPU) via vCenter to enable vGPU support for VMs.Not changing this will result in the VMs with a vGPU profile assigned to not start with the standard “graphics resources not available” error.For those that may be starting to evaluate the November 2016 GRID drivers with vSphere 6.5, an additional step to configure the GPU mode is required.Procedure:This new requirement and procedures will ba added to the documentation shortly, thank you for reporting this issue.I found this and configured my server this way.  It caused all my VMs set to use vmware svga to have issues.  I don’t need them to use the GPU at all.  I only wanted to enable for some.Is this the new way we need to configure?  To have all the VMs use the GPU, regardless of if needed?This happened to VMs that did not have the Shared PCI added with a profile.Hi,Thanks alot for this info. I was working with NVIDIA support team on SR  161202-000639 with no avail until I came with this community.Once again thanks alot Jeremy MainThis worked perfectly and make sure to restart xorg as mentioned by Yem above. I have edited my comments per @Sschaber below.@Taskman: There are different versions of vGPU manager. Our documentation is fully correct. We reference on the Maxwell based vGPU manager (>GRID 2.0) but there is still the kepler one for public download as this version is for K1/K2 only and doesn’t require a GRID license.RegardsSimon@Jmain: I tried to follow your procedure to change the GPU from ""Shared"" to ""Shared Direct"". Although I dont see Edit option available under Graphics setting for my ESxi host. I am running vsphere 6.0.0. Where else can I change the Graphics settings?Hi, this is an option only for vSphere 6.5. You won’t find it on 6.0!!!Hi - Any thoughts on how to fix the ‘GPU memory’ error if we are not on 6.5 vSphere ?  I am on 6.0.0 rev 3018524 of vSphere.  I just upgraded some Esxi hosts to 6.0 Patch 5 ( i.e. rev 5572656 ).  I now can not turn on any VM’s with a K2 card. Do i need to force them to vGPU mode ?  im trying to figure out how to do that now with the rev’s im at . Any ideas?  thanks.@bobtheslob: We have the same issue after upgrading to ESXi 6.0 Patch (Build 5572656). I’ve opened a case at VMware. I will inform you, if I have any news.Friends. With the video card K1 the same problem. I decided temporarily through shared direct. We are waiting for correctionsHi - I’ve received an answer from VMware, they have sent me a link to kb2150498: https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&cmd=displayKC&externalId=2150498
I’ve followed the instructions and copied the attached xorg file, after that I was able to start the service and the VMs again without changing the graphic settings. It seems that there is no other fix for this issue on ESX 6.0 Patch 5 (Build 5572656) with vCenter 6@Neo2k4: Thanks for the link to the article. I will track the decisionThank you!  This resolved our issue.vSphere 6.5 and November 2016 GRID drivers (both Kepler and Maxwell) require changing the default GPU mode from “Shared” (vSGA) to “Shared Direct” (vGPU) via vCenter to enable vGPU support for VMs.Not changing this will result in the VMs with a vGPU profile assigned to not start with the standard “graphics resources not available” error.For those that may be starting to evaluate the November 2016 GRID drivers with vSphere 6.5, an additional step to configure the GPU mode is required.Procedure:This new requirement and procedures will ba added to the documentation shortly, thank you for reporting this issue.I performed this extra step, rebooted and my vm is still not powering on and giving the error ""graphics resource not available"". Any suggestions? Which documentation outlines these steps btw?Ok. I’m getting conflicting info. Should the Tesla M60 GPU card be in PCI passthrough on the ESXi host, or should it not be, in order for vGPU to work? GRID requirements use to state GPU passthrough, but what about Tesla M60? Does the VIB take care of all of that? When I place into passthrough I now notice xorg won’t start and nvidia-smi complains of an initialization error.
So, what’s the correct procedures for ESXi 6.5 with Tesla M60 and Horizon View 7.3 in order to utilize vGPU?For sure you can’t run the GPU in PCI Passthrough if you want to use vGPU.I’m on ESXI 6.5 not using vCenter how do I enable shared-direct graphics? I can’t find the option anywhere.I tried to do it through esxcli but it says I can only set the GPU to Shared, or SharedPassthruPowered by Discourse, best viewed with JavaScript enabled"
268,mixing-vgpu-profiles,"Hi all,is it now possible to mix different vGPU profiles/framebuffers on one gpu, e.g. on RTX8000?
I read about the MIG feature of the a100 an so on, but whould it be possible to have different vGPU profiles (2Gb/4Gb) for Windows 10/11 VMs?thank you. best regards
KevinHi Kevin,at this stage no. What is currently supported (starting with vSphere8) is running different profile editions like 1B and 1Q on the same GPU. Different FB sizes on the same GPU is something that we’re looking at but won’t be possible on older generations like Turing.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
269,unable-to-get-davinci-running-on-vgpu-on-a100,"I don’t know where to get with this. Any help anyone?Davinci seems unable to start with driver issues.Oracle Baremetal a100 seemed to work:https://blogs.oracle.com/cloud-infrastructure/post/media-and-entertainment-apps-on-oracle-cloud-add-more-magic-to-davinci-resolve-studio-17-with-nvidias-a100-gpu-on-oracle-cloudMig and OpenGL are not supported but nvidia-smi says MIG is disabled.T4 on VM/Grid worked just fine.Thanks on any input.Hi,
first of all it would help if you could describe more details what you are going to achieve and which OS you are using.
A100 is not supporting Windows so I assume this is the main issue here.Best regards
SimonHello,and thanks for kind words.I am still trying to get A100 to work on Windows, tried Servers and 10 with different driver versions. nvidia-smi reports the driver loaded and such but Davinci gives an error on start.I haven’t tried Ubuntu as I haven’t found good remote desktop solution. xrdp is slow, nomachine or tigervnc with some settings let davinci (with T4) to start but black window where video was supposed to be.my best regards,AnttiAs I said, you won’t get the A100 to work with Windows as there is no driver available that support WDDM mode which is required for your use case. So no matter if you test with Win10 or Server OS, always the same issue. You can only choose a GPU that supports graphics (all datacenter GPUs except A100, H100 and A30).Thanks,very good and thorough explanation. Bonus points for the list, A100, H100, and A30.sincerely,AnttiPowered by Discourse, best viewed with JavaScript enabled"
270,how-to-create-virtual-displays-using-nvidia-grid-driver-api-on-windows-vm,"I have a windows VM on google cloud which has got NVIDIA GPU (Tesla T4 - Driver Version: 461.33). It has also got Google Graphics Array driver installed.I have a requirement where I need atleast one additional display(virtual display) which I have to enable/disable at runtime. I am trying to enable/disable the virtual displays using NVIDIA Grid driver API. But I am unable to find proper documentation and API description to accomplish this.Any kind of help would be greatly appreciated.Shouldn’t need to use the GRID API for this.See instructions on to setup a virtual Workstation on GCP here: Creating a virtual GPU-accelerated Windows workstation | Cloud Architecture Center | Google CloudI suspect you are not using the GRID driver.-D-Powered by Discourse, best viewed with JavaScript enabled"
271,vgpu-licence-settings-on-linux,"Hello,I just succeeded to get the VGPU license in my Windows machine. But doing it on Linux, I got some troubles.First no server addess was needed when I did it on Windows. But gridd.conf needs server address, where can I get it? I can’t find it on Nvidia web portal.So I left it as empty, so after I restarted gridd, I can see the logs like:
Jul 14 05:35:53 ubuntu-server nvidia-gridd[1512]: Configuration parameter ( ServerAddress  ) not set
Jul 14 05:35:53 ubuntu-server nvidia-gridd[1512]: vGPU Software package (0)
Jul 14 05:35:53 ubuntu-server nvidia-gridd[1512]: Ignore service provider and node-locked licensing
Jul 14 05:35:53 ubuntu-server nvidia-gridd[1512]: NLS initialized
Jul 14 05:35:53 ubuntu-server nvidia-gridd[1512]: Failed to decode signature from token received
Jul 14 05:35:53 ubuntu-server nvidia-gridd[1512]: Failed to read configurations from client configuration token (Error: Invalid client configuration token - signature validation failed)
Jul 14 05:35:53 ubuntu-server nvidia-gridd[1512]: Failed to setup Cloud License Manager: 3Is it because the server address is empty? Or is there any wrong in the client token which resides at /etc/nvidia/ClientConfigToken/client_configuration_token_07-14-2022-13-47-50.tok with permission 744 (which I downloaded from Nvidia web portal)?Hi,the server address is encrypted in the client token. It seems your token is not working. Please check your license assignment in the portal and create a new client token.
Make also sure that the client token file is the only file in the ClientConfigToken folder.regards
SimonThanks for the quick reply. Yes. You were right.I only copied and pasted the string in the token file. But it seems that there are non visible characters at the end of the string. So it’s magically working after I copied file itself. Thanks!Powered by Discourse, best viewed with JavaScript enabled"
272,ffmpeg-vgpu-licensing,"I currently have P2000’s, but looking to move to a blade server form factor. As a result, that forces me into the M6 or P6. I am running multiple VM’s that use FFMPEG for video encoding leveraging the NVENC encoder. What license level is required for that from Nvidia?NVENC is available for all license editions. Anyways, I would recommend to look after hardware that uses Tesla T4 for FFMPEG.Could I revive this thread as I have the same question but was expecting a different answer.We are would like to use a single P4 GPU and share this with four VM’s running FFMPEG. Which NVIDIA VGPU Software Product do we need? It looks like 4x vWS CCU but this seems very expensive for our dev environment. Any advise is welcomed.Powered by Discourse, best viewed with JavaScript enabled"
273,flickering-screen-on-rds-connection-to-windows-server-2019-with-vgpu-9-0-driver,"Has anyone seen an issue with flickering after upgrading to Windows Server 2019 and/or VGPU 9.0? Trying to find out what specifically has led to this. Do not see this at all with the combination of Windows Server 2016 and VGPU 8.0. One of our departments did a big upgrade and now our users are experiencing this. The GPU in use is a T4 on a standalone physical server.It’s affecting everything on the screen when connecting to an RDS session to Windows 2019 with driver version 431.02 on the server.  All graphics appear to be affected. Does anyone else see these symptoms?This seems to be possibly related to the image itself. We are investigating further, as we have some configurations that do not show these symptoms.It looks like the issue was with a defective Windows image. It was rebuilt from scratch and the problem went away. Case closed.Powered by Discourse, best viewed with JavaScript enabled"
274,nvidia-ampere-a16-and-nvidia-tesla-4-with-vmware-vmotion,"Can the Tesla T4 (Server 1 T4-2A) and Ampere A16 (Server 2 A16-2A) graphics cards work together in VMWare with VMotion? We are no longer getting a Tesla T4 from Dell.Hi Jan,this is not possible. You can only use vMotion to migrate profiles to identical GPUs. Currently you can only try to get some T4s on the retail market or from other OEMs if you want to keep you hardware homogenous.Best regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
275,driver-not-loading-vmware-esxi-8-update-1-15-2-vgpu-driver,"I’m trying to set up my lab.Platform:  AMD Ryzen Threadripper PRO 5955WX
GPU: nVIDIA RTX a5000
OS: VMWare vSphere ESXi 8.0 Update 1I signed up for an evaluation account and downloaded the drivers a month ago.  I followed the guide to install the VIBs for the vGPU driver and the management daemon.After installing both, I took the host out of maintenance mode, and restarted the host.  I knew I was in trouble right away when errors showed up during boot.  I checked, and found the following entries in the vmkwarninglog:To double-check the error and test the install, I first ranand received the expected outputThen, I ran nvidia-smi… I get the errorI tried uninstalling the VIBs and re-installing them twice.  Didn’t help.  What should I do to troubleshoot?Thanks.Powered by Discourse, best viewed with JavaScript enabled"
276,vgpu-10-4-on-esxi-6-7,"Hello,I’m trying to install NVidia drivers on Virtual Machines which are running on VMware ESXi 6.7 U3 host, I’ve checked all compatibility matrixes and found that vGPU 10.4 with Driver 443.66 should run perfectly on guest OS Windows Server 2019, although everything was smooth during the vGPU manger installation and adding Shared PCI Devices to VMs, the VM driver installer failed on system check giving the error:
""This NVIDIA graphic driver is not compatible with this version of Windows.""
""This graphic driver could not find compatible graphic hardware.""I’ve checked compatibility matrix and the versions are correct, and when I check device manager on the VM I only see VMware vSGA under Display Adapters and one 3D controller under Other devices.Additional Details:
Host:  HPE Apollo 6500
GPU:   NVidia Tesla v100s
Host OS: ESXi 6.7U3
vCenter Version: 6.7U3j
vGPU Manager: GRID 10.4
Guest VM OS: Windows Server 2019 Std
NVidia Driver: 443.66
CUDA: 10.2Appreciate any thoughts or input that might help. Thanks…Are you sure you run the right Windows driver from the vGPU package? You could check the .inf file from the NV driver to make sure the device ID for the V100 profile you have chosen is listed.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
277,about-licensing-nvidia-vmware,"We would like to upgrade our hardware but have a hard time figuring out what kind of nVidia and VMware licenses are needed.We currently have every host with a GRID K1 card and use VMware’s Essential Plus license.
The card is assigned in PCI passthrough mode to a single Citrix machine that we use for shared desktop.The new host that was proposed to us has a T4 card, but they told us that it is necessary to switch to use vGPU and upgrade the VMware license.
We want to keep PCI passthrough mode (the entire card assigned to a single machine) and, above all, we do not want to update the vmWare license…is it possible? We have not found clear documentation about it…As long as you use the T4 in Passthrough there is no need for VMWare Enterprise Plus. But you will need Nvidia vApps licenses no matter if you use Passthrough or vGPU.regards
SimonThanks Simone!Is there a link or document where it is clearly written? :-)Here you can see that vGPU requires Enterprise Plus:Release information for all users of NVIDIA virtual GPU software and hardware on VMware vSphere.If you run only Passthrough you can trust me that you are fine with vSphere Standard Edition :)I believe you, it is that I have to convince others! :-)Thanks again!Powered by Discourse, best viewed with JavaScript enabled"
278,is-gpu-pass-through-on-nvidia-quadro-rtx-3000-on-a-win11pro-laptop-possible,"I want to test CAD software in Hyper-V and have it use the host GPU.Is GPU pass-through possible on a very-high-spec CAD workstation laptop with an nVidia Quadro RTX 3000 running Windows 11 Pro possible?I wish to try this on the Windows 11 Enterprise Hyper-V (Gen2) evaluation development environment that can be downloaded from https://developer.microsoft.com/en-us/windows/downloads/virtual-machines/Any pointers as to how to do this would be greatly appreciated.
ThanksPowered by Discourse, best viewed with JavaScript enabled"
279,vfio-migration-supported-gpu-cards-info,"Hi,I would like to know if any of the Nvidia GPU cards have vfio migration capability/support available.
I specifically tried to probe(using qemu) for vfio migration region info from Tesla T4 and Tesla M60 GPUs but get “Error: VFIO device doesn’t support migration” (using linux kernel 5.15)Any example references around vfio migration supported GPU cards would be helpful.ThanksPowered by Discourse, best viewed with JavaScript enabled"
280,active-type-gpu-basic-esxi-7-03,"Hello. Have troubles with card Tesla M40, cannot change active type from Basic to Shared direct. Card not passthrough, driver installed, but when typed command nvidia-smi via ssh on host, the output is: “NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.” In packages I see driver with version 460.32.04-1OEM.700.0.0.15525992. I don’t know what to do, need help. Platform is HPE Gen10 DL380Hi,
first of all I hope you meant the A40 and not the M40. You need at least the vGPU 13.x version to have support for Ampere GPUs. Please download the right package from our Nvidia licensing portal.Best regards
SimonOk, I’ll try it. Thank youPowered by Discourse, best viewed with JavaScript enabled"
281,gui-not-loading-properly-after-nvidia-driver-install,"Hi,I’m trying to configure a RHEL 7 VM with a Tesla M10 vGPU. I’ve successfully installed the driver in the ESXi host and the RHEL 7 VM. I’m also able to get the card details via nvidia-smi in both the host and VM. I’ve blacklisted and disabled the nouveau driver and I’ve (manually) configured X to use the nVidia driver instead of the nouveau driver. When I boot up the VM the UI seems to start up (you can see the RHEL 7 wallpaper) but it never shows the user list or prompts for credentials. It just hangs, only showing the RHEL 7 wallpaper. It seems like something must be off as the expectation after installing the driver is to open the nVidia X Server Settings app (which I can’t do without a functioning UI). I can successfully SSH to the VM.Any ideas on what might be wrong?Thanks,
-JayIt seems our problem does not resolve here.Powered by Discourse, best viewed with JavaScript enabled"
282,vgpu-software-installation-fail-on-sles-15-sp2,"Hi,I’m installing NVIDIA vGPU software for Linux KVM 8.3 on SLES 15 SP2.
Currently, I’m blocked by this error:ERROR: Neither the ‘/include/linux/version.h’ nor the ‘/include/generated/uapi/linux/version.h’ kernel header file exists.  The most likely reason for this is that the kernel source files in ‘/usr/src/linux’ have not been configured.It seems the installer requires kernel headers to be installed. In SUSE, it’s included in kernel-devel package and it’s already installed in my server.
Does anyone have any idea on this? Thanks in advance!ceeinfra@compute3:~> cat /etc/os-release
NAME=“SLES”
VERSION=“15-SP2”
VERSION_ID=“15.2”
PRETTY_NAME=“SUSE Linux Enterprise Server 15 SP2”
ID=“sles”
ID_LIKE=“suse”
ANSI_COLOR=“0;32”
CPE_NAME=“cpe:/o:suse:sles:15:sp2”ceeinfra@compute3:~> uname -r
5.3.18-24.46-defaultceeinfra@compute3:~> zypper se -si kernel
Loading repository data…
Reading installed packages…S  | Name                  | Type    | Version         | Arch   | Repository
—±----------------------±--------±----------------±-------±-------------------------
i+ | kernel-default        | package | 5.3.18-24.46.1  | x86_64 | Module-Basesystem-Updates
i+ | kernel-default        | package | 5.3.18-24.46.1  | x86_64 | hostos
i+ | kernel-devel          | package | 5.3.18-24.46.1  | noarch | Module-Basesystem-Updates
i+ | kernel-firmware       | package | 20200107-3.15.1 | noarch | Module-Basesystem-Updates
i+ | kernel-firmware       | package | 20200107-3.15.1 | noarch | hostos
i  | kernel-macros         | package | 5.3.18-24.49.2  | noarch | Module-Basesystem-Updates
i  | purge-kernels-service | package | 0-6.2           | noarch | Module-Basesystem
i  | purge-kernels-service | package | 0-6.2           | noarch | hostosFixed by installing the kernel-default-devel package.In suse 12,I install nvdia driver also encounted same error.I compare the ever installed machine.find the kernel-default does not same,the new machine i update the kernel from 4.4.73 to 4.4.92.I find the version.h come from directory of /usr/src/linux-4.4.73-5/include/linux have a soft link directory source and kernel，but in /usr/src/linux-4.4.92-5/include/linux  does not have the two link directory.so I create the two not exist link directory to new kernel directory，then i twice install by command ”sh NVIDIA-Linux-x86_64-470.63.01.run -q“ success，all done。Powered by Discourse, best viewed with JavaScript enabled"
283,a100-80gb-pcie-opengl-directx,"Hello,I can run CUDA and OpenCL on the A100 with the Datacenter driver. Which one do I need for OpenGL and DirectX? vGPU has no support for A100 anymore…ThanksPowered by Discourse, best viewed with JavaScript enabled"
284,getting-an-error-while-installing-nvidia-driver-on-ec2-server,"I’m trying to install nvidia driver on my aws-ec2 instance, it’s worked fine until I reboot my system, and get error saying nvidia-smi failed. I tried to uninstall and re-install but I am getting this weired error:Errors were encountered while processing nvidia-dkms-470 nvidia-driver-470 E: Sub-process /usr/bin/dpkg returned an error code (1)anyone might know how to fix this issue? thanks!Powered by Discourse, best viewed with JavaScript enabled"
285,session-not-logging-off-when-application-has-been-closed,"Hi,We are running Xenserver 7.5, Grid 6.2 en CVAD 1808.2. I’ve got Xenapp en desktop, in which i both got applications published. When i shut down the app on the Xenapp(on VMWare), it logs off the session. When i do this on the Xendesktop with P4 2q profile(on Xenserver) it keeps the session active, not even disconnecting it.When i check the connection center in the Workspace app, it tells me that the nvidia settings stays open.How can i keep this from passing through to my clients?1808 is not tested /supported with 6.2 yet as it was released only a few days ago.Hi,Installed Grid 6.3, which makes 1808 supported.Session is still nog logged off when the application is closed. Tested with 2 applications, Word and Solidworks.Looks like something from the driver keeps the session open.And which process?
What are you doing? Published App or Published Desktop? If it’s NVTray there is a Regkey to prevent it showing in all RDS sessions.Hi,Published App. Added the StartOnLogin Dword 0 in HKCU\Software\Nvidia Corporation\NvTray, but no changesHi,you should use the following location:
HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\nvlddmkm\NvTrayregardsSimonHi TomPlease determine which process is preventing the session from logging off, and add the process to the reg key:Graceful logoffs from a published application launched in a seamless, fixed window, or as an RDP Initial Program, might result in the session not closing and the user being logged off. Sessions can be reset or exited correctly by manually resetting...Had the same problem with applications and added multiple processes to the reg key, like Kaspersky, Acrotray etc.Regards, CedyPowered by Discourse, best viewed with JavaScript enabled"
286,can-i-use-nvidia-rtx-vws-subscription-license-in-vms-of-vmware-essentials,"Hi. Can I use NVIDIA RTX vWS Subscription license in VMs of VMWare Essentials?No, you need Enterprise Plus licensing on the VMWare side to be able to use vGPU.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
287,k8ss-pod-fail-to-find-gpu,"general condition, we were able to executed nvidia-smi in the pod.but I attached  --cpu-manager-policy=static of kubelet cmd parameter ,after executed nvidia-smi in the pod that show error message failed to initialize NVML: unknow errorwe need this parameter. how can we solve it?system info below.
kubernetes 1.21
nvidia driver 495.46 RTX3090Ti
nvidia-device-plugin 1.10Powered by Discourse, best viewed with JavaScript enabled"
288,gpu-0-overheating-if-1-tesla-k80-installed,"Chassis: Supermicro | Products | SuperServers | 1U | 1027GR-TRF
OS: Ubuntu 20.04.2 LTSWhat I’ve tried so far:Seems like a BIOS or software issue. Any idea where I’m going wrong?Here is nvidia-smi during training:
Wed May 26 12:26:00 2021
±----------------------------------------------------------------------------+
| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:04:00.0 Off |                  Off |
| N/A   91C    P0    93W / 149W |  11658MiB / 12206MiB |    100%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   1  Tesla K80           Off  | 00000000:05:00.0 Off |                  Off |
| N/A   67C    P0    89W / 149W |   8125MiB / 12206MiB |    100%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   2  Tesla K80           Off  | 00000000:08:00.0 Off |                  Off |
| N/A   75C    P0    83W / 149W |   8125MiB / 12206MiB |    100%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   3  Tesla K80           Off  | 00000000:09:00.0 Off |                  Off |
| N/A   60C    P0    92W / 149W |   8125MiB / 12206MiB |    100%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   4  Tesla K80           Off  | 00000000:87:00.0 Off |                  Off |
| N/A   39C    P0    90W / 149W |   8125MiB / 12206MiB |    100%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   5  Tesla K80           Off  | 00000000:88:00.0 Off |                  Off |
| N/A   53C    P0   100W / 149W |   8125MiB / 12206MiB |    100%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
It seems to only be GPU0 that ever reaches any significant temps. The others stay in normal ranges.One additional point I noticed. I got ipmitool working. But when I check the GPU temperatures, it says “No reading”.For now I have set the fan setting to “Full” in ipmicfg from Supermicro. That is keeping the GPUs all cool during training. But I am not looking forward to the electric bill. Is there a way to get ipmi to recognize the temperatures? I think if I can do that, it will take care of the rest on Optimal setting. TIAPowered by Discourse, best viewed with JavaScript enabled"
289,citrix-session-host-nvidia-consulting,"Good morning all,Environment:Our use is Microsoft Office / (many applications) browser (IE / Google chrome / Firefox), MS Teams, Business application (use only CPU) and video (training, youtube)I’d would like to add graphics cards to my ESX hosts for my Citrix VMs for more performance.In terms of the configuration between Vmware and the GPU, what should be taken into account?
In the study we would have gone on a Tesla T4 16giga Gpu per server / host.How works the sharing (at Vmware level) of the graphics card between my citrix vm?In addition to the GPU, there is the license. Could you explain to me how it works?r4zer69Powered by Discourse, best viewed with JavaScript enabled"
290,tesla-p4-low-speech-when-render-video-720p,"I have a Tesla P4 GPU installed on a Dell R630 server with driver version 430.83. However, when I test the speed with and without the GPU, they are the same. Sometimes the performance without the GPU seems even better. Can anyone using a Tesla P4 explain this? Is this speed normal? If it’s not, please guide me on how I can improve the speed.Render with None-GPU:
ffmpeg -y -i input.mp4 -s hd720 -c:v libx264 -crf 32 -c:a aac -strict -2  output_hd.mp4
Output #0, mp4, to ‘output_hd.mp4’:
Metadata:
major_brand     : mp42
minor_version   : 0
compatible_brands: isommp42
encoder         : Lavf58.29.100
Stream #0:0(eng): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 2049:2048 DAR 683:384], q=-1–1, 30 fps, 15360 tbn, 30 tbc (default)
Metadata:
creation_time   : 2023-06-30T08:39:34.000000Z
handler_name    : Mainconcept MP4 Video Media Handler
encoder         : Lavc58.54.100 libx264
Side data:
cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1
Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)
Metadata:
creation_time   : 2023-06-30T08:39:34.000000Z
handler_name    : Mainconcept MP4 Sound Media Handler
encoder         : Lavc58.54.100 aac
frame= 7105 fps= 92 q=38.0 size=    4864kB time=00:03:57.21 bitrate= 168.0kbits/s speed=3.07x
Render with GPU Tesla P4:
Output #0, mp4, to ‘output_hd.mp4’:
Metadata:
major_brand     : mp42
minor_version   : 0
compatible_brands: isommp42
encoder         : Lavf58.29.100
Stream #0:0(eng): Video: h264 (libx264) (avc1 / 0x31637661), nv12, 1280x720 [SAR 2049:2048 DAR 683:384], q=-1–1, 30 fps, 15360 tbn, 30 tbc (default)
Metadata:
creation_time   : 2023-06-30T08:39:34.000000Z
handler_name    : Mainconcept MP4 Video Media Handler
encoder         : Lavc58.54.100 libx264
Side data:
cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1
Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)
Metadata:
creation_time   : 2023-06-30T08:39:34.000000Z
handler_name    : Mainconcept MP4 Sound Media Handler
encoder         : Lavc58.54.100 aac
frame= 4285 fps= 62 q=38.0 size=    2816kB time=00:02:23.29 bitrate= 161.0kbits/s speed=2.09xBelow is ffmpeg worked with GPU±----------------------------------------------------------------------------+
| NVIDIA-SMI 430.83       Driver Version: 430.83       CUDA Version: 10.1     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P4            On   | 00000000:00:10.0 Off |                    0 |
| N/A   44C    P0    24W /  75W |    287MiB /  7611MiB |      2%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0       983      G   /usr/lib/xorg/Xorg                            59MiB |
|    0      1058      G   /usr/bin/gnome-shell                           8MiB |
|    0     81322      C   ffmpeg                                       209MiB |
±----------------------------------------------------------------------------+Thank you in advance.
Best regards and thank you.Powered by Discourse, best viewed with JavaScript enabled"
291,nvidia-vgpu-software-15,"Hi, I have a concern.VMware Horizon View 8, I have NVIDIA driver 513.46 in use, which works fine.When I update the existing NVIDIA driver to version 527.41 (15), then the connection to the license server no longer exists. I have (according to instructions “525.60.12-525.60.13-527.41-grid-licensing-user-guide”) adjusted the registry in Windows but still it does not work.What I still miss in NVIDIA Control Panel is the menu for the entry for the license details?Can anyone here give me some advice on, how to solve this problem?Cheers,
DraganHi Dragan,do you already use NLS (CLS or DLS)? Flexera is not supported any more with vGPU 15.0.
With the client tokens there is no license details in NVCPL at all.regards
SimonHello Simon,Thanks for the quick feedback. I suspected that this is the problem, but I was not so sure, because the license server is not with me. I will then order to migrate the license server.For the client tokens, good to know that it is so.To check if the license is assigned to the VM, is that the only way to check with “nvidia-smi -q”?Regards,
DraganCorrect, nvidia-smi -q is the only option atm.cool, thx Simon.Regards,
DraganPowered by Discourse, best viewed with JavaScript enabled"
292,nvidia-quadro-gv100,"Hello all,Sorry if this is not the right venue for this, but I search the forum and the internet and could not find the information that I am looking for.I am in the process of purchasing a decommissioned Nvidia GV100 that I am planning on using in a Proxmox (Debian - KVM) host running multiple Windows VM to perform scientific simulations (FEA code which has been optimised for CUDA according to the software vendor)). I have already done GPU passthrough on a handful of cards without too much hassle. My question is around the GV100 and whether this card will behave just like a regular Quadro.From reading the literature on Nvidia Grid, it seems that the GV100 is not on the required hardware list, however given its expensive nature, I wanted to double check prior to taking the plunge. So here is my question, can GV100 be passed to a Windows VM without any additional special license (I am not looking to share the GPU across other VMs).TIA!HiThe GV100 is the Quadro equivalent of the V100 (Tesla). It supports Passthrough only or you can use it in a typical workstation tower chassis. It does not support vGPU and does not require any licensing.If you wanted a Quadro GPU that also supports vGPU you’d need to use the Actively cooled version of the RTX6000 / RTX8000 or the A6000 (all 3 of those GPUs are Quadro).RegardsMGThanks a bunch, that’s what I thought.Powered by Discourse, best viewed with JavaScript enabled"
293,does-nvidia-vgpu-provides-spatial-sharing-of-gpu,"Hello Nvidia Experts,I have a question about whether the Nvidia vGPU provides spatial GPU sharing.
When reading the vGPU documentation, I can see that Nvidia driver enforces memory isolation for each vGPUs, but is isolation also applied for SMs (streaming multiprocessor)? For example, if vGPU-A uses a kernel that consumes all the available thread blocks of the GPU then vGPU-B have to wait for the vGPU-A to finish?HiThe Framebuffer is dedicated to each VM, but everything else is shared. To help give the best experience / performance there are a few Schedulers that you can select from or modify depending on your use case. You can read about how these work and how to modify them here: https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#changing-vgpu-scheduling-policyRegardsMGThanks for the reply,
But my question is does the Nvidia vGPU share the same limitations as the normal scenario?
For example, a kernel cannot preempt the other Kernel that occupies all of the GPU resources.HiIf you’re asking whether a single VM can consume the entire GPU so that other VMs are negatively impacted when they try and access it, then the answer is yes. A GPU is no different to any other virtualised resource.To prevent this from happening as much as possible, the Scheduler can be configured to allocate different amounts of the GPUs resources between multiple VMs in different ways, as per the link above.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
294,welcome-to-the-nvidia-virtual-gpu-grid-forums,"Welcome to the NVIDIA GRID Forums. This forum is a dedicated area for discussion around graphics-accelerated virtualization solutions.If you are looking for information about GRID Gaming, please visit the GeForce ForumsIf you are a developer please visit the NVIDIA Developer ForumsCongrats on going live!
@youngtechThanks @youngtech.  If you have any feedback about the forums please let us know!Hi Everybody, I have 2 server with 4 K2 now with VMWare, these 2 server are used by 25 users. Now is time to upgrade my cluster with a new server. The K2 solution are not available to buy, and is time to by the new tesla. Are the Tesla compatible with k2 in the same server?Hi GiovanniLTIf you could please post questions like this in the ""General Discussion"" area, they will gain more visibility.Not to worry though, in answer to your question, mixed generation GPUs are not supported within the same server. You will either need to replace all the GPUs to maintain consistency across your platform or purchase an additional server to host the new GPU.RegardsPowered by Discourse, best viewed with JavaScript enabled"
295,unable-to-unregister-license-server-from-license-portal,"I have noticed that the License Server MAC Address is unique across all Nvidia accounts. Really? Colleague registered License Server under his account and left the company. Now i wanted to register the Lic Server under another account i had access to but could not as it was complaining that the MAC address is already registered…Are we NUTS ? in Virtual Environments it is quite possible for two users to have the same MAC… what ever, i have changed my MAC address and could register this rubbish. Of course i had to uninstall and reinstall this FLEXNET thing to accept the MAC change otherwise the Lic File was refused with error. Horrible SOFTWARE  rubbish. Now it is running just wondering how to unregister a non existent license server . Please advise. Theoretically , i can now go and register all MAC addresses i could generate as Lic Servers and block these for other users…Terrible experience with this rubbish. Do not ever try to use some licensing software. do anything else. just not licensing, it is killing it.Why not simply open a support ticket? NVES would help you with this inquiry and delete the old licserver. And there is no need to delete the licserver to accept a new license with different MAC. You can easily delete the trusted store on the licserver.
I agree, the unique MAC is a mess and we will move away from Flexera portal very soon to mitigate all these restrictions.regards
SImonSo, how do you remove a MAC from portal account A so that same MAC can be registered with portal account B?Wait till Monday and your question will be obsolete.Nice one Simon!The vGPU License Portal has just had a really nice UI upgrade along with additional management features that were requested around the License Server. This should resolve your issue.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
296,remove-evaluation-license-from-license-server,"Hi,
is it possible to remove an evaluation license from the local installed nvidia license server?kind regards
Chrisfound it … License Server User Guide :: NVIDIA Virtual GPU Software License Server Documentationplease close ;)Powered by Discourse, best viewed with JavaScript enabled"
297,how-to-upgrade-from-your-current-version-to-version-vgpu-12-1-on-aws,"Hello everyone I’m using NVIDIA RTX VIRTUAL WORKSTATION (Windows Server 2019 )just got email from AWS according to upgrade to  vGPU 12.1 on Amazon Marketplace from Ingram Micro., Any tutorials how to make it?Powered by Discourse, best viewed with JavaScript enabled"
298,nvidia-driver-460-32-03-on-linux-says-that-the-rtx-6000-vgpu-is-not-supported,"vm-nvidia-bug-report.log.gz (36.1 KB)
Hello,
The HP ProLiant 380 server is equipped with a RTX 6000 card and runs the vGPU manager successfully. mdevctl created vGPU devices. Attaching such a device to a KVM managed VM works fine too. However, the nvidia driver in the VM says that the device is not supported:[ 6262.600443] NVRM: The NVIDIA GPU 0000:01:00.0 (PCI ID: 10de:1e30)
NVRM: installed in this system is not supported by the
NVRM: NVIDIA 460.32.03 driver release.
NVRM: Please see ‘Appendix A - Supported NVIDIA GPU Products’
NVRM: in this release’s README, available on the operating system
NVRM: specific graphics driver download page at www.nvidia.com.GPU passthrough with the same nvidia driver works fine.Both the host and the VM are running Debian 10 (Buster) with kernel 4.19.0. Both are running compatible nvidia software versions: 460.32.04 and 460.32.03. nvidia-smi on the host reports everything properly:Wed Apr 28 16:47:43 2021
±----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.04    Driver Version: 460.32.04    CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     On   | 00000000:86:00.0 Off |                  Off |
| 33%   46C    P8    25W / 260W |   8257MiB / 24575MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     15713    C+G   vgpu                             8088MiB |
±----------------------------------------------------------------------------+Currently, there is no license server, but my understanding is that the driver should work without a license for some time.
I hope somebody can shed some light on the matter.Thanks,
DejanHi again,
Just reinstalled the grid driver from the run file and now the driver loads correctly and the X server starts fine:
[ 22069.718] (II) NVIDIA(0): NVIDIA GPU GRID RTX6000-8C (TU102GL-A) at PCI:1:0:0 (GPU-0)
There were otherwise no changes in the VM.
Cheers,
DejanPowered by Discourse, best viewed with JavaScript enabled"
299,hyper-v-2019-failover-cluster-requirements,"Hi,I’m deploying a Windows Server 2019 Hyper-V failover cluster at the moment that will be hosting Windows Server 2019 RDSH servers for our students to use, they’ll be using fairly low intensive applications like Gimp, Google Earth, etc. but we are aiming for 25 users per RDSH.The host servers both have a Tesla M10 card installed already, but I’m unclear on what licensing we will need and how this would be configured, could any one please help point me in the right direction?From what I’ve looked at online, I will need to get a vGPU license, get the driver installed on the host and then on the RDSH VMs. I’ve done this a few years ago but it was using DDA which I can’t do in a failover cluster.Thanks in advance for any help.Not sure what you are going to achieve other than DDA. There is nothing else available right now. And yes you will need a vApps license for CCU count on the RDSH machines.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
300,virtualization-of-tesla-t4-hyper-v,"Hello.
I’m new to this vGPU world and I’m setting a server 1x Tesla T4 . I had to install windows server 2019 with Hyper-V and configured it with Discrete Device Assignment (DDA). It’s working but, now we would like to “split” the GPU into multiple vGPU  to distribute the GPU across multiple VMs running on the host.We have read documention about on nvidia website but still don’t get it.
Tried to deploy a licence server also(with qDWS), but when deploying the licence on the host, still getting only 1 gpu?Can someone light us and help us to have a clear view about what is possible in our case  .Thanks and regardsGregHi GregUnfortunately, you’re using the only Hypervisor that doesn’t support GPU Virtualisation. Your only option with Hyper-V is Passthrough (DDA) which means either RDSH workloads, or 1:1 allocation for higher performance workloads.ESXi, XenServer, KVM, AHV all support vGPU. If vGPU is a requirement, you’ll need to use one of those.RegardsMGHello MGridThank you very much .we will run ESXi for thatregardsNot that I care, since I’ve switched away from Hyper-V, but that sucks for those folks!Powered by Discourse, best viewed with JavaScript enabled"
301,adding-vgpu-to-vm,"Hi,
I’m currently trying to add a vGPU to a virtual machine on our VX-Rail system. The VM is running under SuSE SLES 15 SP1. I added the vGPU and tried to install the driver.
Before I set under
/etc/modprobe.d/10-unsupported-modules.conf
allow_unsupported_modules 0
and then I tried to install NVIDIA-Linux-x86_64-440.87-grid.run (we run this version on another machine).
The module building is working, but the script is not able to load the driver.
Any idea ? (secure boot is disabled as well)nvidia-installer log file ‘/var/log/nvidia-installer.log’
creation time: Mon Jan 10 14:11:22 2022
installer version: 440.87PATH: /usr/local/Modules/bin:/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/binnvidia-installer command line:
./nvidia-installerUsing: nvidia-installer ncurses v6 user interface
 → Detected 32 CPUs online; setting concurrency level to 32.
 → Installing NVIDIA driver version 440.87.
 → Running distribution scripts
executing: ‘/usr/lib/nvidia/pre-install’…
grep: /etc/sysconfig/kernel: No such file or directory
 → done.
 → The distribution-provided pre-install script completed successfully. If this is the first time you have run the installer, this script may have helped disable Nouveau, but
a reboot may be required first.  Would you like to continue, or would you prefer to abort installation to reboot the system? (Answer: Continue installation)
 → Performing CC sanity check with CC=“/usr/bin/cc”.
 → Performing CC check.
 → Kernel source path: ‘/lib/modules/4.12.14-197.78-default/source’
 → Kernel output path: ‘/lib/modules/4.12.14-197.78-default/build’
 → Performing Compiler check.
 → Performing Dom0 check.
 → Performing Xen check.
 → Performing PREEMPT_RT check.
 → Performing vgpu_kvm check.
 → Cleaning kernel module build directory.
executing: ‘cd ./kernel; /usr/bin/make -k -j32 clean NV_EXCLUDE_KERNEL_MODULES=“” SYSSRC=“/lib/modules/4.12.14-197.78-default/source” SYSOUT=“/lib/modules/4.12.14-197.78-de
fault/build”’…
rm -f -r conftest
make[1]: Entering directory ‘/usr/src/linux-4.12.14-197.78’
…Building modules, stage 2.
MODPOST 4 modules
CC      /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia-drm.mod.o
CC      /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia-modeset.mod.o
CC      /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia-uvm.mod.o
CC      /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia.mod.o
LD [M]  /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia-drm.ko
LD [M]  /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia-modeset.ko
LD [M]  /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia-uvm.ko
LD [M]  /tmp/selfgz18917/NVIDIA-Linux-x86_64-440.87-grid/kernel/nvidia.ko
make[2]: Leaving directory ‘/usr/src/linux-4.12.14-197.78-obj/x86_64/default’
make[1]: Leaving directory ‘/usr/src/linux-4.12.14-197.78’
 → done.
 → Kernel module compilation complete.
 → The target kernel has CONFIG_MODULE_SIG set, which means that it supports cryptographic signatures on kernel modules. On some systems, the kernel may refuse to load modules
without a valid signature from a trusted key. This system also has UEFI Secure Boot enabled; many distributions enforce module signature verification on UEFI systems when Sec
ure Boot is enabled. Would you like to sign the NVIDIA kernel module? (Answer: Install without signing)
ERROR: The kernel module failed to load. Secure boot is enabled on this system, so this is likely because it was not signed by a key that is trusted by the kernel. Please try
installing the driver again, and sign the kernel module when prompted to do so.
ERROR: Unable to load the kernel module ‘nvidia.ko’.  This happens most frequently when this kernel module was built against the wrong or improperly configured kernel sources,
with a version of gcc that differs from the one used to build the target kernel, or if another driver, such as nouveau, is present and prevents the NVIDIA kernel module from
obtaining ownership of the NVIDIA GPU(s), or no NVIDIA GPU installed in this system is supported by this NVIDIA Linux graphics driver release.Please see the log entries ‘Kernel module load error’ and ‘Kernel messages’ at the end of the file ‘/var/log/nvidia-installer.log’ for more information.
 → Kernel module load error: Operation not permitted
 → Kernel messages:[ 2167.032811] nvidia: Loading of unsigned module is rejected, kernel is locked down
ERROR: Installation has failed.  Please see the file ‘/var/log/nvidia-installer.log’ for details.  You may find suggestions on fixing installation problems in the README avail
able on the Linux driver download page at www.nvidia.com.Powered by Discourse, best viewed with JavaScript enabled"
302,passthrough-nvidia-geforce-gtx-1060-oc-using-proxmox-as-host-os-driver-problems-error-code-43,"I have this PC:Motherboard: Gygabyte B550 Gaming v2
CPU: AMD Risen 5 3600 3,6ghz
RAM: HyperX Fury Black 16GB DDR4 3200Mhz CL16
GPU 1: GIGABYTE GTX 1060 WindForce 2X OC GDDR5X - GV-N1060WF2OC-6GD-2.0
GPU 2: RV770 Radeon HD 4850
SSD: Adata SU 480GB SATA IIIThis PC is Running Proxmox. Inside I have a virtual machine that is running Windows.I managed to make the passthrough for the GPU 1 to the VM that is running windows. I can see the video card in the Device Manager but every time I try to install the drivers I get the error code 43.I mention that i have a monitor plugged in the hdmi port of the GPU 1.Powered by Discourse, best viewed with JavaScript enabled"
303,updates-came-later-475-49-driver-cause-mx150-direct3d-acceleration-sometimes-to-crash-while-in-games,"Machine Information :Lenovo Ideapad 320-15IKBDevices and DriversBIOS Latest 6jcn33wwMTM 81BG00RRFElPROCESSORIntel® Core™ i7-8550U CPU @ 1.80GHzGRAPHICSIntel® UHD Graphics 620NVIDIA GeForce MX150 2GB 25WAUDIONVIDIA Virtual Audio Device (Wave Extensible) (WDM)Realtek High Definition AudioIntel® Display AudioNETWORKING AND I/OIntel® Dual Band Wireless-AC 3165Realtek PCIe GbE Family ControllerIntel® Wireless Bluetooth®MEMORY20 GBSTORAGECT240BX500SSD1ST2000LM007-1R8174Powered by Discourse, best viewed with JavaScript enabled"
304,gpu-passthrough-licensing-on-proxmox-without-using-vgpu,"I have an A4000 and am exploring options for virtualization. Do I need a vGPU license (or any additional license) to pass a workstation card through to a Linux VM with VFIO on Proxmox for:If so, would the open source Nouveau driver prevent the need for a license? I’m not interested in using vGPU software, just a straightforward passthrough over VFIO. Thanks.Powered by Discourse, best viewed with JavaScript enabled"
305,hi-everyone-i-have-a-problem-with-the-rtx-a6000-i-made-a-display-mode-change-to-the-graphics-card-on-a-host-that-doesnt-support-compute-mode,"Hi everyone, I have a problem with the RTX A6000. I made a display mode change to the graphics card on a host that doesn’t support ‘compute mode’ without reading the documentation carefully. Now, when this host starts the self-test, it cannot pass the GPU detection and cannot be powered on. So, I would like to ask, is the GPU damaged due to my improper operation, or I have successfully changed the display mode of the GPU, but cannot boot because the host does not support this mode? Can someone give some advice? thank you very much!Hi,you should give more details to judge what happened. Which mode did you switch the GPU to? Datacenter mode with 64GB BAR1 size?
If yes, you disabled the display heads and now you need a primary display adapter in your system as the GPU is not able to serve as primary any more. So simply put in a different GPU and it should work.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
306,is-vm-with-vgpu-license-can-be-used-by-different-users-or-organization,"Is there any restriction on the number or organizations of users for vGPU license? For instance, we have one license and a VM with one vGPU and vGPU license, can it be used by different users from different organization at the same time or at different time?I don’t understand the question. License aquisition is based on CCU so it aquires a license when the VM is up and runningIf I understand correctly, vGPU license do not restrict who is using the VM. As IBM, we can rent the VM to different customers as long as we purchase vGPU license from Nvidia, right?Powered by Discourse, best viewed with JavaScript enabled"
307,nvidia-geforce-gtx-560-cuda-compatible,"I’m trying to enable my GPU for Tensorflow but I’m having a few issues. I’ve downloaded the necessary toolkit, but I’m not sure if my GPU is CUDA enabled. I don’t see the exact GPU on this link: CUDA GPUs - Compute Capability | NVIDIA Developer, but I do see GEForce GTX 560 Ti and GEForce GTX 560M, are those the same? Please do help me out with this and let me know if you require any additional information. - I was directed by customer service to post my question on this forumPowered by Discourse, best viewed with JavaScript enabled"
308,sudo-apt-install-tensorrt-error-in-vmware,"Enviroment: VMWare Ubuntu 18.04
GPU: Tesla T4
GPU driver version: 460.32.03
Cuda version:11.1
Cudnn version:8.1.0.77After installing tensorrt. The follow error occured.daniel@admin:~$ sudo dpkg -i nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211_1-1_amd64.deb
(Reading database … 89285 files and directories currently installed.)
Preparing to unpack nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211_1-1_amd64.deb …
Unpacking nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211 (1-1) over (1-1) …
Setting up nv-tensorrt-repo-ubuntu1804-cuda11.1-trt7.2.2.3-ga-20201211 (1-1) …
daniel@admin:~$ sudo apt-key add /var/nv-tensorrt-repo-cuda11.1-trt7.2.2.3-ga-20201211/7fa2af80.pub
OK
daniel@admin:~$ sudo apt update
Get:1 file:/var/nv-tensorrt-repo-cuda11.1-trt7.2.2.3-ga-20201211  InRelease
Ign:1 file:/var/nv-tensorrt-repo-cuda11.1-trt7.2.2.3-ga-20201211  InRelease
Get:2 file:/var/nv-tensorrt-repo-cuda11.1-trt7.2.2.3-ga-20201211  Release [574 B]
Get:2 file:/var/nv-tensorrt-repo-cuda11.1-trt7.2.2.3-ga-20201211  Release [574 B]
Hit:4 Index of /ubuntu bionic InRelease
Hit:5 Index of /ubuntu bionic-updates InRelease
Hit:6 Index of /ubuntu bionic-backports InRelease
Hit:7 Index of /ubuntu bionic-security InRelease
Reading package lists… Done
Building dependency tree
Reading state information… Done
41 packages can be upgraded. Run ‘apt list --upgradable’ to see them.
daniel@admin:~$ sudo apt install tensorrt
Reading package lists… Done
Building dependency tree
Reading state information… Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:The following packages have unmet dependencies:
tensorrt : Depends: libnvinfer7 (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvinfer-plugin7 (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvparsers7 (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvonnxparsers7 (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvinfer-bin (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvinfer-dev (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvinfer-plugin-dev (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvparsers-dev (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvonnxparsers-dev (= 7.2.2-1+cuda11.1) but it is not going to be installed
Depends: libnvinfer-samples (= 7.2.2-1+cuda11.1) but it is not going to be installedHow can i solve this problem?你下载 cuda安装用deb的包，tensonrt也用deb的包，tryPowered by Discourse, best viewed with JavaScript enabled"
309,vulkan1-2-support-on-virtual-machine,"Hi,
I would like to use Vulkan 1.2 application on more virtual machines with win10 x64 system and only with 1 physical GPU.  Which graphics card and which virtual machine is recommended for it ?Powered by Discourse, best viewed with JavaScript enabled"
310,looking-for-advice-on-optimal-config-for-latest-gen-citrix-xenapp-vgpu-solution,"At this point, it does seem weird that it has ever worked for 10 users on a 1A profile. But again we had it running for a long time, with good results.Today I believe we can still run about 3-4 users on a 1A profile. Because we have a few ""test"" Citrix servers that still have the 1A profile active and it’s running fine, but the amount of users never really exceeds 3-4 users.Our ""prime time"" for user logins is about 8:00 in the morning:
1A profile, 8-10 users, the issue would appear after 2-4 hours.
2A profile, 8-10 users, the issue would appear after maybe 7-24 hours.
4A profile, 8-10 users, not sure we have been able to reproduce the issue.
8A profile, 8-10 users, not an issue.You would think that it’s an issue with framebuffer overflowing to ""windows paging"", and at some point something goes wrong… We haven’t found a way to monitor this or investigate this further.Trying to revert to the original configuration, is something we have discussed a lot of times. As you say, it’s just out of interest in testing. We have come to the conclusion that it’s not worth it. We would not run that in production anyway. Being able to do vMotion with a GPU attached is an amazing feature.This have for sure changed our perspective on the importance of always running within supported versions. Maybe we would have seen the issue start earlier, if we only changed 1 major component at a time. But what’s most likely, that you run into issues running a supported or a unsupported setup?Just for the record, in my POC testing of last year using the 2012R2 golden image I consistently noticed the behaviour that whenever the total framebuffer memory exceeded 8GB (at that time I used the 8A profile) the virtual machine entered a ‘hung’ state and could only be saved by a full hard reset. People’s active citrix sessions were lost as a result.Now in production using 16a profiles and a brand new 2019 golden image I have never dared so far to allow or force the virtual machine to exceed the 16GB total framebuffer memory. Highest I’ve seen was 95% load.@MrGRIDfor the record, what is the expected behaviour according to your knowledge/experience ? Would the fact that I now assign a complete T4 card with its 16GB mem exclusively (as opposed to a 8a profile) to 1 virtual machine make any difference ?Hi AthomsenSorry for the delay in responding, busy time at the moment …Regarding Supporterd vs Unsupported; Supported should always give less issues as that configuration will have been validated to work together and this is what you would always want in a production environment for that peace of mind. Unfortunately what you’re experiencing at the moment isn’t a matter of support, it’s a physical, technical limitation and the correct way to resolve it is to scale out.If you have any budget available, a more cost effective way to resolve this maintaining support could be to look at using C240 M4s with a couple of M10s installed. M4 architecture is really cheap now because it’s superseded, plus you won’t need any local disks (again helping to reduce cost) so this shouldn’t cost you too much to do and this would give you 8 VMs per C240 (in 2U compared to B200s which if you’re using a UCS 5108 is 6U) meaning that in 6U you could have 24x 8GB GPUs instead of 8. Connect them up to your AFF and it may be a viable solution to see you through until your next platform upgrade, which, if this was installed in 2017, should typically only be about another 1-2 years absolute maximum depending on how you run your technology lifecycle. It depends on whether you’d want to start the next upgrade a little early, or top this one up to keep it going and then upgrade the entire thing in one go with a new technology stack. But adding C240 M4s is definitely a cost effective way to add more density whilst maintaining support at this stage.Hi ProfundidoI’ve not personally had machines crash when they run out of resource, but the performance of the machine is severely impacted to a point where it becomes unusable for anyone connected. I don’t run any of my environments consistently above 85-90% Framebuffer usage. This allows a little headroom when required.Regarding 8GB vs 16GB, the end result when you run out of resource should be the same, and this is purely down to how the environment will be designed and whether you want to scale up or out, the type of Applications being used etc etc. 2x 8GB should give you the same total density as 1x 16GB. However you need to account for additional CPU and RAM for the extra VM, as there are economies of scale for scaling up vs out, not forgetting Windows Licensing costs, Management etc etc …RegardsMGWe will not be buying additional hardware for our current platform. Instead the plan is to look forward and plan for our next platform.At the moment the M10 GPU seems like the best choice for maximum density/cost, but it’s an old GPU. Designing a new platform with the M10 for the next 4-5 year would not be ideal. It’s also the only current GPU on the now ""old"" Maxwell architecture.Is there a replacement on the way? Maybe on the latest ampere architecture?Yes, the only reason I listed the M10 was to maintain your existing (Cisco) M4 architecture throughout so you could extend the capacity with the same ecosystem without upgrading. Pascal and newer GPUs require M5+ architecture. You certainly wouldn’t design anything new with Maxwell today (Maxwell has been superseded 4 times!), and this is something I routinely mention on here.The nearest replacement for the M10 is the T4. For configuration information on that, start from the beginning of this topic as we discuss it in detail. We’ll have to see if anything gets announced at GTC in a few weeks regarding any replacements. But even before looking at that, it’s worth asking Cisco if or when their M6 architecture is going to arrive so you can make sure you have the latest tech from all vendors.RegardsMGWe will not be buying additional hardware for our current platform. Instead the plan is to look forward and plan for our next platform.At the moment the M10 GPU seems like the best choice for maximum density/cost, but it’s an old GPU. Designing a new platform with the M10 for the next 4-5 year would not be ideal. It’s also the only current GPU on the now ""old"" Maxwell architecture.Is there a replacement on the way? Maybe on the latest ampere architecture?I’m officially in the dark as much as you are of course but since rumors/announcements of an Ampere-based new Quadro card are already starting to emerge, my 6th sense can already smell a T4 successor (with more memory) on the Horizon. That’s what you should design around imho and the best platform to support it up till today is the one I’m having in production right now.It’s just a matter of time now for that Ampere-based T4 successor. Mark my words.We will not be buying additional hardware for our current platform. Instead the plan is to look forward and plan for our next platform.At the moment the M10 GPU seems like the best choice for maximum density/cost, but it’s an old GPU. Designing a new platform with the M10 for the next 4-5 year would not be ideal. It’s also the only current GPU on the now ""old"" Maxwell architecture.Is there a replacement on the way? Maybe on the latest ampere architecture?aaaaaaand my predictive words from yesterday are barely cold or I stumble upon this today:Register FREE. Streamed online.Yeah, I’v already signed up for that.
But it does mention the A100 specifically, so I’m not sure that means revealing a new GPU as well.Unlock The Next Generation Of Revolutionary Designs And Immersive Entertainment ExperiencesvGPU Profiles Supported: 1 GB, 2 GB, 3 GB, 4 GB, 6 GB, 8 GB, 12 GB, 16 GB, 24 GB, 48 GB;)The world’s most powerful data center GPU for visual computing.
There is a new A40 as well, but it sure does look exactly like the RTX A6000.Sadly there was no news on a new GPU optimized for density. The slides are still showing the M10 dinosaur.Ah yes. I see what a mess they’re creating again with the naming structure.The A40 seems indeed to be the version of the A100 tailored for vGrid compatibility to be added most likely in v11.2 or soon after whereas A100 will not be Grid compatible. They just officially added the A40 to the recommended vgrid cards portfolio:NVIDIA GPU accelerators provide IT departments the graphics and compute virtualization resources needed to meet demands and scale across the enterprise.Meanwhile the current latest version of the Grid software v11.1 only speaks of recent added hardware support for the full A100 and more specifically only for MIG vGPU profiles (no grid):1.2. Updates in Release 11.1
New Features in Release 11.1
Support for Multi-Instance GPU (MIG)-backed vGPUs on GPUs that support MIG
Support for GPUDirect® technology remote direct memory access (RDMA)
Security updates - see Security Bulletin: NVIDIA GPU Display Driver - September 2020
Miscellaneous bug fixes
Hardware and Software Support Introduced in Release 11.1
Support for the following GPUs:
NVIDIA A100 PCIe 40GB
NVIDIA A100 HGX 40GBValidated releases for GPUs based on the NVIDIA Ampere architecture:
Since 11.1: NVIDIA A100 PCIe 40GB
Since 11.1: NVIDIA A100 HGX 40GBIt looks like the A40(=RTX a6000?) is going through its validation cycle for Grid and will apppear in 11.2 or shortly after. Well at least we’re getting there…By the way, something else: Considering this new info and the design I ended up choosing with those specific servers and risers which currently hold 4 T4 cards per physical host server I realized it is now confirmed to be the best most versatile full futureproof set up possible because:The only thing that might still limit that a little bit further is the dual cpu PCIE lanes limitation in terms of max lanes per riser but even then it still will allow for the most possible vGPU to be configured per physical server.So that’s a relief for me. Now I can rest in peace realizing we didn’t buy anything ‘wrong’ for the next upcoming generation. On the contrary ;)update: I’ve been following up when the A40 would actually start making its appearance in the new software releases and documentation, checking it every week. Today is the first time I see the all new 12.0 software and the A40 hardware being mentioned and supported in it:https://docs.nvidia.com/grid/12.0/whats-new-vgpu/index.htmlThat sure took its sweet time ;)Hi there, thank you for this topic. It’es really helpful to size correctly a CVAD Session Host farm. I have a few question still :Since Citrix by default does not use video codec for whole screen but only for Actively changing regions, as long as we do not choose to use video codec for the entire screen, GPU will not be used and frambuffer will not be impacted ? How does it work if not ?Is the A40 the new recommended best way to go for user density in a Session Host environnment ?For 20-30 users, what profile should be used ? Is A40-8A still recommended or should we go with 16 ? We have a 2019 farm with users doing mainly office work but sometimes uses video (yxoutube etc,…) as well as video conferencing. Video conf and youtube can be offloaded to client with content redirection and so usually it’s not an issue.Hi Karsayor,-According to my experience every citrix session from its build up immediately and continuously consumes framebuffer memory from start till end of the session, regardless of “actively changing regions” policy choice or different. Only vGPU computing power is affected by this and will only spike when triggered. This can be monitored nicely using RD analyzer and GPU profiler.-the A40 in combination with HP DL380 latest gen would be my absolute top choice since it will allow you to scale out better than the T4’s and any other solution out there in the world. Framebuffer memory is the (known) bottleneck here and the A40 is the perfect solution. (provided they work just as well as the T4’s and don’t have child diseases)-I’ve personally tested that a 16GB profile supports up to or almost 20 users so I designed that for 15 users. If I would have to make a new design from scratch today for newest tech (full 2019 server graphical interface) that would be still it: 16GB per 15-20 users depending on load profile and take it from there. When I started my testings I was able to cram alot more users in because I was testing on my 2012R2 farm. When going live in production with my new farm based on 2019 server I realized that framebuffer memory usage had DOUBLED pretty much. That’s why my initial scaling only used something like 8GB profiles per 20 users.I hope this answers all your questionsThank you ! I have two more.
image836×675 14.2 KB
I’m not sure if Citrix Director alone is sufficient. I’ve always used GPU profiler since it’s realtime so my analysis is based off of that.Yes, 2019 is a 7year jump ahead into the future compared to 2012. The 2019 OS as a front end user experience has changed dramatically and become alot more graphically intensive. I invite you to test it as well and see it with your own eyes.Hi guys,About licensing the vGPU, if I have 2x XenApp vms running on VMware where each vm will receive a T4-8A profile and each vm should receive about 10 users, what is the right way to license it?Should be 2 vApps licenses considering that I have 2 vms or 20 vApps licenses considering that is the number of concurrent users logged on XenApp.Best
FabricioFabricio,I’m not an official VMware representative nor affiliated (so feel free to double-check with one) but as far as I have understood the Vmware licensing model it’s the number of the concurrent users when used in Citrix Xenapp (aka Virtual apps) where multiple users share 1 vGPU while the per-machine device model applies to scenario’s such as e.g Xendesktop where each content creator uses his own dedicated machine and thus has its own dedicated vGPU.How come you eneded up doubling the profile at 16Gb since MrGrid said that 8Gb should be enough to 20-25 ? There is that much of a difference between 2012 R2 and 2019 ?To answer your question, yes, there’s a huge difference between 2012 and 2019, it’s a huge jump, but there’s more to it than that. The Application requirements and how Users work have also moved on as well. Users running higher multiples of tabs in browsers, more applications open at the same time, newer versions of things like MS Office etc etc all contributes to increased resource usage.You can’t build a hardware spec based on a software stack that’s 2 generations old, update to current versions of that software and expect the same density, which is why you need to allow headroom in your hardware Spec for newer software, or plan to run certain versions of software throughout the lifecycle of the environment before the next refresh.If monitoring for GPU utilisation (framebuffer in your case), the best place to monitor is using nvidia-smi, as this is directly on the GPU. This will give you the most accurate results. Don’t forget, framebuffer is only one component you should be monitoring, there are lots of others to consider as well.Regarding licensing, vGPU is per concurrent user, whether it’s RDSH or VDI. Each user “that is connected” needs a vGPU license. If you have 20 users, but only 10 are connected at a time, then you need 10 licenses. If all 20 are connected at the same time, you need 20 licenses. The only exception to this is vCS, where the software is licensed per GPU, not per user.RegardsMGOk, very good thank you !Powered by Discourse, best viewed with JavaScript enabled"
311,opengl-no-longer-works-after-installing-cuda-11-5-and-optix-7-4,"I’ve created an instance of the NVIDIA RTX Virtual Workstation with Windows Server 2019 (see here: AWS Marketplace: NVIDIA RTX Virtual Workstation - WinServer 2019)I installed an application that uses OpenGL (Blender 2.93.5) and it worked just fine.I then installed CUDA 11.5, followed by OptiX 7.4. One or both of those installed a newer version of the NVIDIA Display driver (496.04 for CUDA and 495.89 for OptiX).After these newer drivers were installed, my OpenGL applications no longer worked. Blender gives this error:A graphics card and driver with support for OpenGL 3.3 or higher is requiredAnd whenever I try to run one of the OptiX sample programs, I get this error:GLFW Error 65542: WGL: The driver does not appear to support OpenGLI tried re-installing the driver that is recommended for the Tesla T4 installed on this virtual workstation (version 472.50), but that didn’t help.I also tried installing OptiX 7.3, which has a lower driver requirement, but that also didn’t help.Can I restore my OpenGL capability without nuking my EC2 instance and starting from scratch?Powered by Discourse, best viewed with JavaScript enabled"
312,hyper-v-dda-and-rdp,"Hello all,We have a R740 server with Windows Server 2019 and 3X Tesla V100. I installed Hyper-v, RDS-V and one Server 2019 VM as RDSH (I plan doing 3 RDSH VMs).  The DDA configuration ran OK and I can see the V100 adapter on the RDSH VM. But when I open a session to the RDSH VM,  OpenGL is not available nor DirectX.  Any application returns an error that DX12 is not installed or whatever. The V100 drivers are installed on the RDSH VM. I assume the V100 adapter is not used.  Obviously, the ""Use hardware graphics adapters for all Remote Desktop Services sessions"" setting is also enabled.Any help would be great. It seems i’m missing something.  Could the V100 adapter be stuck in compute mode ?I also tried my luck with RemoteFX but the get-vMRemoteFXPhysicalVideoAdapter  commands returns absolutely nothing on the host.  The drivers are also installed on the host.I think this system was used has a Linux gpu compute node before.Thanks!!Powered by Discourse, best viewed with JavaScript enabled"
313,nvidia-fx5200-driver-issue,"I recently updated my system graphic card for gaming and graphic designing. After upgradation, I have been trying to update my newly installed video card driver but I cannot find any drivers online. I can see my new graphic card in Device manager but I can also see a yellow color sign with it.Solutions I triedUpdate window
Used universal driver to update driver.My question is how can I update my driver for NVIDIA FX5200.Powered by Discourse, best viewed with JavaScript enabled"
314,t4-vgpu-in-fixed-share-scheduler-vgpus-performace-is-different-when-another-vgpu-is-free-or-running,"Hi,
i create two T4-8Q vGPU from Tesla T4, and deploy them on different virual machines.
Then i run gpu-burn to get the performaces(Number of executions per unit time) of vGPU and GPU.
And i find out the performace result is strange. For example, the result is just like below:
1: T4 passthrough mode: 13000
2: T4-8Q vGPU in fixed share scheduler:
a) vmA running, vmB free:		9000
b) vmA running, vmB running:	6000I was expecting 2a’s result is 6000 but the actual value was 9000, which makes me confused.
can anyone explain this? thanks a lot.ps:
6000 is in line with expectations(6500 loss 500 after virtualization).
The virual machines os is centos7.9, and vGPUs has been liscensed.
gpu-burn is an open source program which run above cuda.Powered by Discourse, best viewed with JavaScript enabled"
315,cinebench-opengl-not-supported-esxi6-7-2012r2-vm-latest-k80-driver,"Hi all, brand new R730xd server.Passthrough vmx config settings work fine on a new UEFI VM but my old VM gets stuck in a spinning loop on bootup. Just going to start fresh.I installed the 2012R2 and latest K80 drivers and went to check that the GPU is being used. This is my first time using cinebench so if I’m missing something let me know. It’s saying ""your GPU doesn’t support openGL"". The ""CPU"" test works fine but I know we need openGL and Dxdiag only reports the SVGA video adapter. Any ideas?Powered by Discourse, best viewed with JavaScript enabled"
316,new-vgpu-installation-failing-to-acquire-license-one-day-after-success,"Hello,Yesterday I installed a bare metal (WS2019, A10) vGPU server. I created the license server/service instance, downloaded the token and setup the registry for vWS with proxy info. I received a license authorization and all was well. Today I upgraded the CPUs and when the system booted, every attempt to acquire a license fails. I downloaded another token, thinking that might actually work, restarted the service, but no joy. Any ideas? I have an eval license and am not sure what support I am entitled to (and clicking on the ‘create ticket’ button just brought me back to the dashboard) so I thought I’d post here…Powered by Discourse, best viewed with JavaScript enabled"
317,how-to-track-an-event-of-getting-a-license,"Hi all, is there some way under Linux except monitoring ""nvidia-smi -q | grep License"" to know when vGPU license is active? There is nothing in man nvidia-gridd. I have one service that depends on CUDA so it needs to be (re)started when vGPU becomes licensed. Thank you.HiThe License is automatically allocated and active when the VM boots and stays active until the VM is rebooted / powered off. If your CUDA dependant service can have a delayed start, then it shouldn’t need to be restarted.RegardsMGThank you for your reply. But how can I determine a moment when license is active on my VM? There may be networking problems and license will be active not very quickly after VM start…HiYour VM will experience poor performance and reduced functionality if a license has not been allocated. Frame rate limitations and reduced resolution will be the main things that are noticeable.Which version of Linux are you running?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
318,configuration-suggestions-for-dell-vrtx-q-m4000-winserv2012r2,"Hi gang -
I’m looking for suggestions on enabling a Remote FX GPU on my Dell.Current setup:
Dell VRTX
M620 Poweredge
Quadro M4000 (alternate, Quadro P4000)
Win2012R2, utilizing Hyper-V
** Note - the M4000 is a new install; The device pass-through is recognized by the OS, but the Win driver has been an issue.Attempt 1:
Installed driver & RTX DesktopManager (v472.98 & 202.21).  The server will start but the driver errors. If I disable then re-enable the device, it will then start.
However 1) DXDIAG will not recognize the hardware; 2) RTX Desktop Manager reports it cannot run because it requires:
Windows 10 and above
NVIDIA display driver
Nvidia RTX / Quadro GPU
** Note - this results from installing 472.98-quadro-rtx-winserv-2012r2-64bit-international-whql.exe
** Note - Hyper-V does not recognize an available GPU to be assigned.
– This is telling me that, while the device is powered-up (verified via CMC & the cooling fan spinning up), the driver is not allowing the GPU to mount successfully.Attempt 2:
Install clean via 453.10-quadro-winserv-2012r2-64bit-international-whql.exe
This driver results in system instability, ultimately requiring it be removed.Attempt 3+:
Attempted alternate drivers, but so far the best (nonfunctional) result was with the 472.x (and have been removed).Alternate path(s):
-Install WinServ2016
-Verify the device is not the problem by installing into another system, or, an alternate OS (currently WIP)** Update -
Installed Quadro P4000.
Same result on the Win2012R2 install;
Win10 installed to a secondary blade, same results…
10, tested with driver 512.78 Win10 64-bit Quadro/RTX driver - the device can be configured but cannot be started unless it’s disabled & re-enabled.
RTX Desktop Manager still will not start due to the same failure message.  Considering it’s a Win10 install, tells me that the driver and/or passthrough is the issue.Hopefully anyone around here may have an idea, but it’s seeming to be more related to the hardware.** Update - May20After working through potential issues with a Dell tech, their suggestion was to upgrade to a Dell M630, or, to try a Grid 2K.Despite the VRTX reporting the M4000 (and P4000) were ‘powered up’ - I did find that WinOS was reporting Error 43 (device failed to start due to power).So - I rigged an external power supply to provide power to the GPU(s); Low and behold, the P4000 was able to start, be assigned by the OS, and register for use.
Additionally - I was also able to stuff in my GTX1080TI as well, with both being powered & registered together…In the end, the issue appears to be related to the VRTX PCIE riser power being insufficient for either the M4000 or P4000 (not to mention anything with higher demands).
The drawback however, is that the VRTX interface is limited to 8x and not 16x.
HyperV_MGMT705×146 21.2 KB
Powered by Discourse, best viewed with JavaScript enabled"
319,unable-to-run-tensorflow-with-vgpu,"Running ESXi 6.5sp3ESXi: NVIDIA-GRID-vSphere-6.5-440.53-440.56-442.06
Created a new VM with Ubuntu 18.04
In VM I installed: NVIDIA-Linux-x86_64-440.56-grid.runI can run in VM:Now I try to run a Docker container on top of VM that contains CUDA/CuDNN and TensorFlow.I get this WarningI get this WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.
When I run TensorFlow I get:I’m having the same issue, and from what I have found this is because Docker is not running with the ""nvidia"" runtime, it is still running with the ""runc"" runtime.  I am having issues figuring out what documentation is correct for getting the nvidia runtime installed, the various docs i’ve read seem to contradict each other regarding what versions of what need to be installed.I’ll update as I find any useful info.Got it working!  basically needed to get the runtime installed and edit the Docker daemon.json to use the nvidia runtime.Powered by Discourse, best viewed with JavaScript enabled"
320,dual-cursors-happend-in-virtual-desktops,"Hi,guys!
Recently we encountered a problem that two mouse pointers displayed when dragging application window in Windows OS in vdi environment.The remote one always moves behind the local one.It’s teradici’s PCoIP protocol we use and it happens in both vmware vSphere and openstack virtualization platform no matter passthrough or vGPU.But the standard desktops without graphic cards don’t have the problem.
Anyone helps me,thanks a lot.Powered by Discourse, best viewed with JavaScript enabled"
321,dls-ip-resets-itself,"I installed a DLS-1 v1.1 Appliance on ESXi-1 and set it up using tokens.
It has an IP of 172.168.45.10 and is registered in DNS.The DLS-1 was ready to serve the  licenses.
However, v2.0 was released.
So I created a new v2.0 VM called  DLS-1-v2 and set it to a new IP 172.168.45.20 as I wanted to use the original 172.168.45.10 after the v2 VM was configured…I did the migration of data from DLS-1 to DLS-1-v2 via migration file accessing the NVIDIA portal, etc.The upgrade worked as on on DLS-1-v2  I can see 2.0.0 listed under the Maintenance page and also the license info.I turned off the DLS-1 VM.So, now i wanted to reset the IP of on DLS-1-v2 back to 172.168.45.10.Under the Service Instance page, I selected “CONFIGURE IP ADDRESS”
I went though the process of setting back the IP to 172.168.45.10
I got a confirmation the IP change worked and  it would be available. in a few minutes.In vCenter, i can see DLS-1-v2 took on the original 172.168.45.10 and i can login vie chrome to 172.168.45.10.However, when i rebooted DLS-1-v2, the Ip reverted back to the temp IP of 172.168.45.20.
I even tried resetting the IP from the console as dls_system and the it does not work.Any ideas on why the IP is reverting back to the temp IP 172.168.45.20 I used for DLS-1-v2thanksI had the same problem but found the solution: License System User Guide (nvidia.com)Powered by Discourse, best viewed with JavaScript enabled"
322,failed-to-install-windows-10-guest-driver-on-centos-7-9-kvm-virtualization-platform,"I have a Tesla M10 and a Tesla T4 card.
Here is the GRID install package I’ve download and tried:
GRID 8.9: NVIDIA-GRID-Linux-KVM-418.226.00-427.60.zip
GRID 10.4: NVIDIA-GRID-Linux-KVM-440.121-440.118.02-443.66.zip
GRID 13.1: NVIDIA-GRID-RHEL-7.9-470.82-470.82.01-472.39.zipI can create mdev devices and add to kvm virtual machines, but when I install the windows guest driver, the driver installer always failed  to install the graphics driver. I’m always trying to use the same guest driver as the host. I’ve tried windows 10 1809 and windows 10 21H1, both not working.The only GRID version working is GRID 6.4, but it only supports M10, not T4.Powered by Discourse, best viewed with JavaScript enabled"
323,opencl-not-available-when-using-nvidia-grid-vgpu-grid-m60-8q-profile-on-vsphere-6-7,"I am using a Tesla M60 card as pass-through by using the m60-8q profile, and I understand that this should allow me to use OpenCL on a Windows 10 VM running on the VSphere 6.7 host, but when I run GPU-Z it shows no OpenCL or CUDA support.Driver version is as below and the Windows 10 client VM is running the 441.66 that came with the GRID software ZIP:[root@stc-vdi-01:~] nvidia-smi
Mon Jan 11 17:04:26 2021
±----------------------------------------------------------------------------+
| NVIDIA-SMI 440.43       Driver Version: 440.43       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla M60           On   | 00000000:05:00.0 Off |                  Off |
| N/A   33C    P8    27W / 150W |   8143MiB /  8191MiB |      0%      Default |
±------------------------------±---------------------±---------------------+
|   1  Tesla M60           On   | 00000000:06:00.0 Off |                  Off |
| N/A   30C    P8    25W / 150W |   8143MiB /  8191MiB |      0%      Default |
±------------------------------±---------------------±---------------------+I can see the M60 GPU in task manager and it is working for graphical operations, just no OpenCL support.The server is a Dell PowerEdge R730 and I have configured the Graphics Cards in VSphere like this:
image1205×249 15 KB
As I understand it, this should work, what do I need to check for?ThanksGaryHi GaryLooks like you’re running that command on the Hypervisor … Try running it inside the VM from a CMD prompt and it should work for you:“C:\Program Files\NVIDIA Corporation\NVSMI\nvidia-smi”CUDA doesn’t get installed inside the Hypervisor, which is why the vGPU Manager doesn’t list it as per your image above. CUDA gets installed with the vGPU Driver inside the VM.For reference, if you were running Pascal or newer architecture, you could use any Q Profile and be able to run CUDA workloads. It’s just Maxwell that requires the full 8Q Profile be used for CUDA due to the age of the architecture. But it’s a good place to start with, as it’s one of the few GPUs that allows you to run mixed vGPU Profiles concurrently on the same board.RegardsMGHi, thanks for taking the time to get back to me on this.Here is the output of the nvidia-smi command from withing the VM itself:Within the VM, Compute Mode also shows as “default” which I think means that CUDA/OpenCL should be available in the VM, but GPU-Z (and also my compute app) both say that OpenCL is not available in the VM:
image383×537 26 KB
You will note that I have used the m60_8q profile, which should allocate an entire GPU to the VM, which should allow OpenCL/CUDA (as it is not a shared GPU without pre-emption)So, how do I enable OpenCL in the VM?ThanksGaryHiIt should just work with that Profile. There’s no special configuration to enable it. I assume the VM has successfully acquired a vGPU License?Also noticed you’re not running the latest driver branch. vGPU 11.x will install CUDA 11 if that’s better for your workload.RegardsMGHi,I am only performance testing to evaluate various hardware setups at this time (I may not virtualise and just run on baremetal) and have not setup a flexlm license server yet. I was under the impression that it should work (albeit with a pop-up warning) for testing. Certainly, the vGPU for graphics is working OK, is the OpenCL/CUDA computation mode different - does it definitely need the vGPU license before it will enable?Once again, thanks for you response.RgdsGaryHi GaryYes, please make sure it’s licensed. Functionality will reduce very quickly if the VM is not licensed.You can register for a vGPU evaluation here GRID Evaluation | NVIDIA However as you already have the vGPU software, I’m assuming you already have access to the licenses and an evaluation. Setting up a license server is very quick, so you should be up and running in no time!RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
324,sharing-nvidia-a100-80gb-to-multiple-vms,"Hi,I wanted to know which host platform I can use to share the Nvidia A100 80 GB in up to 5 Ubuntu VMs?
My system is Dell Poweredge R750 with Dual Xeon 64 Core and 180 Gigs of RAM, Nvidia A100 80 GB.
I tried with Proxmox but failed, If anyone tried this any help is appreciated.Thanks.Powered by Discourse, best viewed with JavaScript enabled"
325,vfio-gpu-passthrough-stops-working-when-vgpu-host-driver-is-installed,"Host OS: RHEL 8.4
vGPU host driver: 460.91.03
libvirt: 6.0.0-35.1
qemu-kvm: 15:4.2.0-48I am attempting to run multiple VMs on the same host. This host contains two Titan RTX cards and two Tesla V100 cards. Prior to setting up vGPU, I was only running two VMs. Each of those two VMs had a Titan RTX passed through to it. When I install the vGPU host driver, the passthrough of the Titan RTX cards to the existing VMs stops working. The VMs won’t start and the libvirtd process hangs with an input/output error message when I run “systemctl status libvirtd”. It seems like the vGPU host driver is grabbing my Titan RTX cards but I have passed the VFIO PCI dummy driver to them at boot time. See /etc/default/grub file below. Any assistance would be greatly appreciated.GRUB_TIMEOUT=5
GRUB_DISTRIBUTOR=“$(sed ‘s, release .*$,g’ /etc/system-release)”
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT=“console”
GRUB_CMDLINE_LINUX=""crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet modprobe.blacklist=nouveau intel_iommu=on iommu=pt vfio-pci.ids=10de:1e02,10de:10f7,10de:1ad6
GRUB_DISABLE_RECOVERY=“true”
GRUB_ENABLE_BLSCFG=trueHi Brad,Thanks for the question.  This is not a configuration we would ever QA.  The vGPU host driver is likely detecting that the Titan RTX GPU is not compatible with vGPU and not initializing correctly on them as a result.:D:Powered by Discourse, best viewed with JavaScript enabled"
326,product-feature-map-not-found-error,"Hi thereI am trying to migrate to the new DLS license server type. What could this error indicate? My GPUs remain unlicensed despite importing the client token.image1830×829 64.9 KBHi,make sure your VMs have at least the vGPU 13.x driver installed!!!Best regards
SimonThanks I installed a lower version on the Citrix prod image and it worked.Powered by Discourse, best viewed with JavaScript enabled"
327,grid-11-to-13-upgrade,"I can’t seem to find any documentation about the upgrade process for GRID 11 to 13.What is the process on the ESXi host?  Just this?
esxcli software vib update -v %path-to-zip%Powered by Discourse, best viewed with JavaScript enabled"
328,first-gpu-server-advice,"I run the software engineering lab at a College and of course over the past number of years as AI has taken off so has the number of students working on AI related final projects (mostly projects based around TF but also others). What we currently have is a dozen or so stand alone ""workstations"" running a mix of single 980/1080 Ti cards and this sometimes means doubling up projects on one PC. The department head now wants to buy something scale-able a GPU server, each project with their own VM that could make use of available resources rather then limited one VM one GPU. But I am a bit overwhelmed and unfamiliar regarding Host OS options, hypervisors, Nvidia vGPU licensing…
The server they want is the Asus ESC8000 G4 https://www.asus.com/us/Commercial-Servers-Workstations/ESC8000-G4/ this is bare meta and it (currently) does not support esxi which we use for our other servers.
The goal for me most likely being responsible for setup and implementation is OS familiarity, minimal headache and learning curve and to keep prices down.
Thanks for bearing with my long post.HiFor simplicity, support, stability, management, compatibility, scaling, general information and all the other benefits associated with enterprise grade hardware, you should be looking at something from one of the big OEMs (Dell, HP, Cisco etc) as your core enterprise infrastructure where you’re supporting hundreds / thousands of concurrent students workloads 24x7x365.As you work in EDU, you should be entitled to significant EDU specific discounts from the OEMs (including NVIDIA) which should make life easier and save you going for less appropriate brands. If you purchase your hardware and NVIDIA licenses from the same vendor (Dell for example) you can negotiate much better discounts.AI isn’t just about the GPU, the whole platform needs to be an end-to-end solution or you will have performance bottlenecks. Storage and network are also crucial to avoiding these issues. You should be looking at nothing less than All Flash / NVMe storage for your workloads and 10GB+ networking depending on where you run the workloads from.As for GPUs, you’ll be wanting V100 and / or T4 GPUs. As you’re working with AI, you’ll want QvDWS licensing which is licensed per concurrent user (so every concurrent (not named) user will need a QvDWS license).Depending on your requirements, you may want a single extremely high powered server (DGX-1 for example, which has 8x V100s running in NVLink and some very special software)) and then a more granular set of servers to cater for student density (maybe a Hyperconverged infrastructure that combines high performance Storage and Compute with linear scaling and easy management, something like Cisco Hyperflex for example combined with multiple T4s per Node). Or if you want individual Nodes, then a Dell R740 / HP DL380 / Cisco C240 all with multiple T4s attached to a high performance All Flash storage appliance would suffice.If a DGX-1 is a slightly scary proposition due to its software stack, then you could go for something like the ""EMC DSS8440"" from Dell which supports up to 10x V100s where you could simply drop ESXi on to it and then virtualise each of the V100s to provide multi user support per GPU. With the latest NVIDIA vGPU software, Multi-vGPU support is available so you could connect multiple V100s into a single VM for added performance if required. Local storage available on this server is both SSD and NVMe and the CPU options currently are dual Xeon Platinum 8168 2.7G, 24C/48T. The slight caveat here is that (unlike the DGX-1) this server is PCIe and doesn’t support NVLink and it also doesn’t support more than 1TB of RAM currently. Cascade Lake Scalable Xeons should be coming for it towards the end of this year / early next year, when hopefully Dell will allow more RAM to be added as well. However, it’s a great bit of kit to get you started if you wanted to go down that route, and then for greater user density scale out to other infrastructure (as mentioned above) using T4s.With respect (and having personally seen it a few times from customers) … You say you want to keep costs down (just like everyone else) but if you cheap out on the platform to start with, it’ll cost you more in the long term by delivering poor performance, limited component support, functionality and scalability (you’ve already mentioned that ASUS doesn’t support ESXi) and most importantly a bad user experience.Speak to the OEMs first, see what EDU discounts are available to you (you should be entitled to some) and go from there.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
329,unable-to-configure-a100-on-a-vsphere-7-0-3,"Hi,
tried to configure A100 (GA100 [A100 PCIe 80GB]) on ESXi 7.0.3 but nvidia-smi fails:[root@xxx:~] nvidia-smi
NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.[root@xxx:~] esxcli software vib install -v /directory/NVIDIA_bootbank_NVIDIA VMware_ESXi_7.0.2_Driver_510.85.03-1OEM.702.0.0
.17630552_77c428eb-3731-4fbf-95da-394c4e086433.vib
Installation Result
Message: Operation finished successfully.
Reboot Required: false
VIBs Installed: NVIDIA_bootbank_NVIDIA-VMware_ESXi_7.0.2_Driver_510.85.03-1OEM.702.0.0.17630552
VIBs Removed:
VIBs Skipped:any idea?Did you manage to get it running, think I´m in the same boat as you are.Hi @weidi1 yes I did :) A100 needs EnterpriseAI license… i explained it here How to configure vSphere 7 with Multi-Instance GPUs (MIG) or Time-Sliced Profiles on the NVIDIA A100 - VIRTUALINCAHi,where did you get the host driver from? Be aware that you need NVAIE license for this use case and the matching host driver from the NVAIE package to contain the right device IDs for this GPUEdit: vesic was a bit faster with his response :)I was hoping that the usual vGPU driver would magically work but was tought better ;)Powered by Discourse, best viewed with JavaScript enabled"
330,is-it-possible-to-recognize-vgpu-as-a-physical-gpu,"Hi.Is it possible to recognize individual vGPUs as individual physical GPUs?I want to do distributed deep learning with multiple vGPUs on a single GPU.
I wish I could use vGPU directly, but it doesn’t seem to be possible.Hi,
Sorry, but I don’t understand the use case described. What exactly are you going to achieve? Assign multiple vGPU profiles to a single VM?Hi.Not a VM. I want to use multiple vGPUs at the same time in a PC equipped with RTX A6000.
It does not connect to other PCs.
I want to use vGPUs for deep learning.Are vGPUs recognized by nvidia-smi like GPU?2022年2月15日(火) 17:55 sschaber via NVIDIA Developer Forums <nvidia@discoursemail.com>:For sure this works. This is exactly the intention for vGPU. You need the use the mode selector tool available from our developer portal to modify the A6000 to make it capable to run vGPU. In addition you need a supported Hypervisorgreat! I wanted to use vGPUs for distributed reinforcement learning, but no one seems to use vGPUs for it.Where is the portal site? I would like to know the specific modification method. However, I don’t know if I can do it2022年2月15日(火) 18:27 sschaber via NVIDIA Developer Forums <nvidia@discoursemail.com>:The tool is available here: NVIDIA Display Mode Selector Tool | NVIDIA Developer I downloaded the’NVIDIA Display Mode Selector Tool’.
How do I run the ‘displaymodeselector’ on Linux? It seems that the manual only mentions Windows…
NVIDIA Display Mode Selector Tool User Guide.pdf (343.2 KB)The tool also works on Linux an mentioned in the docs.Suggestion: As it seems you are not really familiar with vGPU you should look for a skilled partner. As you have seen, vGPU is not a one click solution but a software stack that needs some experience. Here is our partner network where you find a skilled partner in your region:
https://www.nvidia.com/en-us/about-nvidia/partners/partner-locator/That’s right.What exactly is the next “necessary support”?
Also, what should I do if I want to restore the firmware?Please check with a virtualization partner first. If you don’t know what you are doing, you may end up with a displayless machine. Keep in mind that changing mode will disable the display heads so you will need a different onboard GPU or second NV GPU in the machine that serves as primary display adapter!I should check with virtualization partner, but I can’t contact  virtualization partner because my purpose isn’t a VM. If there is no problem with the onboard gpu, there is no problem. There is no problem if the RTX A6000 is not damaged in terms of hardware, but is there a possibility that damage will occur in terms of hardware?The concept of vGPU always works only with VMs. If you want to use GPU partitions on baremetal then you can only use MIG with A30 or A100 GPUs. No way with A6000.I tried my best to support. This is just a forum and not a consulting replacement. Please get professional assistance in your regionPowered by Discourse, best viewed with JavaScript enabled"
331,tesla-m60-power-brake,"Hello guys,
I do own a Tesla M60 using it with VMware vSphere.Within the manual on page 9 is mentioned a power brake header: Tesla M60 Manual (nvidia.com)Is there further documentation? Is it a jumper? Is it used to force lower power consumption?CheersPowered by Discourse, best viewed with JavaScript enabled"
332,crashes,"Hello everyone, do not tell me why when I try to run the Grid (chose a server, after press start) I closed the program and writes that stopped the program, I am sorry for my English. And if I try to run through Google, it does not load, although test i have bandwith:8mbPowered by Discourse, best viewed with JavaScript enabled"
333,nvwmi-fakeedidonport-will-set-all-port,"Hello.
There is a problem about create the second display.
run the command
wmic /namespace:nv path GPU WHERE id=1 CALL fakeEDIDOnPort filePath=C:\ProgramData\EDID.txt output=5 portIndex=1
It will create 4 displays,  It seems that the portIndex paramter is not used.
Then, the 4 displays can be removed all by command wmic /namespace:nv path GPU WHERE id=1 CALL fakeEDIDOnPort filePath="""" output=5 portIndex=1 ,  or can  be removed one by one by command wmic /namespace:nv path display WHERE id=100x CALL setEDID.How can I create one display, not 4 displays by fakeEDIDOnPort ?Powered by Discourse, best viewed with JavaScript enabled"
334,a5000-need-to-execute-the-shell-command-usr-lib-nvidia-sriov-manage-e-000000-0-when-i-reboot-the-machine,"I change the mode as below:
./displaymodeselector --gpumode physical_display_disabled
./displaymodeselector --gpumode compute --auto
and then exec the command:
/usr/lib/nvidia/sriov-manage -e 0000:3b:00.0
the directory  /sys/class/mdev_bus is correct;
but I found a serious problem,when I reboot the machine,I have to execute the shell  command /usr/lib/nvidia/sriov-manage -e 0000:3b:00.0 again,it is unreasonable;because some vGPUs(8G or 16G .and the total is  24G) maybe adapter to VMs;
Some ideas?Can you help me?Powered by Discourse, best viewed with JavaScript enabled"
335,virtual-gpu-members-logging-into-the-new-forums-for-the-first-time,"Step 1 : Click “Login” button on forums.developer.nvidia.com
step 1 - click login1091×1353 128 KB
Step 2: Enter email address
step 2 - enter email1106×865 32.7 KB
Step 3: Login with an existing NVIDIA account OR jump to step 4
step 3 - sign in1106×865 27.2 KB
Step 4: Create a new account
step 4 - create account1106×865 29 KB
Note that the email address for this new account must match the email that was used for the GRID forums.If creating a new account, check your inbox for a verification email.Powered by Discourse, best viewed with JavaScript enabled"
336,hpe-dl380-gen9-vsphere-esxi-6-5-u1-or-u3-with-nvidia-grid-k2-crash,"Hello,For education purpose I’m trying to get a Nvidia GRID K2 card working inside VMware, The cards works fine under Windows Server 2016 with Hyper-v roll using DDA to a VM but I would also like to try some VMware methods.So I downloaded and installed the HPE Vmware custom ESXi 6.5 U1 for Gen9 and later, after this I tried to load in the Nvidia GPU manager driver by uploading the VIB in this download (NVIDIA GRID VGPU SOFTWARE RELEASE 367.130/370.35 | 370.35 | VMware vSphere ESXi 6.5 | NVIDIA) and using the vib install command that is in the included PDF guide.However, 2 things happen. The Server reboots or it will give me the following PSOD.
1919×943 163 KB
After this I tried to update the vmware to 6.5 U3 using HPE custom but it still gives me the same issue.Under PCI hardware it does show the K2 card and when enabling passtrough on both K2 chips the and rebooting and installing the driver again, it completes succesfully, however it won’t see the cards/driver as loaded because they are in passtrough mode.How can I fix this?Powered by Discourse, best viewed with JavaScript enabled"
337,vgpu-vms-vmotion,"Hello Dears,We implemented virtual platform based of VMware vSphere 7.0 and NVIDIA RTX is used for VDI VMs based on VMware Horizon 8.
We are facing the strange issue:
Manual hot migration of VMs with vGPU works well. But when I initialize ESXI host’s entering to maintenance mode, VM with vGPU doesn’t migrated automatically. Only DRS recommendations appears in Cluster>>Monitor>>DRS Recommendations. vGPU VM’s migration starts as soon as we apply DRS recommendations.Is it expected behavior or not?DRS automation level is set to “Fully automatic” and there are no problems with no-vGPU VMs migration in the same scenario.
Latest 460.32.04 host driver is installed on ESXi Hosts.Only DRS initial placement is supported from VMWare at this stage. Full DRS support might come later in the year but we cannot comment on VMWare roadmap features.Hi,is there any improvements on the subject with the last release of vsphere ?RegardsNot that I’m aware of. But as this is a pure VMWare feature you might get a better response in their forums.Powered by Discourse, best viewed with JavaScript enabled"
338,need-help-in-technical-understanding-of-board-design-and-flashing-vbios-of-tesla-k80-cards,"Hi Folks,I also posted this in another NVIDIA forum (but it is 6d ago and no response - guess the forum choice was bad…), so please excuse if you get it twice…If you know a better place to post, please let me know, THX.I’m struggling with some Tesla K80 for a few days…Yes, old cards - but still good for my needs, so I’d really want them to run the way I think they should.HW config: Supermicro 2028GR Server (so enough power is available), 4 Tesla cards - properly cabled and powered. (Very) short description of the problem(s): i) two of the cards won’t reach the max. GPU boost clock, ii) I am not able to find reliable (100% unmodified) VBIOS’es for the card and iii) I have a few technical questions…Here is the output of “nvflash --list” (version 5.792 / linux x64):[root@tesla80 Tesla_K80_flash_linux]# ./nvflash --list
NVIDIA Firmware Update Utility (Version 5.792.0)
Copyright (C) 1993-2022, NVIDIA Corporation. All rights reserved.NVIDIA display adapters present in system:
Tesla K80            (10DE,102D,10DE,106C) S:00,B:04,D:00,F:00
Tesla K80            (10DE,102D,10DE,106C) S:00,B:05,D:00,F:00
Tesla K80            (10DE,102D,10DE,106C) S:00,B:83,D:00,F:00
Tesla K80            (10DE,102D,10DE,106C) S:00,B:84,D:00,F:00
Tesla K80            (10DE,102D,10DE,106C) S:00,B:89,D:00,F:00
Tesla K80            (10DE,102D,10DE,106C) S:00,B:8A,D:00,F:00
Tesla K80            (10DE,102D,10DE,106C) S:00,B:8D,D:00,F:00
Tesla K80            (10DE,102D,10DE,106C) S:00,B:8E,D:00,F:00
[root@tesla80 Tesla_K80_flash_linux]#So let’s start with the technical qustions:Card B, GPU4:
Version               : 80.21.1B.00.01
Board ID              : 0xE505
Card B, GPU5:
Version               : 80.21.1B.00.02
Board ID              : 0xE504
Card B’, GPU6:
Version               : 80.21.1B.00.01
Board ID              : 0xE505
Card B’, GPU7:
Version               : 80.21.1B.00.02
Board ID              : 0xE504So this would make sense for me, the last digit of the BIOS Version is correlated to a specific board number (1 → 0xE505, 2 → 0xE504).However, this does not hold for the other cards, (named A and A’ from now on - these are the cards with the GPUs 0-3):Card A, GPU0:
Version               : 80.21.1F.00.06
Board ID              : 0xE504
Card A, GPU1:
Version               : 80.21.1F.00.05
Device Name(s)        : Tesla K80
Card A’, GPU2:
Version               : 80.21.1F.00.05
Board ID              : 0xE505
Card A’, GPU3:
Version               : 80.21.1F.00.05
Board ID              : 0xE505So, card A’ shows 2x the same Verion & Board ID, which leads me to two questions:What I’ve done so far:I carefully read K80 application clock limited to 562 Mhz :-)When I got the cards A and A’, they both ran on a max GPU clock of 562MHz. So I decided to change / modify the BIOS. I made a backup of the original BIOS (unfortunately just one, as I was not aware that this might be of importance…) and flashed the cards using one original BIOS of card B, leading the system to hang, both Linux (CentOS 7) and Win10 (I think at the very moment when the drivers are loaded, as Win10 wihout installed K80 drivers boots fine). Same behavior when I used the “pairs” of BIOSs from Card B to flash Cards A, A’ (and I cannot remember for sure, but I think at this time, Card A’ had also two different Board IDs…)
So I used “Kepler BIOS Tweaker” from techpowerup to modify the original BIOS I got from Card A, and flashed it to all GPUs of Card B, B’ (using the nvflash for win with the Board ID test disabled…), which particulary led to a success, as the first GPU of the Cards A, A’ ran at 875MHz, but the second one at lower clocks (mostly at 562MHz, sometimes a bit more, but never fullspeed).
As I was not able to find original, unmodofied VBIOSs for the K80, I decided to go for a firmware package of HP (containing the BIOSs versions 80.21.1F.00.06 and 80.21.1F.00.05). This was a *scexe and ran without any issues. However, similar behaviour as before, but the second GPU runs at even lower clocks…
After googeling (there is not much to find about the K80s), I found (by chance) ONE entry at the HP support describing the possibility to recover the original BIOS (which had the card at the time of shipping). So I guess there is a ROM on the card, which can be copied to the EPROM? This is a feature each electronic device using any kind of firmware should have…However, the tool is named iromflsh_ext and is stated to recover the “Info ROM” (is this the same as the BIOS? If yes, why different names? If no, what is this?), runs under linux and performed without any error, stating success. However, The BIOS Versions stayed the same, which I cannot believe to be true.So, thank you for reading so far, I know a lot of text (but a lot of info, too).What I would would like to know now:How can you help me?Experts, freaks, tweakers and modders, any help would be highly appreciated, if you need some more infos on the hardware, please let me know what is of interest.Thanks a lot for your precious time,Grettings from Vienna,ErnstPowered by Discourse, best viewed with JavaScript enabled"
339,hyper-v-pass-thru-license-entitlement,"I’ve read that the vCS has a compute driver, whereas the vWS license does not.  Does that mean (with vWs) i will not be able to run ML workloads in the VM i have attached the GPU to?Also, with this being DDA (not virtualized) and with the fact that I am not using RDSH/VDI (just straight-up VM) - Do i even need a NVidia “virtual GPU” license at all?Powered by Discourse, best viewed with JavaScript enabled"
340,additional-driver-is-showing-tesla-k20c-gpu-but-the-same-is-not-visible-in-nvidia-smi-command,"I am using Ubuntu 20.04. Initially, it was working fine. But as I ran some TensorFlow programs, it stopped working. After rebooting the system the problem persists. Now i am not able to use the second GPU. Please help me to solve the problem.Thanks
Screenshot from 2022-01-10 12-57-42738×465 54 KB
Additional driver screenshot is also attached.
Screenshot from 2022-01-10 13-11-241104×648 83.8 KB
Powered by Discourse, best viewed with JavaScript enabled"
341,another-error-43-in-esxi-but,"Hello,
I should not encounter this problem, but i can’t find a solution. I have been searching since yesterday morning.
Situation:
Esxi 7.2 host.
Guest os: windows server 2022/2019 eval fresh install.
Gpu for passthrough: quadro p400
After a fresh install of the guest os and only the nvidia driver package 528.49 for win server 2022/2019 64bit version i get the gpu installed but it is disabled with an error code 43.On the same host i have an older win 2019 vm which works great with this gpu in passthrough mode.
I did also try to add the advanced parameter ‘hypervisor.cpuid.v0’ as FALSE although this should not be needed anymore, as this is a quadro gpu and now nvidia will not usually block gpu in vm enviroment.So i have already installed 2 new vms with different oses that act abnormally.Any hint as to what i could try next?Thanks!Just to keep track of the evolution on this matter:For the issue of not being able to start the vm after a host restart, one needs to apply:
esxcli system settings kernel set -s vga -v FALSE
in the esxi host console. (according to this: Passthrough of Integrated GPU (iGPU) for standard Intel NUC)After this, I tried following the tutorial here without any luck:
https://logiklan.net/index.php/2021/06/04/fixing-windows-10-code-43-in-esxi-v6-7-vm/
BUT it got me thinking about one thing. Maybe a monitor connected while powering up the HOST would do a difference? and yes, it DID.I managed to start the host with a dummy plug in the dedicated gpu, drivers installed, all ok. The issue is still that on the old vm I do not need a dummy monitor plug. I think it might be an issue with setting the main display unit to use in the host’s bios. Because now it is working for me, I will not investigate this further.My next issue is that I am now not able to remote connect to the guest windows server 2022 vm while the dedicated gpu is available. I tried disabling Use WDDM graphics display driver for Remote Desktop Connection as per https://www.reddit.com/r/sysadmin/comments/jni86j/psa_if_youre_having_issues_connecting_via_rdp/ but this only gets rdp working while the dedicated gpu is disabled. if it is enabled , I still get an error ‘The graphics display components in the remote session failed to start up. Error code 0X11’L.E.
Updated drivers to latest version again, and now remote desktop is also working.Powered by Discourse, best viewed with JavaScript enabled"
342,gpu-in-microk8s-is-not-appearing-as-an-add-on,"Hello,i have a couple of AGX Xavier devices, which i try to connect to a microk8s cluster in order to create containerized services. For both i have used the sdkmanager to install all packages, etc. It seems to have worked fine (i have also installed the NVIDIA runtime).As a bare metal device i managed to run a human presence detection model based on yolo following (Installing PyTorch and YOLOv5 on an NVIDIA Jetson Xavier NX).After installing  microk8s following a typical snap install i can deploy a micro service (e.g., nginx), based on containerd runtime (from snap info microk8s version 1.22.3, and kubect v1.22.3-3+64e63223b19811).Btw, i had do disable ha-cluster, since it uses calico for the cni, and calico kernel modules are not installed in the legacy tegra kernel (it misses some kernel modules such as ip_set). To solve this i disabled  ha-cluster add on, which switches to flannel networking and works fine, (i.e., internet access from the pod)The problem is that the microk8s GPU add-on (MicroK8s - Add-on: gpu) is missing from the microk8s status command. In a legacy x86 system i see the add-on present, however not the the agx xavier.Is there an extra step for this with respect to the installation of the GPU? Did i miss something?Also, i am using containerd as my runtime and NOT docker, is this a problem?
I have also seen this Announcing containerd Support for the NVIDIA GPU Operator | NVIDIA Technical BlogAny help appreciated.all the best,
Pavlos.Wrong forum. Please check to post in the compute related forum. Here we deal with virtual GPU related topicsPowered by Discourse, best viewed with JavaScript enabled"
343,nvidia-grid-license-release-settings,"Hay,We are using several NVIDIA M10 cards and use the vGPU within VMWARE Horizon.
The issue I’m dealing with is how and when the NVIDIA license are released within the NVIDIA license Server.
Therefore in your client / golden image u can use 2 regkeys: LingerInterval and LicenseInterval (see here: Client Licensing User Guide :: NVIDIA Virtual GPU Software Documentation)Now, the LingerInterval is set at 0 and the LicenseInterval is set at 480 (8 hours)
With this settings I see oversubscribed licenses and also double machine names within the NVIDIA license server.My question is: what are the correct settings for these 2 regkeys, so grid licenses are released / removed when the computer will shutdown.Regards,
PascalPowered by Discourse, best viewed with JavaScript enabled"
344,quadro-m4000-on-server-dell-r730,"Hello,I am trying to install my quadro M4000 on my Dell R730 server in order to dedicate its GPU to a virtual machine.
My server is installed on windows server 2016. I installed the driver 461.40winserver-2016-2019. The card is recognized in the device manager but disabled by windows (error code 43). I have tested lots of older drivers, nothing works. My M4000 card works on a workstation on windows 10. A geforce 9600GT works on the server. Are my R730 Server, windows server 2016 and my M4000 compatible? Which driver should I install? Is error code 43 related to a driver problem? thank you in advance!

Capture2764×920 44.3 KB
Hello merlin.pinet
Thank you for the post.
I will pass your inquiries on to the proper channels for review.
Thank you for your patience.Moving this to the vGPU forum.Powered by Discourse, best viewed with JavaScript enabled"
345,vmware-sanity-check,"Hello all,I am trying to setup a vGPU cluster using Tesla v100 32GB GPUs on several HP ProLiant DL380 Gen10 running ESXI 6.7u3. So far I have been able to setup the vSAN and install the NVIDIA .vib version 11.2, and can successfully run nvidia-smi on each host.I now attempting to configure a VM, adding a single I have tried adding a single V100D-16C vGPU to a VM and installing the 450.89 grid driver with and without DKMS, however cannot seem to load the kernel module. Dmesg tell me that the ""PCI I/O region assigned to your device is invalid: NVRM …"" and the supposed address of the GPU. I get the same error on Debian Buster, and Ubuntu Server bionic and focal.I have checked the hidden settings in the HP BIOS, and is enabled ""PCI Express 64-bit BAR Support"". ECC should be working fine on a ""C"" style VGPU.Is there anything I am missing?Powered by Discourse, best viewed with JavaScript enabled"
346,vsphere-6-7-toggle-passthrough,"Hello   May I use Vsphere esxi 6.7 to use Nvida license server for toggle passthrough?
16196656175831323×466 83.8 KB
Powered by Discourse, best viewed with JavaScript enabled"
347,view-horizon-7-xx-tesla-m10-nvidia-license-server-needed,"I in a Horizon View 7.xx with sVGA VDI’s do I need the license nvidia server? Of course I need the license, but in my opinion the license server is only needed for vGPU’s. Right?Powered by Discourse, best viewed with JavaScript enabled"
348,xenserver-passthrough-gtx-1080,"Hello,I would like to passthrough my GTX 1080 to a VM using XenServer (XenDesktop).
Is this possible with a consumer card?RegardsBlvckBatHiYes, this works.If this is for R&D or a Lab etc, then great. But if you’re planning to use it on a larger scale in a datacenter for enterprise type workloads, then please read the NVIDIA EULA first … :-)RegardsBenHi MCYes, have done it myself about 2 weeks ago. Physical workstation with XS 7.5 installed and GTX 1080 TI. Requires BIOS modification so that XS doesn’t grab the 1080 for its self, but works absolutely fine :-)RegardsBenHi BJones, can you share some details how you did it?Guys,
this is not the right place to discuss topics that violate our EULA. For sure there are ways to do so but this is not permitted as we don’t allow to use Geforce in virtualized environments.Regards
Simon.Guys,
this is not the right place to discuss topics that violate our EULA. For sure there are ways to do so but this is not permitted as we don’t allow to use Geforce in virtualized environments.Regards
SimonSimon,
Any license agreement that restricts the personal use of an overpriced piece of hardware that I bought is illegal.
Your EULA only concerns the use of your software, not your hardware. And it says ‘no datacenter deployment’, not ‘no virtualized environment’. My home is not a datacenter.
It means that we have the right to passthrough our gpus on our own virtualized system, and to perform any tricks that will override the artificial limitations of your software, as long as we’re not in a datacenter.
It’s my understanding that NVidia cannot imagine a retail consumer doing something else with their gpus than playing video games, and that’s why this lazy trick is implemented in Nvidia software to block companies from buying GeForce for their datacenters, not concerned about the implications for other legitimate retail consumers use cases, and the potential for an expensive class action down the line.
Additionally, going so far as to block any discussions on this topic on your official forum is a bit insulting for the people that spend so much money buying your products.
Sincerely
PaulPowered by Discourse, best viewed with JavaScript enabled"
349,nvidia-driver-on-esx-6-5-causing-psod,"Hi,We have a Dell R730 running VMware ESXi, 6.5.0, 13932383 with a Tesla M10 GPU installed.
A colleague yesterday installed the NVIDIA ESX VIB onto it and configured GPU passthrough
This morning it gave a purple screen of death as below.IOMMU Fault detected for (vmgfx1/nvidia)
NOTE: Backtrace likely does not yield the culprit.PanicvPanicInt
Panic_NoSave@vmkernel
IOMMUProcessFaults@vmkernel
helpFunc@vmkernel#nover
CpuSched_StartWorld@vmkernel#I opened a case with VMWare support who responded with the following.[i]We had a vmkernel panic with IOMMU fault.The IOMMU fault happened because the PCI device (0000:06:00.0 which is the nvidia graphics pcie device) trying to access the memory address (IOaddr: 0x6055b0d000) via DMA operation which nvidia device (vmgfx1/nvidia) is NOT intended to access the memory and IOMMU unit faulted the illegal memory access and panic the system.The illegal DMA memory access may be caused by buggy nvidia driver or nvidia firmware running inside the card.
Kindly check with you NVIDIA if there is further update on the driver and firmware that can be performed.
[/i]We don’t have an active NVIDIA support contract so I’m hoping someone here has experienced similar and has a solution?Thanks.Powered by Discourse, best viewed with JavaScript enabled"
350,nvidia-tesla-m10-memory-issue,"Hello,
We have a Dell R740 server and Tesla M10 graphics card.
I have installed the grid driver “NVIDIA-GRID-vSphere-6.7-460.32.04-460.32.03-461.09” on the esxi 6.7 host.
But the M10 memory is just 24GB as below.

I try with other server like HP DL380, DL580, it’s the same issue.
Kindly let me know is this a known issue and any resolution available for this issue?Regards,Hi,Looks like you are not seeing 1 GPU.
Did you connect the power cable to the Card? If you did, maybe you need a firmware update.Let me know if you need any further help.Regards,SjoerdPowered by Discourse, best viewed with JavaScript enabled"
351,microsoft-cloud-solution-provider-csp-program-nvidia-deployment-unavailability,"Hi,Need your help with deployment of Nvidia Azure Marketplace images to Azure subscriptions opened under the Microsoft CSP program.

Azure deployment of NVIDIA image - CSP unavailability827×844 40.2 KB
Any suggestions NVIDIA?BR,
MarkoPowered by Discourse, best viewed with JavaScript enabled"
352,grid-k2-different-versions,"Hi all,
I am about to buy a Grid K2 for vsga in a vmware esx 6.5 server. On ebay there are many listings, and some list with a dell part number (KVJ6K).
Are these physically or software-wise different from others, or in general are there different versions of these cards that will only work in specific systems? Or do som just happen to have a dell stock number?Don’t want to buy one that does not fit or work. I have a hp proliant ml350P G8, vmware 6.5U3.Thanks in adwance,
Sven.Powered by Discourse, best viewed with JavaScript enabled"
353,vgpu-a40-mixed-display,"Hi all, i search how enable mixed display mode on my A40 card under VMware ESXi, 7.0.3, 20328353 on DELL Poweredge R750. I can enable VM with different profile. So is it possible or not ? Thanks in advance.Powered by Discourse, best viewed with JavaScript enabled"
354,dls-client-token,"I have a new DLS Licensing server that will be running as a stand-alone for a period of time. I will be generating the client token with only this server to start with and issuing it to clients. When I add the second DLS server and enable HA I’m assuming I will need to generate a new client token that would include it and distribute to clients. Is this correct? Thanks.Correct!Powered by Discourse, best viewed with JavaScript enabled"
355,need-latest-driver-for-windows-2016-server-with-grid-k2,"Hi All,
I need latest driver Windows 2016 server with Grid K2 i got NVIDIA Windows drivers for vGPU version 370.21 but this is not the latest.Reference the documentation for all releases of NVIDIA virtual GPU software.4.x branch. 4.8 is the latest driver available for K2.
What’s the issue with downloading the latest driver from our website?Download the English (US) NVIDIA GRID VGPU SOFTWARE RELEASE 367.130/370.35 for  VMware vSphere ESXi 6.0 systems. Released 2019.3.19regards
SimonDownload the English (US) NVIDIA GRID VGPU SOFTWARE RELEASE 367.130/370.35 for  VMware vSphere ESXi 6.0 systems. Released 2019.3.19Is it the latest drivers set as my vendor tells us that ""Schlumberger support are now recommending that we use NVidia driver version 377.11""and i can see drivers on the URL is for Operating System:	VMware vSphere ESXi 6.0  will it work for windows 2016 Physical server.Currently attached are the screenshot of drivers which i can see so i am not sure which drivers my machine is using.
Is it Matrox G200eh or NVidia 370.21.


nvidia.PNG769×74 7.02 KB
For sure the guest driver is compatible with Windows. If you need a newer driver you need a new GPU. K2 is EOL for a long time already and R367 is the latest branch supporting K2.Powered by Discourse, best viewed with JavaScript enabled"
356,proposed-talks,"Want to ask a question of the developers, post here!Hello,I saw a video on Youtube, where Jason Southern has connected an Oculus Rift with a Grid Server. We are trying to do something similar and would you to ask some questions about this.
We have a Grid K1 server here and trying to realize this solution on a native headless Linux Server without a hypervisor solution like XenServer etc.So the first thing I want to ask is, how do you handling latency with the Rift? In VR Application, latency is more important than in usual Application, so in best case, you would have 30ms latency for the Server, 30ms for the networking and 16 on client side, without the Software Overhead for getting Position from the Rift Device to the Server.I know the video from Jason Southern is not quite long, but I am interested in if he uses a shim layer Application for Encoding, or does he instrumentalizes the Oculus Application to get informations needed?
We want to try some Optimizations for Frameprediction so where would you cut the Application to realize something like that?Best regardsHow to register in Ukraine?I saw a video on Youtube, where Jason Southern has connected an Oculus Rift with a Grid Server. We are trying to do something similar and would you to ask some questions about this.I didn’t build it, the Occulus setup was actually by Magnar Johnsen, and nothing was done to minimise latency beyond optimising hte network.Magnar has a blog here:https://www.virtualexperience.no/Latency is a huge issue with VR, and there’s a lot of research going into how to enhance the experience using remote protocols.Maybe this video by Magnar. https://www.citrix.com/blogs/2014/05/23/is-running-xendesktop-remotely-on-a-server-8000km-away-with-700ms-latency-on-an-airplane-with-an-oculus-rift-virtual-reality-application-insane/This was done on the oculus v1, later versions have been problematic to get working as oculus changed some stuff that made it less citrix/VMware friendly. In v1, support just happened by multi-monitor support.Latency per se isn’t an issue depending on what you are doing - in this case with magnar on 700ms was fine because he was essentially watching video, a rollarcoaster simulation. Video is very tolerant, can be buffered. Interactive shoot-em-up or CAD will be harder as you can’t fight the speed of light (although Citrix’s new USB on WAN - see Wacom support has some support that could be exploited in these scenarios to some extent)Powered by Discourse, best viewed with JavaScript enabled"
357,vmware-esxi-7-0u2a-after-installing-nvidia-driver-vib-nothing-happens,"Hi I really need help on getting started with out Nvidia vgpu. However during the installation of the “NVIDIA-GRID-vSphere-7.0” on vmware Esxi 7.0U2a, we could manage to install the VIB file on the esxi successfully. However after checking with “vmkload_mod -l | grep nvidia” nothing comes up. Also with ""dmesg | grep -E “NVRM|nvidia” the results doesn’t not match with the tutorial video. And running “nvidia-smi” says that the driver cannot connect with server and asks to download the latest version driver. We tried all the version with their allocated esxi versions same thing occurs. Please do help with this issue. Thankyou.Pictures with information of the Vmware version and Output has been given below :

Trouble shoot1909×888 92.1 KB
It looks like you are running ESX within VMWare Workstation and what I can see from the processor this won’t be a supported hardware. There is a good reason why vGPU is only supported on qualified servers.Download NVIDIA GRID datasheets, guides, solution overviews, white papers, and success stories. Watch GRID videos, webinars, and webcasts.Best regards
SimonCan you please explain what do you mean by unsupported hardware. What if I boot esxi directly from a pen drive rather using vmware workstation.
Thanks.Depending on the GPU the hardware needs to fullfill different requirements. You didn’t even mention which GPU you are trying to use. For example you need to enable SR-IOV for several GPUs which I don’t think is working in a vested virtualization. It might work in other servers/workstations but please understand that we cannot be of much help then.regards
SimonHello there we chose nvidia’s vgpu enterprise version “https://www.nvidia.com/en-us/data-center/resources/vgpu-evaluation/“ using this link. For our project we selected Rtx 6000 version as our vgpu. However upon following the YouTube tutorial by nvidia we faced some errors and, now here in the forums we seek guide, we saw Simon successfully helped a guy out with his problems. We hope our problems do get solved too.Thank you for the helping us with your precious time.Hi, GPU is fine but again: Without knowing which server hardware and BIOS settings it is almost impossible to help. Please don’t expect that you will get some help on non qualified hardware as this is most likely the source of failure.Powered by Discourse, best viewed with JavaScript enabled"
358,tesla-k20xm-remote-desktop-acceleration,"System Setup:
HP DL380 G6 - XenServer 7.2
Teala K20Xm Whole GPU Passthrough to Windows VM - Windows 10 / Windows Server 2012 R2DRIVERS:
340.84-quadro-tesla-grid-winserv2008-2008r2-2012-64bit-international-whql
442.50-tesla-desktop-winserver-2012r2-64bit-internationalHello, I have got a couple of these Tesla cards and have been trying to set them up in order to be used with Parsec (A remote game streaming program).
So far I have tried on Windows 7, 10 and Windows Server 2012. Following the steps which can be found here: Headless Parsec Streaming on GPU's without graphics outputs! - Guides and Tutorials - Linus Tech Tips
This involves using cmd to set the card to GOM ‘All on mode’ and then Setting the card to WDDM mode. As soon as I do this, I am unable to connect to the Virtual Machine via remote desktop, chrome remote desktop or via the XenCenter Console.
My question is. Can the Tesla K20Xm Card be used for Remote Desktop acceleration or graphics applications such as games via remote desktop or parsec?HiNot sure why you’re trying to use a GPU that’s nearly 9 years old and has been long discontinued?A far easier alternative would have been to buy a slightly more modern Quadro GPU and used the free Quadro drivers from NVIDIAs website. An M2000 (Maxwell) or P2000 (Pascal) would be a far better choice than a K20 and will work out of the box without having to try and play around with WDDM or anything else.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
359,vgpu-and-tensorflow,"Dear all,
I am trying to run tensorflow based programs on a VM Windows10. I don’t manage the installation so that tensorflow sees the GPU.The card is a NVIDIA Tesla P40, Hypervisor VMware ESXi, 6.7.0, 8169922
The VM has GRID-P40-24Q with driver 411.81 that works with CUDA 10.0I installed CUDA 10.0 and VisualStudio 2017, compiled the sample deviceQuery and when I run it the GPU is recognized and the output of the command looks like this:Installation of python 3.7 and tensorflow-gpu 1.14.0 worked. However when I query tensorflow if a GPU is found I get FALSE. The AVX2 comment seems more to be connected to the CPU only so it is probably not the issue.Overall I think that CUDA and vGPU are working but that the tensorflow is not able to access it.
Do you have a suggestion of what I can do?GreetingsAntonioAfter I posted the issue I tried it a last time by taking care that all versions match correctly and finally it worked.So it was all a question of versions of tensorflow and CUDA matching together. I also did reinstall tensor-flow not using condaGreetingsantonioPowered by Discourse, best viewed with JavaScript enabled"
360,visiting-certain-web-pages-breaks-the-nvidia-hardware-encoder-on-linux,"Sorry for the cross post but I don’t know which forum this should be in.This problem appears to be specific to the grid drivers on Linux.Nvidia hardware encoder errors cannot lock bitstream error 8 = NV_ENC_ERR_INVALID_PARAM  I’ve been having intermittent problems with the Nvidia encoder - it is reporting errors from my own code and I have also tested other code too, specifically...Powered by Discourse, best viewed with JavaScript enabled"
361,vm-start-failed-nvidia-a40-vgpu-could-not-initialize-plugin-usr-lib64-vmware-plugin-libnvidia-vgx-so-for-vgpu-nvidia-a40-1b,"When we want to start a VM on ESXi we get the message:
Could not initialize plugin ‘/usr/lib64/vmware/plugin/libnvidia-vgx.so’ for vGPU ‘nvidia_a40-1b’.VMware ESXi, 6.7.0, 19195723
Model: PowerEdge R750 with 2x A40 ECC disabled / SR-IVO enabledNVIDIA-SMI 470.82       Driver Version: 470.82       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A40          On   | 00000000:17:00.0 Off |                  Off |
|  0%   28C    P8    31W / 300W |      0MiB / 48687MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   1  NVIDIA A40          On   | 00000000:CA:00.0 Off |                  Off |
|  0%   27C    P8    31W / 300W |      0MiB / 48687MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+Does anyone know this error?Output from nvidia-smi -q:
==============NVSMI LOG==============Timestamp                                 : Mon Jan 31 10:31:42 2022
Driver Version                            : 470.82
CUDA Version                              : Not FoundAttached GPUs                             : 2
GPU 00000000:17:00.0
Product Name                          : NVIDIA A40
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Enabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1323721106657
GPU UUID                              : GPU-b1142892-1049-9944-c936-bdc6c4c59986
Minor Number                          : 0
VBIOS Version                         : 94.02.5C.00.03
MultiGPU Board                        : No
Board ID                              : 0x1700
GPU Part Number                       : 900-2G133-0100-030
Module ID                             : 0
Inforom Version
Image Version                     : G133.0200.00.05
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GSP Firmware Version                  : N/A
GPU Virtualization Mode
Virtualization Mode               : Host VGPU
Host VGPU Mode                    : SR-IOV
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x17
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x223510DE
Bus Id                            : 00000000:17:00.0
Sub System Id                     : 0x145A10DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 1
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : 0 %
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 48687 MiB
Used                              : 0 MiB
Free                              : 48687 MiB
BAR1 Memory Usage
Total                             : 65536 MiB
Used                              : 1 MiB
Free                              : 65535 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 192 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 28 C
GPU Shutdown Temp                 : 98 C
GPU Slowdown Temp                 : 95 C
GPU Max Operating Temp            : 88 C
GPU Target Temperature            : N/A
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : Supported
Power Draw                        : 31.56 W
Power Limit                       : 300.00 W
Default Power Limit               : 300.00 W
Enforced Power Limit              : 300.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 300.00 W
Clocks
Graphics                          : 210 MHz
SM                                : 210 MHz
Memory                            : 405 MHz
Video                             : 555 MHz
Applications Clocks
Graphics                          : 1740 MHz
Memory                            : 7251 MHz
Default Applications Clocks
Graphics                          : 1740 MHz
Memory                            : 7251 MHz
Max Clocks
Graphics                          : 1740 MHz
SM                                : 1740 MHz
Memory                            : 7251 MHz
Video                             : 1530 MHz
Max Customer Boost Clocks
Graphics                          : 1740 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Voltage
Graphics                          : 712.500 mV
Processes                             : NoneStrange output in vCenter:
grafik1342×351 26.2 KB
In case anyone comes across this, ESXi 6.7.0 only supports A40 in pass-through mode, not NVIDIA vGPU. You’ll need to upgrade to 7.0.2+, then your graphics devices will appear properly and then you can use NVIDIA vGPU.Powered by Discourse, best viewed with JavaScript enabled"
362,does-tesla-t4-support-pci-msi-x,"qemu-kvm throws error failed to add PCI capability 0x11[0x38]@0xc8: 0000:00:00:00.0 Attempt to add PCI capability 11 at offset c8 overlaps existing capability c8 at offset c8.I want to use GPUDirect Cliques according to vfio/pci: Add NVIDIA GPUDirect Cliques support · qemu/qemu@dfbee78 · GitHub.Powered by Discourse, best viewed with JavaScript enabled"
363,validation-failed-when-trying-to-create-nvidia-quadro-vws-win2019-in-microsoft-azure,"I received a validation error message on create virtual machine review page when trying to deploy nvidia-quadro-vws-win2019:{""code"":""MarketplacePurchaseEligibilityFailed"",""message"":""Marketplace purchase eligibilty check returned errors. See inner errors for details. "",""details"":[{""code"":""BadRequest"",""message"":""Offer with PublisherId: nvidia, OfferId: nvidia-quadro-vws-win2019 cannot be purchased due to validation errors. See details for more information.[{&quot;The Publisher: nvidia does not make available Offer: nvidia-quadro-vws-win2019, Plan: win2019-19-12 in your Subscription/Azure account’s region: ID.&quot;:&quot;StoreApi&quot;}]""}]}Any help would be appreciated.Hello, I and colleagues are experiencing the same error with all available options and regions. Is there an update on this?Powered by Discourse, best viewed with JavaScript enabled"
364,t4-driver,"I am looking for where to buy the driver package for Nvidia Grid xSphere 7.xAny help is appreciated.Hi Troy,please use the partner locator to find a partner in your region. Partners with the virtualization specialization can sell vGPU licenses.Use the NVIDIA Partner Locator tool to find a partner by country, competency, partner level, or partner type.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
365,is-it-possible-to-remove-a-licensed-client-or-shorten-the-lease-time-in-the-nvidia-license-manager,"Is it possible to remove a licensed client in the NVIDIA License manager? Some non-persistent VDI clients are already deleted but are still registered in the NVIDIA license manager because the lease time is not expired. Is there a way to shorten the lease time or delete the client from the NVIDIA license manager?Sure, just reduce the lease time in License server Web UI.
The default is 7 days so reduce it to 1 day as example.RegardsSimonWhere is that option in the UI and what version of the license manager are you using?Hi,sorry, my mistake. This is done with the RegKey:Documentation for system administrators that describes NVIDIA Virtual GPU licensed products and how to configure licensing for them on supported hardware.See LicenseInterval…RegardsSimonI believe there was a ‘Drop Client’ option on the older licence server however i don’t see this option on the latest GRID5 license server.  REGKEY looks to be the only option for client removalHi Nealus,you’re right. Unfortunately this option was removed from Flexera. We’re working on this to get the option back or another improvement.RegardsSimonWe have Tesla M10s and are running the 5.0 management console and cannot remove licenses that were assigned to deleted VMs. We also do not have those registry entries mentioned since our licenses do not have an expiration date but are perpetual instead. What makes it worse is that Nvidia support never calls back after the case is opened. Is there a workaround to this issue for customers that have perpetual (permanent) licensing?Hi Streuber,the workaround was posted 3 posts above. Please implement the RegKey.RegardsSimonDo I have to set LicenseInterval REGKEYS on Vm or on License Server or both?Just on the connecting client.I don’t fully understand how i can remove licensed clients if this VMs are deleted?
About LicenseInterval REGKEYS i understand, i can do it, when i still have VMs, but when they are delete, only option is to wait default LicenseInterval what is 7 days?Correct, there is currently no way to delete individual licensed clients.I am studying how NVIDIA Licensing works and will setup a Failover License Server. As we all agree,there is currently no way to delete individual licensed clients.But what, if it is too late, and like Edgars I have to free this locked licenses?Can I just wait for, let’s say 1 day, or are they never release again?Do I have to delete the license server database and set it up again, to get back my locked licenses?Locked licenses will be relased (default) after 24h.How is this done on a Linux based License server?Powered by Discourse, best viewed with JavaScript enabled"
366,510-47-03-rhel8-5-kvm-rtxa5000-nvidia-vgpu-vfio-unable-to-get-symbol-for-nvidia-vgpu-vfio-get-ops-from-nvidia-ko,"I have an RTX A5000, RHEL 8.5 with KVM, and I’m unable to get the nvidia-vgpu-vfio driver to load.  I’m using the NVIDIA-GRID-RHEL-8.5-510.47.03-511.65 driver package.Nvidia driver seems to install ok:After installing the vgpu manager (NVIDIA-vGPU-rhel-8.5-510.47.03.x86_64.rpm) and restarting, the nvidia-vgpu-vfio driver is not loaded, and I get this:Note in particular the line: [nvidia-vgpu-vfio] Unable to get symbol for nvidia_vgpu_vfio_get_ops from nvidia.ko.Some more details for context:Could someone help me out on this?  I’m at a loss…Thanks!Powered by Discourse, best viewed with JavaScript enabled"
367,a100-not-recognized-by-nvidia-smi-but-recognized-by-lspci,"There are two Graphics Cards on my PC. One is RTX 3090 and another one is A100. My main purpose is to install the A100 card. When I install A100 card on this PC, I enabled the CSM, and 4G encoding (Above 4G). However I cannot switch to integrated gpu graphics which disappeared when I enabled CSM. So I used a RTX 3090 at hand to output the graphics and it worked. But when I installed ubuntu server and sudo apt install nvidia-driver-###-server/open/None. I can only find the 3090 card in nvidia-smi. Meantime, all these can be finished in an SSH terminal because the HDMI output is totally black. I tried many combinations like download drivers from the official website or desktop or server.This is the output of lshw and I smmarized with ChatGPT.Based on the information provided in the output of the sudo lshw -short command, here are the details of the hardware components of the system:The command nvidia-smi worked before. But when I write the topic it outputs like this
$ nvidia-smi
Unable to determine the device handle for GPU0000:02:00.0: Unknown ErrorMy next try is buying an AMD graphic card RX580. I want to use this card to cheat the hardware and system.What can I do to make A100 available? Thank you for your help in advance.Powered by Discourse, best viewed with JavaScript enabled"
368,tesla-t4-vmware-esxi-7-0-1-and-citrix-virtual-apps-and-desktops-not-working,"HiI have a strange situation:Dell R6525
2x Tesla T4
VMware ESXi 7.0.1, 17325551Two VMs with Server 2019 and Citrix Virtual Apps and Desktops 7 1912 LTSR
Each VM has one Tesla T4 (in direct passthrough)Nvidia driver 461.09In windows device manager the Teslas showed up with no error (also the VMware SVGA 3D)When i run GPU-Z the Tesla showed up correctly with all its data (and 15360 MB memory size, which i think is correct)When i run dxdiag there are some problems:
Name: unknown
Vendor: unknown
Chip type: unknown
DAC-type: unknown
Device type: not applicable
Memory: 24575 MB (??)
VRAM: 0MB
Driver: unknown
Dirver-Version: unknownIf i run some Benchmarks in a Citrix Desktop Session (Unigine Heaven) it runs only with DirectX11 settings and 5 frames per second. CPU-load is at 80%, GPU-load (on GPU-Z or GPU Profiler) is at 0%So i think the card is not working correctly or i have some misconfiguration.
Or is it because i have not eny license yet because I am in an test phase at the moment?ThanksWithout a license, the driver is limited to ~3FPS–which it sounds like you are hitting.Nope. You need to enable the local policy in Server OS to allow to use the GPU in RDS sessions :)To use the GPU in RDS sessions on Windows Server 2012, enable the Use the hardware default graphics adapter for all Remote Desktop Services sessions setting in the group policy Local Computer Policy > Computer Configuration > Administrative Templates > Windows Components > Remote Desktop Services > Remote Desktop Session Host > Remote Session Environment.Powered by Discourse, best viewed with JavaScript enabled"
369,rtx3090-available-for-vgpu-on-vmware,"I’m trying to setup dell T640 and RTX3090 2ea.
I use vmware EXSi 6.7 version and want to know does this VGA model available to use Grid VGPU ???
thanksHiThe only GPUs you can use with the vGPU software are the top end Quadros (currently RTX 6000 / RTX 8000 / A6000) and the Datacenter (Tesla) GPUs. Consumer (GeForce) and Prosumer (Titan) GPUs are not supported.If you wanted to use Passthrough, then again, you need at least a Quadro GPU.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
370,sxm2-vs-sxm3-dimensions-and-pin-count,"The specs for the various SXM2, SXM3, SXM4, SXM5 connectors seem to be trade secret, or proprietary to the point where you can’t talk about it unless all parties involved in the discussion are members of the PCI-SIG.  Otherwise this info should exist somewhere on the internet and it doesn’t.  It’s quite frustrating.As far as I know SXM2 connector is physically incompatible with SXM4 and SXM5.  They are different dimensions and pin count.  I’m not 100 percent sure but based on guesstimation.Is SXM2 and SXM3 also not physically compatible?It would really help to have specs for these things, but it seems impossible.Powered by Discourse, best viewed with JavaScript enabled"
371,all-gpu-memory-in-use-and-no-program-running,"Hi,I use an ec2 server g2.2xlarge with GRID K520.
I’m wondering why the GPU reports that all memory is in use, reported with nvidia-smi.
I’m the only user on the server and don’t run any application.FB Memory Usage
Total                       : 4095 MiB
Used                        : 4052 MiB
Free                        : 43 MiBWhen I use GPU-Z to monitor the metrics, I see
Memory Usage (Dedicated):118 MB
Memory Usage (Dynamic): 19MBC:\Program Files\NVIDIA Corporation\NVSMI>nvidia-smi -i 0 -q==============NVSMI LOG==============Timestamp                           : Tue May 09 23:21:12 2017
Driver Version                      : 337.88Attached GPUs                       : 1
GPU 0000:00:03.0
Product Name                    : GRID K520
Display Mode                    : Disabled
Display Active                  : Disabled
Persistence Mode                : N/A
Accounting Mode                 : Disabled
Accounting Mode Buffer Size     : 128
Driver Model
Current                     : WDDM
Pending                     : WDDM
Serial Number                   : 0325213073507
GPU UUID                        : GPU-4cc386c7-1511-e998-f8f8-c3fe800a90
Minor Number                    : N/A
VBIOS Version                   : 80.04.D4.00.03
Inforom Version
Image Version               : 2055.0052.00.04
OEM Object                  : 1.1
ECC Object                  : N/A
Power Management Object     : N/A
GPU Operation Mode
Current                     : N/A
Pending                     : N/A
PCI
Bus                         : 0x00
Device                      : 0x03
Domain                      : 0x0000
Device Id                   : 0x118A10DE
Bus Id                      : 0000:00:03.0
Sub System Id               : 0x101410DE
GPU Link Info
PCIe Generation
Max                 : 3
Current             : 1
Link Width
Max                 : 16x
Current             : 16x
Bridge Chip
Type                    : N/A
Firmware                : N/A
Fan Speed                       : N/A
Performance State               : P8
Clocks Throttle Reasons         : N/A
FB Memory Usage
Total                       : 4095 MiB
Used                        : 4052 MiB
Free                        : 43 MiB
BAR1 Memory Usage
Total                       : 128 MiB
Used                        : 37 MiB
Free                        : 91 MiB
Compute Mode                    : Default
Utilization
Gpu                         : 0 %
Memory                      : 0 %
Ecc Mode
Current                     : N/A
Pending                     : N/A
ECC Errors
Volatile
Single Bit
Device Memory       : N/A
Register File       : N/A
L1 Cache            : N/A
L2 Cache            : N/A
Texture Memory      : N/A
Total               : N/A
Double Bit
Device Memory       : N/A
Register File       : N/A
L1 Cache            : N/A
L2 Cache            : N/A
Texture Memory      : N/A
Total               : N/A
Aggregate
Single Bit
Device Memory       : N/A
Register File       : N/A
L1 Cache            : N/A
L2 Cache            : N/A
Texture Memory      : N/A
Total               : N/A
Double Bit
Device Memory       : N/A
Register File       : N/A
L1 Cache            : N/A
L2 Cache            : N/A
Texture Memory      : N/A
Total               : N/A
Retired Pages
Single Bit ECC              : N/A
Double Bit ECC              : N/A
Pending                     : N/A
Temperature
Gpu                         : 24 C
Power Readings
Power Management            : Supported
Power Draw                  : 17.45 W
Power Limit                 : 125.00 W
Default Power Limit         : 125.00 W
Enforced Power Limit        : 125.00 W
Min Power Limit             : 85.00 W
Max Power Limit             : 130.00 W
Clocks
Graphics                    : 324 MHz
SM                          : 324 MHz
Memory                      : 324 MHz
Applications Clocks
Graphics                    : N/A
Memory                      : N/A
Default Applications Clocks
Graphics                    : N/A
Memory                      : N/A
Max Clocks
Graphics                    : 797 MHz
SM                          : 797 MHz
Memory                      : 2500 MHz
Compute Processes
Process ID                  : 1664
Name                    : Insufficient Permissions
Used GPU Memory         : Not available in WDDM driver model
Process ID                  : 1588
Name                    : Insufficient Permissions
Used GPU Memory         : Not available in WDDM driver model
Process ID                  : 1760
Name                    : Insufficient Permissions
Used GPU Memory         : Not available in WDDM driver model
Process ID                  : 5396
Name                    : Insufficient Permissions
Used GPU Memory         : Not available in WDDM driver model
Process ID                  : 6208
Name                    : C:\Windows\Explorer.EXE
Used GPU Memory         : Not available in WDDM driver modelHere’s why:
https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdfGPU Memory Usage
Amount of memory used on the device by the context.  Not available on  Windows when running in WDDM mode because Windows KMD manages all the memory not NVIDIA driver.Powered by Discourse, best viewed with JavaScript enabled"
372,hpe-dl-280-with-a16-bare-metal-setup-not-working,"We have a standalone, bare metal server (HPE DL 280 w/ A16) that we would like to use for 3D workloads under RDS.  We have completed the nVidia licensing process (created a DLS, registered with the license portal, generated a client token).One the server we haveinstalled the latest A16-supplied driver:
Data Center Driver For Windows
Version: 528.89 WHQL
Release Date: 2023.3.30Configured the registry per the documentation for physical devices:
HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\nvlddmkm\Global\GridLicensing
FeatureType = 0x00000000Copied the client token to the correct directory:
%SystemDrive%:\Program Files\NVIDIA Corporation\vGPU Licensing\ClientConfigTokenThe nVidia control panel lists only ‘Developer’ options and acceleration doesn’t appear to be working properly given the tests that we’ve run.  The A16 card(s) are listed properly in the device manager and are accessible in GPU-Z.What are we missing?Upon further reading, the documentation states:In a bare-metal deployment, you can use NVIDIA vGPU software graphics drivers with vWS and vApps licenses to deliver remote virtual desktops and applications. If you intend to use Tesla boards without a hypervisor for this purpose, use NVIDIA vGPU software graphics drivers, not other NVIDIA drivers.However, I do not see a standalone vGPU driver in the SOFTWARE DOWNLOADS section.  I attempted to use the Hyper-V “Complete DDA GPU driver package for Microsoft platforms”, but the 64-bit Windows 2019 server driver reports that it doesn’t detect any cards.Is there a different driver that I should be installing?Hi,You did the right thing. Guest driver is the same in all the packages. This driver should definetely recognize A16 GPU
Coul you elaborate which driver you tried?
I would recommend to use LTSB release 13.8.In the nvidia Licensing Portal, I selected Software Downloads which presents ~115 pages of packages.I chose the latest Microsoft Hyper-V:Microsoft Hyper-V Server
11.13
Complete DDA GPU driver package for Microsoft platforms
Jun 26, 2023That package contains the driver installer:454.23_grid_win10_server2016_server2019_64bit_international.exeWhen I run that package, it reports no card found.  I don’t see a standalone vGPU driver package after scrolling through the entire collection of packages.  I don’t recall seeing any packages marked with ‘LTSB’.vGPU 11.x cannot work!
Please use the current vGPU 13.8 package as stated above.
BTW: a current release date doesn’t mean it is the newesg version but this branch got a minor update if it is also a LTSB brach which we support for at least 3 years.Please see NVIDIA Virtual GPU (vGPU) Software Documentatio to get more infos on our release cadence…Powered by Discourse, best viewed with JavaScript enabled"
373,tesla-p4-in-plex-server,"I have a home-lab and, within that, I use a Win10 VM on Windows Server 2019 (HyperV) as my dedicated Plex server.  It’s all running on a Dell R730xd machine. I’m planning on passing through a Tesla P4 GPU that I managed to pick up recently and I’m curious what vGPU license is needed for Plex transcoding. Would I need an RTX vWorkstation license or could I get away with vApp or vPC?  I currently have a vWorkstation license dedicated to a Tesla P40 on another machine (HP DL380 G9) and it would be good if I could get the P4 running on something more cost effective for this use case. Thanks!After pulling the trigger on the Tesla P4 and passing it through to my Windows 10 VM Plex Server (and doing a bit of tinkering), it turns out the Plex transcoder is able to use the P4 to transcode video streams using nothing more than the free data center drivers that can be downloaded from the Nvidia main site.  Performance of the P4 in this use case is excellent.  Very happy with the outcome and it was nice to discover that I could get this working without subscribing to another vGPU license… just thought I’d share for others.Hi Roland.
I recently got a P4 and I am trying to get a Dell PE 720 setup as my new plex server. I am having issues with transcoding 4K. Do you have any insight?ThanksPowered by Discourse, best viewed with JavaScript enabled"
374,installing-k1-into-dl380p-gen-8-am-i-missing-something,"I’m trying to install our K1 card onto our DL380p Gen8. What components are needed to install this?We have both processors, a PCI riser card, but it looks like it still needs a power cable?What am I missing? Did I get the wrong riser cage? I’m ordering a bigger Power supply, so that isn’t the issue.Pictured below is a closeup on the aux power adapter. http://i.imgur.com/aphvj1d.jpgYou require the PCIe power cable.When you purchased the K1 card from HP did they advise on the GPU enablement requirements? They may provide all the components as a single kit (several OEM’s do).Did you ever get this working I have the same issue ?it ended up we needed an additional power cable, and patches that weren’t on the main website. An HP retailer assisted us.Powered by Discourse, best viewed with JavaScript enabled"
375,duplicate-features-when-uploading-licenses,"I’m trying to upload our license.bin file to a License server that was recently deployed.  We have two vAPP licenses (features(?)), for 5 users each.  However if i try to upload a .bin with both of them (for a total of 10 users), i get the error:[""key"" : ""Capability response rejected: the response has features with duplicate feature ID: <some kind of key?>"", ""message"" : ""Capability response rejected: the response has features with duplicate feature ID: <same key(?)>""]This worked originally, and the server showed 4 features in the ""Licensed Feature Usage"" page;Quadro-Virtual-DWS , Count 5
GRID-Virtual-Apps, Count 5
GRID-Virtual-Apps, Count 5
GRID-Virtual-PC, Count 5We had an issue with the default lease times, so cleared the ""nvidia"" folder to drop all leases, then when going to reapply the .bin, got the above message.  However, it works if we remove the second V-App feature @ ui.licensing.nvidia.com and download the license file that way.How can we get the server to accept the .bin with both Virtual-Apps in it?HiTry resetting the License Server, then download a new license file from the License Portal to replace your existing one. I’m not sure why the current license shows duplicate features, did they come from a different PAK? Make sure the new license contains your total user count and feature requirements.RegardsMGFor such issues please open a support ticket with NVES and let them look into it.Powered by Discourse, best viewed with JavaScript enabled"
376,a10-vgpu-problem-on-linux-ubuntu-20-04,"Hello!I have prolems with activate vGPU. I installed the driver but the vGPU is not active. Why?nvidia-vgpu-ubuntu-470_470.82_amd64.debOn server installed: Linux 5.4.0-96-generic #109-Ubuntu SMP Wed Jan 12 16:49:16 UTC 2022 x86_64 x86_64 x86_64 GNU/Linuxlsmod|grep nvidia
nvidia_vgpu_vfio       53248  0
nvidia              35315712  11
mdev                   24576  2 vfio_mdev,nvidia_vgpu_vfio
drm                   491520  6 drm_kms_helper,nvidia,i915#> nvidia-smi vgpu -qGPU 00000000:01:00.0
Active vGPUs                      : 0#> nvidia-smi -q==============NVSMI LOG==============Timestamp                                 : Fri Jan 21 15:42:42 2022
Driver Version                            : 470.82
CUDA Version                              : Not FoundAttached GPUs                             : 1
GPU 00000000:01:00.0
Product Name                          : NVIDIA A10
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Enabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1321521056920
GPU UUID                              : GPU-b786d290-38b7-3943-c853-68f9c7e3c5d1
Minor Number                          : 0
VBIOS Version                         : 94.02.5C.00.04
MultiGPU Board                        : No
Board ID                              : 0x100
GPU Part Number                       : 900-2G133-0020-100
Module ID                             : 0
Inforom Version
Image Version                     : G133.0215.00.06
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GSP Firmware Version                  : N/A
GPU Virtualization Mode
Virtualization Mode               : Host VGPU
Host VGPU Mode                    : SR-IOV
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x01
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x223610DE
Bus Id                            : 00000000:01:00.0
Sub System Id                     : 0x148210DE
GPU Link Info
PCIe Generation
Max                       : 3
Current                   : 1
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : 0 %
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 24258 MiB
Used                              : 0 MiB
Free                              : 24258 MiB
BAR1 Memory Usage
Total                             : 32768 MiB
Used                              : 1 MiB
Free                              : 32767 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 192 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 47 C
GPU Shutdown Temp                 : 101 C
GPU Slowdown Temp                 : 98 C
GPU Max Operating Temp            : 91 C
GPU Target Temperature            : N/A
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : Supported
Power Draw                        : 24.34 W
Power Limit                       : 150.00 W
Default Power Limit               : 150.00 W
Enforced Power Limit              : 150.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 150.00 W
Clocks
Graphics                          : 210 MHz
SM                                : 210 MHz
Memory                            : 405 MHz
Video                             : 555 MHz
Applications Clocks
Graphics                          : 1695 MHz
Memory                            : 6251 MHz
Default Applications Clocks
Graphics                          : 1695 MHz
Memory                            : 6251 MHz
Max Clocks
Graphics                          : 1695 MHz
SM                                : 1695 MHz
Memory                            : 6251 MHz
Video                             : 1575 MHz
Max Customer Boost Clocks
Graphics                          : 1695 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Voltage
Graphics                          : 650.000 mV
Processes                             : None#> nvidia-smi
Fri Jan 21 16:21:05 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82       Driver Version: 470.82       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A10          On   | 00000000:01:00.0 Off |                  Off |
|  0%   43C    P8    23W / 150W |      0MiB / 24258MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+#> nvidia-smi vgpu
Fri Jan 21 16:21:30 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82                 Driver Version: 470.82                    |
|---------------------------------±-----------------------------±-----------+
| GPU  Name                       | Bus-Id                       | GPU-Util   |
|      vGPU ID     Name           | VM ID     VM Name            | vGPU-Util  |
|=================================+==============================+============|
|   0  NVIDIA A10                 | 00000000:01:00.0             |   0%       |
±--------------------------------±-----------------------------±-----------+#> cat /var/log/syslog | grep vmiop
Jan 21 10:10:20 nvidia-vgpu-mgr[1058]: notice: vmiop_env_log: nvidia-vgpu-mgr daemon started
Jan 21 14:48:24 nvidia-vgpu-mgr[1022]: notice: vmiop_env_log: nvidia-vgpu-mgr daemon started
Jan 21 15:18:43 nvidia-vgpu-mgr[1016]: notice: vmiop_env_log: nvidia-vgpu-mgr daemon started
Jan 21 15:34:10 nvidia-vgpu-mgr[3265]: notice: vmiop_env_log: nvidia-vgpu-mgr daemon started
Jan 21 15:34:12 nvidia-vgpu-mgr[3303]: notice: vmiop_env_log: nvidia-vgpu-mgr daemon started#> ls -l /sys/bus/pci/devices/0000:01:00.0/
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn0 → …/0000:01:00.4
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn1 → …/0000:01:00.5
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn10 → …/0000:01:01.6
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn11 → …/0000:01:01.7
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn12 → …/0000:01:02.0
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn13 → …/0000:01:02.1
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn14 → …/0000:01:02.2
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn15 → …/0000:01:02.3
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn16 → …/0000:01:02.4
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn17 → …/0000:01:02.5
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn18 → …/0000:01:02.6
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn19 → …/0000:01:02.7
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn2 → …/0000:01:00.6
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn20 → …/0000:01:03.0
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn21 → …/0000:01:03.1
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn22 → …/0000:01:03.2
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn23 → …/0000:01:03.3
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn24 → …/0000:01:03.4
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn25 → …/0000:01:03.5
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn26 → …/0000:01:03.6
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn27 → …/0000:01:03.7
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn28 → …/0000:01:04.0
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn29 → …/0000:01:04.1
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn3 → …/0000:01:00.7
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn30 → …/0000:01:04.2
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn31 → …/0000:01:04.3
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn4 → …/0000:01:01.0
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn5 → …/0000:01:01.1
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn6 → …/0000:01:01.2
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn7 → …/0000:01:01.3
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn8 → …/0000:01:01.4
lrwxrwxrwx 1 root root           0 Jan 21 16:27 virtfn9 → …/0000:01:01.5Help me please!Powered by Discourse, best viewed with JavaScript enabled"
377,horizon-windows-10-evc-and-gpus-adding-newer-generation-of-processors-and-gpus,"Hello,  Just wondering if there is any guidance on preventing problems with adding new host with newer generation of GPU, RAM and processors to a existing cluster?    Do you loose vmotion capabilities?HiDifferent CPUs are fine as you can use EVC, however you may lose features and functionality of the new CPUs until other Servers are upgraded / replaced with the same CPUs. RAM doesn’t make any difference.Different GPUs can exist in the same Cluster, however you can’t vMotion between different GPUs. So you can’t vMotion from a T4 to a RTX 6000 for example.Best way to handle that, is either start a new Cluster with the newer Server hardware and gradually build that out, that way you maintain the full feature set of all components and can vMotion between Servers. Or, you can gradually replace the Servers in your existing Cluster, however until all Servers are the same specs, you won’t be able to use all the features and functionality.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
378,cudamalloc-failed-when-gpu-passthrough-by-qemu,"I try to perform the experiment about GPU passthrough by qemu. Start VM and find cudaMalloc failed on error 46(CUDA_ERROR_DEVICE_UNAVAILABLE) without setting -cpu host.  After setting -cpu host, cuda can run normally.
Why GPU passthrough must set -cpu host to run cuda API like cudaMalloc?Powered by Discourse, best viewed with JavaScript enabled"
379,nvida-rtx-virtual-workstation-build-on-aws-not-fully-compatible-with-omniverse,"The  NVIDIA RTX Virtual Workstation - WinServer 2019 uses Build 17763.   This version is not fully compatible with Omniverse applications like View and Create.  .An error requesting an upgrade to at least build 18362 occurs when installing and running.I do not think and in-place upgrade is possible.   The windows standard update process does not modify the build version in Windows Server I guess.   Would it be possible to get this updated in the AMI so the VM fully supports Omniverse apps, especially for viewing and testing?TxHi, was considering using this service to get started with Omniverse Development since GPU’s are hard to obtain.   Were the issue(s) resolved?Powered by Discourse, best viewed with JavaScript enabled"
380,i-am-using-vmware-7-and-trying-to-get-a-tesla-p6-nvidia-driver-installed-on-redhat-7-or-8-virtual,"So why wont the driver load?Dec  8 15:23:35 rhel7test kernel: NVRM: The NVIDIA GPU 0000:02:01.0 (PCI ID: 10de:1bb4)#012NVRM: installed in this system is not supported by the#012NVRM: NVIDIA 510.108.03 driver release.#012NVRM:Appendex A shows it  is supportedtrying to  install grid  510.108.03I see this as the card on redhat 7:
*-display UNCLAIMED
description: VGA compatible controller
product: GP104GL [Tesla P6]
vendor: NVIDIA Corporation
physical id: 1
bus info: pci@0000:02:01.0
version: a1
width: 64 bits
clock: 66MHz
capabilities: msi vga_controller cap_list
configuration: latency=0
resources: memory:fc000000-fcffffff memory:d0000000-dfffffff memory:fa000000-fbffffffos virtual release
cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.9 (Maipo)nvidia-smi
NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.yum list nvidia-driver-branch-[0-9][0-9][0-9].x86_64
Loaded plugins: langpacks, nvidia, product-id, search-disabled-repos, subscription-managerInstalled Packages
nvidia-driver-branch-510.x86_64                                                       3:510.108.03-1.el7                                                       @cuda-rhel7-x86_64Available Packages
nvidia-driver-branch-418.x86_64                                                       3:418.226.00-1.el7                                                       cuda-rhel7-x86_64
nvidia-driver-branch-440.x86_64                                                       3:440.118.02-1.el7                                                       cuda-rhel7-x86_64
nvidia-driver-branch-450.x86_64                                                       3:450.216.04-1.el7                                                       cuda-rhel7-x86_64
nvidia-driver-branch-455.x86_64                                                       3:455.45.01-1.el7                                                        cuda-rhel7-x86_64
nvidia-driver-branch-460.x86_64                                                       3:460.106.00-1.el7                                                       cuda-rhel7-x86_64
nvidia-driver-branch-465.x86_64                                                       3:465.19.01-1.el7                                                        cuda-rhel7-x86_64
nvidia-driver-branch-470.x86_64                                                       3:470.161.03-1.el7                                                       cuda-rhel7-x86_64
nvidia-driver-branch-495.x86_64                                                       3:495.29.05-1.el7                                                        cuda-rhel7-x86_64
nvidia-driver-branch-515.x86_64                                                       3:515.86.01-1.el7                                                        cuda-rhel7-x86_64
nvidia-driver-branch-520.x86_64                                                       3:520.61.05-1.el7                                                        cuda-rhel7-x86_64
nvidia-driver-branch-525.x86_64                                                       3:525.60.13-1.el7                                                        cuda-rhel7-x86_64I was able to get the nvidia-linux-grid-510-510.47.03  on redhat 7.9 (latest patches for that OS)   with these kernel options:rhgb quiet splash nomodeset rd.driver.blacklist=nouveau…on redhat 8 - it would load install with the same kernel options
but would install only when running on this kernel:grubby --info=ALL | grep titletitle=“Red Hat Enterprise Linux (4.18.0-425.3.1.el8.x86_64) 8.7 (Ootpa)”title=“Red Hat Enterprise Linux (4.18.0-372.32.1.el8_6.x86_64) 8.6 (Ootpa)”title=“Red Hat Enterprise Linux (4.18.0-348.12.2.el8_5.x86_64) 8.5 (Ootpa)” <------ running kernel the driver nvidia-linux-grid-510-510.47.03-1.x86_64 was built on this kernelnvidia-smi
Fri Dec  9 10:08:35 2022
±----------------------------------------------------------------------------+
| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GRID P6-8Q          On   | 00000000:02:00.0 Off |                    0 |
| N/A   N/A    P8    N/A /  N/A |      0MiB /  8192MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
381,driver-installer-not-working-with-rtx-4090-on-passthrough-dda,"Hi there,I hope everyone is doing great.  I was wondering if someone could give me some hints on how to solve a problem with the NVIDIA driver installer I’m having when connecting an RTX 4090 to a VM trough DDA. Here is the scenario:I followed the steps described by Microsoft here in order to connect the GPU to my virtual machine.It could be relevant that, when profiling the PC to check if the GPU would accept DDA, it first showed me that the device was using line-based interruptions. I followed this information to change it to message signaled-based interrupts.The problem comes when I try to install the driver on the virtual machine. The device is detected before installing it, but, when the setup ends (failing), the device manager shows the GPU as disconnected (Error 45).Before installing the driver.

image1369×875 214 KB
After installing the driver.

image1367×875 230 KB
Driver installer error.

image1366×879 62.4 KB
Thanks!You need to increase MIMO to 33Gb with:Set-VM -HighMemoryMappedIoSpace 33GB -VMName $vm,and reboot vm. That’s what helped me.I’ll give it a try. Thanks :)Powered by Discourse, best viewed with JavaScript enabled"
382,stereoscopy-3d,"Good afternoon, I have a question that I do not know if it’s normal or not, what’s wrong with the PC and he has installed the nvidia drivers (I have an RTX 2080) and now I realize that the Nvidia panel does not work the option of stereoscopy 3d, can it be put or have they been removed? before I had it when I had the GTX 1070, thankswrong forumwrongPowered by Discourse, best viewed with JavaScript enabled"
383,nvidia-driver-for-vsphere-6-7,"Hi all,We are deploying VMWare horizon and upon checking, we can’t find a driver for vsphere 6.7 U1 for NVIDIA P40.Though we’ve checked the compatibility guide,the GPU is compatible and supports vsphere 6.7 U1. Where can we get the drivers?Thank you.Powered by Discourse, best viewed with JavaScript enabled"
384,does-rtx-a5500-gpu-support-multi-instance-gpu-mig,"Hi. I have the RTX A5500 GPU in my workstation. I want to create virtual machines so that multiple clients can use the workstation resources at the same time. Although other components such as RAM, CPU, etc can be divided into pieces, I couldn’t find a way to do the same on my GPU. I checked NVIDIA’s website for it and found out about MIG. However, it is only supported by several GPUs. The GPU supporting MIG should have Ampere architecture and its compute capability version should be at least 8.0. My GPU has Ampere’s architecture but I couldn’t find any information about its compute capability. The RTX A5000 GPU has an 8.6 version so I supposed my GPU also has at least that version. I don’t know whether my GPU can support MIG for GPU share. Is there a way to check it? Thanks for the replies in advance.Powered by Discourse, best viewed with JavaScript enabled"
385,multiple-license-of-nvidia-rtx-virtual-workstation-5-0-taken-by-vgpu-enable-vdis,"We are facing issue is that some VDIs are consume multiple licenses of NVIDIA RTX Virtual Workstation-5.0  we have setup 50 VDI with 50 Nvidia Licenses GPU configured as “NVIDIA GRID vGPU nvidia_a40-4q” due to this issue licenses are getting fullPlease contact our Enterprise Support. Most likely you are using instant clones.Regards SimonThanks Simon to respond me, Yes I am using clones but some VMs are not cloned , can you please given me support email id , Sorry I am beginner for vgpu environmentPowered by Discourse, best viewed with JavaScript enabled"
386,i-subscribed-and-used-ami-in-aws-marketplace-but-the-license-is-not-available-normally,"[AWS Marketplace]
Product : NVIDIA RTX Virtual Workstation - CentOS 7 (Amazon Machine Image)
Product ID : 6c23a674-1645-468f-a1cc-ab5da8cd1516
Offer : Ingram MicroI used the AMI after subscribing because I needed an RTX Virtual Workstation license for nvidia-grid.
The RTX Virtual Workstation license is lost during the installation of the gnome package for Nice-DCV installation.cat << EOF | sudo tee --append /etc/modprobe.d/blacklist.conf
blacklist vga16fb
blacklist nouveau
blacklist rivafb
blacklist nvidiafb
blacklist rivatv
EOFAdd GRUB_CMDLINE_LINUX=“rdblacklist=nouveau” to Add GRUB_CMDLINE_LINUX=“rdblacklist=nouveau” to /etc/default/grubgrub2-mkconfig -o /boot/grub2/grub.cfgyum groupinstall “GNOME Desktop”When rebooting after installation, the Licensed Product will be changed as follows.Check with nvidia-smi -qvGPU Software Licensed Product
Product Name                      : NVIDIA Virtual Applications
License Status                    : Licensed (Expiry: N/A)Result : “The RTX Virtual Workstation license is no longer in effect and is covered by the NVIDIA Virtual Applications license.
If Gnome is installed and becomes a GUI environment, RTX Virtual Workstation is no longer available.”Powered by Discourse, best viewed with JavaScript enabled"
387,limitations-for-cpu-which-used-with-quadro-rtx-8000,"Hi
I want use Quadro RTX 8000 and AMD EPYC 7702 CPU (200 watts) in HPE ProLiant DL385 Gen10.Sales manager HPE sad to me that this graphics card is not supported with processors higher than 166W. So I would have to change the CPU or the Graphics card.Is it true? Can you send to me a proof link?HiI’m not familiar with current HPE power limitations, but that doesn’t sound right at all. And for HPE’s sake, I hope the Sales Manager is mistaken. I would suggest you speak to someone else at HPE about this.Depending on your urgency, if HPE can’t currently do it, Dell can 100% support that configuration (No, I don’t work for Dell). I’m in the process of deploying dual AMD EPYC with a 240W TDP and 3x RTX 8000, so I can validate it’s definitely possible.Speak to a different HPE Sales Manager or maybe someone technical in Pre-Sales from HPE would be better. If the answer is still the same, then depending on your urgency you may want to consider using Dell instead, as you can order those today :-)RegardsMGThanks MrGRID,I has found that info in QuickSpecs HPE ProLiant DL385 Gen10 Server:
https://h20195.www2.hpe.com/v2/getdocument.aspx?docname=a00026913enwHPE NVIDIA Quadro RTX 8000 Graphics Accelerator R1F97C
NOTE: Max Qty=1 Doublewide GPU is allowed per riser
NOTE : This option requires High Performance Fan Kit (867810-B21) and High Performance Heat sink
(882098-B21)
NOTE: This option IS NOT supported with 166W or higher Processors
NOTE: System memory restriction < 128 TB
NOTE : This GPU requires Pwr Cable Kit (871830-B21) to be selected
NOTE: Not supported on 12 LFF chassisThere are same info about all Graphics Accelerators which mentioned in the QuickSpecs:What Dell server do you use?Are there server platforms for AMD Epyc and Quadro RTX 8000 besides HP and Dell?HiIf your preference is HPE, then make sure you actually speak to someone from HPE, rather than use the on-line configurator which may not be up to date.I’ll be deploying the PowerEdge R7525 for a customer (the Dell equivalent of the DL385). It has lots of configuration options, including the one you specifically mention above (and the on-line configurator is far easier to use then HPE’s ;-) ).Other than HPE and Dell, there’s IBM, Cisco and Supermicro, then you’re in to lesser known brands.I don’t use IBM or Supermicro so can’t comment on them. Cisco don’t currently list the RTX GPUs against their Servers, as Cisco only support Passive GPUs and the Passive RTX versions have only recently been released. They will support them, but I’m not sure when that will be official. If you want it today, then Dell would be my recommendation.The Dell PowerEdge R7525 rack server delivers powerful performance and flexible configurations. The bedrock of the modern data center.As with all the Server OEMs, you can safely ignore the on-line price. Once configured, get it priced properly through your distributor.RegardsMGThanks MrGRID,I like Supermicro, but I can’t find a platform which support Epyc and GPU together :(HiGo with Dell. I’ve just run your spec through the configurator … You’ll be up and running in less than 2 weeks.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
388,hypervisor-hard-lockup-crash-when-using-mig-on-kvm,"We are running the following setupUbuntu 22.04 - 5.19.0-41-generic
Dual A100 Cards PCIE
NVIDIA driver -  525.85.07
KVM/Libvirt
OpenStack ZEDWe have both GPU set to MIG mode, with the following slices
1x 3g.40Gb
1x 2g.20Gb
4x 1g.10GbEverything works as expected apart from now and again when a user destroys/creates a vgpu backed instance the following occurs, usually resulting in a hardlockup of the entire hypervisor.WARNING: kernel stack frame pointer at 00000000d007fb49 in nvidia-vgpu-mgr:3794759 has bad value 000000000af58e6e
Jul 11 11:16:04 ock00035 kernel: [621872.807705] [nvidia-vgpu-vfio] 0839f86e-4eab-4622-b81c-c77532e569f3: Register read failed. index: 0  offset: 0xfeb80000 status: 0x65 Timeout occuredAt this point the hypervisor usually hard locks. Sometimes we dont see these messages but the hypervisor sitll becomes unresponsive.Any one have any ideas i can nvidia-debug logs if needed.Powered by Discourse, best viewed with JavaScript enabled"
389,remote-desktop-session-host-gpu-load-balancing,"Hi,Just wondering if anyone is successfully using multiple GPUs on a Server 2019 Remote Desktop Session Host?I’m in the process of testing a couple of new session hosts, I’m running them bare metal with Quadro P2200 GPUs (the session hosts aren’t expected to do any heavy stuff, just web browsing and documents - this is for a school so cost is a big factor).Server 2019 is supposed to perform ‘Load balancing between multiple GPUs presented to the OS’ according to this:Provides information about supported configurations for RDS in Windows Server 2016 and Windows Server 2019.So I’ve tried sticking both GPUs in one box to establish if this increases our user capacity relative to single GPU performance, and in the testing I’m getting some strange results.Basically the test is that I log onto the session host and open internet explorer with a web page with a lot of active content (background video, spinny graphics…) which happens to be the school website, then repeat for as many sessions as it takes to saturate the CPU.With no GPU installed, this happens at 4 users - with the single Quadro P2200 we get up to 11 users.When running two Quadro P2200’s in the host, we get to nearly 20 users before the CPU is saturated, but you can see that the website is not rendering smoothly - there are stops and starts.The issues become obvious looking at task manger - GPU 0 is running at:
95% 3d load
0% video encode
11% copy
52% video decodewhere GPU 1 is running at:
14% 3d load
57% video encode
29% copy
2% video decodeSo obviously the load being created is not being properly shared between the two.Is there some way to make this work?I could virtualize two session hosts on each physical host and pass through one quadro to each vm to workaround the problem, but the hope was to keep the setup required on each host as simple as possible.Just to be clear we are using the vanilla RDP protocol for this, with AVC444 etc enabled via Group Policy.Heho,have you any update to your problem, reached any conclusions?Does nvidiaopenglrdp do anything to alleviate the choppy RDP experience?
Did you try to lift the 30fps RDP limit up 60fps?
Does AVC 4:2:2 instead of 4:4:4 anything in this regard?
Have you some idea how the picture changes between a bare metal deployment and a virtualized one, with DDA?
Did you try a consumer card like a 12GB RTX3060 in conjunction with the Quadro?
How bad is the 5GB memory limitation of the P2200 in a multi-Session RDSH enviroment?Questions, questions, questions…Greetings from Berlin.Hi McKay, thanks for getting in touch.To be absolutely clear, the experience is good and smooth when not deliberately overloaded (as I had done in the test).I didn’t try nvidiaopenglrdp as I can’t say I was aware of it at the time, although I wouldn’t imagine any of the elements in the test were opengl, I suppose they could be.I was able to up the RDP framerate on my windows 10 desktop to 60 fps using a registry tweak, i seem to recall recreating the tweak on a session server but finding it wasn’t effective - however I have a feeling that I was running Server 2016 at the time, where there might have been more luck with Server 2019. Ultimately it wasn’t a huge consideration as I doubted our users would notice.I’m sure that AVC 422 would have some effect on the GPU capacity but I didn’t test for it - ultimately this mode looks worse so I was keen to avoid it (I did do some testing with linux based thin clients but results were unsatisfactory, mainly as they had to use CPU decoding).We were using a virtualised session host before commissioning these dedicated physical servers, and it had a Quadro P2200 assigned via DDA on hyper-v - basically our testing showed that CPU limits could be fairly quickly reached on this session host, and we didn’t want to have this contesting with our other server roles that were on the same hypervisor.The easiest and cheapest way for us to scale up was to build a couple of workstations with 3950x CPUs, 64gb ECC RAM and quadro P2200 gpus - our thinking was that this role did not warrant the same level of hardware as a hypervisor that might host core services such as domain controller or email server.These have proved more than ample for our current thin client roll out (22 units), indeed in practice one session host of this spec is plenty if we want to take the other unit offline for maintenance and upgrades.But yes, once we had concluded that the bottleneck most easily hit by the host was CPU usage it made sense to scale up with dedicated physical resources - this calculation will change for you depending on how many users will be on the session hosts and how much CPU availability you have on your hypervisors.I did try a consumer card, but it was only a 4gb GTX 1650 - and it was better in terms of bang for buck, in the same test above I could have 9 clients on the website with Internet Explorer, versus 4 with no GPU, and 11 with the P2200.It made sense at the time to stick with the P2200 as it left open the possibility of virtualising the session host(s) (although happily Nvidia have relaxed their previous restrictions and I am now using that 1650 with DDA in a virtualised desktop role) along with peace of mind that it was professional grade kit.Which GPU makes sense for you will of course depend on what 3d work your users are doing - the actual 3d graphics needs of my users are minimal, hence the basic GPU chosen. You will need to choose your own tests if you want to establish your needs.For our needs, 5gb of memory simply isn’t a limit, although we’re only usually talking about ten users at a time - usually when I check the GPU usage at this time the stats show perhaps 20% memory usage at most.I do think the comparison between the 1650 and p2200 is somewhat interesting as in principle these are very similar graphics cards - the differences being 1gb of RAM and the limit to 2 video encoding streams on the 1650 - it isn’t clear which of the two made the difference so I would be cautious of assuming that a RTX 3060 will be capable of accommodating hugely more users, when it could be the limit hit in that case is the video encoding streams.Certainly it would be capable of accommodating hugely more 3d processing from those users but it wouldn’t necessarily mean you could, for example, achieve 20 or 30 internet explorer users on my test.Anyway, I might have some more time for testing now that we are coming into the summer holidays at last!Powered by Discourse, best viewed with JavaScript enabled"
390,vmotion-behaviour,"Hi there,Hopefully a quick one for you all…With a standard vSphere GRID deployment, where two ESXi hosts are identical, including GPU, and vMotion functions as expected, can anyone provide details of whether any ‘pre-flight’ checks are done on the GPU side prior to the migration task?Imagine the scenario above, however all the GRID VMs on one host are assigned, say T4-2Q.  On the target host, a VM is running T4-4Q.  Will the migration task stop the migration because the profiles do not match or will the migration take place, and the error only occurs when that VM attempts to boot with the non-matching profile?Thanks in advance - I would run this up myself but our test environment is down for a few days!NealHiIf the 4Q VM you’re migrating is powered on, the migration will fail due to insufficient resources. If the 4Q VM is powered off, then the migration will succeed, but it won’t be able to power on until a GPU with suitable Profile support is available.The issue becomes more interesting in environments that rely on DRS, as DRS is not GPU aware at this time.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
391,hpe-apollo-xl190r-gen10-esxi-6-7-u3-2x-tesla-v100-virtual-machines-crashing,"Hi,I have been fighting with this issue of VMs crashing or becoming unstable after a random length of time for the last 5 days.sample of the (many) errors in the vmware.log of any of the VMs using vGPUs (v100D_2Q profile):2019-12-07T14:14:01.622Z| vcpu-2| W115: Memory regions  (0xfc000000, 0xfcfff000) and  (0xfc810000, 0xfc81f000) overlap (0x54f0024000 0x5520026000).vcs = 0xfff, vpcuId = 0xffffffff2019-12-07T14:14:01.627Z| vcpu-0| W115: Memory regions  (0xfc000000, 0xfcfff000) and  (0xfc810000, 0xfc81f000) overlap (0x54f0024000 0x5520026000).vcs = 0xfff, vpcuId = 0xffffffffWhen the screen is rendering it is choppy/laggy and eventually freezes, then requires the use of esxcli vm process kill on the host to stop the VM.VM Specs:EFI Boot
4x vCPU
16GB vRAM - Reserved
Paravirtualized SCSI Adapater
Shared PCI Device vGPUThese VMs are to serve desktops using Horizon 7.11, Both Windows 1903 and Ubuntu 1804 LTS are generating the same errors in their respective vmware.log files.Ubuntu seems to crash more offten than windows, I think due to the Video Ram Usage on the vGPU.Tried GRID Drivers (and VM drivers to match)
10.1
10.0
9.2ESXi Versions tried
6.7 U3
6.7 U2
6.7 U1We are fully licensed for vQwS and vPCHPE RBSU (BIOS) Profile - Virtualization - Max Performance (SR-IOV, VT-D enabled)I cannot provide a full vmware.log as this is a darksite.Looking for any Assistance/Hints to solve this.Thanks in AdvanceHiWhat changed in the environment 5 days prior to this? Or is it a new deployment that’s only 5 days old?Are these issues there all the time or only on a specific workload? Also, what kind of workload?Have you monitored the GPU locally inside the OS to see how much resource is being used when the issue occurs?RegardsMGHi MG,This is a brand new install on vendor Certified equipment, we ran into this problem when we spinning up some initial Horizon desktops, some of the desktops became unresponsive, the workload is just rendering the desktop using a vGPU, I have watched the output of nvidi-smi vgpu -u while this happens, nothing unusual about the data, from within the VM the desktop is very sluggish like its drops alot of frames, Low utilization of all other resources, and only a single VM on the host.At one time… I was able to get a VM running without errors in the vmware.log and without frame rate issues, this was straight after converting the VM to EFI boot, but I was not able to repeat, it seemed to be a fluke, restarting the same box for another run ended up with the same errors this was on the same host.The errors are indicative of memory remapping issues from the GPU to the Virtual Machine., today I will be looking at the vmkernel.log and mapping out where all the devices are registered on the host and from within the virtual machine focusing on the vGPU.HiI know you’ve mentioned it’s ok, but double check the license is being applied from your license server. Low FPS / sluggish performance is indicative of a license not being applied.You mention the workload is just rendering the desktop, do you mean you’re not running any Apps and the VM is just slow whilst using the OS? If yes, again, sounds initially like a license issue.If the licensing is working and being applied correctly …Have you monitored the vGPU from inside the VM to see what it’s doing? Is it running out of Framebuffer? (How much is it using?)Once the VM has been created, you should not be changing the BIOS mode as they work in different ways and can cause issues. EFI is what you should be using and with the VMware Windows 10 template it’s default and there’s no need to change it.Try a manual clean build Windows 10 VM from scratch. Leave the VM template options, just give it enough vCPUs, RAM, Storage, VMXNET3 Network Adapter and add a vGPU. Install VMTools making sure to do a Custom Install and unselect the vSGA graphics driver so it’s not installed. Get it domain joined and enable RDP, then get the vGPU driver installed. After that, install the Horizon Agent, but without Instant Clone or Linked Clone options. Once installed, install the Direct Connect Agent. Connect directly to the VM and see if the issue still remains.RegardsMGHey Squishy,I encountered a similar issue where I had to use esxcli to kill the frozen GPU enabled VM on 6.7 U3 with the T4 Tesla GPU.One thing i’d check is that your Nvidia ECC settings are set the same across all of your hosts. We had all our hosts set to disable Nvidia ECC except for one. That caused issues when a VM migrated there, where a different host would have a lock on the vmx, which then caused issues with managing the VM in vCenter.I noted also a migration related ECC mismatch error in the vmware.log of the VM.I’m still waiting back to see if those VMs that were impacted will crash again. I am not entirely sure this ECC related migration issue was the cause.Just wanted to follow up, even after verifying all the proper settings, the VMs are still crashing. It’s suspected to relate to a in house developed 3D application that this particular department uses. However, there’s nothing really obvious in the logs other than the overlap entries in the OP. Case opened with Nvidia Enterprise Support for further troubleshooting. Will report back if a solution is found.@squishy,I am curious how that XL190R can accommodate two double width V100 GPUs assuming your configuration has the 32GB V100s, of course.  From the spec sheets I look at, there is only room for one double width GPU card in these based on the backplane slots.Powered by Discourse, best viewed with JavaScript enabled"
392,questions-of-switching-multiple-nvidia-gpu-cards-between-host-and-guest-os-in-linux,"We meets some problems when multiple GPU cards switch between host and guest OS in Linux.We make some survey for this topic, and have someone do the samething.Optimus (Non-MXM/Muxless/""3D Controller"") passthrough testing notes - GitHub - jscinoz/optimus-vfio-docs: Optimus (Non-MXM/Muxless/""3D Controller"") passthrough testing notes
We would like to know is this (switch between host and guest OS) possible for vfio and native nvidia driver?
(Is there offical release information or documentation)
Or we may only use the methods as the previous link?
Please advise!
Thank you!
Cheers,
Edward TsengPowered by Discourse, best viewed with JavaScript enabled"
393,problem-with-nvidia-quadro-p4000,"Hi,
I have a Windows 2019 server with Hyper-V. I assigned an NVIDIA Quadro P4000 card to a Session-Host server (Windows Server 2019).
My first problem is that I don’t have the NVIDIA Control Panel.The second problem is that when I turn off the base video card and it’s more than the NVIDIA, when I do benchmark tests, the NVIDIA card is not used in the task manager…thanks for your helpHiIf you’re connecting via RDP, not seeing the Control Panel is expected behaviour due to the way in which the GPU is being accessed. Use a different protocol to connect, something like HDX, Blast, TGX or VNC, then you’ll see it.Regarding the GPU being used in tests, make sure you have it enabled via GPO:Computer Configuration\Administrative Templates\Windows Components\Remote Desktop Services\Remote Desktop Session Host\Remote Session EnvironmentEnable: Use the hardware default graphics adapter for all Remote Desktop Services sessionsRegardsMGHi,Do you know another software like Remote Desktop ?where do i apply the gpo? on which server? server session host ?According to this link, my Quadro P4000 card is not compatible with Session Host and does not support DDA, is it possible ?The NVIDIA vGPU software product support matrix.HiDo you know another software like Remote Desktop ?Yes, mentioned above: HDX (Citrix), Blast (VMware), TGX (Mechdyne) or VNC.VNC is free, try that first. However, why do you need to get to the NVIDIA Control Panel? What is it you’re looking to change?where do i apply the gpo? on which server? server session host ?You apply the GPO to the VM that has the GPU attached. You can do that either by local policy or if your VM is part of a domain, by a Server in your environment that has Group Policy Management installed.According to this link, my Quadro P4000 card is not compatible with Session Host and does not support DDA, is it possible ?The link you provided is for vGPU compatible GPUs, which you aren’t using. Your GPU will work in Passthrough / DDA.RegardsMGHi,if it isn’t too much of a problem I would like to clarify and confirm the results of this thread. I have an almost exact situation that I would like to implement.in short:You have a windows server 2019 where you have created a Hyper-V VM that is a Session-Host Server. You have then passed an Nvidia P4000 into the VM. Can I confirm the result that sessions of the VM will use the GPU resources? Does the host operating system lose the ability of RDP?Setting the Group Policy below is required to use the GPU for rendering in RDP.  This is true for Physical GPU’s, VM Passthru and even vGPU.We use Tesla M10’s DDA Passthru on Server 2019 and without that setting apps like Autocad do not use the GPU.Computer Configuration\Administrative Templates\Windows Components\Remote Desktop Services\Remote Desktop Session Host\Remote Session EnvironmentEnable: Use the hardware default graphics adapter for all Remote Desktop Services sessionsHi,
The P4000 is uniquely planned with the exhibition that is important to drive vivid VR conditions. Also, you can make gigantic computerized signage arrangements of up to 32 4K presentations for every framework by interfacing different P4000s through Quadro Sync II2.Powered by Discourse, best viewed with JavaScript enabled"
394,gpu-missing-in-azure-nvidia-rtx-virtual-workstation-winserver-2022,"Hello All,I setup an Azure based NVIDIA RTX Virtual Workstation - WinServer 2022 from the Azure Marketplace.When I power on the machine there is no NVIDIA GPU.  And no GPU is detected by the NVIDIA software.Did I miss a step?TIA,EricPowered by Discourse, best viewed with JavaScript enabled"
395,windows-server-2019-with-9-0-vgpu-software,"hello,
I’m trying the new windows server 2019 (build 1809…)  with the latest nvidia grid drivers.
I run several CLEAN installations but an error always occurs with Hyper-V as soon as I install the 431.02_grid_win10_server2016_server2019_64bit_international.exe , for which I cannot create any new VM (HV complains saying it encountered an error rrying to access an object).I suspect that the installation screws up something because with the 8.0 version of grid software HyperV is working fine.GiulioSPowered by Discourse, best viewed with JavaScript enabled"
396,a100-sxm-80gb-a100-enforced-power-limit-different-from-server-to-server,"Hello,I have a few server where Enforced Power limit are being degrade and some where the Enforced Power Limit are set at max. Out of about 30 server, 10 of the enforced power limit at set for 350.00.
OS: Red Hat Enterprise Linux release 8.3 (Ootpa)Trying to figure out why?
I will paste the complete the nvidia-smi -a out for these 2 servers.Power Readings
Power Management                  : Supported
Power Draw                        : 83.64 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 350.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 WPower Readings
Power Management                  : Supported
Power Draw                        : 78.20 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 400.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 WNvidia-smi -a for the working server Enforced power 400w==============NVSMI LOG==============Timestamp                                 : Mon Jul 19 15:34:49 2021
Driver Version                            : 460.73.01
CUDA Version                              : 11.2Attached GPUs                             : 8
GPU 00000000:07:00.0
Product Name                          : A100-SXM-80GB
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : Disabled
Pending                           : Disabled
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1560221014681
GPU UUID                              : GPU-9dac6767-3c33-d879-fafe-e52c241896f3
Minor Number                          : 2
VBIOS Version                         : 92.00.36.00.01
MultiGPU Board                        : No
Board ID                              : 0x700
GPU Part Number                       : 692-2G506-0210-002
Inforom Version
Image Version                     : G506.0210.00.03
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : None
Host VGPU Mode                    : N/A
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x07
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x20B210DE
Bus Id                            : 00000000:07:00.0
Sub System Id                     : 0x146310DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 4
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P0
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 81251 MiB
Used                              : 0 MiB
Free                              : 81251 MiB
BAR1 Memory Usage
Total                             : 131072 MiB
Used                              : 25 MiB
Free                              : 131047 MiB
Compute Mode                          : Exclusive_Process
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 640 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 33 C
GPU Shutdown Temp                 : 92 C
GPU Slowdown Temp                 : 89 C
GPU Max Operating Temp            : 85 C
GPU Target Temperature            : N/A
Memory Current Temp               : 49 C
Memory Max Operating Temp         : 95 C
Power Readings
Power Management                  : Supported
Power Draw                        : 79.49 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 400.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 W
Clocks
Graphics                          : 1380 MHz
SM                                : 1380 MHz
Memory                            : 1593 MHz
Video                             : 1245 MHz
Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Default Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Max Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1593 MHz
Video                             : 1290 MHz
Max Customer Boost Clocks
Graphics                          : 1410 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes                             : NoneGPU 00000000:0B:00.0
Product Name                          : A100-SXM-80GB
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : Disabled
Pending                           : Disabled
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1560421017230
GPU UUID                              : GPU-d1e0deee-4d00-c73a-a2be-39af80eecc42
Minor Number                          : 3
VBIOS Version                         : 92.00.36.00.01
MultiGPU Board                        : No
Board ID                              : 0xb00
GPU Part Number                       : 692-2G506-0210-002
Inforom Version
Image Version                     : G506.0210.00.03
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : None
Host VGPU Mode                    : N/A
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x0B
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x20B210DE
Bus Id                            : 00000000:0B:00.0
Sub System Id                     : 0x146310DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 4
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P0
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 81251 MiB
Used                              : 0 MiB
Free                              : 81251 MiB
BAR1 Memory Usage
Total                             : 131072 MiB
Used                              : 13 MiB
Free                              : 131059 MiB
Compute Mode                          : Exclusive_Process
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 640 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 32 C
GPU Shutdown Temp                 : 92 C
GPU Slowdown Temp                 : 89 C
GPU Max Operating Temp            : 85 C
GPU Target Temperature            : N/A
Memory Current Temp               : 48 C
Memory Max Operating Temp         : 95 C
Power Readings
Power Management                  : Supported
Power Draw                        : 78.20 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 400.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 W
Clocks
Graphics                          : 1380 MHz
SM                                : 1380 MHz
Memory                            : 1593 MHz
Video                             : 1245 MHz
Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Default Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Max Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1593 MHz
Video                             : 1290 MHz
Max Customer Boost Clocks
Graphics                          : 1410 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes                             : NoneGPU 00000000:48:00.0
Product Name                          : A100-SXM-80GB
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : Disabled
Pending                           : Disabled
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1560421016803
GPU UUID                              : GPU-ede66894-4716-6697-0d5d-4abc69a565c7
Minor Number                          : 0
VBIOS Version                         : 92.00.36.00.01
MultiGPU Board                        : No
Board ID                              : 0x4800
GPU Part Number                       : 692-2G506-0210-002
Inforom Version
Image Version                     : G506.0210.00.03
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : None
Host VGPU Mode                    : N/A
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x48
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x20B210DE
Bus Id                            : 00000000:48:00.0
Sub System Id                     : 0x146310DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 4
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P0
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 81251 MiB
Used                              : 0 MiB
Free                              : 81251 MiB
BAR1 Memory Usage
Total                             : 131072 MiB
Used                              : 21 MiB
Free                              : 131051 MiB
Compute Mode                          : Exclusive_Process
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 640 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 32 C
GPU Shutdown Temp                 : 92 C
GPU Slowdown Temp                 : 89 C
GPU Max Operating Temp            : 85 C
GPU Target Temperature            : N/A
Memory Current Temp               : 49 C
Memory Max Operating Temp         : 95 C
Power Readings
Power Management                  : Supported
Power Draw                        : 82.12 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 400.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 W
Clocks
Graphics                          : 1380 MHz
SM                                : 1380 MHz
Memory                            : 1593 MHz
Video                             : 1245 MHz
Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Default Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Max Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1593 MHz
Video                             : 1290 MHz
Max Customer Boost Clocks
Graphics                          : 1410 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes                             : NoneNvidia-smi -a for the none working 350W server==============NVSMI LOG==============Timestamp                                 : Mon Jul 19 14:51:27 2021
Driver Version                            : 460.73.01
CUDA Version                              : 11.2Attached GPUs                             : 8
GPU 00000000:07:00.0
Product Name                          : A100-SXM-80GB
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : Disabled
Pending                           : Disabled
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1560421009991
GPU UUID                              : GPU-8a9b0ba3-4dd6-f6be-99f1-7170f479482a
Minor Number                          : 2
VBIOS Version                         : 92.00.36.00.01
MultiGPU Board                        : No
Board ID                              : 0x700
GPU Part Number                       : 692-2G506-0210-002
Inforom Version
Image Version                     : G506.0210.00.03
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : None
Host VGPU Mode                    : N/A
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x07
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x20B210DE
Bus Id                            : 00000000:07:00.0
Sub System Id                     : 0x146310DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 4
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P0
Clocks Throttle Reasons
Idle                              : Not Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 81251 MiB
Used                              : 0 MiB
Free                              : 81251 MiB
BAR1 Memory Usage
Total                             : 131072 MiB
Used                              : 237 MiB
Free                              : 130835 MiB
Compute Mode                          : Exclusive_Process
Utilization
Gpu                               : 59 %
Memory                            : 2 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 640 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 35 C
GPU Shutdown Temp                 : 92 C
GPU Slowdown Temp                 : 89 C
GPU Max Operating Temp            : 85 C
GPU Target Temperature            : N/A
Memory Current Temp               : 50 C
Memory Max Operating Temp         : 95 C
Power Readings
Power Management                  : Supported
Power Draw                        : 83.64 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 350.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 W
Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1593 MHz
Video                             : 1275 MHz
Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Default Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Max Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1593 MHz
Video                             : 1290 MHz
Max Customer Boost Clocks
Graphics                          : 1410 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes                             : NoneGPU 00000000:0B:00.0
Product Name                          : A100-SXM-80GB
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : Disabled
Pending                           : Disabled
Accounting Mode                       : Disabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1560421010244
GPU UUID                              : GPU-5fbc191a-1afc-7546-8f0d-905c0fd8551b
Minor Number                          : 3
VBIOS Version                         : 92.00.36.00.01
MultiGPU Board                        : No
Board ID                              : 0xb00
GPU Part Number                       : 692-2G506-0210-002
Inforom Version
Image Version                     : G506.0210.00.03
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GPU Virtualization Mode
Virtualization Mode               : None
Host VGPU Mode                    : N/A
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x0B
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x20B210DE
Bus Id                            : 00000000:0B:00.0
Sub System Id                     : 0x146310DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 4
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : N/A
Performance State                     : P0
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 81251 MiB
Used                              : 0 MiB
Free                              : 81251 MiB
BAR1 Memory Usage
Total                             : 131072 MiB
Used                              : 189 MiB
Free                              : 130883 MiB
Compute Mode                          : Exclusive_Process
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 640 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 34 C
GPU Shutdown Temp                 : 92 C
GPU Slowdown Temp                 : 89 C
GPU Max Operating Temp            : 85 C
GPU Target Temperature            : N/A
Memory Current Temp               : 49 C
Memory Max Operating Temp         : 95 C
Power Readings
Power Management                  : Supported
Power Draw                        : 83.48 W
Power Limit                       : 400.00 W
Default Power Limit               : 400.00 W
Enforced Power Limit              : 350.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 400.00 W
Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1593 MHz
Video                             : 1275 MHz
Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Default Applications Clocks
Graphics                          : 1155 MHz
Memory                            : 1593 MHz
Max Clocks
Graphics                          : 1410 MHz
SM                                : 1410 MHz
Memory                            : 1593 MHz
Video                             : 1290 MHz
Max Customer Boost Clocks
Graphics                          : 1410 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Processes                             : NoneMight be related to the hardware (BMC) settings, for example if the PSUs are unable to provide enough power. What kind or hardware are we talking about?This is HPE Apollo xl675d gen10. Why would the power be different? All of the 6500 Chassis have the same power supply
Enforced Power Limit
The power management algorithm’s power ceiling, in
watts. Total board power draw is manipulated by the
power management algorithm such that it stays under this
value. This limit is the minimum of various limits such
as the software limit listed above. Only available if
power management is supported. Requires a Kepler
device.If all my Power Limits are 400w… and i’m not overclocking 1410 Mhz… I don’t know understand my my Enforced Power Limit algorithm calculation are different.when it comes to power… I have 3000W power supplys
Power Supply 1            3000 watts    5XBMF0C5NET0KK    P28152-001      N/A           3.11      ARTSN
Power Supply 2            3000 watts    5XBMF0C5NET0L0    P28152-001      N/A           3.11      ARTSN
Power Supply 3            3000 watts    5WWQV0B5NES065    P25430-001      N/A           1.00      ARTSN
Power Supply 4            3000 watts    5WWQV0B5NES069    P25430-001      N/A           1.00      ARTSN
Power Supply 5            3000 watts    5XBMF0C5NET0KW    P28152-001      N/A           3.11      ARTSN
Power Supply 6            3000 watts    5XBMF0C5NET0KL    P28152-001      N/A           3.11      ARTSNI am only drawing about 220 Watts per power supply,
Power Supply 1
Status: Present (OK)
Mismatch: No
Ready: Yes
Input Status: OK
General Failure: No
Enabled (PS ON): Yes
Input Voltage: 217 volts
Power Supply 2
Status: Present (OK)
Mismatch: No
Ready: Yes
Input Status: OK
General Failure: No
Enabled (PS ON): Yes
Input Voltage: 219 volts
Power Supply 3
Status: Present (OK)
Mismatch: No
Ready: Yes
Input Status: OK
General Failure: No
Enabled (PS ON): Yes
Input Voltage: 216 volts
Power Supply 4
Status: Present (OK)
Mismatch: No
Ready: Yes
Input Status: OK
General Failure: No
Enabled (PS ON): Yes
Input Voltage: 215 volts
Power Supply 5
Status: Present (OK)
Mismatch: No
Ready: Yes
Input Status: OK
General Failure: No
Enabled (PS ON): Yes
Input Voltage: 219 volts
Power Supply 6
Status: Present (OK)
Mismatch: No
Ready: Yes
Input Status: OK
General Failure: No
Enabled (PS ON): Yes
Input Voltage: 218 voltsSame SBIOS on all the machines? Did you contact HPE already? On DGX systems the enforced power depends on BMC settings. On HGX systems I have no idea and you should get support from the OEMPowered by Discourse, best viewed with JavaScript enabled"
397,418-92-vgpu-vfio-module-not-loading,"I am setting up a KVM Hypervisor in evaluation mode to demonstrate multi-monitor vGPU with SPICE.
KVM is set-up and working perfectly.
nVidia License Manager is setup and working perfectly.I installed the nVidia Linux Driver included in the vGPU download (for my RTX8000 card) and it seems to be working perfectly. Here is the output of ‘nvidia-smi’:
±----------------------------------------------------------------------------+
| NVIDIA-SMI 418.92 Driver Version: 418.92 CUDA Version: 10.1 |
|-------------------------------±---------------------±---------------------+
| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |
| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |
|===============================+======================+======================|
| 0 Quadro RTX 8000 On | 00000000:02:00.0 Off | Off |
| 33% 38C P8 29W / 260W | 133MiB / 48573MiB | 0% Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes: GPU Memory |
| GPU PID Type Process name Usage |
|=============================================================================|
| 0 2218 G /usr/libexec/Xorg 63MiB |
| 0 2335 G /usr/bin/gnome-shell 69MiB |
±----------------------------------------------------------------------------+My problem is the nVidia vGPU modules (specifically the VFIO module) is not loaded.
Here is the problem from ‘dmesg | grep vfio’:
[ 5.433000] nvidia_vgpu_vfio: Unknown symbol nvidia_vgpu_vfio_get_ops (err 0)
[ 5.433109] nvidia_vgpu_vfio: Unknown symbol nvidia_vgpu_vfio_set_ops (err 0)The issue is apparent at the install via RPM:
$ sudo rpm -Uhv NVIDIA-vGPU-rhel-8.0-418.92.x86_64.rpm
Verifying… ################################# [100%]
Preparing… ################################# [100%]
Updating / installing…
1:NVIDIA-vGPU-rhel-1:8.0-418.92 ################################# [100%]
chcon: can’t apply partial context to unlabeled file ‘/lib/modules/4.18.0-74.el8.x86_64/extra/nvidia/nvidia.ko’
chcon: can’t apply partial context to unlabeled file ‘/lib/modules/4.18.0-74.el8.x86_64/extra/nvidia/nvidia-vgpu-vfio.ko’
depmod: WARNING: /lib/modules/4.18.0-80.el8.x86_64/weak-updates/nvidia/nvidia-vgpu-vfio.ko needs unknown symbol nvidia_vgpu_vfio_get_ops
depmod: WARNING: /lib/modules/4.18.0-80.el8.x86_64/weak-updates/nvidia/nvidia-vgpu-vfio.ko needs unknown symbol nvidia_vgpu_vfio_set_opsThings I’ve tried:Not sure what I’m missing. Anybody have any ideas?
I’ve attached the nvidia-bug-report.log.gz file
nvidia-bug-report.log.gz (1.03 MB)Hi,Have you managed to resolve this issue? I am having the same problem when installing the driver.Hi, I am having the same problem when installing the driver with Quadro RTX6000 and RHEL 8.2
Have you managed to resolve this issue?Seeing a very similar thing with the NVIDIA-GRID-RHEL-8.5-510.47.03-511.65 driver package.
nvidia-vgpu-vfio doesn’t load, and dmesg | grep vfio shows:The versions of the drivers are:Powered by Discourse, best viewed with JavaScript enabled"
398,cloud-virtual-desktop-w-gpu,"Hello guys,I am prolly the newest kid on the block to be playing or messing around with server grade hardwares but recently I have been searching high and low for the perfect solution to my gaming and my company’s work needs. Most of my staff comes and go and we are a small startup and we usually encourage BYOD - bring your own device. However, most of their devices are low spec devices and I’m toying with the idea of using parsec for them to stream to a virtual powerful desktop instead.Most cloud virtual desktop and gaming solutions are either too expensive or too far from where I am - Asia. ( Input lag ) - i.e GCS, Shadow, MaxSettings, AzureI am now toying with idea of building my own cloud server so 3-5 people could connect to the server via Parsec and use.Unraid is of course the choice of OS for the GPU passthru, However, instead of following Linus 's PC build that have multiple gpu, I was thinking of using Tesla because A) I don’t need any display port output because it’s all virtualized and B) it’s easier to just install one card.However, I would like to knowcan Tesla cards like P4, T4 be used for gaming and rendering and is it as easy as passing the card to the VM on unraid and allocate a certain amount of vgpu ram to each vm ? And can Unraid support vgpu or i do need to have vsphere?same question as above for Quadro p4000/p5000also I couldn’t find any build or tutorials for my setup anywhere. Can someone point me into the right direction? I’m thinking of using Epyc or Xeon or Threadripper 16-32 core processor for this.Thanks in advance.I’ve been thinking of doing something similar for a while, I’m also on unraid. I’ve got a lot of docker containers running and 2 vms, with pass through. And with my specs I could handle quite a few vms if there were enough pcie slots for video cards. so vgpu via grid or sr-iov would be awesome, but as far as I can tell unraid doesn’t have any support for this right now. If you do find a solution please share!Powered by Discourse, best viewed with JavaScript enabled"
399,unable-to-handle-kernel-paging-request-at-ffffb1f144f52090,"Hello,I’m confused by these errors:[ 1719.653554] BUG: unable to handle kernel paging request at ffffb24b8479d000
[ 1719.653569] IP: [<ffffffffc0263ee8>] os_unlock_user_pages+0x28/0x60 [nvidia]
[ 1719.654834] PGD 17fd77067 PUD 17fd78067 PMD 504563067 PTE 0
[ 1719.654839] Oops: 0000 [#1] SMP
[ 1719.654858] Modules linked in: xt_comment xt_mark nvidia_uvm(OE) veth nfsv3 rpcsec_gss_krb5 nfsv4 dns_resolver nfs fscache fuse ipt_MASQUERADE nf_nat_masquerade_ipv4 nf_conntrack_netlink nfnetlink iptable_nat xt_addrtype iptable_filter xt_conntrack br_netfilter bridge stp llc overlay(T) vport_vxlan vxlan ip6_udp_tunnel udp_tunnel openvswitch nf_conntrack_ipv6 nf_nat_ipv6 nf_conntrack_ipv4 nf_defrag_ipv4 nf_nat_ipv4 nf_defrag_ipv6 nf_nat nf_conntrack ppdev mlx4_ib iosf_mbi crc32_pclmul snd_hda_codec_generic ghash_clmulni_intel ib_core mlx4_en ptp pps_core aesni_intel lrw gf128mul glue_helper ablk_helper cryptd snd_hda_intel joydev snd_hda_codec parport_pc parport snd_hda_core snd_hwdep snd_seq snd_seq_device pcspkr mlx4_core sg virtio_balloon snd_pcm qxl ttm snd_timer snd devlink soundcore i2c_piix4
[ 1719.654907]  nfsd auth_rpcgss nfs_acl lockd grace sunrpc ip_tables xfs libcrc32c nvidia_drm(POE) nvidia_modeset(POE) nvidia(POE) sr_mod cdrom virtio_blk ata_generic pata_acpi virtio_console drm_kms_helper crct10dif_pclmul crct10dif_common crc32c_intel syscopyarea sysfillrect sysimgblt fb_sys_fops drm floppy ata_piix libata serio_raw drm_panel_orientation_quirks ipmi_devintf virtio_pci ipmi_msghandler virtio_ring virtio dm_mirror dm_region_hash dm_log dm_mod
[ 1719.654935] CPU: 5 PID: 10931 Comm: python Kdump: loaded Tainted: P           OE  ------------ T 3.10.0-957.el7.x86_64 #1
[ 1719.654937] Hardware name: Red Hat KVM, BIOS 0.5.1 01/01/2011
[ 1719.654939] task: ffff9cf83a27c100 ti: ffff9cf82b37c000 task.ti: ffff9cf82b37c000
[ 1719.654941] RIP: 0010:[<ffffffffc0263ee8>]  [<ffffffffc0263ee8>] os_unlock_user_pages+0x28/0x60 [nvidia]
[ 1719.655012] RSP: 0018:ffff9cf82b37fcb0  EFLAGS: 00010216
[ 1719.655014] RAX: 00000000000001ff RBX: 0000000000000200 RCX: 0000000000000034
[ 1719.655016] RDX: 0000000000000000 RSI: fffffe7a8a3b3d40 RDI: fffffe7a8a3b3d40
[ 1719.655017] RBP: ffff9cf82b37fcd0 R08: ea00000000000000 R09: f9ea28ecf5000000
[ 1719.655019] R10: 0615d58d953b3d40 R11: 000000000000ffff R12: ffffb24b8479d000
[ 1719.655021] R13: ffffb24b8479c008 R14: 0000000000040000 R15: 0000000000000027
[ 1719.655024] FS:  00007f6ed7fff700(0000) GS:ffff9cf921d40000(0000) knlGS:0000000000000000
[ 1719.655026] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[ 1719.655027] CR2: ffffb24b8479d000 CR3: 00000004f33f0000 CR4: 00000000003606e0
[ 1719.655037] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
[ 1719.655039] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
[ 1719.655041] Call Trace:
[ 1719.655255]  [<ffffffffc098d4a9>] _nv000870rm+0xa9/0xe0 [nvidia]
[ 1719.655380]  [<ffffffffc098dd62>] ? _nv000940rm+0x882/0x900 [nvidia]
[ 1719.655523]  [<ffffffffc0998254>] ? rm_ioctl+0x54/0xb0 [nvidia]
[ 1719.655569]  [<ffffffffa8bf09ff>] ? vma_set_page_prot+0x2f/0x50
[ 1719.655585]  [<ffffffffa8c3e001>] ? __check_object_size+0x191/0x250
[ 1719.655649]  [<ffffffffc0258859>] ? nvidia_ioctl+0x609/0x7d0 [nvidia]
[ 1719.655710]  [<ffffffffc0253083>] ? nvidia_frontend_unlocked_ioctl+0x43/0x50 [nvidia]
[ 1719.655735]  [<ffffffffa8c56210>] ? do_vfs_ioctl+0x3a0/0x5a0
[ 1719.655738]  [<ffffffffa8c564b1>] ? SyS_ioctl+0xa1/0xc0
[ 1719.655769]  [<ffffffffa9174ddb>] ? system_call_fastpath+0x22/0x27
[ 1719.655770] Code: 00 00 00 0f 1f 44 00 00 55 31 c0 48 89 e5 41 56 49 89 fe 41 55 49 89 f5 41 54 53 31 db 48 85 ff 74 22 90 4d 8d 64 c5 00 83 c3 01 <49> 8b 3c 24 e8 1f da 95 e8 49 8b 3c 24 e8 56 06 96 e8 89 d8 4c
[ 1719.655806] RIP  [<ffffffffc0263ee8>] os_unlock_user_pages+0x28/0x60 [nvidia]
[ 1719.655870]  RSP <ffff9cf82b37fcb0>
[ 1719.655871] CR2: ffffb24b8479d000Host : CentOS 7.6
VM : CentOS 7.6
GPU : Tesla P40
vGPU : P40-8CThere is no support for CentOS. So what do you expect here? You should open a support ticket with the stack trace but this won’t be possible with CentOS. Try to reproduce with Redhat.Powered by Discourse, best viewed with JavaScript enabled"
400,nvidia-control-panel-multi-monitor-driver-label,"Hi,I’m using Nvidia Grid vGPU in vSphere 6.5 and Horizon Instant Clones 7.12.In the Windows 10 v1809 LTSC virtual machine with 2 or monitors, the Nvidia Control Panel > Display > “Change Resolution” or “Set up multiple displays” … the primary monitor has the label NVIDIA VGX under it while all other monitors have the label Dell VMware VD.Running DxDiag shows all monitors running under NVIDIA GRID T4-1B.  In the VMware Blast log, it shows each display using a different driver …2021-02-26 08:26:48.479+0800 [INFO ] 0x11c0 bora::Log: VNCSERVER-WIN32: Screen ID 0. Display name: “\.\DISPLAY2”, Device String: “NVIDIA GRID T4-1B”, Device Id: “PCI\VEN_10DE&DEV_1EB8&SUBSYS_130910DE&REV_A1”
2021-02-26 08:26:48.480+0800 [INFO ] 0x11c0 bora::Log: VNCSERVER-WIN32: Screen ID 1. Display name: “\.\DISPLAY1”, Device String: “Microsoft Basic Display Adapter”, Device Id: “PCI\VEN_15AD&DEV_0405&SUBSYS_040515AD&REV_00”… but 2 seconds later, it show both displays using the Nvidia driver:2021-02-26 08:26:50.987+0800 [INFO ] 0x11c0 bora::Log: VNCSERVER-WIN32: Screen ID 0. Display name: “\.\DISPLAY2”, Device String: “NVIDIA GRID T4-1B”, Device Id: “PCI\VEN_10DE&DEV_1EB8&SUBSYS_130910DE&REV_A1”
2021-02-26 08:26:50.988+0800 [INFO ] 0x11c0 bora::Log: VNCSERVER-WIN32: Screen ID 1. Display name: “\.\DISPLAY3”, Device String: “NVIDIA GRID T4-1B”, Device Id: “PCI\VEN_10DE&DEV_1EB8&SUBSYS_130910DE&REV_A1”Just wondering if the Nvidia Control Panel labels for each monitor is mis-represented and both monitors are actually running with the Nvidia driver.Is there a way to verify this within the Nvidia Control Panel or Nvidia logs?Thanks.Powered by Discourse, best viewed with JavaScript enabled"
401,is-vgpu-vdws-always-required,"We have deployed vGPU on Red-hat KVM. And our virtual machine only need OPENGL. Do we require to have vGPU vDWS license?HiIf you’re using any aspect of vGPU, then you need to have licensing in place.RegardsMGFor OpenGL it should be sufficient to have a vPC licenseThank you for the information. Is there any place I can purchase the license.I have another question about the license. Is there any restriction on the number or organizations of users for the license? For instance, we have one license and a VM with one vGPU and vGPU license, can it be used by different users from different organization at the same time or at different time?Powered by Discourse, best viewed with JavaScript enabled"
402,nvidia-license-server-silent-install,"Looking to automate the deployment of the license server on Linux.I see there’s a -i silent option but I don’t see any other documentation on additional configuration options.Please adviseHi,I’m not aware that there is any kind of automated installation possible with the current license server.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
403,nvidia-tesla-k40c-12gb-in-rdsh,"Hi!
We have GPU ""NVIDIA Tesla K40C 12GB Computational Accelerator"" HPE P/N 753960-B21As RemoteFX is deprecated by Mycrosoft, we are trying to use DDA. And we have troube with DDA it to RDSH.Host Hyper-v Version: Windows server 2019 Datacenter
Guest OS Version: Windows server 2019 StdQuestions:Thanks for your reply!HiAs you’ve written in your comment, this is a ""Computational"" GPU, it’s not for Graphics.Using DDA, you can Passthrough a GPU to 1 VM, as DDA is a 1-1 assignment.You’re far better off with another type of GPU, this is very old and very limited. Choose something from the Quadro series, like a P2000 or newer, then you can use DDA and standard Quadro drivers to work with Graphics.RegardsMGHi, Thank you very much.
We have HPE DL 380 as a physical platform.And only this graphics are in hardware compatibility list:Questions:Thanks for your answer!)HiQuadro GPUs use a standard driver available from the NVIDIA drivers website, not vGPU. The only exception to this are the RTX6000 / RTX 8000 / A6000 which can use vGPU and standard Quadro drivers.Due to the age of the K1 and K2, these do not require any licensing. However, you’ll be extremely limited on supported driver and Operating System combinations due to their age.RegardsMGThanks for you answer!See, we also already have ability to get ""HP Nvidia J0X20A GRID M40 16GB QUAD GPU"". HPE P/N 796120-001
Does it require Additional Nvidia VGPU lisence in Microsoft DDA GPU pass-through mode (4 VM)
WE would like to have 4 VM to work with CAD SoftwareThanks for reply!HiThe M40 is a 1st Generation Maxwell board and is not supported for vGPU.The oldest GPU you should be working with for vGPU would be an M10 which has 4x 8GB GPUs on it and is currently a fully supported board with the latest vGPU Software. This will run CAD workloads (assuming that the other components of the Server are up to Spec), however it should be noted that this is a low performance GPU, but it should allow you to run the software to some degree.I would strongly recommend that you stay well away from anything older than the Maxwell architecture. This means avoiding any GPU starting with a ""K"" (Kepler).Depending on the CAD applications you will be using (AutoCAD ?), you will also benefit from a QvDWS license to get the best performance out of it. This will allow the maximum amount of Framebuffer to be used for each User.That said, although the M10 will run CAD workloads, it is not the ideal board for them. You would typically be looking at something like a T4 in combination with QvDWS, assuming the Generation of DL380 is compatible with the T4 GPU.You’ve mentioned Passthrough / DDA a few times. I’m assuming this is because you are running Hyper-V which currently does not support GPU Virtualisation. The best way forwards would be to either use an M10 with each of the GPUs in Passthrough, and then licensed accordingly, or change your Hypervisor for one that supports GPU Virtualisation. vSphere / XenServer / AHV / KVM all support GPU Virtualisation. That way, you can use a much wider selection of GPUs, and if you’re trying to save costs, you could buy 1x GPU and use the vGPU Software to share it between all of your Users.As a reference, for CAD, you should be looking at the following VM Spec for each User:vCPUs: 4-6 Cores @ 3.0Ghz (3.0Ghz at least - Faster is better)
System RAM: 12GB (or higher)
vGPU: 4GB & QvDWS License (4GB at least or higher depending on model size)
Storage: SSD / NVMeRegardsMGPowered by Discourse, best viewed with JavaScript enabled"
404,physical-ram-and-gpu-vram-capacity-matching,"I have heard that memory should be paired with at least 1.5 times the GPU memory. For example, if I want to pair two RTX 4090 cards (24GB each), then my memory should be at least 72GB.I would like to inquire whether such a large memory capacity is truly necessary. And if I were to use a smaller amount of memory, would it affect performance, particularly from a machine learning perspective?I would like to know if there would be any issues or performance impacts when the memory capacity falls below that of the graphics card during machine learning. For example, using 8GB of memory with one RTX 4090(24GB) for machine learning purposes.Powered by Discourse, best viewed with JavaScript enabled"
405,unable-to-update-firmware-on-k1-in-dell-720,"We have been running our K1 in a dell 720 running esx5.1 for the past few years.  I am now planning on running vGPU in esxi 6 and understand I need to upgrade the firmware on the K1 card to avoid the PSOD.  I am trying to apply
Nvidia High Resolution (Dual-Link) Multi-Monitor Virtual Machine Enablement for K1 (Dell PN R8RGR) and K2 (Dell PN JW9YC and 98RCK) cards Nvidia Multi-Monitor Virtual Machine Enablement for K1 and K2- Adds High Resolution Multi-Monitor support for Nvidia K1 (Dell PN R8RGR) and K2 (Dell PN JW9YC and 98RCK) cards in Virtual machine configurationsHi,
I’m currently facing the same issue - I’m not able to find firmware compatibility matrix for our K1 cards against ESXi 6.0 (or even 6.5). We are using 80.07.be.00.xx. I noticed that for 80.07.DC.00.xx the release notes are from 2013 - for me personally this is totally unacceptable…
I managed to upgrade the DELL R720 ESXi hosts to 6.0 U2 2 weeks ago and since then some VDIs are just loosing connection and unable to reconnect. If i reboot the hosts it works for some time. The firmwares for the BIOS, NICs, storage controllers have been upgraded/confirmed to be compatible with ESXi 6.0 U2.
Did you manage to find more information? Any help will be greatly appreciated…I have the same issue, and do not see this solved anywhere.  Its looking like maybe the server needs to be set to boot in BIOS mode and cannot boot in UEFI mode without throwing PCIe “training” errors.  This issue goes away in BIOS mode provided you have set the “Memory Mapped I/O above 4GB” BIOS setting enabled:
Screen Shot 2021-04-19 at 10.18.50 AM1554×1178 156 KB
As well as the associated PCIe slot enabled?  For my R720 the valid slots would be 4 OR 6:The firmware hasn’t been updated in a very long time (presumably due to the inability to monetize additional licensing fees based on how much use you actually get out of these cards…) so I am going to load up my Ubuntu LiveCD on a USB drive OR Remote Console “Virtual Media” in BIOS mode (already installed in UEFI mode, but the Grid Cards don’t let me boot in UEFI mode for whatever reason…) and reinstall Linux, then attempt to reflash the VBIOS of the NVidia card.I see there is an “URGENT!” update covering these and the Tesla cards in 2016 I can try next if that doesn’t work…This is pretty shady from a support perspective NVidia.  Tisk tisk.  You have been shamed.LOLPowered by Discourse, best viewed with JavaScript enabled"
406,vmware-esxi-6-7-u2-and-crashing-windows-10-vm-with-tesla-t4-or-p100-vgpu,"Hi,I have a Tyan GPU server with Tesla T4 (also happens with P100) running the q4 profile and its freezing overnight on the VM or when the VM is left idle for long periods.
Is there any known issues peope are aware of? Some VM best practises for esxi I should be applying to win10 machine?
I am using the latest grid driver : NVIDIA-GRID-vSphere-6.7-440.43-441.66. Im going to create a ticket on this but in the mean time if anyone has piinters would be helful.HiNo known issues immediately come to mind. Have you changed the Windows Power Management settings inside the VM?RegardsMGHi MG,
Interesting thought, is there a best practise guide showing what’s best?
Is it a known issue with power management settings, I guess just disable them allCharlesHi CharlesI always configure the Windows Power Management in Control Panel for High Performance. You can do that manually or through GPO.I’m not aware of any specific best practice guide that details it, it’s just something that I’ve always done. Worth a try and it’s quick and easy to do :-)RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
407,failed-to-acquire-grid-virtual-workstation-license,"I am running a Windows 10 for both server and clients with an Nvidia Tesla T4. Everything works fine launching new VMs when the server is recently launched with a fresh install. We’ve tried several times, and it always fails after a couple of hours running. Once it starts to fail, the logs are always the following:16:04:43,253 WARN  srvpool-966 [16C63EFF4533 request] Unable to handle request for feature GRID-Virtual-PC 2.0 count=1. Reason: FEATURE_NOT_AVAILABLE.
16:04:45,112 INFO  srvpool-932 [16C63EFF4533 request] Successfully handled request for feature Quadro-Virtual-DWS 5.0 count=1 correlationID=531fc554-55f5-40d0-adb2-1002d7646549.
16:04:46,768 WARN  srvpool-932 [16C63EFF4533 request] Unable to handle request for feature GRID-Virtual-WS 2.0 count=1. Reason: FEATURE_NOT_AVAILABLE.
16:04:46,768 INFO  srvpool-932 [16C63EFF4533 request] Feature Quadro-Virtual-DWS 5.0 was returned.
16:04:48,432 WARN  srvpool-966 [16C63EFF4533 request] Unable to handle request for feature GRID-Virtual-WS-Ext 2.0 count=1. Reason: FEATURE_NOT_AVAILABLE.The feature usage on the server at the time of the above logs, of course, is the following:
image1778×443 194 KB
The environment is the following:Powered by Discourse, best viewed with JavaScript enabled"
408,black-screen-after-i-reboot-ubuntu-18-04,"nvidia-but-report.log.gz (682.3 KB)
linux-kernel is 5.4.0-42
nvidia driver is 465.19
This is the PC provided by the school with the new graphic card RTX3070,
but it still has some problem. Last week, i use it nomarlly, then i off it on last Friday, when i back this Monday, black screen appear when i boot it.
@generix  please help me, thanks in advanceSorry, looks broken. Please check with vendor or your school to have it replacedThanks, i will email the school.Powered by Discourse, best viewed with JavaScript enabled"
409,poor-blender-performance-after-a-few-minutes-of-use,"Hello,When starting the VM, Blender works perfectly. After a few minutes of use (5 to 10 min) performance becomes very low (2 fps).
I don’t have this problem with driver version 430.46. The problem appeared with later versions.
here is the configuration of the vm:
Debian 11. (I tried with debian 10, the problem also exists)
GPU: TESLA P4.
Driver Version: 495.46 - CUDA Version: 11.5
Blender: 2.92 (the problem exists with 2.78 too)performance test with __GL_SYNC_TO_VBLANK=0 glxgears shows constant FPS of 1177.705 FPSThanks.I attach the bug report with and without the bad performance.nvidia-bug-report.log.zip (528.9 KB)Powered by Discourse, best viewed with JavaScript enabled"
410,azure-rtx-workstation-omniverse,"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/nvidia.nvidia-quadro-vws-win2019?tab=OverviewI can’t run Omniverse Code, I need to upgrade windows…
AzureRTXImage1773×919 176 KB
Hi, could you please give us a few details which image you took from the marketplace? Was it the latest one including 14.1 vGPU drivers? Would need to verify the MSFT build number.regards
SimonI tried the latest image…

image1440×823 74.9 KB
That is the WinServer release channel issue. The only solution is not use this image.But this is the only image that will work to run RTX workstation, so it is impossible?Powered by Discourse, best viewed with JavaScript enabled"
411,tesla-m10-with-windows-server-2019-vm-3d-options-missing,"Hi All,Apologies if I’ve done something dumb.We’ve just deployed our first GRID license with our Tesla M10 on our new Dell Poweredge servers.It was all going well, I had the Solidworks user installing the Solidworks software and adjusting the 3D settings in the Nvidia Control Panel.I shut down to allocate more RAM, restarted the VM and now the Control Panel doesn’t show any 3D settings.  As in, the Control Panel no longer shows any option other than the License options.I’ve connected to the GRID license server, allocated a vDWS license to the VM and I can see it’s been issued in the server.I’ve tried the current version of the driver 442.06 and the previous version 441.66 and no change…Any ideas?Without this, it’s literally useless to me!HiNo idea what’s happened there.First thought, uninstall / reinstall of NVIDIA driver.You mention Server 2019. Is that RDSH or a single user VM? If RDSH, what’s your connection protocol?RegardsMGHi,Obviously I’ve tried uninstalling and reinstalling a dozen different ways and nothing.RDSH, but we’re just connecting via RDP locally.I’ll try a reinstall of the OS, I don’t want to waste anymore time on it.  I’ve literally spent hours on it already trying to make it work.We’re just experimenting at this point to see if it’s going to do what we want… Currently it’s not great…Thanks for the reply!Are you really going to run Solidworks with Tesla M10???Powered by Discourse, best viewed with JavaScript enabled"
412,do-i-need-to-purchase-vgpu-licience-to-use-nvidia-qudro-vm-on-aws-marketplace,"Ingram is selling nvidia qudro vm for free and just charging for instance.So is there any license to be bought prior to use it or is there any other catch there.looks its still unclear :(Powered by Discourse, best viewed with JavaScript enabled"
413,v100-gpu-driver-collision-with-vdi,"HI,I use a V100 GPU for VDI purpose on the HPE Server and driver version 470.63.
One of the VDI user failed to load driver with below.9 28 08:07:09 LVM6802978 nvidia-gridd[859]: Started (859)
9 28 08:07:09 LVM6802978 nvidia-gridd[859]:  Failed to initialise RM client
9 28 08:07:09 LVM6802978 nvidia-gridd[859]:  Failed to initialise RM client
9 28 08:07:09 LVM6802978 nvidia-gridd[859]: Failed to unlock PID file: Bad file descriptor
9 28 08:07:09 LVM6802978 nvidia-gridd[859]: Failed to close PID file: Bad file descriptor
9 28 08:07:09 LVM6802978 nvidia-gridd[859]: Shutdown (859)
<<9 28 08:07:09 LVM6802978 nvidia-topologyd[915]: Started daemon with PID 922>>
<<9 28 08:07:09 LVM6802978 nvidia-topologyd[922]: Failed to build internal tree representation from VTDS, error: 3>>
<<9 30 08:24:03 LVM6802978 nvidia-settings.desktop[19297]: ERROR: NVIDIA driver is not loaded>>
9 30 08:24:03 LVM6802978 nvidia-settings.desktop[19297]: ERROR: Unable to load info from any available systemnvidia-bug-report.log.gz (88.8 KB)Are there any known issues with the above?Having the exact same issue here. If you fixed it, would you mind telling how? I would highly appreciate it.Powered by Discourse, best viewed with JavaScript enabled"
414,gpu-operator-problem,"Hello all. I’m attempting to get Nvidia GPU Operator running stand alone on my laptop (No Virtualization). When deploying via Helm to kubernetes, the gpu-operator pod shows up as pending and does not work, nor does it have any log files.My questions:
-Can GPU Operator run on any hardware?
-Does GPU Operator require an install of vGPU or can my normal nvidia driver work?Environment: Centos 7, Kubernets:v1.20.3, Helm:3.5.2,  NVIDIA-SMI 418.113      Driver Version: 418.113
Hardware: Dell Laptop,  Video Card: Quadro K1100M
Literature: Getting Started, GPU Operator: https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.htmlPowered by Discourse, best viewed with JavaScript enabled"
415,power-off-or-reboot-ubuntu-vm-with-gpu-passthru-disables-gpu,"Hello I seem to have run into a fun issue.  I am attempting to setup a ubuntu VM with a Quadro P4000 and I’ve run into an issue once drivers load in the VM.  From what I can tell this doesn’t matter if the Guest OS is Server or Desktop.  Here are the details of my environmentHost: Windows Server 2016 Core
GPU: Quadro P4000
Guest: Ubuntu 20.04I have an app that can run in Windows or Linux, this app uses ffmpeg for decoding/encoding videos.  The Linux version handles videos with HDR on the gpu where the windows version will use CPU for the HDR portion.  So I am doing some testing before making the full move.I currently have the GPU passed into a Windows Guest.  Works great rebooting the vm card starts no problem extra.So Installed, Ubuntu Desktop first, installed the app and copied some videos that are 4K HDR for testing.  Without the GPU the app was working without issue as best it could CPU rendering the videos pegs the vm cpu.  So I shut down both the windows guest and ubuntu guest.  removed the P4000 from the Windows VM and attached it to the Ubuntu VM.  Powered on, installed drivers, rebooted. Got No display on the VM…(I should have expected that actually).  removed the card to install SSH Server so I can at least have terminal.  After powering back up I had display on the vm and testing the app would through errors trying to start it’s encoding/decoding process.  So while trying to figure out why I was having issues with the app in linux I put the GPU back to the Windows Guest and powered it back on.  Only to find it wasn’t working either now.  In Device manager the card had a code 43 error. after failing to get the device to start in windows I decided to reboot the entire host.  Which solved the issue with the windows guest.  So I decided to got back to my testing of the Ubuntu Guest and I was able to get everything to work (no display on the VM still), but I wasnt’ done.  I wanted to test the functionality on Ubuntu Server as well so I powered off the Ubuntu Guest, Swithed VHD’s to the server and powered it on and same thing again won’t run the app’s process and the Windows Guest again has code 43 error.In linux I was using the 510 driver package, on windows i’m using a 47X driver.  I’ve not tired with the 470 driver package on Linux yet, but I am planning on it.  But my question is, is there a setting in the linux drivers that cause a part of the card to stop that is reset during reboot of the physical machine.  And if there is, how do I disable it.  Or is the an issue with the 510 package.Hi,Windows Server Core OS is not supported at all as a host. Most likely causes the issues…regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
416,gpu-in-a-vm-pass-through-setting,"Hi All,My system environment is as below:
Host system: Windows Server 2019
GPU: NVIDIA Titan RTX
Guest system: Hyper-V Ubuntu Linux 18.04.2 LTS VM.I have done the GPU pass-through on my Host system to dismount the GPU and mount it to my Hyper-V Ubuntu Linux VM by referring to this documentation: https://docs.nvidia.com/grid/5.0/grid-vgpu-user-guide/index.html#using-gpu-pass-through-windows-server-hyper-v.After assigning a GPU to a VM, install the NVIDIA graphics driver in the guest OS on the VM as explained in Installing the NVIDIA vGPU Software Graphics DriverAnd according to the documentation, I am required to install the NVIDIA vGPU software graphic driver.
But from https://docs.nvidia.com/grid/latest/grid-vgpu-release-notes-microsoft-windows-server/index.html#hardware-configuration
The Titan RTX GPU is not listed as the supported GPU, am I able to install the NVIDIA vGPU software with the Titan RTX GPU on the Hyper-V Ubuntu Linux VM?I am working on installing CUDA on my Hyper-V Ubuntu Linux VM and I am encounter the error as show below when running the nvidia-smi:I am able to install CUDA but encounter the following error when running the CUDA sample binaries to verify the CUDA installation:For my case, what should I do in order for me to enable my Hyper-V VM to be able to use the GPU and run CUDA successfully?Thanks and regards,
YiYangHiThe only GPUs that support vGPU are Tesla and the RTX 6000 & RTX 8000. The TITAN cannot be used with vGPU, so you will need to run the TITAN in Passthrough / DDA for your Ubuntu VM.As the TITAN doesn’t support vGPU, you can use the standard driver from the NVIDIA drivers page: https://www.nvidia.co.uk/Download/index.aspx?lang=en-uk.RegardsMGHi Sir,I have successfully done the GPU pass-through by following the instruction here:https://docs.nvidia.com/grid/5.0/grid-vgpu-user-guide/index.html#using-gpu-pass-through-windows-server-hyper-vAs the TITAN doesn’t support vGPU, you can use the standard driver from the NVIDIA drivers page: Official Drivers | NVIDIA.I have tried to install the standard driver before.
What I did was I installed CUDA first by following this documentation:https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation.
Then I downloaded the NVIDIA drivers from the page you suggested, but after installing the NVIDIA driver and reboot my Hyper-V Ubuntu Linux VM, my VM be cannot be boot and just stuck at the black screen.
The NVIDIA drivers that I have downloaded and installed from the page for Titan RTX are the Linux 64-bit Operating system and Linux 64-bit Ubuntu 18.04 Operating System.Thank You and Regards,
YiYangHiYou should install the NVIDIA drivers in the OS first, that way anything that relies on the GPU will have access to it.Regarding the black screen … If you were using a Hyper-V Console to connect to the VM, after installing the NVIDIA driver, you may now need to use a proper remoting protocol to connect to it. Depending on your requirements, maybe something like VNC. Or if you’d prefer to use RDP, then connect to the VM via SSH and install XRDP to allow RDP connectivity.RegardsMGTitan doesn’t support virtualization at all.Hi MrGRID,I have install the NVIDIA driver in my hyper-V Ubuntu Linux 18.04.2 LTS OS VM and I am connecting to the VM using RDP.
The NVIDIA driver version I have installed is 430.34 for Linux 64-bit OS.
But I still encounter the same error when running the nvidia-smi command as below:Does this mean I am not able to use the Titan RTX GPU in my hyper-V Ubuntu Linux VM with the standard NVIDIA drivers?Thanks and Regards,
YiYangHi sschaber,Titan doesn’t support virtualization at all.Is it mean if I am using the Hyper-V Ubuntu Linux VM, I must have the vGPU drivers and NVIDIA GPU that support virtualization in order for the NVIDIA GPU to work in the VM?Thanks and regards,
YiYangIt means that Titan (consumer product) is not enabled for virtualization (including Passthrough) and therefore it is not working or at least not supported.Hi sschaber,Does it means that only GPUs, like Tesla V100/P100, RTX6000/8000, can be passed through to the linux vm and work properly with standard NVIDIA driver?Should I install vGPU driver in linux vm or standard GPU driver is OK?HiThe GPUs listed here are supported for vGPU: Supported Products :: NVIDIA Virtual GPU Software DocumentationPassthrough GPUs are Quadro P2000 and above.Don’t confuse vGPU with Passthrough, they are not the same.RegardsMGHello,My environment is;
Host: Windows Server 2019
GPU: NVIDIA RTX 2080Ti
Guest system: Hyper-V Ubuntu Linux 20.04I have the same problem with YiYang.I have spend like 18 hours to solve this problem. Nvidia X Server Settings is empty screen. Also I have attached some links of screenshot that can help solve the problem.
https://ibb.co/DrbkF4Y
https://ibb.co/grKP4TS
https://ibb.co/DMV57fLCan you please help me about this issue?Thank you.HiThe 2080Ti is a Consumer (GeForce) GPU. You should be running Quadro or Tesla for this to work.RegardsMGThanks for the reply @MrGRID,Is there any way to virtualize 2080Ti with different host like KVM, VMWare. Because as a company we bought 2 2080Ti for AI.What we want is we need 1 prod VM and 1 test VM. Both GPUs should usable for those 2 VMs.RegardsHiUnfortunately you should have purchased Quadro or Tesla GPUs if you need to virtualise them. GeForce are Consumer GPUs and do not support virtualisation.Best advice, send them back to where you purchased them from and purchase a pair of RTX 5000 / 6000 or 8000 GPUs. These can be used in either Passthrough without a vGPU license and a standard Quadro driver, or you can use them with vGPU and run multiple instances per GPU (which does requires a license).RegardsMGThank you so much for the advise.We’ll change the GPU’s and probably we ll buy 2x RTX5000. Supported Products :: NVIDIA Virtual GPU Software Documentation at this document i can’t see RTX5000 i think this is not updated document.So with RTX 5000 we can attach both GPU’s to multiple VMs.For example:1 Prod VM
1 Test VM2 GPU’s memory is fully available to use sometimes for Prod VM and sometimes for Test VM.Have I got it right?I’ve bought a Quadro P2200 card and it is also not working with Discrete Device Assignment. Wheter in Windows nor in Linux! Could not recommend therfore to buy a Nvidia Quadro!@ sschaberModeratorSeems that from "" 30 March 2021"" Nvidia support passthrough for Consumer GPU, like RTX2080 and RTX3080/3090.
It is real and possible on Hyper V with a win10 guest OS? or only under KVM hypervisor?Hi Alessandro,I don’t test consumer products. The announcement only mentions KVM as a tested environment so I would assume that could work on HyperV but for sure it would be untested.Regards
Simontnks so muchHello @sschaber. Im running the same setup as the author of this post, but with 8 x Tesla T4 cards on a bare metal AWS machine (g4dn.metal). So those are non-consumer cards. Windows Server 2019 with HyperV and Ubuntu 20.04 guest. I’m getting the following error before VM startup:Virtual Pci Express Port (Instance ID 02583E40-07CB-4C02-9CF4-B4D3A55868F9): Failed to Power on with Error 'The hypervisor could not perform the operation because the object or value was either already in use or being used for a purpose that would not permit completing the operation.'.We have a commercial product upcoming and rely on GPU passthrough to work properly. Any help and pointer highly appreciated.Powered by Discourse, best viewed with JavaScript enabled"
417,k1-grid-driver-on-vmware-esix-6-5-vm-machine-driver-needed,"Hi everyone,I already pass-through and installed driver on Esix 6.5 physical server Dell R730 successfully.I can find the VMSgva3D on the VM but I cannot run the driver setup on the Virtual Machine (Windows 10)Could you please tell me how can I setup driver for all of my VMs on Esix 6.5?Do I need to do some configure on VCenter 7.0??Tks.KhangHi,K1 is a pretty old GPU and went EOL a few years ago. The vGPU branch 4.x was the last one supporting this GPU:
https://docs.nvidia.com/grid/4.10/index.htmlregards
SimonPowered by Discourse, best viewed with JavaScript enabled"
418,can-t-start-nvidia-driver-460-in-ubuntu-18-04-geforce-t1650i,"I’m trying to install Nvidia driver on Ubuntu 18.04, try all solution but still have problem. I can’t change the resolution. The X server is empty. Please helpnvidia-bug-report.log.gz (80.3 KB)Hi aakbarig,Thanks for the question but unfortunately this forum is related to NVIDIA’s vGPU products.  I suggest that you post in the Geforce forums.thanks
Powered by Discourse, best viewed with JavaScript enabled"
419,motherboard-support-for-tesla-t4,"I have an ASUS Prime Z390-A Motherboard LGA1151 and I’m wondering what the easiest way to verify if it does or does not support a 16GB graphics card.  If it is supported, does anyone know what settings I would need to adjust in Bios to enable the card?HiThat’s a Consumer grade motherboard you’ve listed, so I’m assuming you’ll be installing it inside a Tower chassis and not a rack mount chassis. The Tesla T4 (that you mentioned in the heading) is a datacenter grade GPU and is Passively cooled, so is completely unsuitable for a Tower chassis.If you need a 16GB GPU to go with the motherboard you’ve listed (assuming in a Tower chassis), a more suitable choice would be an RTX 5000 (Turing) or P5000 (Pascal), as these are both Actively cooled. For around the same sort of money, you might then also consider a TITAN RTX (Turing / 24GB), however this is a Prosumer level GPU not a Professional one (like the RTX 5000 / P5000). It depends on your use case as to whether this is suitable.Regarding BIOS changes, you shouldn’t need to make any. However, if your system doesn’t boot, then check out the ""Above 4G Decoding"" setting.RegardsMGI’ve got a cooling solution for the T4 that seems to be working fairly well for temps (using a thermaltake p3 case with a GPU tray and a couple be:Quiet fans).  I can use other GPUs as well, but I’d like to occasionally do some testing with a T4 as that’s the hardware platform I’m targeting, and it would be nice to have one in my desktop.I see options for ‘Above 4G …’ on a co-worker’s motherboard but don’t seem to see a similar setting on the ASUS Prime Z390-A.Thanks for the help MrGRID, I’m convinced after a little more googling for ‘Above 4G Decoding’ that as you say the card should ‘just work’ with this motherboard.  I’m going to try testing with a 2070 I have (8GB) and suspect that will work out of the box, which should rule out bios or motherboard compatibility as the source of my issues.kellensunderlandvirtgpu - How did it work out?  Did the T4 work and did your cooling solution hold up?Powered by Discourse, best viewed with JavaScript enabled"
420,display-mode-selector-tool,"Hello,i have some problems changing the display mode from your A40 cards with the Display_Mode_Selector_Tool.
We want to use the A40 as vGPUs. Right now ECC is diabled and  SR-IOV in enabled…VMware ESXi, 6.7.0, 19195723
Dell PowerEdge R750 with 2x Nvidia A40NVIDIA-SMI 470.82       Driver Version: 470.82       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A40          On   | 00000000:17:00.0 Off |                    0 |
|  0%   29C    P8    31W / 300W |      0MiB / 45634MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   1  NVIDIA A40          On   | 00000000:CA:00.0 Off |                    0 |
|  0%   28C    P8    31W / 300W |      6MiB / 45634MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+As far as i can see the GPUs are running in wrong mode:
GPU 00000000:CA:00.0
Product Name                          : NVIDIA A40
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : EnabledSo i want to Switch to physical_display_disabled and get this output:./displaymodeselector --gpumodeNVIDIA Display Mode Selector Utility (Version 1.48.0)
Copyright (C) 2015-2020, NVIDIA Corporation. All Rights Reserved.WARNING: This operation updates the firmware on the board and could makeAre you sure you want to continue?
Press ‘y’ to confirm (any other key to abort):
y
Select a number:
<0> physical_display_enabled_256MB_bar1
<1> physical_display_disabled
<2> physical_display_enabled_8GB_bar1Select a number (ESC to quit):
1Specifed GPU Mode “physical_display_disabled”Update GPU Mode of all adapters to “physical_display_disabled”?
Press ‘y’ to confirm or ‘n’ to choose adapters or any other key to abort:
yUpdating GPU Mode of all eligible adapters to “physical_display_disabled”Segmentation faultDoes anyone know this error?Same issue here. If you find a solution I would be happy if you share it with us.Hi,what are you trying to achieve? A40 is already in the correct mode to run vGPU. There is no need to use mode selector tool!!!The A40 comes configured as displayless, so unless you know it was changed, it’s probably fine.ESXi 6.7.0 only supports A40 in pass-through mode, not NVIDIA vGPU. Upgrade to ESXi 7.0.2+ and then you can use vGPU.Powered by Discourse, best viewed with JavaScript enabled"
421,troubleshooting-tesla-m10-in-a-horizon-vdi-environment,"Good afternoon,We have recently deployed Tesla M10 cards within our environment. I currently have a test pool created and a few users testing this solution.ESXi 6.7, Horizon 7.7, Drive version 25.21.14.2531.
VMs have 4 CPU and 8Gb RAM.
We are using the blast protocol and the 1B profile.My coworker and I are on identical VMs spun up from the same image. Our client side hardware is also identical (MacBook Pro). When he views a video on youtube, it is very smooth with no delay in audio or video. General performance on his side is great.When I attempt the same, my experience is very different. Choppy audio/video and general performance is bad. Performance is actually worse than when I use another VM without a vGPU.The biggest difference between us is that his internet connection is gigabit fiber and mine is standard coax. But surely this is not enough to cause this large of a performance gap? Per VMWare docs, we should need a max of 2Mbps for optimal performance. Is this a protocol issue? How can I troubleshoot this problem?HiWhat happens when you try a different network connection or from a different geographical location (work office / home / tethered 4G mobile phone)? Have you tried a different Client to rule that out?Has your VM definitely picked up an NVIDIA license?RegardsMGHiWhat happens when you try a different network connection or from a different geographical location (work office / home / tethered 4G mobile phone)? Have you tried a different Client to rule that out?Has your VM definitely picked up an NVIDIA license?RegardsMGThanks for the reply! If I’m in the office, performance is fine. I’m just wondering if there is an adjustment we need to make on the clients to see better performance on a slower connection.I have validated that the VM I’m seeing the issue on is licensed.HiHave you configured the maximum bandwidth policy? Maximum Frame rate? Type of encoding to be used?Those settings (and many others) can be configured under Group Policy in Active Directory once you’ve imported the Horizon templates. There’s plenty of settings you can investigate in there to get the desired experience.You’ll need more than 2Mbps for a decent experience. What kind of internet connection performance do you have? Bandwidth / Latency? Is your Client connected via WiFi or ethernet cable internally?RegardsMGHiHave you configured the maximum bandwidth policy? Maximum Frame rate? Type of encoding to be used?Those settings (and many others) can be configured under Group Policy in Active Directory once you’ve imported the Horizon templates. There’s plenty of settings you can investigate in there to get the desired experience.You’ll need more than 2Mbps for a decent experience. What kind of internet connection performance do you have? Bandwidth / Latency? Is your Client connected via WiFi or ethernet cable internally?RegardsMGWe do have policies in place for our Windows clients. Unfortunately I am stuck with a Mac that is not domain joined.Below are my results for the dslreports speed test.http://www.dslreports.com/speedtest/63919396HiThe Windows VM (Horizon) is what the GPOs are applied to that define the experience. Your Client doesn’t need to be domain joined.Have you tried a different type of Client instead of your MacBook? Can you try a Windows powered device instead?RegardsMGHiThe Windows VM (Horizon) is what the GPOs are applied to that define the experience. Your Client doesn’t need to be domain joined.Have you tried a different type of Client instead of your MacBook? Can you try a Windows powered device instead?RegardsMGThank you! I thought they were client settings. I will tinker with them a bit to see if I can improve my experience. Do you know if VMWare or NVIDIA has recommendations for settings?I can try a windows device when I get a chance. My coworker is also on a Mac and has no trouble at all, but his is slightly newer. I also have no issues when I’m in the office. I only have issues when working from home.Powered by Discourse, best viewed with JavaScript enabled"
422,not-support-centos-stream-9-host-os,"Hello
I want to use vGPU in CentOS (host OS) through OpenStack (guest instance OS = Windows 10). Is this possible?
Please help and answer to me!
God bless you~Powered by Discourse, best viewed with JavaScript enabled"
423,what-license-for-vgpu-in-linux-vms,"Hi,I work for a company that develops a system that runs on Linux that does remote rendering for medical applications. I would like to be able to run it on ESXi with vGPU. It is completely unclear to me if I need a software license for this application and if I do what type I need. My application creates one or more OpenGL contexts per user for remote rendering, but it does this in a single VM. It does not use common RDI infrastructure like RDP, it is a proprietary system. My wish is to get as much of the native GPU power through to the VM. Can you advise?For testing purposes I plan to buy a Tesla T4 and stick it in a test server that we already have running ESXi 6.5. If I need a license for the VM can I buy it directly from NVIDIA or where would I go?I have browsed https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/Virtual-GPU-Packaging-and-Licensing-Guide.pdf and https://docs.nvidia.com/grid/licensing-faq.html. If my answer is in there, I failed to find it.I really hope you can help me.Best regards,
ThomasHi Thomas,To be honest I’m wondering why you couldn’t find the answer in the licensing guide. For sure you will need a license for your use case. It is required to have at least a vPC license or a vWS license if you need a profile with more FB or CUDA support.
NVIDIA doesn’t sell directly so you need to go to Distis or OEMs that are able to resell NV licenses.
BTW: T4 seems to be the right GPU :)regards
SimonThanks for your answer, Simon. I think part of the problem with the licensing guide for me is that it frustrates me how much of the advantage of vGPU that is chopped off by having to deal with a complicated license model. If you could take a humble wish back to the product managers it would be to drop this per-VM multiple types of clients licensing mess and just recoup the revenue loss by making the data center GPUs (even) more expensive.Powered by Discourse, best viewed with JavaScript enabled"
424,dsr-is-nice-but-issues-has-been-present-till-now,"First of all, hello and sorry for posting this in here I kind of knew user to this developer page So excuse me if there are some mistakes in this post.Basically, I have an issue with dsr factors From Nvidia control panels First of all, when I set the resolution to be on. to be at 4K. from the control panel settings by the way, I have a 1080p native resolution. and RTX 3070 laptop GPU. and then after I set 4K with the factors Then I will jump back to my game. in order to change the resolution beyond my native resolution which this is what the DSR is about. Ok, no issue Perfect stable frame rates at this 4K DSR. No lag at all. But here’s here come the problem. When I finished gaming and I just want to shut down the computer or even do a restart. Now, when the computer freshly booted. and I jumped back to my game, which of course the settings was saved. was saved at 4K. last time. Now the game stutters like crazy. and constant lagging. It is like the GPU doesn’t recognize the resolution after a restart or shut down the only solution that I came up so far is I have to change the resolution back to 1080p from the game settings and not only that still it is present but when I send it to 1080p and the next step I have to restart my computer in order to the GPU res Self and became afresh. boot kernel. Now when I jump back the game if you remember now it should be 1080p because before the shutdown or before the restart in order to overcome this issue, I have changed back to 10 adp. Now there is no problem that game works fine run fine. And then like the first time I can now change back from the menu of the game to the 4KDSR factors that I have specified before. Now again the game runs fine perfectly with No. issue. Now here. to come again the cycle. when I shut down the computer again or I just want to quit and do a restart now because the game settings save it at 4K. now when I jump back to a game after a restart or shut down it is like the first I’ve talked about it It will be constantly lagging and stuttering. So like I said, it is look like the graphic card doesn’t recognize the 4K DSR after a clean restart or shut down. now and before you respond to me I. have done literally everything fresh. clean windows install up the GPU drivers try different games and by the way it doesn’t happen with every game. I think. specifically it happens with Vulcan IPI systems and directed X12 games. which means not the directed echoes 11 or 10 or 9 which all their games it doesn’t happen to those games. Unfortunately it will only happens to Vulcan and directed X12 games. So no, I really search everything Did everything nothing will solve this issue and even through the Internet I have searched about it. It seems that no one having the same. issue or there isn’t even a post about such issue. so I don’t know Do you guys think this is a bug from Nvidia because I don’t think my system has any issue provided that I have did Windows update Windows reinstall I used. DDU 3rd app. party even to wipe everything shader cash everything everything restored the default settings played with the settings and by the way I haven’t even maxed out the graphic when I’m have constantly. lagging and stuttering at the DSR after the restart of the previously saved settings of the game which is at 4KDFR so I really hope you get what I said…Powered by Discourse, best viewed with JavaScript enabled"
425,hpe-nvidia-quadro-p4000-driver-for-vmware-esxi-6-5-on-hpe-dl360g10,"We needed higher resolution on a Virtual Machine to boost the security camera system VIDEO rendering & playback on a virtual Server.
We are running a small VMware ESXi 6.5 (6 cpu lic ) cluster on HPE DL360 GEN10sHPE Ilo recommended and we purchased qty 1 Hpe - NVIDIA QUADRO P4000 GPU video  (Q0V78A), and added to the HPE DL360G10Currently, the VMware OS sees the new HPE Nvidia Quadro P4000 video Card but  Vmware OS is asking for a current driver.
I read somewhere along the way we need to purchase the NVIDIA GRID vGPU solution licensing and the login ID
To get the correct driver, We were recommended
NVIDIA GRID Virtual Applications Perpetual LTU
NVIDIA GRID Virtual Applications Production SUMS 3yr 1 Concurrent User Service
Unfortunately, I don’t see any compatibility matrix to confirm.
Please advise if this is a supported configuration.
Thanks in advance !HiThe P4000 doesn’t support vGPU, and therefore doesn’t require what you have been ""recommended"". Be careful taking advice from others who don’t understand the technology :-)You can use the P4000 in ""Passthrough"" and you can then use the standard Quadro driver which is available from here: Official Drivers | NVIDIAYes, it will definitely work :-)RegardsMGThanks for the reply. We are running Vsphere ESXI 6.5 soon to upgrade to Vsphere ESXI 6.7
but the Nvidia driver download says it for Vsphere ESXI 5.5
Any feedback if it will still definitely work ?
Cheers !HiThe driver has nothing to do with VMware. You just want the standard Quadro driver as if you’re installing it in a local workstation under your desk. Use my link above, use the following details:Product Type: Quadro
Product Series: Quadro Series
Product: P4000
Operating System: Windows 10 64-bit
Windows Driver Type: Standard
Download Type: ODEThat’s the driver you need :-)Remember to set the GPU to ""Passthrough"" mode in vSphere so you can allocate it to the VM. The vSphere Host will need a reboot for it to take effect, after which you’ll be able to allocate it to your VM and install the driver.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
426,nvidia-vgpu-grid-profile-is-missing,"Hello, my organisation want to use vGPU.We use VMWare vSphere 7.03 and vCenter 7.03. I allready have installed the driver over putty and the command nvidia-smi shows me the graphics card. The Problem is, that i can`t choose a profile in the configuration of the VM. I can choose nvidia grid, but thats all.I have allready activate shared direct in the GPU Settings of the host. Direct IO is activatet too. The persistence-mode is on.Can anyone help me with this issue?Which GPU? Which server? Which driver version?
A bit more detail would help to get a better responseRegards SimonIts an Quadro RTX 8000 in an Intel 3.Gen Server with ESXi 7.03.The driver number is 14.1 (510.73.06) in the license portal.Hi,thanks for the additional information. But it would still be helpful to know which server (OEM, type). We have a HCL and only supported systems are tested. Often there are specific BIOS settings (MMIO, Above 4G and others) necessary, the OEM needs to advise in order to run the GPU properly with vGPU profiles.Download NVIDIA GRID datasheets, guides, solution overviews, white papers, and success stories. Watch GRID videos, webinars, and webcasts.In your specific case do you also have the Enterprise Plus license from vSphere in place?
Sometimes there is also an issue if you only have the GPU in one host in a cluster. You need to make sure that the VM is located on the right host, otherwise you also won’t see the profiles.Best regards
SimonHey,its an Intel Serverbarebone R2208WFTZSR with two Intel XEON Gold 6244.Can you tell me what kind of bios settings are need to see the profiles?Yes i have an Enterprise Plus license. There is no cluster at the moment. I have create an Datacenter in VCenter, but there is only one Host.Do you need more informations?Greetings
TobiasHard to say. Really depends on the OEM BIOS. But you could check this document from an example:This is part 2 of a series of blog articles on the subject of using GPUs with VMware vSphere. Part 1 of this series presents an overview of the various options for using GPUs on vSphere Part 2 describes the DirectPath I/O (Passthrough) mechanism for...
Est. reading time: 11 minutes

Above 4G decode needs to be enabled as example.Thanks for the details. I try it tomorrow, when i am in the office.I think there some options not configured in the BIOS.Hello,so i made it work now, but if I restart the vSphere Server its gone and the only way to solved this issue is to reinstall the driver.The driver couldn`t found by nvidia-smi. The only way to find the driver is first to activate passtrough and then to deactivet it.Unfortunately I assume this is related to the host you are using. This is not tested/supported and therefore there is not much we can do. There is the HCL for good reason. Please try to get some certified servers after your evaluation period to avoid such issues.Download NVIDIA GRID datasheets, guides, solution overviews, white papers, and success stories. Watch GRID videos, webinars, and webcasts.Best regards
SimonThe server from Wortmann TERRA SERVER 7220 G3 is supported by VMWare (HCL). Its only the Intel Barebone whats used.You can see it here:
https://www.vmware.com/resources/compatibility/search.php?deviceCategory=server&details=1&partner=93&releases=578&keyword=TERRA%20SERVER%207220%20G3&systemTypes=2&cpuSeries=128&page=1&display_interval=10&sortColumn=Partner&sortOrder=AscYesterday i had a call with VMWare support and they toke a look in the logs and make sure that all is configured the right way. The problem can´t solved by them. They say, there are no problems in VMWare and they think thats an Firmware Problem of the card who makes this issue.Do you have any idea?Sorry but I’m not talking about the VMWare HCL. As long as the server is not on our HCL it is not tested for GPUs and therefore not supported/working.
We don’t have firmware issues and there is no option for customers to modify the firmware (as not needed) so the VMWare response is not helpful nor correct.
Please check the link I posted previously with our HCL. If your server is not present there we cannot do anything further.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
427,tesla-t4-graphical-errors-virtual-desktops-1903,"Hi FolksI’ve already opened a case with NVIDIA and also with Citrix for this. But they don’t have an idea what causes the problems yet. So I thought maybe someone here has an idea or recommendation.Since we updated to Citrix 1903 and NVIDIA GRID drivers 9.0, we randomly get graphic errors inside XenDesktop Sessions (Please see the screenshot).This issue can be reproduced when moving windows around inside a XenDesktop session. The graphical errors mostly persist until I resize the Citrix Session Windows or switch from fulscreen to window mode and back.Enviroment:Hypervisor: VMware ESXi 6.5 latest patch
Virtualization: Citrix XenDesktop 1903
Guest OS: Windows 10 1803
NVIDIA Host driver: 430.27
NVIDIA Guest Driver: 431.02
Citrix Workspace App: 1905Please see the screenshot in the link for configuration settings which are applied.I’ve also tested with Citrix VDA 1811 and 1906, same problem. With VDA 7.15 the issue does not occur, but we recognized a way better performance, quality and also latency with VDA 1903. That’s why we want to upgrade to 1903, it’s a big improvement for our virtual AutoCAD workspaces.NVIDIA Support mentioned the following thing:""As I mentioned, starting with Citrix Virtual Apps and Desktops 7 1903 version, Citrix remoting implementation has changed from using NVFBC to using DDAPI.""If anybody has an idea I would be happy to hear some of them.Regards, CedyHiHave you tried running a newer version of Windows 10? The version you’re running is over a year old now, try a test build on 1903 and see if that makes a difference.RegardsMGFirst of all I would suggest to check the Framebuffer usage. Sounds like FB exhausting effects. Our support is right in terms of NVFBC / DDAPI so this can have a huge impact. DDAPI is meant for at least RS5 so I would also suggest to move to latest Win10 build first.regards
SimonThanks for the advicesI will give 1903 a try today.Regards, CedyJust tested with Windows 10 1903, VDA 1903 and NVIDIA Driver 431.02.The problems still exist, so Windows 10 version is not the reason for the issues.Any other ideas?

Unbenannt.JPG2485×607 141 KB
I did some more tests on this.Seems like I am not able to reproduce the issues with P4 and VDA 1903/1906.2.So it is definitly a Tespla T4 / CVDA 1903/1906.2 issue…Performance and latency is way better with T4, but not usable with the graphical issues.Hi,I can confirm these issues also exist on our setup:
Hypervisor: VMware ESXi 6.7 U2
Guest OS: Windows Server 2019
NVIDIA Host driver: 430.46
NVIDIA Guest Driver: 431.79Not too aware of the actual Citrix versions…Oh this is also an a Tesla T4 setup.
You can quickly test for these artifacts by visiting the site https://www.mumfordandsons.com/ where the background video behaves like a severly scratched DivX movie CD (long trails behind objects, tearing all over the place.)Got same problem, same HDX settings, same GPU card.
Disabling HW encoding make the artifacts go away, but we bought that card with a purpose.Wondering if anyone has a solution by now?There is no solution atm. This is a Citrix issue with hardware decode YUV444 on their current Citrix receivers. Please open a support ticket with Citrix. They are well aware of this and are working on a fix.
Simply create a screenshot in the session when the issue occurs and you will see, that you won’t see any corruption in the screenshot later…Hi sschaber,Do you have a ticket ID we can reference at Citrix?
We’re seeing similar issues, but we are not using YUV444/AlwaysLossLess.
Do you know with what Citrix Workspace App version the issues started? Perhaps a workaround could be to use one of the older versions.Thanks,KoenraadHi,we have the same issues on our CAD VDIs. Any news from Citrix about that?Thanks
KorbinianYes, there is a private fix available from Citrix (new workspace app). Please contact Citrix to get the required bits.Regards
SimonHi, we have similar issues with M60 YUV444/AlwaysLossLess Settings. Case is opened and they confirmed that they have a known issue regarding T4 but not M60 will test the new Workspace App and report back here.Hi, we are still waiting to get the fixed Workspace App version from Citrix for testing.Hi Gormat,I can guarantee that you won’t be affected by this issue with Tesla M60! The new workspace app added support for multiframe encode which was introduced with Turing (T4) architecture.You should test with a bigger framebuffer profile first to see if your issue is related to framebuffer exhaust, which is the issue I see most.regards
SimonCitrix told me to test the 1911, you can download it from https://www.citrix.com/en-in/downloads/workspace-app/windows/workspace-app-for-windows-latest.htmlDidnt had time to test it yet.@sschaber, sorry didnt saw that we already have a second page :-)Thank you for the input. But the looks like the same as the opening post. Are you sure?Br
Mat1911 is not correct. You need a private build…Hi sschaber do you have any Case number or something i can refer to?Thank youBr
MatFYI - this is addressed in Citrix Workspace App 2006.1 and above under fixID: RFWIN-14188Powered by Discourse, best viewed with JavaScript enabled"
428,unable-to-start-vms-with-vgpu,"Hello,
I have a vm in windows server 2019 on which I have an NVIDIA GRID vGPU grid-rtx8000-12q Ppofil.
When this vm is running, and I want to start another vm with the same NVIDIA GRID vGPU grid-rtx8000-12q profile, I get an error message saying ""Insufficient resources. One or more devices (pciPassthru0) required by the TEST VM are not available on the host ""the ecc is indeed deactivated.
I am in vsphere client 7.0.2 and the vcenter is in the same version.
I have walked a lot of tracks, in vain …
Thanks for your helpHave a idea ?
ThanksPlease open a  support ticket with NVES ti look into this. Could be a hardware defect or other reasons.Regards SimonCan you please show us how we open a ticket?I assume you have valid SUMS if you are using vGPU. Then you should know how to create a support ticket. If you are evaluating the product then there is no chance to open a support ticket. You should contact a partner to assist in troubleshooting.regards
SimonWe have a few A100 cards attached to our severs. We plan to split them into MIGs and attach the MIG slices into KVM virtual machines (VMs). Do we need to use vGPU license to attach MIG slices to the VMs or we can use PCI pass-through without licenses. Thank you for your support in advance.When using a virtualization layer, adding vGPU capability to VM(s), vGPU licenses will be required.Documentation for administrators that explains how to install and configure NVIDIA Virtual GPU manager, configure virtual GPU software in pass-through mode, and install drivers on guest operating systems.Please contact your NVIDIA vGPU Partner for more details with regard to acquiring NVIDIA vGPU Software.Use the NVIDIA Partner Locator tool to find a partner by country, competency, partner level, or partner type.Thanks.Hello,
i have the nvidia support and my problem is solve.
If you have a vm with a nvidia profil grid with 12q, you can’t power on another vm with a different nvidia profil grid.
My second VMs has a nvidia profil grid 4q, that the reason why she doesn’t start.
i put nvidia profil grid with 12q and she start.
Thank you for helpOk, good to hear. But in your previous problem description you mentioned you are unable to start another 12q profile.
So this is different situation and we only support homogenous vGPU profiles at this stage. Anyways, good example how fast our NVES can help to solve such issues.Best regards
SimonYeah strange,  I also noticed he listed the same profile twice, so according to the “solution” it should’ve worked from the beginning. But is that actually true? I thought this is the whole purpose of vGPU, to be able to split it (and that includes different sizings in my opinion)?!I have the same problem with VMs with profile “NVIDIA GRID vGPU grid_p40-4q”. Four identical hosts with a P40 each, four VMs with that profile, and I cannot migrate two VMs to one host…?Powered by Discourse, best viewed with JavaScript enabled"
429,help-needed-a40-in-vmware-esxi-7-0u2,"Hi guys,I’m trying to use Nvidia A40 for Xendesktop in VMware 7.0u2 here. Now I met a issue that VM with vGPU profile cannot start. Anyone can help please? thanks!Error when starting VM with vGPU profile (tried different VM/vGPU profile and no luck)Task Name: Power On virtual machine
Status: Could not initialize plugin ‘libnvidia-vgx.so’ for vGPU ‘nvidia_a40-6q’. Failed to start the virtual machine. Module DevicePowerOn power on failed.
Initiator: administrator@vsphere.local
Error stack:
Module DevicePowerOn power on failed.
Could not initialize plugin ‘libnvidia-vgx.so’ for vGPU ‘nvidia_a40-6q’.EnvironmentServer: Dell R740 with newest BIOS 2.11.2
ESXi: 7.0u2, build 17867351nvidia-smi outputTue Aug 17 02:17:03 2021
±----------------------------------------------------------------------------+
| NVIDIA-SMI 470.63       Driver Version: 470.63       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A40          On   | 00000000:AF:00.0 Off |                  Off |
|  0%   50C    P8    37W / 300W |      0MiB / 48687MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+ECC memoryI searched internet and many posts said the error “Could not initialize plugin ‘libnvidia-vgx.so’” is because of enabled ECC memory, but I’ve confirmed ECC memory disabled in nvidia-smi -q output==============NVSMI LOG==============Timestamp                                 : Tue Aug 17 02:36:02 2021
Driver Version                            : 470.63
CUDA Version                              : Not FoundAttached GPUs                             : 1
GPU 00000000:AF:00.0
Product Name                          : NVIDIA A40
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Enabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1320921024371
GPU UUID                              : GPU-2aefb9b1-5506-f46e-b53f-70ea9f2db5d8
Minor Number                          : 0
VBIOS Version                         : 94.02.5C.00.03
MultiGPU Board                        : No
Board ID                              : 0xaf00
GPU Part Number                       : 900-2G133-0000-000
Module ID                             : 0
Inforom Version
Image Version                     : G133.0200.00.05
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GSP Firmware Version                  : N/A
GPU Virtualization Mode
Virtualization Mode               : Host VGPU
Host VGPU Mode                    : SR-IOV
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0xAF
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x223510DE
Bus Id                            : 00000000:AF:00.0
Sub System Id                     : 0x145A10DE
GPU Link Info
PCIe Generation
Max                       : 3
Current                   : 1
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : 0 %
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 48687 MiB
Used                              : 0 MiB
Free                              : 48687 MiB
BAR1 Memory Usage
Total                             : 65536 MiB
Used                              : 1 MiB
Free                              : 65535 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : DisabledError message in VM logI see a error “NVOS status 0x17” in the log, anyone know its meaning?2021-08-16T08:17:29.087Z| vmx| | A000: ConfigDB: Unsetting “vmiop.guestVgpuVersion”
2021-08-16T08:17:29.111Z| vmx| | I005: VMIOP: Registered device 0000:af:00.0
2021-08-16T08:17:29.123Z| vmx| | A000: ConfigDB: Setting pciPassthru0.pgpu = “2235145A0606060606060600000002”
2021-08-16T08:17:29.123Z| vmx| | I005: VMIOP: Enabling checkpoint support
2021-08-16T08:17:29.123Z| vmx| | I005: VMIOP: Initializing plugin vmiop-display
2021-08-16T08:17:29.125Z| vmx| | E002: vmiop_log: NVOS status 0x17
2021-08-16T08:17:29.125Z| vmx| | E002: vmiop_log: Assertion Failed at 0xf8fb34b3:97
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: 16 frames returned by backtrace
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /usr/lib64/vmware/plugin/libnvidia-vgx.so(_nv005327vgpu+0x35) [0x58f8ffb615]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /usr/lib64/vmware/plugin/libnvidia-vgx.so(+0x7f6f8) [0x58f8fb76f8]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /usr/lib64/vmware/plugin/libnvidia-vgx.so(+0x7b4b3) [0x58f8fb34b3]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /usr/lib64/vmware/plugin/libnvidia-vgx.so(+0x99b97) [0x58f8fd1b97]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /usr/lib64/vmware/plugin/libnvidia-vgx.so(+0x9caeb) [0x58f8fd4aeb]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /usr/lib64/vmware/plugin/libvmx-vmiop.so(+0x91f4) [0x58f8b2f1f4]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x3adf98) [0x58b0d7ff98]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x2dc924) [0x58b0cae924]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x2dc45c) [0x58b0cae45c]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x2dd557) [0x58b0caf557]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x2e82bb) [0x58b0cba2bb]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x25a0c5) [0x58b0c2c0c5]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x25a8e2) [0x58b0c2c8e2]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x24e741) [0x58b0c20741]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /lib64/libc.so.6(__libc_start_main+0xed) [0x58f4082b2d]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: /bin/vmx(+0x24f115) [0x58b0c21115]
2021-08-16T08:17:29.126Z| vmx| | E002: vmiop_log: (0x0): Initialization: Failed to alloc host vgpu device handle error 1
2021-08-16T08:17:29.127Z| vmx| | E002: vmiop_log: (0x0): init_device_instance failed for inst 0 with error 1 (unable to setup host connection state)
2021-08-16T08:17:29.127Z| vmx| | E002: vmiop_log: (0x0): Initialization: init_device_instance failed error 1
2021-08-16T08:17:29.127Z| vmx| | E002: vmiop_log: display_init failed for inst: 0
2021-08-16T08:17:29.127Z| vmx| | E002: VMIOP: Plugin vmiop-display initialization failed: 1Do you have vCenter also on 7.0.2?Regards Simonyes, vcenter 7.0.2, newest versionHow much system memory did you assign?the server has 256GB memory. for VM, I assigned 8GB.Please try to increase the ESX VM Version. Not sur if 11 will work with vGPU 13I tried VM with newest version 19 but no luck.hi Simon,We also borrowed a V100 for comparison. So after replaced A40 with V100 on the same server, VM started successfully with no error. I really have no clue now, please help. thanks!Which server model do you use for testing? Sounds like A40 is not working properly with the hardware. Ampere GPUs require SR-IOV enable in BIOS.Thank you so much Simon! After enable SRIOV in the BIOS of our R740 server, the VM started successfully and works fine now. Really appreciate your help!Powered by Discourse, best viewed with JavaScript enabled"
430,nx-gk20a-channel-timeout-handler-and-then-auto-reboot,"operation: The cmdline is frequently started, with a small probability of automatic reboot. only in 4K and /dev/video0
cmdlne:
gst-launch-1.0 v4l2src device=“/dev/video0” -v -e ! “video/x-raw, width=(int)3840, height=(int)2160, framerate=(fraction)60/1, format=(string)NV12” ! tee name=t ! queue ! fpsdisplaysink video-sink=fakesink text-overlay=false sync=false t. ! nvvidconv ! “video/x-raw(memory:NVMM), width=(int)3840, height=(int)2160, format=(string)RGBA” ! queue ! nvoverlaysink sync=false
call trace:
[  941.144145] nvgpu: 17000000.gv11b     gk20a_channel_timeout_handler:1573 [ERR]  Job on channel 505 timed out
[  941.147496] nvgpu: 17000000.gv11b   nvgpu_set_error_notifier_locked:137  [ERR]  error notifier set to 8 for ch 505
[  941.149736] nvgpu: 17000000.gv11b     gk20a_channel_timeout_handler:1573 [ERR]  Job on channel 507 timed out
[  941.150955] nvgpu: 17000000.gv11b   nvgpu_set_error_notifier_locked:137  [ERR]  error notifier set to 8 for ch 507
[  941.153502] nvgpu: 17000000.gv11b    gk20a_fifo_handle_pbdma_intr_0:2744 [ERR]  semaphore acquire timeout!
[  948.640620] Kernel panic - not syncing: Watchdog detected hard LOCKUP on cpu 0
[  948.640805] CPU: 5 PID: 0 Comm: swapper/5 Tainted: G           O    4.9.253-tegra #5
[  948.640939] Hardware name: NVIDIA Jetson Xavier NX Developer Kit (DT)
[  948.641054] Call trace:
[  948.641125] [] dump_backtrace+0x0/0x198
[  948.641225] [] show_stack+0x24/0x30
[  948.641321] [] dump_stack+0xa0/0xc4
[  948.641413] [] panic+0x12c/0x2a8
[  948.641504] [] watchdog_check_hardlockup_other_cpu+0x11c/0x120
[  948.641632] [] watchdog_timer_fn+0x98/0x2c0
[  948.641739] [] __hrtimer_run_queues+0xd8/0x360
[  948.641846] [] hrtimer_interrupt+0xa8/0x1e0
[  948.641974] [] arch_timer_handler_phys+0x38/0x58
[  948.642442] [] handle_percpu_devid_irq+0x90/0x2b0
[  948.642931] [] generic_handle_irq+0x34/0x50
[  948.643354] [] __handle_domain_irq+0x68/0xc0
[  948.643816] [] gic_handle_irq+0x5c/0xb0
[  948.648542] [] el1_irq+0xe8/0x194
[  948.653100] [] cpuidle_enter_state+0xb8/0x380
[  948.659220] [] cpuidle_enter+0x34/0x48
[  948.664297] [] call_cpuidle+0x44/0x70
[  948.669630] [] cpu_startup_entry+0x1b0/0x200
[  948.675668] [] secondary_start_kernel+0x190/0x1f8
[  948.681711] [<0000000080f6e1a8>] 0x80f6e1a8
[  948.686172] SMP: stopping secondary CPUs
[  949.781901] SMP: failed to stop secondary CPUs 0,5
[  949.782034] Kernel Offset: disabled
[  949.782102] Memory Limit: none
[  949.782163] trusty-log panic notifier - trusty version Built: 02:25:37 Apr 17 2022 [  949.794688] Rebooting in 5 seconds…
[  954.803854] SMP: stopping secondary CPUs
[  955.862567] SMP: failed to stop secondary CPUs 0,5
?hutdown state requested 1
Rebooting system …i also received waring: tegra-ubuntu kernel: [ 5463.150089] soctherm: OC ALARM 0x00000001I wonder what causes this problem？Powered by Discourse, best viewed with JavaScript enabled"
431,vaio-quadro-gpu-for-cad,"
s-l16001080×1080 217 KB
Happy New Year To All,
I’d like to make my laptop into a CAD workstation by installing a modern Quadro GPU and its required RAM.
Here is an image of my Motherboard
https://ibb.co/H2cB61L
And attached is an example of another with the stock AMD GPU in place.
Could an official Nvidia engineer/informed person please help me in knowing which is the most performative GPU compatible with my MB?
I currently have an I73840QM and soon will upgrade to I73940XM, 16GB of RAM and sometime later will upgrade 32GB, currently with Intel XTU I can overclock my CPU so this motherboard is clearly built well.
Though I cannot find any official info it anywhere.If i am correct, my GPU RAM slots are FBGA-96, so DDR3/DDR4
They’re 8 slots (both sides of MB), after searching everywhere online I found currently the most I can get out of this Motherboard is DDR4 16GB (2GB each chip) at 3200Mbps.
I found this product:
https://www.skhynix.com/products.view.do?vseq=2462&cseq=73
Also, that means 3200 “core speed” and 6400 ""Memory clock effective” right?Ive done a few pairs of Mobile Quadros with I73940XM on pcbuilds to check for bottlenecking and i’ve gotten some good results.
But the question is which of the Quadros fit the BGA profile of this MB?
And then there’s the BIOS issue which I hope, if finding an GPU can be later solved.Also, one can see to the left of where the GPU should be are missing components such as capacitors etc.
I don’t know how to go about doing this project, can someone assist me please.
I imagine I would have to purchase the RAM from AliexpressSmarter Shopping, Better Living!  Aliexpress.com
Then purchase a MXM board with the desired GPU and get an expert to desolder/solder what’s needed to my MB
But then the next hurdle is analyzing the board to know which components to install.
As an amateur this is a big project i’m looking forward to,
I’m grateful for any and all assistance/further discussions
Thank youPowered by Discourse, best viewed with JavaScript enabled"
432,nvidia-canvas,"Hello, I wish to run Nvidia Canvas using
NVIDIA RTX Virtual Workstation - WinServer 2019. However, when I try to create an instance I get the following error message: “Instance launch failed: You have requested more vCPU capacity than your current vCPU limit of 0 allows for the instance bucket that the specified instance type belongs to.”  I can try and make a request for a higher vCPU limit, but what do I require to run Nvidia Canvas?Powered by Discourse, best viewed with JavaScript enabled"
433,nvidia-grid-k2,"I have installed the Nvidia Grid K2 in Dell R720 and Active the Passthrough PCIe but getting only 2 vGPUs in the list as
0000:45:00.0 NVIDIA Corporation NVIDIAGRID K2
0000:44:00.0 NVIDIA Corporation NVIDIAGRID K2So I assigned these to 2 VM’s running Windows 10 Pro
VGPU 44 is working fine but the vGPU 45 is showing me this error in the Device Manager Driver PropertiesPCI Slot 192 (PCI bus 11, device 0, function 0)
Windows has stopped this device because it has reported problems. (Code 43)I am running the VM’s in ESXi 6.7 with 6 cores and 16Gb Ram.And what is the question?
K2 is EOL for years. There is no current driver for K2 to support multi-vGPU.And what is the question?
K2 is EOL for years. There is no current driver for K2 to support multi-vGPU.So what to do now as I just buy it from Amazon and I find the Drivers for ESXi 6.5 Grid K2 on Nvidia Website download page.Powered by Discourse, best viewed with JavaScript enabled"
434,bare-metal-windows-2016-server-install-with-tesla-m60,"Hi - Couldn’t find the proper forum for a non vGPU issue, but I’ve got a Windows Server 2016 ibstall on a Dell R730 and after installing the driver the system appears to recognize that the M60 is installed.The plan it to access the server exclusively over RDP but I want to make sure I’m using the M60 as my Display driver - Is there anything special I need to do, or another forum I can post this too.Thx,PVsnip
On Windows Server 2016 and Windows Server 2012, Remote Desktop Services (RDS) sessions on the RD Session Host server use the Microsoft Basic Render Driver as the default adapter. To use the GPU in RDS sessions on Windows Server 2012, enable the Use the hardware default graphics adapter for all Remote Desktop Services sessions setting in the group policy Local Computer Policy > Computer Configuration > Administrative Templates > Windows Components > Remote Desktop Services > Remote Desktop Session Host > Remote Session Environment.
snipHI ,I have a same problem . I’ve got a Windows Server 2016 install on the Huawei server using tesla P40 .On windows server 2016 , how can I verify that RDP able to use the GPU ?I can see the P40 in GPU-Z & Device manager in local , but I can’t see the P40 driver after RDP .Thank youHere is the list of RDS 2016 new features and improvements, that can be interesting for service providers:Windows10-like experience
New GPU acceleration capabilities - RemoteFX improvements and Discrete Device Assignment feature
Personal Session Desktops - VDI, based on Windows Server 2016 inside the guest
New traffic protocol - RDP v10
Remote Credential Guard - protects credentials from being stolen during the logon process into RDS
New RDS clients for Windows, MacOS, iOS and Android
Optimized Connection Broker - handles much more requests and can store its DB in Azure SQL Database
Simplified deployment of RDS in Azure
Integrated MultiPoint ServicesPowered by Discourse, best viewed with JavaScript enabled"
435,rtx-4000-in-passthrough-in-vsphere-6-7,"Hi! I am using the RTX 4000 in vSphere 6.7 and assigned the adapter to the VM as PCI device ( 4 devices ). I installed the NVIDIA drivers in Windows 2016 VM. But when I RDP into the system and click on the Display properties it’s telling me I am using Generic Monitor ( that’s fine ) and using a MS drivers. Under the Device Manager I have disabled the VMware SVGA 3D adapter and left the RTX 4000 enabled. I am not able to change the resolution and also not able to add the GPU option in Task Manager to view the GPU utilization. Please help!HiWhen installing VMTools, you should have unselected the SVGA driver so it wasn’t installed.You need to change your connection protocol to something other than RDP. HDX, Blast, PCoIP, TGX, VNC will allow you to use the GPU properly.Regarding resolution, if using RDP you set that before you connect, you don’t change it while your session is open. If using one of the other protocols, you can simply ""full screen"" the window and the internal resolution will automatically resize to match that of your physical monitor. Or you can manually drag the window to a size you want and the resolution will automatically adjust to the size of the window. There’s no need to manually set the resolution within the VM.RegardsMGThanks for the reply! Is there any way I can see the GPU tab in Task Manager in Windows 2016. I searched and searched but not able to find an answer. Also, the NVIDIA Control Panel setting ""Usage Mode"" ""Use for Graphics and compute needs"" option is per user or can Administrator set this for all users in a Terminal Server (Remote Desktop Services)?HiNo, Windows 2016 is too old. Windows 2019 or Windows 10 have that feature.You can use this application if you wish to see GPU metrics: Releases · JeremyMain/GPUProfiler · GitHubI believe an Admin can set that mode in a RDSH when connected with an appropriate protocol.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
436,blank-vmware-console-screen-after-installing-nvidia-grid-driver,"Host = ESXi 6.7U3 P04, with Nvidia T4 GPU
VM Guest  = Windows server 2019 with one T4 GPU in PCI-e passthrough mode + Citrix 1912 LTSR CU2
After installing the latest grid driver (461.33_grid_win10_server2016_server2019_64bit_international.exe) the vmware remote console screen shows only blank/black. RDP & Citrix HDX work fine.Tried logging a support ticket with VMware but they told me it was an Nvidia driver issue so they cant provide support for it.
Tried using latest VMtools.
Tried increasing VM Hardware >> Video card >> Total Video Memory to 128GBHi Matt,Thanks for the post.  This is expected behavior see - Quick Start Guide :: NVIDIA Virtual GPU Software DocumentationDOK so I see the statement: “VM console in vSphere Web Client is not supported in this vGPU release. Therefore, use VMware Horizon or VNC to access the VM’s desktop.” That makes troubleshooting the VM really difficult. For example, I have an issue right now where one VM doesn’t reboot cleanly from a nightly scheduled reboot task. It just gets stuck somewhere half-way as its shutting down. RDP & VNV dont work, but I can still ping it. Without the console, I cannot see what is causing the problem.Is NVidia going to fix this bug??? VM Console is a fundamental part of administering a  vmware environment!I understand your frustration.  The fix to the bug requires a change to the “VM Console in vSphere”  which NVIDIA does not have control of.  I have raised the issue internally to see if we get this issue addressed with vmware.HiRemove the GPU from the VM, power it back on before its nightly automated shutdown and let it run through it’s automated shutdown process and hang. You can then use the Console to view the VM. Once the issue is resolved, reattached the GPU and carry on as normal. If it reboots cleanly without the VM attached, this will give you an area to investigate once you reattach it.RegardsMGDisable the VM Console is a stupid design.So feed this feedback to your VMWare contacts. The more customers complain, the better the chance that VMWare would change their console access behavior. All other hypervisors have a solution for this.Regards SimonPowered by Discourse, best viewed with JavaScript enabled"
437,nvidia-a2-not-being-used-for-computing,"Hi guys,I got a virtual machine running with windows server 2016 (also tried it on win srv 2022) with an nvidia A2 GPU passed through to it. The passthrough of the GPU is working correctly as vmware support confirmed in a remote session.
So the nvidia A2 shows up in my device manager etc. I can see it in GPU Z.
But when I run benchmarks there is no difference between running them with or without the gpu. So it is obviously not doing anything.
Did someone experience similar?I already tried clean installing the driver.Powered by Discourse, best viewed with JavaScript enabled"
438,rtx-8000-windows-2022-server-with-hyper-v,"Hello,
I have 2 x NDIVA Quadro RTX 8000 and a Windows 2022 server with Hyper-V  on a DELL 740
I had to go back with the BIOS and deinstalled the NDIVA driverWhen I try to install again the driver it says: “NDIVA Installer cannot continue”
I would like to use gPU for the virtual Hayper-V machinesAny idea how I can remove the NDIVA and install again?After experimenting and reading the docs I am now on the point that I have 1 NVIDIA RTX 8000 assigned to 1 virtual Win2022 server.PS C:\Windows\system32> Set-VM -LowMemoryMappedIoSpace 2GB -VMName Vtest
PS C:\Windows\system32> Set-VM -HighMemoryMappedIoSpace 48GB -VMName Vtest
PS C:\Windows\system32> Add-VMAssignableDevice -LocationPath “PCIROOT(D7)#PCI(0000)#PCI(0000)” -VMName Vtestthe NVIDIA card is also deactivated on the physical serverIn the virtual machine (remote desktop) in device settings I see 2 display cards
Microsoft Hyper-V Video
NVIDIA Quadro RTX 8000I can open the NVIDIA control panel and see:NVIDIA System Information report created on: 03/07/2022 03:04:50
System name: Vtest[Display]
Operating System:	Windows Server 2022 Standard, 64-bit
DirectX version:	12.0
GPU processor:		Quadro RTX 8000
Driver version:		511.79
Driver Type:		DCH
CUDA Cores:		4608
Core clock:		1620 MHz
Memory data rate:	13.00 Gbps
Memory interface:	384-bit
Memory bandwidth:	624.10 GB/s
Memory type:		GDDR6
Total available graphics memory:	46080 MB
Dedicated video memory:	46080 MB GDDR6
Video BIOS version:	90.02.4E.00.03
IRQ:			Not used
Bus:			PCI Express x16 Gen3
Error Correction Code (ECC):	On
Device Id:		10DE 1E78 13D810DE
Part Number:		G150 0231[Components]nvui.dll		8.17.15.1179		NVIDIA User Experience Driver Component
nvxdplcy.dll		8.17.15.1179		NVIDIA User Experience Driver Component
nvxdbat.dll		8.17.15.1179		NVIDIA User Experience Driver Component
nvxdapix.dll		8.17.15.1179		NVIDIA User Experience Driver Component
NVCPL.DLL		8.17.15.1179		NVIDIA User Experience Driver Component
nvCplUIR.dll		8.1.940.0		NVIDIA Control Panel
nvCplUI.exe		8.1.940.0		NVIDIA Control Panel
nvWSSR.dll		30.0.15.1179		NVIDIA Workstation Server
nvWSS.dll		30.0.15.1179		NVIDIA Workstation Server
nvViTvSR.dll		30.0.15.1179		NVIDIA Video Server
nvViTvS.dll		30.0.15.1179		NVIDIA Video Server
nvLicensingS.dll		6.14.15.1179		NVIDIA Licensing Server
nvDevToolSR.dll		30.0.15.1179		NVIDIA Licensing Server
nvDevToolS.dll		30.0.15.1179		NVIDIA 3D Settings Server
nvDispSR.dll		30.0.15.1179		NVIDIA Display Server
nvDispS.dll		30.0.15.1179		NVIDIA Display Server
NVCUDA64.DLL		30.0.15.1179		NVIDIA CUDA 11.6.110 driver
nvGameSR.dll		30.0.15.1179		NVIDIA 3D Settings Server
nvGameS.dll		30.0.15.1179		NVIDIA 3D Settings ServerWhat to do next to use this grafic card?I tried also a WIN10 as virtual machine.
The NVIDA drivers install correct.
The NVIDA Control Panel shows not all features (I started the program as admin)I used the microsoft documentation and Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software Documentation … no errors, everything looks ok.… but still I can not use the NVIDIA graphic card
09-03-_2022_17-49-051920×1086 171 KB
Hi,
and could you please describe what is not working? How do you know that the GPU is not working? Did you test with Youtube or other applications to see in Taskmanager or with nvidia-smi if there is GPU load? From the screenshots given it looks like it needs to work already as the GPU is properly recognized within the VM.I did just a fresh installation.
No error messages and also the installation of the the NVIDIA driver 511.79 worked fine on a virtual machine with Windows 2022.NVIDIA card is shown correctly under the display adapters.Points that do not work:
11-03-2022_09-41-081138×749 269 KB
I assigned now 48GB of the RTX 8000 to this virtual machine. The RTX Desktop Manager works, but the grafic card is not used …Hi,
unfortunately it doesn’t help if you make assumptions. Please use a tool to check if GPU is working or not. You can use GPUProfiler Releases · JeremyMain/GPUProfiler · GitHub or nvidia-smi which is already installed (command line tool).
You also need to be aware that you need to set a local policy on Server OS to use the GPU for RDP sessions which might be the case here.
And one more thing: Is this a passive cooled RTX8000 or an active one? This really makes a difference as you would need a different driver (vGPU driver) + licenses if running the passive one. This would also explain why it cannot work properly.Thanks for the hint “passive cooled RTX8000”. I bought the server from DELL. I guess I can then buy the soware also from DELL. Is there a test license? Or should the driver from the enterprise area work?
NVIDIA Licensing Portal (here there is a lower driver version)
11-03-2022_13-18-051479×1159 146 KB
Correct, you need the driver from NV licensing portal. As you can see in GPUProfiler, the GPU is running in TCC mode so it is definitely a passive RTX (datacenter GPU) and therefore the public driver is only capable to do compute on Windows. For WDDM support you need the vGPU driver from the NV portal and then it will switch to WDDM mode and should work as expected. You can buy the vApps licenses from Dell (1vApps per CCU running on the RDSH). As you seem to have already access to the portal you should also got a 90 trial automatically…Thank you.
With the vGPU driver from the NV portal it is working. GPU is shown in the taskmanager and in the GPU Profiler tool.One more (basic) question:
I have as a physical server WIN2022 and 2 RTX 8000 with 48 GB.
Let assume I would like to have 8 Virtual machines (WIN2022) using this hardware.
As I understood from the manuals there are 2 ways to use the RTX8000.
a) GPU Pass-Through (this is working now)
b) vGPU (NVIDIA Virtual GPU Manager)With a) I could have 2 VMs (or add more NVIDIA cards) and I could add Terminal licenses to the VM and this way I have 1 VM with 4 different users (and a second VM with the same). Correct?With b) (NVIDIA Virtual GPU (vGPU)) I would have to install Citrix Hypervisor or VMware vSPhere on the physical server, correct?Thank youCorrect. vGPU only works with VMWare/Citrix or KVM as hypervisor.Powered by Discourse, best viewed with JavaScript enabled"
439,tesla-t4-gpu-with-windows-server-2019,"Hello
I have a windows server 2019 with NVIDIA Tesla T4 GPU
but I am not able to get GPU work via RDP unfortunately
I have enabled everything mentioned in this article :This article discusses how to allow the use of GPU rendering during a Remote Desktop session by modifying the group policy on the host computer.
but still not working
I hope you help me
thank youHiI’m assuming you’ve licensed the GPU and are using the correct vGPU driver. Which hypervisor are you using and which vGPU Profile have you allocated?You’ll want to change Protocol to a better one, RDP isn’t sufficient. PCoIP, HDX, Blast, TGX, RGS or another high-end Protocol.This is a better guide to getting started: Quick Start Guide :: NVIDIA Virtual GPU Software Documentation More advanced / complete documentation is available if needed on the same Site.Hope that helpsRegardsMGHi,Same question here but with an A30 on Windows Server 2016. I don’t want nor have any virtualization software. But I just want Hardware acceleration to be accessible via RDP session as mentionned in the link of sales5 and as I was doing with a previous GeForce GPU.
Why do you talk about vGPU?Manu thanks,No way with A30. This GPU is not meant for WDDM. Only supports TCC (Compute).regards
SimonHello,
I have similar question about Windows Server 2019 with Tesla T4. The PC contains Tesla T4 and Matrox G200e (on-board) only.
When I use Tesla T4 by WDDM mode via Microsoft Remote Desktop, do I need a virtual machine such as VMware or Microsoft Hyper-V, not only GRID license?
Regards
IchiroPowered by Discourse, best viewed with JavaScript enabled"
440,fedora-33-root-exec-systemctl-suspend-no-longer-works,"Hello Friends:As of yesterday, after performing a “sudo dnf -y update” on my Fedora-33 machines, I’ve been having all kinds of suspend and resume problems, which vary depending on the laptop model and therefore on the nVidia card.Let’s start with just on laptop. On a ASUS g750 laptop, with the below card, suspending the O/S no longer works (but did for many years):user$ sudo lspci | grep -i nvidia # Show card information.
01:00.0 VGA compatible controller: NVIDIA Corporation GK104M [GeForce GTX 780M] (rev a1)
01:00.1 Audio device: NVIDIA Corporation GK104 HDMI Audio Controller (rev a1)Now, when I issue, “root# exec systemctl suspend” (which worked for years), the O/S starts to suspend, with the screen even going off momentarily, but then comes right back.I put more information about this problem here:Any ideas? Thank you in advance.Powered by Discourse, best viewed with JavaScript enabled"
441,nvidia-tesla-m10-license-with-physical-windows-server,"Dears,
I’m actually asking for the required license (Grid) for Nvidia Tesla M10 installed on physical Dell Server with windows server 2019 standard. there is no virtualization, just physical server.
So, what is the required Grid License?You need vApps licensing. Please check our licensing and packaging guide. It doesn’t matter if you use baremetal, PT or vGPU, as long as you need the WDDM support for Windows on datacenter GPUs, you need to use the vGPU drivers.Hi Sschaber,
thanks a lot for your reply. I got the application that would be used with this card which is “La Semaforica S.r.l. and TECSEN deal with traffic regulation and the development of ITS systems for Smart Mobility applications”
So, kindly advice with the required NVidia License and Windows server edition standard or data center?
Also, what if there is no virtualization. the end user will use the card directly from the server. is the license differ from paremetal or virtualization?vApps license should be sufficient. Windows Server Standard or DC is independent from our driver. You can choose what you prefer.Dear Sschaber,
I founded the following"" In a bare-metal deployment, you can use NVIDIA vGPU software graphics drivers with Quadro vDWS and GRID Virtual Applications licenses to deliver remote virtual desktops and applications. If you intend to use Tesla boards without a hypervisor for this purpose, use NVIDIA vGPU software graphics drivers, not other NVIDIA drivers.""Documentation for administrators that explains how to install and configure NVIDIA Virtual GPU manager, configure virtual GPU software in pass-through mode, and install drivers on guest operating systems.As per this document, If no hypervisor, there is no need for any vGPU license? or must be license even no hypervisor?If you intend to use Tesla boards without a hypervisor for this purpose, use NVIDIA vGPU software graphics drivers, not other NVIDIA driversI don’t get your point. You highlight a sentence that exactly describes that you need the vGPU software. And vGPU software means vGPU licensing in order to do so.
So please believe me that you need the vApps licensing for your use case!Dear Sschaber,
thanks a lot for your reply. I think I got the your message which is"" we must have vGPU License + GPU Driver either paremetal and virtual environment"".
if the application is 3D rendering or 3D visualization, I think the  Quadro vWS license is the optimum.Powered by Discourse, best viewed with JavaScript enabled"
442,putting-best-foot-forward,"Hi all - forgive me if this has all been asked and answered - I did try looking!Scenario:-
vSphere 6.0U3 and above across a number of hosts.
Horizon View 7.x
RDSH Windows 2012 and above (being migrated over time to 2019)
HP based site
RDSH sessions accessed through View Client and a little BLAST.
1800-ish users of which around 1,000 are on at any time.The vast majority of users are ‘Knowledge Users’ - so Email, Office, bit of web usage etc.This system operates for 90%+ of users just fine and we can manage/maintain/deploy etc etc all fine and dandy.Here comes the question :-)We’ve been struggling with the last 10%-ish of users in terms of GPU access. We don’t have ‘high-end’ CAD users but the occasional user wants to use mapping software, or someone else may want to make a promotional video or some-such, so, we’ve begun dipping our toes into NVIDIA GPU world…And struggling to be honest!I think we’re at the point where we have two options…M10s for ‘everyone’ (I believe these offer maximum density and whilst they are fine at the moment we need to consider moving forwards) and T4s for the more ‘power users’.I understand that we need to licence the software (vPC stuff?) per CCU - so in our instance would we need 1,800 licences or 1,000?I’ve been reading about core count vs clock speed - Am I correct in assuming that anything over 3.0GHz base (not turbo) should be just fine?What’s really confusing us is the relationship between the Physical Hosts, the virtual Windows Server 201x RDSH hosts (more than one per physical host) and the actual sessions people connect to (many per virtual 201x host). For example we have a pool of 522 users spread across 35 virtual Windows Server 201x guests on 9 physical hosts.In addition the same hosts support a (small-ish) number of ‘real’ VM’s for people who have ‘wonky stuff’ to run :-)My further understanding is that a Vib is needed within vSphere/ESX and that driver software is needed on the RDSH guests - is this correct?Does anyone have any thoughts/recommendations for pointing us in a direction of travel that means we can get to where we need to be - supporting the 90% people to have a ‘better’ experience and future proofing us and allowing the 10% of people actually do what they need to do?I hope this is enough information - if not, ask and I’ll get what you need!Many thanks in advancePatHey PatFirstly, before you do anything hardware related, check over the application requirements to see how it uses the resources. It may be able to use multiple Cores, it may put more emphasis on the GPU or it may just want a single high speed core, or a bit of everything. If you can’t find it in the system requirements documentation, contact the software vendor and ask them directly, you can then look at appropriate hardware to support it.If the application is single thread limited, then yes, to make life much easier for yourself, focus on the base Clock and forget Turbo. It’s obviously possible to get Turbo to work in a virtualised environment, but there are many hoops to jump through, and to be honest, it’s not worth the hassle. Then you’re into Single Core Boost vs All Core Boost (they have different levels of Boost depending on how many Cores Boost at the same time, and this is dependant on all sorts of variables as well) and trying to keep them engaged so you don’t get peaky performance, it’s just a real pain to work with when virtualising and it’s far easier just to opt for a high Base Clock from the start and not have to worry about it. For CAD applications that are predominantly single threaded, 3.0Ghz would be the minimum I’d work with whilst maintaining a balance vs Cores. For example, there are Xeons that have a higher base Clock, but you’re compromised on Core count. The best balance at the moment is the Gen 2 Scalable Xeon Gold 6254, which is 18 Cores @ 3.1Ghz. You can obviously trade up or down (Core vs Clock) depending on your requirements, but this is the sweet spot in my opinion.Regarding vGPU Licensing … It’s really simple … vApps, vPC, QvDWS are all licensed Per CCU. So if you have 1800 users, but only 1000 connect to the platform at any one time, then you only need 1000 licenses. As for the type of license, if you’re running RDSH you’ll want vApps, for your normal single user Windows VMs, you’ll need vPC and for your 3D Workstations you’ll potentially want QvDWS depending on the application requirements. All of those are Per CCU.Honestly … Forget the M10 at this stage. You can absolutely still buy it and it will be supported, but unless you already have them and are looking to scale out an already existing M10 deployment, give them a miss at this stage. They’re superseded 3 times architecture wise and are lacking in features and functionality compared to the current generation. From what you’ve said above about the majority of your user base being Knowledge Workers (Now referred to as ""Digital Workers"") and that you don’t have any high-end CAD users, you should be looking at T4s for all of your workloads. You can use the same model of GPU, but use the Profiles to allow different amounts of performance, for example:RDSH VMs will use the T4-8A and you’ll have 2 of those per T4.Single User VMs will have either the T4-1B or T4-2B depending on your requirements, and you’ll have 8 or 16 of those per T4.3D Single User VMs ""could"" have T4-4Q and you’ll have 4 of those per T4.You mention HP above (I’m assuming this is your server platform), but don’t mention what your server hardware or generation is (DL380 Gx … ?). If you were planning on purchasing completely new HP hardware, then you can speak to your partner about the appropriate configuration, if retro fitting GPUs into existing servers, firstly make sure they’re supported, the BIOS and Firmware are fully updated, then purchase appropriate PSUs, PCIe Risers, GPU Enablement Kits (low profile heatsink for CPUs, and GPU power cables if needed) and potentially high-performance fans and also the GPUs. When working with vGPU, it’s important to have an up to date software stack, this includes Hypervisor, Management (vCenter in your case), Operating System and vGPU Drivers. This prevents a lot of issues and allows the best performance and functionality. Before proceeding with vGPU, you need to check your licensing situation. For VMware, at a minimum you’ll want vCenter Standard and vSphere Enterprise and ideally, you’ll be running 6.7U3.Before setting up vGPU, make sure you get your vGPU License Server built and then vGPU licenses ordered through your Partner. Licenses can sometimes take up to 24hrs to arrive in your NVIDIA Portal, so best to get that kicked off from the start as your vGPUs have very limited (unusable) performance until licensed.As per your question, the vGPU software comes in two parts. A .vib is required to be installed in each physical vSphere Host that will be running vGPU (this is referred to as the vGPU Manager), this will allow you to allocate vGPU profiles to your VMs through vCenter. The second part is a driver that goes inside the Windows / Linux OS.Regarding configuration, it’s relatively strait forward with some extremely basic maths to workout approximate user capacity per VM as a ballpark number to aim for pending a POC where you can firm things up. These are very general guidelines, and there are a lot of variables to consider, but on average, you should be aiming for 20 - 25 concurrent users per vGPU enabled RDSH VM (sometimes it’s slightly more, sometimes it’s slightly less), and 2 VMs per T4. This is really going to depend on your applications, how the users use those applications, platform and system hardware including hardware generations and overall optimisations etc etc. If we take the lower of those two numbers (which combined is 40 (2 VMs each with 20 users)) as a working number, we can workout how many GPUs we’ll need to support 1000 concurrent users, and by default, how may servers we’ll need to support X number of GPUs.1000 (Users) / 40 (Users Per GPU) = 25 (GPUs Required)(This bit would be handy to know your server hardware and generation, so I’m just going to use the current Gen10 …)HP DL380 G10 will support 5 T4 GPUs ( Qualified System Catalog | NVIDIA ).25 (GPUs) / 5 (The capacity of a DL380 G10) = 5 (DL380 G10 each with 5 T4 GPUs, each supporting 40 users)So what this means, is that if you’re able to support 20 users per RDSH VM, and get 2 of those on 1 T4, then you’ll want 25 T4 GPUs, and 5 DL380 G10 servers to support it.This scales up / down either way. If you can get 25 users on a VM, that’s 50 users per T4, long story short, you only need 4 DL380s instead of 5. If you can only get 4 T4s in your existing server hardware, then you’re going to need more DL380s etc etc … And don’t forget your N+1 for resilience and maintenance windows, or every time you want to work on a Host, you’ll be doing it out of hours, or removing it from service and impacting your total usable capacity … ;-)FYI, your limiting factor will be vGPU Framebuffer, as you’ll split the T4 into 2 8GB vGPU Profiles and run the RDSH VMs with 8GB, and you’ll be using the T4-8A vGPU Profile.Now, as you’ll also have single user desktop VMs, as well as your 3D Workstation VMs, what I would do is run all of your RDSH VMs in a dedicated vSphere Cluster, that way there are no vGPU Profile issues and it makes scaling, migration and management really easy. Then create a second vSphere Cluster for your single user VMs that have a different vGPU Profile (Probably T4-2B), and depending on how many 3D Workstations you need you may even want a 3rd vSphere Cluster to support that vGPU Profile. It is possible to manage that from a single Cluster using the breadth first / depth first configuration settings in vCenter (Performance vs Density), and if you wanted to do that, you’d be constantly running in ""Density"" mode, so up to you how you’d like to configure it.The reason it can be better to split out the vGPU Profiles into dedicated Clusters, is that you can’t mix Profiles on the same physical GPU. So if a VM with a particular profile starts up on a GPU, only other VMs with the same Profile can use that specific GPU. Despite a lot of customer frustration, this does make sense. For example, a vPC workload assumes a different workload to QvDWS or vApps, so why would you run those on the same GPU, or in some instances, even the same physical server? We also need to remember, that this isn’t about cramming as many users onto a single physical server as is humanly possible, this is about giving the best user experience whilst still delivering a cost effective solution. If anyone wants to cram users on to the platform to the detriment of the user experience, then simply remove the GPU from the system altogether and you can do just that.Right, I’ve rattled on for long enough. I hope at least some of that is useful. As said, recalculate some of those numbers and apply what’s useful to your own environment and hardware. Let me know if you’d like more detail about anything …RegardsMGMGThanks so much for the information - helps massively.HP…yes we have a mix HP DL380 Gen9 and Gen 8 … ideally I’d be looking to get the budget for a number of new machines and buy brand new completely configured HP Gen10’s with 5 T4’s each as that seems to be the sweet spot.We currently have 0 GPU offering for our users and a handful are ‘not very happy’ (to quote you, above, ‘If anyone wants to cram users on to the platform to the detriment of the user experience, then simply remove the GPU from the system altogether and you can do just that.’) - that’s pretty much where we are.For the VAST majority of users what we’ve given them is just fine, but as we’ve been rolling out we’ve been putting ‘problem use cases’ to the end, and, well we’re pretty close to the end and have to revist the last 10%!if I could get the budget for at least two machines (we have two sites) then, from the above, I should be able to get in the order of 40 users happy.From what you’ve said above though it sounds like I should be pushing for four machines - 2 for an RDSH ‘Cluster’ of 2019 (for 2 sites) that will support 40-ish users and a further 2 for dedicated VMs with, again, 40 (or 80 depending on config) per machine.There are no 3D users as such, just planners who like complicated maps … I will try to gain more info on the spec of the machines they would expect to run on non-virtually.Is there a URL of which you are aware that explains these vGPU profiles?Oh I meant to say - it’s all on Nimble Flash storage (which is good :-) )Seriously, thank you again.PatHi PatNo worries, glad the info is usefulWhen designing each cluster, try and keep the server hardware as similar as possible (ideally identical) as this keeps performance, functionality and density the same no matter which VM the users connect to.Use the numbers I’ve mentioned above as a guide to get started, your best bet would be to work with your technology supplier and get a DL380 Gen10 on evaluation, run a small POC on it with each type of VM and work out which specs of each are correct for you, then reconfigure it and purchase accordingly.The main vGPU Documentation Site is available here: NVIDIA Virtual GPU (vGPU) Software DocumentationThe current release is vGPU 10.1. If you select that, it will open up all the documentation for that specific version. The document you’re looking for with all the vGPU Profiles is called “Virtual GPU Software User Guide”. Open that and scroll down a few pages and you’ll see all the Profiles listed in a few big tables.If you’re looking at physical workstation specs, it’s well worth doing a little monitoring to check utilisation to make sure you cover off any unforeseen requirements. This is my favourite monitoring software: Releases · JeremyMain/GPUProfiler · GitHub It’s free to use and will give you plenty of accurate metrics to work with.To save you a bit of troubleshooting, when you GPU enable your RDSH VMs, you must set this GPO for them, otherwise the RDSH VMs won’t use the GPU:Computer Configuration\Administrative Templates\Windows Components\Remote Desktop Services\Remote Desktop Session Host\Remote Session Environment: Use the hardware default graphics adapters for all Remote Desktop Services sessionsNice work with the All Flash! That’ll definitely help with performance and user experience!Let me know if you have any questions on the vGPU ProfilesRegardsMGPowered by Discourse, best viewed with JavaScript enabled"
443,unified-memory-support-on-vgpu,"I hired one of A100 equipped VM from vultr. It appears to be partitioned temporally,  but it failed to run UnifiedMemoryPerf from official CUDA demo suite.Exception threw at unified memory allocation.Please clarify the availability of unified memory with vGPU.Powered by Discourse, best viewed with JavaScript enabled"
444,heterogenous-vgpu-profiles-on-two-nodes-of-a-vmware-cluster,"Hello Team,Two node VMware Cluster. Each node has single A100 cards. Running MIG on each host. Install ESX 7.0 UPdate 2. Since the process for creating GPU Instances and Compute instances is now  automated with vSphere 7 Update 2 and later, so created  2 VM  with 3g,20GB profile on one host and 3VM with 2g.10gb on another Host. Live migration doesn’t work . Getting error as ""one or more devices (pcipassthru0) required by vm xx-xxx are not available on host xx.xx.xx.xx.Is this supported to have different vGPU profiles on different nodes in Cluster? is the above design valid
If yes, any specific rule to follow.
Any suggestion for the error messageLive migration doesn’t workI realize this is an aging post.   Live migration is not supported among differing hardware/vGPU profile types.Powered by Discourse, best viewed with JavaScript enabled"
445,nvidia-docker-decoder-and-cuda-function-performance-issue-on-multiple-cards,"Dear Guys,There is a nvidia docker decoder and cuda function performance issue on mutiple cards we have meet. We have test on Tesla T4 cards. We used 2 cards on one server to test. At beginning, we just use nvidia docker work on cenos 7, we found that when we use 2 cards working at the same time, the performance reduced almost to half. Then we use vmware to create 2 virtual machines on one server with gpu passthrough technology, each vm bound with one card, the result show each card arrive it’s best performance.The test case and snaps as follow:The program we use nvidia Video_Codec_SDK_11.1.5 to decode , then we write cuda code transform nv12 to bgr:
bool CudaSyncData::DevDataSyncDev(void *dst, int dst_width, int dst_height, void *src, int src_width, int src_height)
{
cuCtxPushCurrent(context);
void *bgr_ptr = nullptr;
if (src_width == dst_width && src_height == dst_height)
{
bgr_ptr = dst;
}
else
{
AI_Log(“CudaSyncData”, KLERROR, “not support width or height covert!please input the same width height”);
return false;
}
Nv12ToBGR(bgr_ptr, src, src_width, src_height);}cuframe_convet.cu
#include <cuda_runtime_api.h>
#include “cuframe_convert.h”const auto THREADS_PER_BLOCK_1D = 16u;
const auto CUDA_NUM_THREADS = 512u;unsigned int GetNumberCudaBlocks(const unsigned int totalRequired,
const unsigned int numberCudaThreads = CUDA_NUM_THREADS)
{
return (totalRequired + numberCudaThreads - 1) / numberCudaThreads;
}global void YCrCb2RBG(unsigned charpYdata,unsigned char pUVdata,int stepY,int stepUV,unsigned char* pImgData,int width,int height,int channels)
{
const int tidx = blockIdx.x * blockDim.x + threadIdx.x;
const int tidy = blockIdx.y * blockDim.y + threadIdx.y;}void Nv12ToBGR(uint8_t* bgr, uint8_t* nv12, int width, int height)
{}we just run one docker container on one gpu card.we put 30 channels of rtsp video to test, the performance is good. we can get valid picture from the program, the fps kept on more than 25.
then we run one docker container with 2 gpu cards to test. we put 60 channels of rtsp video to test, the result reduce to half
after that , we run two docker containers with 2 gpu cards, each container bound each card. we put 60 channels of rtsp video to test. we make sure that each container have 30 channels. the result is the same as on docker container with 2 cards.so we think the container can’t isolate the gpu card very well, then we use vmware to test.we created 2 virtual machines to test. we passthrough 2 cards to each machine.then run one container in each vm.The performance is well, each card is the same as the first case.as the result, we don’t know what’s wrong with the nvidia dockerthe environment:
os: centos 7
nvidia vga driver: 460.73.1
nvidia docker: 2.11.0 docker: 20.10.21
nvidia container runtime version 1.11.0docker run commond:
docker run --runtime=nvidia -p 25000:8087 --name=$CONTAINER_NAME -d --cap-add=SYS_PTRACE --security-opt seccomp=unconfined 
-e NVIDIA_DRIVER_CAPABILITIES=video,compute,utility 
-e EurekaClientEnable=false 
-e NVIDIA_VISIBLE_DEVICES=0 
-e EurekaInstancePort=8087 
-e EurekaInstanceHeartRate=30 
-v /etc/localtime:/etc/localtime:ro 
-v /data/syl/serial/:/root/koala/osmagic/serial 
$IMAGE_NAME
docker logs -f $CONTAINER_NAMEPowered by Discourse, best viewed with JavaScript enabled"
446,nvidia-grid-m40-driver-for-windows,"HiI was wondering if there is a Driver for the GRID M40 for windows.
I understand Vdi is not possible but i wanted to use the card for compute for encoding h.264ThanksI have tried every driver, There is a driver that works there was a seller on ebay who had a screenshot of the M40 being used in Windows. God knows which version though i tried to message with no luck.Yes the ignorance of Nvidia repeatedly saying there is no such card, The card works in Linux with standard drivers for Compute I’m in the process of install CentOS to see.Great card for compute on paper, Low power draw quad gpu in a dual slot form factor. Has great potential for Video Encoding IMO.I agree with the above and thanks for the effort although at less than 50% the cost of the others listed it offers great value (I got it for $400us), Also max power draw under compute is 130w Total as documented at STH.Also the encoder we use is a little different to NVENCODE, There are effects that utilise cuda and Resolve scales well with multi gpu.Card is working on CentOS with Nvidia Drivers. Resolve is seeing all 4 cards.Now to get windows compute drivers??The M40 was never released as a board with supported drivers for GRID or encode. Sometimes we issue not-for-resale samples to OEMs to evaluate cards for certain uses with development drivers. Those third-parties are contracted not to resell such prototypes.Hi!
And What what Windows OS was used for that Drivers?My Windows 10 Pro 1903 is unsupported(((Powered by Discourse, best viewed with JavaScript enabled"
447,tesla-m10-32gb-with-esxi-setup-question,"Hello,I have purchased a Dell730XD with two 14 core CPUs with a lot of RAM and SSD space.  My desire is to create a group of gaming servers.  I must use one Windows host per server and am using ESXi.  I was planning on buying a Tesla M10 w/ 32GB next week.  My worry is doing the setup wrong and wasting a lot of money.To start with, the setup document states that you need to install ""Horizon"".Setup Doc…4.15 MBThe cost of the cheapest Horizon version is $3100.  Is this NEEDED to get virtualization?  That is a LOT of money.  What are my options outside of using Horizon?  Is what I am trying to do even possible without Horizon?I appreciate your time reading my post, thank you.Cheers,
PetePowered by Discourse, best viewed with JavaScript enabled"
448,about-upgrade-nvidia-rtx-virtual-workstation-winserver-2019-on-amazon,"Hi,I’ve received an update notification for subscription to NVIDIA RTX Virtual Workstation - WinServer 2019 on AWS.Could you please inform how to upgrade existing Windows instances?
Should i need to create a fresh instance to get upgraded one?Thanks in advance,Powered by Discourse, best viewed with JavaScript enabled"
449,no-hardware-decoding-on-youtube-with-m10,"Hi guysWhile I’m working on a virtual desktop with Windows 10 and Horizon 7.10 I run ""nvidia-smi vgpu -es"" on the ESXi and all I see are blank lines.What’s it like there?In the Nvidia vgpu user guide the example looks like thisShouldn’t there be a codec or a percentage in the decoders?Do you know a good site where these codecs are described in connection with VDI?Best regardsPowered by Discourse, best viewed with JavaScript enabled"
450,nvfbc-spurious-failures-in-nvfbccreatecapturesession,"Video capture software we’re working on is failing about 5-10% of the time when creating the capture session, and we’re at a loss for how to proceed debugging it.Context
For context, our video capture code uses the newer API with NVFBC v8.0.4 to capture to GL. We then pass the captured frames to NVENC and handle the h264-encoded frames ourselves. Our program is multithreaded, with a main thread and separate threads for video and audio capture. Our NVFBC implementation is almost verbatim from NvFBCToGLEnc.c from the samples included with the latest NVIDIA Capture SDK. We run this on EC2 instances in AWS that are running Linux 5.4 with Ubuntu 20.04.We’ve tried this on pretty much every valid combination of the following, with identical results:Issue
Under certain conditions (resolution updates, for example), we need the capture session to update to the new state. NVFBC should automatically take care of this, but oftentimes it would hang for 10-12 seconds before returning with an error string vkCreateDevice failed: -3 or -4 (that’s VK_ERROR_INITIALIZATION_FAILED or VK_ERROR_DEVICE_LOST).We tried circumventing this issue by destroying the capture session, updating the resolution, and then recreating the capture session, but still got this spurious failure – now the session creation nvFBCCreateCaptureSession sometimes hangs for 10-12 seconds before failing with vkCreateDevice failed: -3/-4.To reduce the problem to its simplest state, we now create a capture session, capture a few frames, and destroy the capture session in a loop, with no resolution resizing. (Here’s a very hacky example modified from NvFBCToGLEnc.c: nvfbc_loop.c - Pastebin.com – build it according to the makefile from the Capture SDK samples.). When we run this code directly, the capture session is repeatedly recreated with no problems at all (even running it at a rapid pace for up to 20 minutes!).However, when we run this code in the video thread of our program, while leaving the rest of the program (main thread, audio thread, etc.) alive, then we start to see the spurious failures again, sometimes even on the first creation!This could suggest that there’s something that we’re not understanding about running NVFBC in multithreaded applications, even though the documentation says it should be perfectly safe.I’d really appreciate pointers for how to proceed debugging this, as we’re at the end of our wits here. It’s especially annoying because we can test something successfully 5 or 6 times in a row, and then get our hearts broken by the error on the next run </3Happy to provide any additional information that would be helpful. Thanks!Powered by Discourse, best viewed with JavaScript enabled"
451,horizon-rdsh-density,"We currently have a Horizon RDSH farm that supports ~800 CCU. There are 32 servers across 2 cloud pods to accommodate the ~800 CCU at ~25 users per virtual server. The current environment runs ok and there are no graphics cards. We decided that we would venture into testing some vGPU in different use cases so we bought 8 new Cisco UCS B200 M5 blades with 2 x I6248R CPU, 512GB of RAM and a single P6 in each blade. All blades are connected to a Pure x70 all flash array.My question is, would it be possible to run the same ~800 CCU RDSH farm on these new blades and if so what would be feasible profiles for the P6s? Do we build the same number of servers and assign them the 4A profile or can we get by with a 2A or 1A profile given that the current environment doesn’t have graphics at all?Since we are new to this and bought this setup for testing purposes for various applications I am just curious if it is possible to run our largest farm with vGPU and maintain our user density.Hi ADTThe B200 M5 supports 2x P6 GPUs and it’s worth running that configuration so you can maximise the density. You should be looking at either 8A or 16A vGPU Profiles meaning that with 2x P6 installed, you’ll have 2x (16A) or 4x (8A) RDSH VMs per Blade. Don’t use anything less than 8A with RDSH VMs in a production environment.The following link is targeted at Citrix XenApp, but it relates directly to your use case as well. Have a read all the way through, as I believe you’ll find the information useful in understanding what kind of configurations to go for and the pitfalls of sizing the vGPU Profiles incorrectly: https://gridforums.nvidia.com/default/topic/10042/xenapp/looking-for-advice-on-optimal-config-for-latest-gen-citrix-xenapp-vgpu-solution/RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
452,help-with-generating-random-ints,"I am just learning CUDA. Trying to learn curand. I need to be able to call random int of a designated range many times in 1 CUDA thread but no need to store them or return them to host. They can be discarded after use. For example I may need to have a random int 1-25 and then do some things then have another 1. I may need to do this thousands of times in that thread but I don’t need to store those numbers. I only ever need 1 at a time and when it’s used I can toss it and get the next one. Can anyone tell me if this is even possible onboard the device and how to do it please? I am using C++ btw.Powered by Discourse, best viewed with JavaScript enabled"
453,mix-license-on-single-rtx-card-6000,"Dear All,I plan to setup VDI system with vmware horizon for 30 users (5 for design and 25 for normal office). I use single RTX 6000 card, so can i buy 5 vWDS and 25 vPC for license mixing? If can not mix license like that, I have to mix type of cards on same server (1 RTX card for vWDS and 1 M10 card for vPC)?Thank You for your help!HiYou can’t mix licenses / profiles on the same GPU. So run your high-end users on a single RTX 6000 and your other users on a more appropriate GPU, maybe an M10 or 2x T4.RegardsMGDear Sir,Thank for your responding. So that mean we can mix 2 type of physical card on the same server? Or have to install 2 same cards on same server then assign license (vPC, vDWS) to each card?HiYou should be installing the same type of GPU in a single server. Mixing different types of GPU in the same server is not supported.You can run different vGPU license types for each GPU within the same server. For example, the first GPU could run RTX vWS (formerly QvDWS). The second GPU could run vPC, and so on … depending on how many GPUs are installed.However, this design is still not optimal, as high-end users and standard users require different types of CPU and other technologies due to their workloads, so bundling mixed workloads on the same server is definitely sub-optimal, however it is clearly possible. If budget allows, the workloads should be split out to run on more focused types of hardware.Hope that makes sense.RegardsMGDear Support Team,Thank your very much for your supporting.Powered by Discourse, best viewed with JavaScript enabled"
454,memory-usage-question,"helloI have ESXi 6.7 and run ubuntu 18.04
there have a question is
when I usage NVIDIA-SMI show memory-usage in ubuntu
the usage don’t match processes’s gpu usagelike pic
https://imgur.com/O4AqhcnI don’t have any processes running
but there have a 528M memory-usage
why ?

20200818_002.png790×303 9.54 KB
Powered by Discourse, best viewed with JavaScript enabled"
455,what-software-to-use-for-our-new-single-nvidia-t4-tesla-card-on-vmware-6-7-esxi-host,"Hi there, I am installing and configuring a NVIDIA T4 Tesla card on our new CCTV infrastructure using VMWare ESXi 6.7.
The problem is neither the CCTV software vendor Briefcam or Dell/VMware cant tell me what NVidia software option/license to setup. The CCTV software is being installed on 1 Virtual server (Server 2019) and it wants to see 1 GPU per process as follows.Review GPUs	0.3
Research GPUs	0.6
Respond GPUs	0.7Can anyone say if the best option would be the NVIDIA Virtual Compute Server software  or NVIDIA GRID? Please keep inmind this is not for virtual desktops, its for vGPU presentation to this Briefcam software processes.HiThe easiest option is download a vGPU Evaluation so you can try the different features for yourself. This is free for 90 days.Deliver Graphics Acceleration to Virtualization.RegardsMGYeah cheers I got that, I’m waiting for account clearance to download. I’m a bit surprised this is still somewhat uncharted grounds and no ""experts"" can advise a definitive course of action/software to use.HiIt’s not that it’s uncharted grounds, it’s that software has different requirements depending on it’s purpose, and as you have 3 different bits of software that undoubtedly do different things (especially in a modern CCTV system), they may all have different requirements, so the easiest thing to do is validate exactly what you need with a quick Eval.Are you Training? Inferencing? Rendering? All of them?If you’re rendering or want accelerated video then you may want QvDWS. If you’re only Inferencing / Training then vCS will be fine. Budget for QvDWS (as that covers all license options), but if you can get away with vCS in the Eval then go for that.RegardsMGHi MG, its hard to get any specifics from the software vendor, here is the detail from their website.::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
The BriefCam Processing Server requires an NVIDIA GPU to process video. The exact model and amount of GPU cards required will depend on the requirements of the resolution of video to be processed along with the number of hours of video to process per day.For a system with a large video processing requirement, multiple GPUs can be installed in each processing server, as well as the ability to utilize multiple processing servers simultaneously.Each GPU installed in the BriefCam server must be assigned to process video in a specific processing mode, either for on-demand processing (REVIEW and RESEARCH modules) or for real-time processing (RESPOND module), a single GPU cannot process video both real-time and on-demand.
:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::We are using 1 Virtual machine (server 2019) sitting on 1 VMware Host Dell VxRail V570 with 1 Tesla T4 card. Trying to alocate an individual vGPU per process of the 3 porcesses.I have created an account to download the trial software.
Downloaded NVIDIA-GRID-vSphere-6.7-430.99-432.44, and NVIDIA-ls-Windows-2020.05.0.28406365 (for license server).
I have installed the follwing VIB NVIDIA-VMware-430.99-1OEM.670.0.0.8169922.x86_64.vib on the ESXi 6.7 Host after a successful install, reboot then running the command nvidia-smi I dont see any vGPU’s listed…!Oh the output from the nvidia-smi command is:[root@vxesxi5:~] nvidia-smi
NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.MG, I tried a reinstall of the driver, made no change, then listed the vibs installed, so the driver is installed. See below.[root@vxesxi5:~] esxcli software vib install -v /tmp/NVIDIA_bootbank_NVIDIA-VMware_ESXi_6.7_Host_Driver_430.99-1OEM.670.0.0.8169922.vib
Installation Result
Message: Host is not changed.
Reboot Required: false
VIBs Installed:
VIBs Removed:
VIBs Skipped: NVIDIA_bootbank_NVIDIA-VMware_ESXi_6.7_Host_Driver_430.99-1OEM.670.0.0.8169922
[root@vxesxi5:~] esxcli software vib list
Name                                Version                               Vendor  Acceptance Level  Install Datebnxtnet                             214.0.230.0-1OEM.670.0.0.8169922      BCM     VMwareCertified   2020-06-10
bnxtroce                            214.0.187.0-1OEM.670.0.0.8169922      BCM     VMwareCertified   2020-06-10
dellptagent                         1.9.4-41                              DEL     VMwareAccepted    2020-06-10
dcism                               3.4.1.ESXi6-1818                      Dell    VMwareAccepted    2020-06-10
lpfc                                12.2.373.1-1OEM.670.0.0.8169922       EMU     VMwareCertified   2020-06-10
i40en                               1.8.6-1OEM.670.0.0.8169922            INT     VMwareCertified   2020-06-10
igbn                                1.4.10-1OEM.670.0.0.8169922           INT     VMwareCertified   2020-06-10
ixgben                              1.7.17-1OEM.670.0.0.8169922           INT     VMwareCertified   2020-06-10
nmlx5-core                          4.17.15.16-1OEM.670.0.0.8169922       MEL     VMwareCertified   2020-06-10
nmlx5-rdma                          4.17.15.16-1OEM.670.0.0.8169922       MEL     VMwareCertified   2020-06-10
NVIDIA-VMware_ESXi_6.7_Host_Driver  430.99-1OEM.670.0.0.8169922           NVIDIA  VMwareAccepted    2020-07-06Just FYI I follwed this process:
I disabled the passthrough setting in ESXi Host by PCI-Devices.
I change with vSphere Web Client the Settings for the Host Graphics and Graphics Devices to shared direct.
Restart the ESXi Host. It seems to have goten the card to show up.[root@vxesxi5:~] nvidia-smi
Tue Jul  7 00:54:46 2020
±----------------------------------------------------------------------------+
| NVIDIA-SMI 430.99       Driver Version: 430.99       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:3B:00.0 Off |                    0 |
| N/A   42C    P8    17W /  70W |     75MiB / 15359MiB |      0%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+
[root@vxesxi5:~] vmkload_mod -l | grep nvidia
nvidia                         13    18176I can now add ""a"" GRID vGPU, I chose the GRID_T4-16C profile.When trying to add a second vGPU I am unable to add more than 1 to the one VM, it states I should be able to add up to 4 vGPU’s to the one VM. I just get the error: The maximum number of devices of this type has been reached, what am I doing wrong?You’re funny man. Add more GPUs. How do you want to add multiple T4s if you have only 1 physical GPU present?Hi SSDGood progress so far, nice work getting it up and running :-)Yes, within vCenter you need to change to ""Shared Direct"" for vGPU to be enabled, the other setting is for Passthrough which you aren’t using in this instance. This is a ""Per Host"" setting, not ""Per Cluster"", so you’ll need to set it on all VX Nodes that have a GPU in.Regarding vGPU Profiles, the number in the Profile equates to Framebuffer. 1 = 1GB / 2 = 2GB / 4 = 4GB / 8 = 8GB / 16 = 16GB. Other GPUs can go higher as they have more Framebuffer (24 / 32 / 40 / 48).With vGPU, you hard allocate the framebuffer per VM, but share the GPU processing / encoding / decoding cycles between VMs. What this means is that if you want to run 4 VMs at the same time, the maximum Profile size you can use with a 16GB GPU is 4GB. In case you aren’t aware, detailed documentation is available from here: NVIDIA Virtual GPU (vGPU) Software Documentation The vGPU Software User Guide lists all the available Profiles per GPU (as well as other information) and is worth having a read through: Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software DocumentationWhat I would do in this instance, is start off with a well spec’d VM. Give it 8 vCPUs, 16GB (System) RAM and a 16Q vGPU Profile (Quadro, not Compute) at this stage and run each of the applications independently (1 VM at a time as it’s a 16GB Profile) to build up an understanding of how the application uses the hardware and what kind of resources it needs. Using the ""Q"" Profile means that you’re enabling all of the GPUs features and performance and as you’ll only be testing 1 VM at a time, you can allocate all of the Framebuffer. Once the Application is working and you are happy with performance and have tailored the resources (CPU / RAM / GPU Framebuffer), you can then change the GPUs Profile to a ""C"" and run the same tests to see what the differences are. You can then decide which vGPU Profile (C or Q) is appropriate for each Application. Be aware though, I see that the website mentions the Application can make use of multiple GPUs, which means that it may be quite heavy, meaning you could end up requiring an entire T4 per VM purely for processing cycles. Your testing will give you the results and you can then decide how to proceed.To help you with resource monitoring, you can use a tool called ""GPU Profiler"": Releases · JeremyMain/GPUProfiler · GitHubOnce your testing is complete, you should have a complete Resource Profile for each of the Applications. Each Application may require different amounts of resources depending on what it’s doing, so don’t assume they will all be the same. This includes CPU, RAM and GPU. GPU Profiler can help with monitoring all of those at the same time and will create a nice graph you can save and refer to later on. However, if the Application is also Multi-Threaded on the CPU, then just use (Windows) Task Manager to see what each Thread is doing and whether you need to scale up or down on the CPU side.Don’t forget to optimize Windows as well: VMware OS Optimization Tool | VMware FlingsLet me know how you get on …(FYI - I’m UK based, so there’s a bit of a time difference between us ;-) )RegardsMGWow awesome information thanks MG, I had worked out the vGPU’s profiles Framebuffer size, did not know about the Q=Quadro.As budget would allow this card is going to be doing all the work on one 128GB Mem 4xCPU VM, so we are going to simply try giving the vGPU’s 4GB profile (NVIDIA GRID vGPU grid_t4-4c) each to begin with and tune from there, thanks for the link to GPU profiler etc. this will come in handy.We only have this 1 Host with the T4 GPU card, so its kinda on its own running 1 VM, any changes i make is to the Host alone, not the cluster.I hadnt seen your response to this post and started another thread in here about the issues starting a VM with more than 1 vGPU, can you please have a read of it and tell me what you think?So in UK your working now?? And I’m up late trying to get this thing working…after work lolRegards,
SSDHi SSDResponded to the other post as well :-)May be a bit of confusion …As each Application wants to see a GPU per process, I’m assuming that you would run multiple VMs, and run each Application on a dedicated VM? (up to 4 VMs with a 4Q or 4C Profile assigned to each). This would share the T4s resources across 4 individual VMs simultaneously.The alternative to that, is to assign the entire T4 to a single VM using the 16Q / 16C Profile. However, you mention above that the Application wants to see 1 GPU per process, so I’m not sure if that will work. Do these Applications all need to run at the same time as each other?Yes, working now … :-)RegardsMGI have installed the follwing VIB NVIDIA-VMware-430.99-1OEM.670.0.0.8169922.x86_64.vib on the ESXi 6.7 Host after a successful install, reboot then running the command nvidia-smi I dont see any vGPU’s listed..!HiMake sure your Host Graphics Setting is still configured for ""Shared Direct"".RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
456,p40-graphic-mode,"Hi,How to using Graphic mode in Tesla P40 in esx 6.7 ?before we using M60 in esx 6.7. we can change to graphic mode from compute modeNo need to do so for Pascal chips. Dynamic use of graphics/computePowered by Discourse, best viewed with JavaScript enabled"
457,i-cant-boot-vm-with-vgpu,"Host : vSphere 8.0a-20842819/Tesla P4
Guest : Windows 10 x64 (1809/21H2 Tested)
NVIDIA-GRID-vSphere-8.0-525.85.07-525.85.05-528.24, NVIDIA-GRID-vSphere-8.0-525.60.12-525.60.13-527.41 Tested same resultAll work well without vGPU (Even when i passthrough Quadro) but can’t work with Grid vGPUWhen i add Grid vGPU it seem OK but If i try to install VGA Driver on Guest OS It stop to work and endless BSOD (Video TDR Failure) loopTest lastest version  → Remove Driver and MGMT from host&Reboot → Test Older versionCurrent StatusHi,could you please share a few more details? Which hardware are you using? Is the hardware on the certified servers list for vGPU?Download NVIDIA GRID datasheets, guides, solution overviews, white papers, and success stories. Watch GRID videos, webinars, and webcasts.
I’m asking as the P4 is a pretty old GPU and I haven’t seen it for a while in new projects.Best regards
SimonIt test server (Not certified hardware)Using comet lake (i5-10600 + RAM 128G + Old Intel AIC SSD)Also P4 is test purpose (If it work well I will use turing or ampare)I want to service small (1~20 client) VDI service(by RDP) for Internal (use Server + Thin Client) )I want to check performance and delay, power usage, etc… before buying hardware for serviceI will run 8 VMs for test (4 VMs with vGPU&4 VMs without vGPU) (and compare 2 group)
If i want to use vGPU I need certificated hardware? or not? (Is this work only with certificated board?)It might work on “not certified hardware” but it might be pretty hard to give you proper advise in case of issues with unsupported hardware as we always have dependency from hardware.Powered by Discourse, best viewed with JavaScript enabled"
458,tesla-and-vsync,"Hi,looking for some guidance to help me port an existing application to a VM environment using a TESLA board (in passthrough mode).The application usually uses glFinish() to synchronize itself to the Vsync. In the VM environment, glFinish() doesn’t block so the app runs much too fast.What is the best practice to get a controlled frame rate on such a setup (note: I consider myself a n00b with everything GL and gfx, so any pointer is appreciated).Thanks,
S.Powered by Discourse, best viewed with JavaScript enabled"
459,anyone-knows-how-to-set-default-plugin-parameters,"Is there a way to set default plugin parameters that apply to every new vGPU instance instead of having to set them individually for each new instance (as indicated in the docs for KVM)?I would like to have unified memory enabled by default for every new vGPU VM that is instantiated, so having to set this parameter individually hurts automation. Additionally,  from what I have tested the VM has to be stopped for the changes to go through.Powered by Discourse, best viewed with JavaScript enabled"
460,checking-for-vgpu-support-for-telsa-k40m-and-geforce-rtx-2080,"Hello Nvidia Experts!I have Telsa K40m and GeForce RTX 2080 on the private cluster.
Unfortunately, I was looking at whether the GPU in my possession can support vGPUs. I have found out in the vGPU support document that K40m does not support the vGPU, and  GeForce RTX 2080 is not referenced.
Is any of my GPUs support vGPU?HiNone of your GPUs support vGPU.For a list of supported products, have a look here: https://docs.nvidia.com/grid/latest/product-support-matrix/index.html#abstractRegardsMGThank you!Powered by Discourse, best viewed with JavaScript enabled"
461,aws-official-grid-driver-version,"Hello,It seems that the official NVIDIA GRID driver version for Windows which we can access over AWS /latest bucket is not updated for a while. Even though the latest grid driver version is 516.94 on NVIDIA drivers page, the driver version 513 is available in the AWS /latest bucket.When will it be updated to the latest version? and ideas or a roadmap for this?Thanks513.64 is the latest vGPU driver. Not sure why you think that there is a 516.x version available.Regards SimonHey Simon,Can you please check the following page, am I missing something? When we search drivers for Data Center T4 GPUs - Windows Server 2022, it returns 516.x.Download the English (US) Data Center Driver for Windows for  Windows Server 2016, Windows Server 2019, Windows Server 2022 systems. Released 2022.8.2There is a huge difference between public drivers and vGPU drivers!
Here you can check what is available for vGPU:Reference the documentation for all releases of NVIDIA virtual GPU software.We ended up with this issue while we were trying to run Unreal Engine 5 experiences/games. So, do you have any idea how to fix the following issue?
nvidia-error982×795 69.1 KB
There won’t be a solution for now. You will need to wait for the next major update to have driver version R525. But this will take a few more weeks.
Be aware that vGPU offering is not meant for gaming where you often need the latest gaming drivers.Do you have any idea when it will be updated? Is there any roadmap for this?Hi, for sure there is a roadmap and given release dates but we cannot comment on unreleased versions without NDA. As I already mentioned, you will need the next major release of vGPU for your requirementsPowered by Discourse, best viewed with JavaScript enabled"
462,from-nvbuffer-to-cvmat-bgra,"Hi, Nvidia,
I try to decode the jpeg data with fd and convert to cvMat BGA, but the final cvMat could not save and display with
cv::imwrite and cv::imshow, i dont know the root cause, pls help!
thanks!the code as below:void decode_image_nvidia_from_fd(NvJPEGDecoder *jpeg_decoder,unsigned char *in_buf, unsigned long in_buf_size, cv::Mat &img)
{
int fd = 0;
uint32_t width, height, pixfmt;}
static int
decode_image_with_fd(const int input_fd, uint32_t const height,uint32_t const width, cv::Mat &img)
{
int ret = 0;// output_params.memsize = 4 * width * height;//     typedef struct _NvBufferChromaSubSamplingParams
//  {
//    uint8_t chromaLocHoriz;
//    uint8_t chromaLocVert;
//  }NvBufferChromaSubsamplingParams;
NvBufferChromaSubsamplingParams SubsamplingParams;
SubsamplingParams.chromaLocHoriz = 0;
SubsamplingParams.chromaLocVert = 0;}the pixfmt is YUV422M ( jpeg_decoder->decodeToFd(fd, in_buf, in_buf_size, pixfmt, width, height))Powered by Discourse, best viewed with JavaScript enabled"
463,where-to-get-a-pci-passthrough-supported-gpu-list,"Hi all,I’ve already found this page showing vgpu supported list, and this announcement showing that geforce series card could be passed to windows guest.So do cards like rtx a2000, rtx a4000 support pci passthrough (not virtualization to vgpu just pass through only) or only those cards which support vgpu could be passed through to guest and function normal?GPU Passthrough on A2000 and A4000 is supported.Best regards
SimonThank you Simon!What about geforce cards like rtx3090 pass to linux guest via kvm supervisor?Should work but not supportedPowered by Discourse, best viewed with JavaScript enabled"
464,10bit-hardware-and-vdi-for-medical-purpose,"Hi, currently i’m looking for vGPU board for VDI that support 10bit hardware output technology, taken from AMD site (https://www.amd.com/Documents/10-Bit.pdf).The solution is for reading medical radiology image that need 10bit hardware output technology and running on top of VDI and at least 3K resolution, currently we are using ATI FirePro works great but we need to move to VDI solution.Does NVIDIA GRID support this solution? Thanks!Have you discussed with the various VDI vendors whether they support this?The GRID cards are capable of delivering this, but are reliant on the remoting technologies to expose the 10bit greyscale option which will appear in the Control Panel when a 10Bit greyscale monitor is detected.If the remoting protocol cannot present a compatible display the option is not presented, regardless of what is physically at the endpoint.The ADC10221 is a guaranteed to have no missing code to over then the full operating temperture range.If that any unique two stage architecture achevies 9.2 effectiveness signal.As JAson said you are dependent on the remoting protocols used by the VDI stack vendors. Currently neither VMware/Citrix support this in their ICA/HDX and Blast Extreme protocols.You may want to contact them to raise your need or explore other vendors such as NICE/Teradici/Mechdyne. I’m not myself aware of a full VDI solution that implements 10-bit colour.10-bit colour (40-bit over the 4 channels) vs. 32-bit VDI increases the data volumes greatly, add in 3K and the fact medical images are usually very large and it is a huge challenge on bandwidth to maintain frame rates. This maybe why adoption by the mainstream VDI vendors hasn’t happened.RachelPowered by Discourse, best viewed with JavaScript enabled"
465,nvidia-a40-citrix-hypervisor-8-2-cu1-bluescreen,"±----------------------------------------------------------------------------+
| NVIDIA-SMI 510.73.06    Driver Version: 510.73.06    CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A40          On   | 00000000:2B:00.0 Off |                  Off |
|  0%   44C    P8    35W / 300W |      0MiB / 49140MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   1  NVIDIA A40          On   | 00000000:A2:00.0 Off |                  Off |
|  0%   44C    P8    34W / 300W |      0MiB / 49140MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+
|   2  NVIDIA A40          On   | 00000000:C0:00.0 Off |                  Off |
|  0%   45C    P8    37W / 300W |      0MiB / 49140MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+==============NVSMI LOG==============Timestamp                                 : Wed Jun  1 13:58:39 2022
Driver Version                            : 510.73.06
CUDA Version                              : Not FoundAttached GPUs                             : 3
GPU 00000000:2B:00.0
Product Name                          : NVIDIA A40
Product Brand                         : NVIDIA
Product Architecture                  : Ampere
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Enabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1565221004370
GPU UUID                              : GPU-05bde6b5-ed98-02a1-5ca3-b0f29aa9713a
Minor Number                          : 0
VBIOS Version                         : 94.02.5C.00.03
MultiGPU Board                        : No
Board ID                              : 0x2b00
GPU Part Number                       : 900-2G133-0300-030
Module ID                             : 0
Inforom Version
Image Version                     : G133.0200.00.05
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GSP Firmware Version                  : N/A
GPU Virtualization Mode
Virtualization Mode               : Host VGPU
Host VGPU Mode                    : SR-IOV
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x2B
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x223510DE
Bus Id                            : 00000000:2B:00.0
Sub System Id                     : 0x145A10DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 1
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : 0 %
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 49140 MiB
Reserved                          : 452 MiB
Used                              : 0 MiB
Free                              : 48687 MiB
BAR1 Memory Usage
Total                             : 65536 MiB
Used                              : 1 MiB
Free                              : 65535 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 192 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 44 C
GPU Shutdown Temp                 : 98 C
GPU Slowdown Temp                 : 95 C
GPU Max Operating Temp            : 88 C
GPU Target Temperature            : N/A
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : Supported
Power Draw                        : 35.51 W
Power Limit                       : 300.00 W
Default Power Limit               : 300.00 W
Enforced Power Limit              : 300.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 300.00 W
Clocks
Graphics                          : 210 MHz
SM                                : 210 MHz
Memory                            : 405 MHz
Video                             : 555 MHz
Applications Clocks
Graphics                          : 1740 MHz
Memory                            : 7251 MHz
Default Applications Clocks
Graphics                          : 1740 MHz
Memory                            : 7251 MHz
Max Clocks
Graphics                          : 1740 MHz
SM                                : 1740 MHz
Memory                            : 7251 MHz
Video                             : 1530 MHz
Max Customer Boost Clocks
Graphics                          : 1740 MHz
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Voltage
Graphics                          : 706.250 mV
Processes                             : None@sschaber , you always have great tips :)Have you also tried an older guest driver from the vGPU 13.x branch? Just to rule out the latest guest driver? I’m not aware of any given issues with the vGPU 14.1 driver but I didn’t test it myself yet.regards
SimonThank you for the reply. I have tested 13.3 both host and guest.  There is no other settings  etc you are aware of ? could try an earlier to…@sschaber  I tried 13.0 now and it made no difference… I am out of ideas. Same thing when passing through the whole GPU …Which profile did you assign during the driver installation?A40-8Q… For CAD machines.Sounds to be more related to GPOs or Windows OS. Is the VM joined to a domain?
Had once a case that a security setting in a GPU stopped our drivers to install properlyYes, Provisioned citrix W10 machine. Also to rula that out installed a “local” 2019 server with no domain. Same issue.Hi, another idea would to modify the TDRDelay settings to see if it installed when having more time (10sec instead of 2sec)TDR testing and debugging information for developersPerfect, I will try that next.Made no difference. Any other tip ?@sschaber  here is the daemon log on the Hypervisor :Jun  2 09:46:21 xen01 vgpu-9[13537]: notice: vmiop_log: ######## Guest NVIDIA Driver Information: ########
Jun  2 09:46:21 xen01 vgpu-9[13537]: notice: vmiop_log: Driver Version: 512.78
Jun  2 09:46:21 xen01 vgpu-9[13537]: notice: vmiop_log: vGPU version: 0xd0001
Jun  2 09:46:21 xen01 vgpu-9[13537]: notice: vmiop_log: (0x0): vGPU license state: Unlicensed (Unrestricted)
Jun  2 09:46:21 xen01 vgpu-9[13537]: notice: vmiop_log: (0x0): Timeout detection and recovery (TDR) completed.
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): Timeout occurred, reset initiated.
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x52445456 0x004403f8 0x000001cc 0x00000001
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00989680 0x00000000 0x000001bb 0x0000000f
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000100 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00001600 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00001a00 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00001f00 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000b00 0x00000000 0x0000000a 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000c00 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000a00 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00001300 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00002100 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00001700 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00002400 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00001800 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000e00 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000f00 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00001000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x000001aa 0x0000000b
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x0000000a 0x0000000a 0x0000000a 0x00020b01
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00005188 0x00000000 0x1b43a113 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x1d0f9bb1 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000009 0x00000009
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000009 0x00020b01 0x000000dc 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x1b439cf5 0x00000000 0x1d0f9bb1 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000008 0x00000008 0x00000008 0x00020b00
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00005188 0x00000000 0x1813f8f1 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x1b12ad84 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000007 0x00000007
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000007 0x00020b00 0x000000dc 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x1813f4ee 0x00000000 0x1b12ad83 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000006 0x00000006 0x00000006 0x00020b00
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00005188 0x00000000 0x14e487a5 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x17e3169c 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000005 0x00000005
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000005 0x00020b00 0x000000dc 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x14e483a6 0x00000000 0x17e3169c 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000004 0x00000004 0x00000004 0x00020b00
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00005188 0x00000000 0x11a832a9 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x14b307b7 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000003 0x00000003
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000003 0x00020b00 0x000000dc 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x11a82e88 0x00000000 0x14b307b3 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000002 0x00000002 0x00000002 0x00020b00
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00005188 0x00000000 0x0e4b16ea 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x1176a3be 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000001 0x00000001
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000001 0x00020b00 0x000000dc 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x0e4b1194 0x00000000 0x1176a3bc 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000b00
Jun  2 09:46:26 xen01 vgpu-9[13537]: error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000
Jun  2 09:46:26 xen01 vgpu-9[13537]: message repeated 2 times: [ error: vmiop_log: (0x0): TDR_DUMP:0x00000000 0x00000000 0x00000000 0x00000000]Unfortunately I’m running out of ideas. Did you try to run a Win10 guest already to see if this would work? But I assume there must be something else going wrong with the hypervisor.I guess it is Citrix Hypervisor as well. Going to create a ticket. Thank you for your help!Hi @sschaber , Citrix working on it. This is what Nvidia /driver on the host says.
Anything you seen before ?Jun 20 09:41:31 xen01 vgpu-2[2281]: __mapcache_fault: 6f7a
Jun 20 09:41:31 xen01 vgpu-2[2281]: demu_register_msi_pirq: Error mapping MSI-X entry: 0, Invalid argument
Jun 20 09:41:31 xen01 vgpu-2[2281]: error: vmiop_log: (0x0): failed to register msi pirq
Jun 20 09:41:31 xen01 vgpu-2[2281]: notice: vmiop_log: ######## Guest NVIDIA Driver Information: ########
Jun 20 09:41:31 xen01 vgpu-2[2281]: notice: vmiop_log: Driver Version: 512.78
Jun 20 09:41:31 xen01 vgpu-2[2281]: notice: vmiop_log: vGPU version: 0xd0001
Jun 20 09:41:31 xen01 vgpu-2[2281]: notice: vmiop_log: (0x0): vGPU license state: Unlicensed (Unrestricted)
Jun 20 09:41:31 xen01 qemu-dm-2[2316]: 2316@1655710891.463647:xen_platform_log xen platform: xen|ModuleAdd: FFFFF801511E0000 - FFFFF801511FAFFF [monitor.sys]
Jun 20 09:41:36 xen01 vgpu-2[2281]: error: vmiop_log: (0x0): Timeout occurred, reset initiated.
Jun 20 09:41:36 xen01 vgpu-2[2281]: error: vmiop_log: (0x0): TDR_DUMP:0x52445456 0x00910238 0x000001cc 0x00000001Just wanted to share the solution. It was a setting in dom0 of Citrix Hypervisor.
/opt/xensource/libexec/xen-cmdline --set-xen x2apic_phys=truex2apic was enabled i BIOS all the time but not in the Hypervisor ( by default ).This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
466,tesla-p4-hp-dl385-gen10-esxi-6-5-showing-no-ram-available-on-telsa-p4,"Hi there,   We have 3 x Tesla P4 cards we are wanting to use on ESXi 6.5 for vSGA use.   I installed the first 2 on HP DL380 Gen9 server with Intel CPU’s and installed the NVIDIA-VMware-418.196-1OEM.650.0.0.4598673.x86_64.vib file and everything is working fine with those 2 servers.  We are running ESXi V 6.5.0 build 17477841 on all 3 hosts.The issue I have is with the 3rd host which is HP DL385 with AMD CPU.  I’ve tried installing the same driver and it shows up in vCenter.  It shows the card, it shows the Active type ‘shared’ and configured type ‘shared’ but shows memory as 0.00mb.Also if I run nvidia-smi it shows it says no devices were found even though the bios and ESXi show it’s there.   So it’s obviously something to do with the drivers not loading etc but I don’t know why.I’m clearly missing something here.I’ve also tried updating the driver to the latest version I could download NVIDIA-VMware-460.73.02-1OEM.650.0.0.4598673.x86_64.vib but it hasn’t changed anything.I’m losing my mind with this one…any help is very much appreciated.Can you run nvidia-smi on the ESX host after installing the VIB? What is the output? Seems the GPU is not recognized properly. Maybe you need to check the BIOS settings first.Yes I have run it, as mentioned in my original post.  It just says ‘no devices were found’ but clearly it is seen by the bios as it’s shown in iLO, BIOS and in ESXi …That’s why I’m confused.check with dmesg on the host if there are errors, I still assume a wrong BIOS settingThere’s a whole load of stuff in there when I run that command…not sure what I should be looking for, but this stuff seems GPU related.2021-07-06T09:54:40.203Z cpu44:72073)NVRM: GPU at 0000:23:00.0 has software scheduler DISABLED with policy BEST_EFFORT.
2021-07-06T09:54:40.217Z cpu44:72073)NVRM: GPU 0000:23:00.0: RmInitAdapter failed! (0x26:0xffff:1290)Any idea what sort of settings in the BIOS I should be looking for  ??  I checked the IO-SRV in virtualisation section and that’s enabled.   Well it’s greyed out so I can’t select it, but it says enabled in grey.As you can see the board is not loaded properly. Might be BIOS related or hardware defect. Please check with HPE first for the right BIOS setting. Especially the MMIO settings are relevant. P4 doesn’t require SR-IOV enabled. In addition, I’m not sure if P4 is qualified for the given server at all. As far as I can see only T4 was validated.Yeah I figured out that something like that was going on, but have been through all of the setting in the BIOS and there’s nothing at all that I can see that’s related.   I just assumed if they worked fine with Gen9 of the same server that the Gen10 would be fine… I know that’s not always the case, but wouldn’t of expected it to not work like this, but wasn’t sure if I needed to get advice from HP or NVIDIA or VMWare so I’ll see what I can get from HP.Thanks for the advice.OK so annoyingly HP says it’s not supported on this server which is really dumb… and frustrating.   But at least if someone else is looking for this information it’s here now.Thanks for your help sschaberOK so I have a bit of a wrinkle in this story.   Today I removed the card from the HP DL386 Gen10 and put it into the Cisco UCS C210 M2 server we had to see if it worked there and got exactly the same issue…everything looks fine in the sense that the BIOS reports it, VMWare see’s it, but says it’s 0 Mb of RAM.nvidia-smi reports no devices available.It seems a bit to coincidental that both servers are doing the same thing…   I know I have read that some of the Tesla cards are selectable between modes but I’m not sure if the Tesla P4’s are like this and maybe the card is in the wrong mode ?   I haven’t been able to find any information about that with the P4 but just thought I’d ask the question in case I’m missing something there and I’m fighting a losing battle if the card isn’t going to respond properly.Any advice is appreciated as always.   I’ve got some other later model Cisco servers I’m going to give the card and go in to see if I get similar results.Have you tried to use ESX 6.7 instead? Why do you still use 6.5? Modeswitch is not possible on the P4 as it handles graphics and compute in parallel.
Did you open a support ticket with our NVES? They could analyze the nvbugreport to see if points to the issue.
And please keep the “old” 418.x driver for your testing as I doubt the latest one is working with 6.5 due to extended VIB size. You even need a current patch for 6.7 to extend the VIB size accepted and VMWare didn’t release a patch for 6.5 as far as I know.regards
SimonHi Simon,I used ESXi 6.5 because I understood that it was the only version that officially supported the VSGA function without some kind of licencing.   As I said, we have 2 other servers with the same card, running the same version of driver but with DL380 Gen9, not DL385 Gen10 but hard to know if it’s a card issue or something else going on as I’m not familiar enough with these cards and ESXi to diagnose.I haven’t done anything else other than post here as I wasn’t aware of any other options sorry.Thanks for the info on the modeswitch, I did assume it couldn’t, but thought maybe it was a reason the card might not seem to be working properly, but at least if we know it’s not possible then at least I know it’s not that !I am going to use another server to do some more trialing with different drivers, ESXi etc etc to see if I get any different results.  I couldn’t really do too much on our production servers, but now I have some other servers to prove if the card is or isn’t working properly.  That’s my first step I guess.Even when I installed the latest driver I had, ESXi didn’t complain and said it was installed successfully I thought, but I better read it again just to be super sure.Unfortunately you are wrong. ESX version is not relevant for licensing. You always need a vPC license for vSGA as soon as you use a GPU like P4.Thanks for letting me know that.   The licencing model is super complicated I found when I tried to look up what was needed.   Found plenty of posts in other places with very confused I.T staff also, so was obvious it wasn’t just me struggling to understand it.I found a driver for ESXi 6.5 from before NVIDIA had their vPC licencing so that’s why I assumed it didn’t need any kind of licencing for that version.  I know I needed some kind of licencing for the later versions (which I ended up needing to install to get things going on the other servers) so once we get all three going we will get whatever we need to make us legal.So I haven’t got anywhere with running the card on seperate servers or seperate O/S’s.I’m just wondering if it’s worth me attempting a bios / firmware flash to make sure it’s not something like that  ?   or is there some process so we can diagnose further ?I can find a BIOS but it’s for SUSE or some other Linux, so wondered if there’s some other easier method than going through setting all that up just to flash it again ?It’s really frustrating…Do you mean flashing the GPU? Doesn’t make any sense as this is never necessary.regards
SimonYes.  I mean I know it’s not normally needed, but obviously in this situation it’s not working as expected so I just thought maybe it could be something like that since it shows up in BIOS and in ESXi, but the drivers won’t initialise in ESXi or Windows…  so guess I was clutching at straws a bit.how can I diagnose further what might be happening ?Just wanted to let everyone know that might be having similar issues that this was down to a faulty card.I went through everything over and over and have had working cards in other servers with no drama’s so I knew what it should be doing.Finally after exhausting all options I contacted the supplier and got a return / replacement and it worked straight off once it showed so clearly it was some kind of fault, but it showed in BIOS etc and in VMWare partially as mentioned… but now I know it was a faulty card.Thanks for everyone that replied.Powered by Discourse, best viewed with JavaScript enabled"
467,topic,"Здравствуйте, у меня довольно старая 940М. ну с недавнего времени когда я запускаю что то с этим графическим процессором происходит следующее ( см скриншот)
Объясните что мне делать для исправления проблемы.
Uploading: image.png…скриншот image — ImgBB (ibb.co)Powered by Discourse, best viewed with JavaScript enabled"
468,aws-quadro-virtual-workstation-display-issues,"Hello. I’ve installed Steam and the PC game COMPANY OF HEROES 2 in my AWS Quadro virtual workstation to see if it will run. I cant seem to make the game it full screen even if I click on the maximize screen button. The other software’s I installed have no issues. I hope anybody here can give me how to fix it.HiWhich Client / Protocol are you using to connect to your VM?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
469,hi-i-need-ur-help-who-can-help-me,"i need ""vGPU Manager [418.66-418.130]"" and ""Linux Driver [418.66-418.130]""
Can someone download it for me and pass it to me ?Only one same version is needed, thxHiIf you sign up for a 90 day evaluation you can simply download it yourself:https://enterpriseproductregistration.nvidia.com/?LicType=EVAL&amp;ProductFamily=vGPUBesides, even if someone were to give it to you, you’d still need to have the vGPU License Server and Licenses, so you’d need an account anyway.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
470,cant-use-nvidia-smi-on-vm,"I’m using a VM with Ubuntu 22.04 and trying to do GPU pass-through.
The drivers are detected and in use however when I use the commandI get the following outputWith the errorHowever, it appears I only have 470 nvidia-drivers. What is going on? Everytime I purge the nvidia driver, it appears some random version again. Am I missing something here?PS: I need max nvidia-driver-470 since I’m using a legacy graphic card GT 740MAdditionally, I find  some files with this 520 version. Not sure what is going on :/Nvidia-smi on the host or guest?Can’t run nvidia-smi on my vm. Additionally I’m using proxmox on my host but my vm runs on Ubuntu 22.04Hi I have similar issue described here: RTX 6000 Ada Linux driver crash
Looking for suggestions but also my info might helpPowered by Discourse, best viewed with JavaScript enabled"
471,trial-setup-r740xd-esxi-hostd-not-starting-after-vib-install,"Trying to get a trial working on a R740xd box on esxi 7.0. After installing the nvidia VIB file to manage the GPUs and telling esxi to do shared direct I reboot the host. Once the host is back up you cannot access it through the GUI and you get a 503 error. It appears there is a problem in the hostd file not finding some of the recognized GPUs from before the nvidia VIB file was installed. Looking for troubleshooting assistance to recover from this error. I have gotten the same results twice (I reinstalled ESXI thinking I did something wrong).HiSo you’ve installed the vGPU driver in the ESXi Host and restarted it. When it comes back up, you can no longer connect to it through your browser? Is that correct?Which GPUs are you using?
Have you configured the BIOS correctly?
Is the Server connected to vCenter?
Which vGPU Driver did you install? (Where did you download it from)RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
472,m5000-not-showing-in-dell-r720xd-with-hyper-v-2019,"I have a PowerEdge R720xd with the following config.
2 x E5-2660
128 Gb Ram
2 x 1100W PSU
Hyper-V 2019 CoreBIOS Settings>
>Integrated Devices
Embedded Video Controller: Enabled
SR-IOV Global: Enabled
Memory Mapping I/O above 4GB: Enabled
>System Profile> Dense ConfigI installed Quadro M5000 in the PCIe 16x Slot with 8 to 6 pin Power cable.Integrated GPU Enabled (If I disable the Server keeps rebooting)
M5000 is also showing the Output using DVI but only the Dell BIOS Page all the rest, it’s Blank.But in the Hyper-V Manager, there is no GPU showing also in the Win 10 Pro Client the Display Adaptor is Hyper-V.Powered by Discourse, best viewed with JavaScript enabled"
473,vgpu-for-rtx-a4000-rtx-a5000,"Hi,Could you kindly consider opening the rtx a4000 and a5000 for vgpu drivers? Limit to 6000 and 8000 sucks.HiThe A5000 is supported with vGPU 12.2.Please bear in mind that new hardware releases are not always immediately supported and may require a subsequent branch update to allow functionality.RegardsMGthank you for the update. Might the A4000 be supported too?HiThe RTX 5000 wasn’t supported, so it’s unlikely the A4000 will be either.It’s only the top tier Quadro / RTX GPUs that are supported with vGPU, as well as Tesla.RegardsMGBoth the NVIDIA RTX A5000 and RTX A6000 are supported with vGPU 12.2 - Supported Products :: NVIDIA Virtual GPU Software DocumentationThe NVIDIA RTX A4000 does not support vGPUPowered by Discourse, best viewed with JavaScript enabled"
474,grid-virtual-pc-license-usage,"I have a question about how the license usage works under VMware horizon. We have multiple desktop pools bases on instant cloning.
I have in totaal 500 license for GRID-Virtual PC and 500 concurrent users for VMware horizon.
Is someone login the desktop does it cost one license. Or every desktop that i have available cost a license.Also when does it gives a license back. It looks now i always have to wait 1 day and not when i delete the machinePowered by Discourse, best viewed with JavaScript enabled"
475,nvidia-t4-vmware-could-not-initialize-plugin-error-when-powering-up-too-many-vms-at-the,"Hi there,does anyone encountered this strange issue?When powering on all VMs on a single host some of the VMs report ""Could not initialize plugin ‘/usr/lib64/vmware/plugin/libnvidia-vgx.so’ for vGPU ‘t4-2q’."" error?After a little wait time i can start some to all of these VMs fine.The server is a Lenovo SR650 with 4xT4 GPU inside. We use the 2Q profile and the server hosts 32 VMs.
Almost all VMs power up fine, all GPUs are used (saw in nvidia-smi and in the vCenter).Could this be a driver related issue? I currently don’t have a test server to verify but this is my only guess since we use an older driver. Newer drivers had the issue that they crashed our CAD application.Thank youHiWhich version of VMware and vGPU driver are you using?RegardsMGRelease 8 (418.66) if this helps you to identify.HiThanks. Although supported, that’s over a year old and should be updated.All I can initially suggest is upgrading to the latest 10.2 branch and see if that solves your issue.Which version of VMware are you running? 10.2 supports 7.0 …RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
476,assign-1-gpu-to-3-vms,"Hi, I have Setup the Dell Poweredge R720
2 x Xeon E5-2680 8 Core with Total 32 Cores
128 GB ECC Ram
RAID1 2 x 500 SAS Drives for vSphere
RAID 10 4 x 1TB SSD for the VM’s
1 x Nvidia Quadro M5000 CardEach VM is
Windows 10 Pro
6 Cores
16 GB Ram
250 SSD StorageI Assign the PCIe as M5000 and it’s working fine but I can only run 1 VM at a time with the M5000 as soon as I try to run the other 2 VM’s I get the errorPower On VM
Key: haTask-12-vim.VirtualMachine.powerOn-538978948
Description: Power On this virtual machine
Virtual machine: Win10-2
State: Failed - Module ‘DevicePowerOn’ power on failed.
Errors:
Module ‘DevicePowerOn’ power on failed.
Device 66:0.0 is already in use.
Failed to start the virtual machine.And what is the question? For sure you can only run GPU Passthrough with a single VM.
For everything else you would need vGPU which requires specific Tesla GPUs like Tesla T4.HiAs Simon mentions, this is the expected and correct behaviour for this GPU.The only Quadro GPUs that support virtualisation / vGPU are the RTX 6000 and RTX 8000.Depending on your Applications and use case, what you could do is build a single RDSH VM, run the GPU in Passthrough and have your 3 (or more) users share the GPU like that.RegardsMGHello
can i add two frame plates in the vm esxi and define one for each vm, thus using one plate in each vm? would have any configuration problem?Powered by Discourse, best viewed with JavaScript enabled"
477,can-nvidia-virtual-gpu-manager-generate-multiple-vgpus-that-nvidia-smi-can-recognize,"Hi.I want to do reinforcement learning with distributed deep learning. I would like to generate multiple vGPUs on one RTX A6000 and do that.
Is it possible to generate multiple vGPUs on one RTX A6000 and use them on one PC with RTX A6000?I looked it up, but with vGPU, it seems impossible for me to do what I want to do.I hope I can use’MIG’with RTX A6000.A6000 supports vGPU but for sure no MIG. Only A30 and A100 are capable to run MIGPowered by Discourse, best viewed with JavaScript enabled"
478,home-server-with-an-m40-for-parsec-or-steam-in-home-streaming,"Hello @eltonHello,Yes, you are indeed right. Citrix did the trick.Hello, i dropped you a message. Please do check if you have the time. ThanksHi, excuse, did you manage to use the M40 to play games?
I have one and I would like to know how you made the settings, and what tools did you use?Hello,It’s been some time but I’m back. The M40 in the end was a no-go.
I didn’t get it to work and I most likely never will but I am trying it again with a Tesla T4.:) T4 will work for sure…Yes, it worked. I even use it to mine Ethereum in the downtime to pay a little for itself.Hello.
I managed to use the M40 12GB RAM
I have 2 Tesla M40s on a Dell T620 server Running with Windows Server 2019
Modified files to recognize the card as a GTX Titan X.
As my server only has basic video output, I make a remote desktop connection with the resolution I want to have, and then I make the connection with Parsec.
The only problems are some delays when loading the game, then it normalizes.
Until now I have only played Horizon Zero Dawn at 2560x1440 with Medium quality.It’s been some time but I’m back. The M40 in the end was a no-go.
I didn’t get it to work and I most likely never will but I am trying it again with a Tesla T4. firmwarexbdMay I ask how you accomplished that? Which “files” did you modify and did you get it working with other games? I did manage to run ARK in DX mode off of the M40 once by mistake, and it was pretty decent but I forgot to plug in the fan so it crashed on me because of the temperatures and I didn’t have any luck since. Don’t get me wrong, the game starts but in OpenGL mode and that’s not what I want.Hello.
I managed to use the M40 12GB RAM
I have 2 Tesla M40s on a Dell T620 server Running with Windows Server 2019
Modified files to recognize the card as a GTX Titan X.
As my server only has basic video output, I make a remote desktop connection with the resolution I want to have, and then I make the connection with Parsec.
The only problems are some delays when loading the game, then it normalizes.
Until now I have only played Horizon Zero Dawn at 2560x1440 with Medium quality.I have been playing Cyberpunk 2077, in FHD with high graphics and Vsync disabled, it gives me between 24 and 30 FPS, Doom Eternal running in Vulkan gives me about 60 FPS, Middle-earth: Shadow of War still gives me about 60 FPS.The file that I modified was “nv_dispi.inf” located in the Display.Driver folder.
Replace the identifier of the TItan X card with the identifier of the Tesla M40, throughout the file.You have to unzip the driver to gain access, you also have to disable the requirement for signed drivers in windows.Since Parsec needs to have an active monitor, I must make a remote connection to the virtual machine, I tried to use a quadro card together with the Tesla to connect a monitor, but in that configuration, windows does not assign the Titan X card (Tesla M40) to high performance use, and the games run on the quadro card.For the fan use this Tutorial so that they are activated when I start playingArduino PWM Fan Control for Tesla K80. Contribute to rgrosset/CoolingTeslaK80 development by creating an account on GitHub.
Captura de Pantalla 2021-03-14 a la(s) 21.20.192560×1440 807 KB

Rage 2 running on vulkan
Captura de Pantalla 2021-03-15 a la(s) 20.22.332560×1440 531 KB

Captura de Pantalla 2021-03-23 a la(s) 23.32.132560×1440 816 KB
CyberPunk 2077They are the only captures I have, at the moment.Thanks for the reply!Great results and thanks for the “hack”. Are u using VNC to emulate a display using a remote connection or just rdp?
How’s the stability? Have you had any games that refused to run?I’m using RDP, some games have a FPS drop when you enter menus or load another scenario, one or two seconds it goes down to 15 fps and then it normalizes, and I had problems with the last Batman game: Arkham Knight, it tells me no It can be executed on a remote connection, the game Hellblade Senua’s Sacrifice does not run, it doesn’t send me any error, it just won’t open, NieRAutomata sends me a “No Graphic Memory” error, and seeing that it can be solved but this game is from GamePass PC and files are protected.The biggest problem I have is with vsync, it drops too much in performance in most games, and in Doom Ethernal with vulkan, it does not lower the FPS but I feel more input lag.
By keeping it deactivated you can feel the displacement of the environment with small pauses when you go very fast on the map.Some of the games that I tested do not run as full screen, if not as a borderless window, it looks like full screen, if I change it to full screen, it looks like a window.
Captura de Pantalla 2021-03-12 a la(s) 1.44.25390×522 21.1 KB

Captura de Pantalla 2021-03-25 a la(s) 22.28.542560×1440 767 KB
 
Captura de Pantalla 2021-03-25 a la(s) 23.53.452560×1440 761 KB
 
Captura de Pantalla 2021-03-25 a la(s) 23.58.322560×1440 910 KB
 
Captura de Pantalla 2021-03-26 a la(s) 0.02.102560×1440 670 KB

Watch Dogs LegionMarvel Avengers It runs much more stable in 1080p and with high graphics, the physics activated.
Captura de Pantalla 2021-04-23 a la(s) 22.50.592560×1440 454 KB
 
Captura de Pantalla 2021-04-23 a la(s) 22.53.052560×1440 871 KB
 
Captura de Pantalla 2021-04-23 a la(s) 23.04.462560×1440 825 KB
 
Captura de Pantalla 2021-04-23 a la(s) 23.11.452560×1440 792 KB
Haven’t been following the thread, so sorry for the late answer but dude that looks so amazing! It’s hard to believe that the M40 can be so powerful.A few days ago I saw this live, I already tried it and it gives much better results.
I currently have my server with an Nvidia Quadro P400 card for video output, and the Tesla M40 card.
You have to use the latest Windows 10 from the Insider program.The games are more stable, without so many loading problems, or jerks when going to play.The games that I tested are:Horizo Zero Dawn: 1080p - Ultra - 30fps
Fornite: 1080p - Epic - 60fps
CyberPunk: 1080p - Ultra - (30, 45)fps
Ark : 1080p - Epic - (40, 60) fpsI leave here the links of the post with the steps that I followed, the overclock does achieve improvements in performance, but you have to be careful because the system becomes unstable.https://www.miyconst.com/Blog/View/2094/nvidia-tesla-m40-cooling-tuning-gaming-overclocking-and-bios-modificationsClickbait title aside, its true. There are a couple of caveats to get this working, but the bottom line is that you can pick up a used Tesla M40 12GB off ebay for around $150 while used GTX Titan X GPUs go for around 3x that. As far as I can tell,...Resident Evil 3 RemakeHigh graphics with High texture quality (8 GB)
Playing at 60 FPS a few drops at 50 FPSHorizon Zero Dawn
Settings 1080p UltraPowered by Discourse, best viewed with JavaScript enabled"
479,proxmox-7-1-nvidia-vgpu-tutorial-on-a5000,"Hi,Can any one help with installation of the pro-priority drivers in latest proxmox for VGPU (i got a trial license)I dont find any guide for proxmox, specially vgpu on latest drivers.I tried installing the latest driver 510.47.03, but its not working.i did dpkg -i nvidia-linux-grid-510_510.47.03_amd64.deb then removed the blacklist nvidia driver from /etc/modprobe.d/pve-blacklist.conf and rebooted the machine and did nvidia-smiI am getting NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.Hello how are you? I hope so, I’m temporarily with an A5000 board, I made a Tutorial with pieces of code that I found from other tutorials on the internet and I was testing, I have the drivers on the HOST working, but at the moment I don’t know what else to do, if you can help , thank you. see here the tutorialPowered by Discourse, best viewed with JavaScript enabled"
480,rtx6000-on-physical-rack-workstation,"I have a quick question, is the Quadro virtual DWS installed by the NVidia vGPU software, and is it required for a 1:1 dedicated rack workstation using an RTX6000?  The NVIDIA vGPU software only comes in hypervisor flavors, and the machine running the RTX6000 is Windows 10 (no hypervisor).  I’ve been told that the QvDWS is necessary to access more than 2GB of GPU memory, is that also true?Hi PaulIf you’re using an RTX 6000 / 8000 in Passthrough, no license is required and you can use the standard driver from the public website in the same way as if you were installing it in a local workstation. You only need a license when you’re using vGPU.QvDWS is required for more than 2GB of Framebuffer, but that’s only if you’re using vGPU.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
481,nvidia-license-borrow-time,"Hi all,since the latest nvidia grid license server 11.2020 I can’t reduce the borrow license time of the clients.I set on the registry “LicenseInterval = 0x0000000a (10)” which means 10min. So after a  client will 10min not report to the license server, his license should free up again.
But this is not the case. I can see on the license server a borrow time of 9 hours. It was working before I updating the license server to the latest server.I already opened a support case but the guy wasn’t able to help me. Does anyone of you have the same issue?Regards,
VM_MasterPowered by Discourse, best viewed with JavaScript enabled"
482,drivers-needed-for-playing-with-tesla-k80-p4-p100-v100,"Okay, i just want to test some games with those gpu, they are provided by google, and i want to give them a try. But what drivers should i install? it has directx support? I can play?One of the games i want to test is metin2, and also eve online. Eve works slowly witouth settuping nothing but metin2 dosnt. Dunno why. Hope someone can help me out.Forget the K80, that’s pointless, completely the wrong GPU.For the other GPUs, you’ll need to register for a 90 day evaluation to obtain the drivers.Get instant access to hours of accelerated, virtualized graphics.I take it you’re installing those GPUs in a server chassis, not a workstation? …All 3 of those GPUs will play games without issue.
2021-04-25 (1)1920×1080 345 KB
Powered by Discourse, best viewed with JavaScript enabled"
483,tesla-p4-driver-for-6-7-u3-vsga,"Hello together!I would like to use a P4 card for vSGA sceneries.Where can I find the appropriate driver? (6.7 u3)Thanks in advance,
RonHi,are you aware that you will need vPC licensing for this use case? You need to download the vGPU driver from the Nvidia licensing portal.Best regards
SimonvSGAHi,somehow it’s all a bit diffuse, think that licensing is nevertheless only necessary for the use case of vgpu!?Hi,Everything is described in our guide:319.41 KBSee Table 13 for vSGA use case.Best regards
SimonHi simon,thanks for the pdg.What exactly does “VMware Horizon vSGA” mean?Where is the difference (license) between vGPU/vSGA?What about K1/2 cards?regards
ronHi,there is no difference in terms of licensing between vSGA and vGPU. As you will need to pay for vPC anyways, customers tend to use vGPU instead of vSGA to benefit of all the advantages as vSGA doesn’t provide all the features vGPU does.K1/K2 doesn’t require licensing at all but you won’t get current drivers for these extremely old GPUs. Even P4 is already pretty old. We are now at Ada which means: Pascal → Turing → Ampere → Ada. So we are now 3 generations in advance with the current GPUs.Powered by Discourse, best viewed with JavaScript enabled"
484,capture-sdk-and-cuda-encode-sdk-interop,"Hello there!I’m trying to make a program that will capture the screen on both Linux and windows and then encode the output video on the fly. Because the capture SDK is only supported on Linux (and not all Nvidia GPUs are compatable) I wanted to separate the capturing and encoding. Not only that but there will be preprocessing before encoding.So how should I go about capturing the screen and then using the NvEncode library in a decoupled way? I can’t use system memory, only GPU memory. I’m sure I’m missing something.I’m providing no code examples of my attempts because I’m embarrassed and will certainly start again from scratch.Thanks in advanceJamesPowered by Discourse, best viewed with JavaScript enabled"
485,why-nvlink-not-effect,"my server dell c4140 with 4 v100 sxm2 inside.
then i found the nvlink is not effect, and i want to know how to enable it.
C:>nvidia-smi nvlink -c
GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-fde8b6eb-3fcc-6062-d0df-ec38368d04c1)
Link 0, P2P is supported: true
Link 0, Access to system memory supported: true
Link 0, P2P atomics supported: true
Link 0, System memory atomics supported: true
Link 0, SLI is supported: false
Link 0, Link is supported: false
Link 1, P2P is supported: true
Link 1, Access to system memory supported: true
Link 1, P2P atomics supported: true
Link 1, System memory atomics supported: true
Link 1, SLI is supported: false
Link 1, Link is supported: false
Link 2, P2P is supported: true
Link 2, Access to system memory supported: true
Link 2, P2P atomics supported: true
Link 2, System memory atomics supported: true
Link 2, SLI is supported: false
Link 2, Link is supported: false
Link 3, P2P is supported: true
Link 3, Access to system memory supported: true
Link 3, P2P atomics supported: true
Link 3, System memory atomics supported: true
Link 3, SLI is supported: false
Link 3, Link is supported: false
Link 4, P2P is supported: true
Link 4, Access to system memory supported: true
Link 4, P2P atomics supported: true
Link 4, System memory atomics supported: true
Link 4, SLI is supported: false
Link 4, Link is supported: false
Link 5, P2P is supported: true
Link 5, Access to system memory supported: true
Link 5, P2P atomics supported: true
Link 5, System memory atomics supported: true
Link 5, SLI is supported: false
Link 5, Link is supported: false
GPU 1: Tesla V100-SXM2-16GB (UUID: GPU-a1d45500-e099-7229-fe4e-21f96bab285d)
Link 0, P2P is supported: true
Link 0, Access to system memory supported: true
Link 0, P2P atomics supported: true
Link 0, System memory atomics supported: true
Link 0, SLI is supported: false
Link 0, Link is supported: false
Link 1, P2P is supported: true
Link 1, Access to system memory supported: true
Link 1, P2P atomics supported: true
Link 1, System memory atomics supported: true
Link 1, SLI is supported: false
Link 1, Link is supported: false
Link 2, P2P is supported: true
Link 2, Access to system memory supported: true
Link 2, P2P atomics supported: true
Link 2, System memory atomics supported: true
Link 2, SLI is supported: false
Link 2, Link is supported: false
Link 3, P2P is supported: true
Link 3, Access to system memory supported: true
Link 3, P2P atomics supported: true
Link 3, System memory atomics supported: true
Link 3, SLI is supported: false
Link 3, Link is supported: false
Link 4, P2P is supported: true
Link 4, Access to system memory supported: true
Link 4, P2P atomics supported: true
Link 4, System memory atomics supported: true
Link 4, SLI is supported: false
Link 4, Link is supported: false
Link 5, P2P is supported: true
Link 5, Access to system memory supported: true
Link 5, P2P atomics supported: true
Link 5, System memory atomics supported: true
Link 5, SLI is supported: false
Link 5, Link is supported: false
GPU 2: Tesla V100-SXM2-16GB (UUID: GPU-3220fdb4-507a-d838-3219-44187789d766)
Link 0, P2P is supported: true
Link 0, Access to system memory supported: true
Link 0, P2P atomics supported: true
Link 0, System memory atomics supported: true
Link 0, SLI is supported: false
Link 0, Link is supported: false
Link 1, P2P is supported: true
Link 1, Access to system memory supported: true
Link 1, P2P atomics supported: true
Link 1, System memory atomics supported: true
Link 1, SLI is supported: false
Link 1, Link is supported: false
Link 2, P2P is supported: true
Link 2, Access to system memory supported: true
Link 2, P2P atomics supported: true
Link 2, System memory atomics supported: true
Link 2, SLI is supported: false
Link 2, Link is supported: false
Link 3, P2P is supported: true
Link 3, Access to system memory supported: true
Link 3, P2P atomics supported: true
Link 3, System memory atomics supported: true
Link 3, SLI is supported: false
Link 3, Link is supported: false
Link 4, P2P is supported: true
Link 4, Access to system memory supported: true
Link 4, P2P atomics supported: true
Link 4, System memory atomics supported: true
Link 4, SLI is supported: false
Link 4, Link is supported: false
Link 5, P2P is supported: true
Link 5, Access to system memory supported: true
Link 5, P2P atomics supported: true
Link 5, System memory atomics supported: true
Link 5, SLI is supported: false
Link 5, Link is supported: false
GPU 3: Tesla V100-SXM2-16GB (UUID: GPU-f5a6ea19-ce0f-bd08-d367-3ecbb135ff3b)
Link 0, P2P is supported: true
Link 0, Access to system memory supported: true
Link 0, P2P atomics supported: true
Link 0, System memory atomics supported: true
Link 0, SLI is supported: false
Link 0, Link is supported: false
Link 1, P2P is supported: true
Link 1, Access to system memory supported: true
Link 1, P2P atomics supported: true
Link 1, System memory atomics supported: true
Link 1, SLI is supported: false
Link 1, Link is supported: false
Link 2, P2P is supported: true
Link 2, Access to system memory supported: true
Link 2, P2P atomics supported: true
Link 2, System memory atomics supported: true
Link 2, SLI is supported: false
Link 2, Link is supported: false
Link 3, P2P is supported: true
Link 3, Access to system memory supported: true
Link 3, P2P atomics supported: true
Link 3, System memory atomics supported: true
Link 3, SLI is supported: false
Link 3, Link is supported: false
Link 4, P2P is supported: true
Link 4, Access to system memory supported: true
Link 4, P2P atomics supported: true
Link 4, System memory atomics supported: true
Link 4, SLI is supported: false
Link 4, Link is supported: false
Link 5, P2P is supported: true
Link 5, Access to system memory supported: true
Link 5, P2P atomics supported: true
Link 5, System memory atomics supported: true
Link 5, SLI is supported: false
Link 5, Link is supported: falsePowered by Discourse, best viewed with JavaScript enabled"
486,grid-k2-on-dell-r720-not-able-to-boot-with-crash-screen,"I am having very weird issue with GRID K2When I install the card, I am unable to boot.System looks like its getting booted but right before RAID controller initialize, the screen turns like this.https://ip1.i.lithium.com/85962a601a16244821647597b8e6d7a45cb65773/68747470733a2f2f7777772e656576626c6f672e636f6d2f666f72756d2f696e6465782e7068703f616374696f6e3d646c6174746163683b746f7069633d31343934312e303b6174746163683d3834303435383b696d616765System Model	PowerEdge R720
BIOS Version	2.7.0
Firmware Version	2.65.65.65
CPU	2x E5-2620 v2
Power	Dual 1100WK2 BIOS 80.04.F5.00.03 and 80.04.F5.00.04
K2 PLX BIOS F0.47.1C.00.C0I tested K2 on Dell T3610 which is confirmed working and able to detect from Linux systemnvflash shows following information from T3610NVIDIA display adapters present in system:
<0> Quadro K2000         (10DE,0FFE,10DE,094C) H:–:NRM  S:00,B:02,D:00,F:00
<1> PLX (8747h)          (10B5,8747,10B5,8747) H:–:NRM  S:00,B:03,D:00,F:00
<2> GRID K2              (10DE,11BF,10DE,100A) H:04:SP8  S:00,B:05,D:00,F:00
<3> GRID K2              (10DE,11BF,10DE,100A) H:04:SP16 S:00,B:06,D:00,F:00Right now, I am not even able to go into BIOS setup because the system freezes at above screen shot.When I checked in iDRAC, I do not see K2 is in Hardware list tabsI also tried both Riser2 and Riser3 but both seems to have same issue.Is there specific setting that I need to do in BIOS prior to install K2 into system?Please help me why am I having such issue.Thanks,

grid-r720.jpg1210×908 333 KB
Powered by Discourse, best viewed with JavaScript enabled"
487,vgpu-11-0-released-09-07-2020,"For those looking to run the latest features and enhancements in their environment, vGPU 11.0 is now available for download from the Portal!Full documentation about this release is available form here: NVIDIA Virtual GPU Software DocumentationThis release contains some very nice additions, including the ability to support ""Cross-branch drivers"", which there have been a lot of requests for. The minimum combination of vGPU drivers required to support and use this feature are vGPU 10.0 and 11.0. Please read the documentation for full details.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
488,how-to-update-an-existing-registered-license-server-with-a-backup-license-server,"Hello,
I decided to add High availability functionality to my existing NVIDIA license server. I need to download an updated license file in order to add the new license server.
How do I update an existing registered license server with a backup license server?
When trying to create a new on I get the error: ""Host ID ""xxxxxxx"" already exists (or a host with the same UUID exists).""
I couldn’t find where to update an existing license server.When you add a license server to the License Management Portal, you do this as either a single license server, or as a HA pair. Due to current limitations in the License Management Portal, you cannot turn a single license server into a HA pair once it’s been added, nor can you remove it. The easiest way to resolve this is either:A: If you contact NVIDIA Support, they have the ability to remove an existing license server for you. You should then be able to re-add it as a new license server along with your new backup license server. Create the new license which will be bound to both of those new MAC addresses and download it. To stop any unexpected issues, reset your existing license server before applying the new license file to it using this link: https://nvidia.custhelp.com/app/answers/detail/a_id/4111/~/a-change-occurs-on-the-grid-licensing-server-such-as-ip-address,-or-a-change-in. Import the new license file into both of your license servers, and using a GPO, push out the new addresses onto your vGPU enabled VMs.B: Leaving your existing license server running to maintain service, build 2x new license servers in your local environment (you’ve already built 1 new one). Once built, add them to the License Management Portal as a HA pair. Remove the licenses from your existing single license server (un-map add-ons). Then create the new license which will be bound to both of those new MAC addresses. Download and import the new license file into both of your license servers, and using a GPO, push out the new addresses onto your vGPU enabled VMs. Regarding your old license server, you can either leave this unused in the License Management Portal, or contact NVIDIA Support to remove it.C: Assuming your license server runs as a VM and not a physical server … Shutdown your local license server, generate a new MAC address in your hypervisor and power it back up. Using the URL from Option A, reset your license server. In the License Management Portal, remove the licenses from your existing single license server (un-map add-ons). Then create the new license which will be bound to both of those new MAC addresses. Download and import the new license file into both of your license servers, and using a GPO, push out the new addresses onto your vGPU enabled VMs.I have not personally tried Option A, however I know that NVIDIA Support have the ability to remove a license server. If it were me, I’d go with option B, as you can run this in parallel with your existing license server until the change over happens. There won’t be any issues with VMs not being able to contact the license server if there are any delays in bringing the service back up. You can take your time and not be rushed. However, if you have other services on your existing license server that are reliant on a specific MAC address, then you may want to use options A or C.Just to add … License server management is something that’s being worked on internally at NVIDIA as we speak. Expect new management features and enhancements to be released as and when they are developed. Everyone I’ve spoken to is well aware of the current limitations and these are being worked on. So don’t worry, this will become easier as the platform evolves :-)BenNetworking is defined as the act of making contact and exchanging information with other people, groups and institutions to develop mutually beneficial relationships, or to access and share information between computers. There are a lot of people who are looking for the knowledge of networking books so i am here to highlight a best book for NetworkChampionBookPowered by Discourse, best viewed with JavaScript enabled"
489,windows-10-64-virtual-machine-and-nvidia-grid-k1,"Hello,we now want to use Windows 10 VMs in our ESXi Environment.
Now we have Windows 7 with Nvidia Grid K1 and its working fine.But with WIndows 10 - i cannot see ""hardware"" - Driver installation says that there is no hardware.
But - i can download the drivers for Windows 10 and Grid K1Why is there no card in Windows 10 to see ?Thank youMarcusAre you inside the specifications?Client: Windows 10 RTM (1507), November Update (1511), Anniversary Update (1607),Creators Update (1703) (32/64-bit)Hypervisor: ESXi 6.5 or lower?K1/K2 is EOLHello Gormat,yes it is EOL - but i can download the drivers
370.41-grid-desktop-notebook-win10-64bit-international-whqlVersion Windows 10 1903ESXI 6.7.0As Gormat already mentioned. There is no support for K1/K2 and Win10 1903 release. The board is EOL and even the software branch is EOL since a few weeks.Powered by Discourse, best viewed with JavaScript enabled"
490,gpu-purchase-decision,"Hello everyone,I need some advice regarding the right Nvidia GPU for my needs. My goal is to run a full-fledged VDI (Virtual Desktop Infrastructure) in the Citrix environment. Currently, we are using a pure Citrix server desktop structure. I’m unsure whether the A100 or the A40 would be the best choice. The GPU will be used to run various GIS applications, Adobe products, and CAD products.Thank you in advance!You should use the A16 GPU for your needs.Powered by Discourse, best viewed with JavaScript enabled"
491,license-not-releasing-when-vdi-logs-off,"Was doing some performance testing, and noticed our vGPU backed Horizon desktops weren’t going above 15 fps. After some digging, I found that our Horizon VMs aren’t releasing licenses to the server. It appears that the license expiry time is 2 months for some reason. Not sure how to change this, or get the licenses to release.Just got off the phone with NVIDIA. Turned out I had a ‘bad’ version of the licensing server. Uninstalled that version, installed the latest, and all appears to be well.Powered by Discourse, best viewed with JavaScript enabled"
492,help-needed-uncorrectable-ecc-memory-error,"JUST BOUGHT TWO NVIDIA A100-PCIE-40GB. One of the two  says ‘DRAM Uncorrectable:  47’ and does not run.
Is this a hardware problem?  If it is a permanent damage I guess I can have the unit replaced since I just bought it. I read that one has to reset the unit but I don’t want to do it if it involves loosing memory banks  or any limitation to my brand new unit.I would try to replace the GPUThanks.Powered by Discourse, best viewed with JavaScript enabled"
493,how-to-configure-multiscreen-for-video-games-with-a-gtx-1080ti,"Hello everyone, does anyone know how to configure multiscreen for video games with a GTX 1080ti? I have tried what they recommend here but I can’t quite understand what is wrong. Any other tutorial or recommendation?You can simply run your game in “windowed fullscreen” mode to achieve multiscreen video games. I’ve been able to do this with a grid of 6 monitors plugged into 2 x 1080Ti with and without SLI.Because the monitors are 4k, I was able to stretch the video game window to 8k+. However a 1080Ti, even 2 x 1080Ti are not capable of playing 8K DX12 games at a reasonable framerate. Either way, it is doable.You can simply run your game in “windowed fullscreen happy wheels” mode to achieve multiscreen video games. I’ve been able to do this with a grid of 6 monitors plugged into 2 x 1080Ti with and without SLI.Because the monitors are 4k, I was able to stretch the video game window to 8k+. However a 1080Ti, even 2 x 1080Ti are not capable of playing 8K DX12 games at a reasonable framerate. Either way, it is doable.Yes was thinking of something like that as well…Powered by Discourse, best viewed with JavaScript enabled"
494,vmware-vgpu-v100-cant-run-a-few-profiles-together,"Hello all ,the environment is Vmware esx6.7 u3 &Nvidia card v100 .
The license should be received and the license server has been installed.
I should try deploy vGPU via Horizon VDI and directly run VM’s.When I try to run another VM or the different desktop pool I receive the error message :
The amount of graphics resource available in the parent resource pool is insufficient for the operation.HiWhich vGPU Profile are you using on your VMs and how many V100s do you have?RegardsMGHiI have only one v100. I found that I can run only one profile , I can’t run a few different profile on one card.How I can a few VM’s withe different properties?Thank ,
IgalHiWhich specific vGPU Profiles are you trying to use? (What’s the name of the vGPU Profile?)You can only run the same vGPU Profile on a single GPU. Assuming you have the V100 32GB, you can run the following:1x 32GB
2x 16GB
4x 8GB
8x 4GB
16x 2GB
32x 1GBThe V100 will also support A, B, C and Q workloads. Make sure you’re using the same vGPU Profile on all of your VMs.RegardsMGHiGot it.
thank you very much for the answer!another question , if I want use Vmware shared vGpu mode , how I should work?
is it possible to provision vgpu for the few Vm’s at all?Thank you ,
IgalPowered by Discourse, best viewed with JavaScript enabled"
495,m10-1q-profile-not-allowing-more-than-2-displays-with-10-2-drivers,"Hello,We recently upgraded our ESXi hosts and VMware Horizon 7.12-managed virtual desktops from vGPU software version 8.0 to version 10.2.  According to the release notes for the software, I thought that this would allow the M10-1Q profile to allow up to 4 display heads.However, when in Horizon, the ""max number of monitors"" is locked to 2.  I’ve tried creating a new pool with the snapshot, but as soon as Horizon detects that the graphics drivers is the M10-1Q profile, it still locks the max number of displays to 2.Any assistance understanding and/or fixing this would be appreciated.Thank you,JordanHi JordanWhat resolution are the 4 monitors?Out of interest, if you change to a higher vGPU profile for a test, does it work with the 4 monitors?RegardsMGThank for the reply.On further testing, I note that I can in fact do at least 3 monitors, so I guess there’s no actual issue with the amount of pixels the profile will allow displays.My issue, then, is the for non-persistent pools in VMware Horizon, in the pool settings the max number of monitors shill shows up as 2, and this is incorrect.  My understanding is that the there is no maximum number of monitors, just a maximum number of pixels, so I guess there’s no ""correct"" value to put here, but perhaps it could be indicated somewhere in the documentation that Horizon will continue to display this value.Hi JordanBack when vGPU 10.0 was released, NVIDIA switched from a ""Fixed Resolution"" to ""Pixel based Resolution"". They did this due to the large amount of non-standard panels that are becoming increasingly popular, such as the Super Ultra-Wide variants. I myself use a Dell U4919DW which has a resolution of 5120 x 1440. At first glance, the resolution looks quite high, however once you calculate the total amount of pixels, it’s not very high and is actually less than a single 4K panel. The problem is that because it’s a non-standard resolution, the previous versions of vGPU drivers wouldn’t support it, and when trying to run Virtual Machines in full screen, I’d have a full screen vertical display (1440), but with the black ""bookend"" on both ends of the screen as the vGPU driver had a maximum horizontal resolution of 4096 (and my monitor is 5120) so wouldn’t accept the resolution, even though that same version of vGPU driver would support multiple 4K monitors (up to 4) which as said, with even just 1 of those being a higher total pixel count than my U4919DW. The logical option for NVIDIA was to move to a far more flexible configuration, which is where we are today.The reason for asking how many monitors you have and the resolution of them, is that with the 1Q profiles you can support up to 17694720 pixels. A few examples of common resolution options are available here: https://docs.nvidia.com/grid/10.0/grid-vgpu-user-guide/index.html#vgpu-types-tesla-m10 so you can calculate what you’ll be able to run.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
496,losing-driver-after-reboot-ubuntu,"After deploying a default Linux VM(NVIDIA Quadro Virtual Workstation - Ubuntu 18.04)
(All default settings, no changes) and following the driver installation I can succesfully run nvidia-smi which gives me the correct output.But if I stop the instance (Without changing anything on the VM) and restarting it and run nvidia-smi again I get:NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.In other words I can’t reboot the VM without losing the driver.Is that the expected behaviour? Is this fixable? I don’t really get the point of having a VM if you can’t stop and start it.Hi Kazaloo, Can you elaborate which Cloud Service you are using here ?Google Cloud. Sorry, I thought this subforum is specifically for GCP.I just used this image:Spend smart, procure faster and retire committed Google Cloud spend with Google Cloud Marketplace. Browse the catalog of over 2000 SaaS, VMs, development stacks, and Kubernetes apps optimized to run on Google Cloud.I just double checked and can confirm it’s reproducable.Edit:
I was thinking about this. I am using the 300$ Trial account currently (because - why say no to free money?), could that be a problem?Powered by Discourse, best viewed with JavaScript enabled"
497,passthrough-for-ms-hyper-v-sles15-vm,"I have MSI laptop with GeForce RTX-3060 card (NVidia 11.8 suite is installed), running Windows 11.
In its Hyper-V the SUSE/SLES15 VM is created, all standard developer tools and appropriate NVidia drivers are installed.
The problem is, that we don’t know, how to make this VM SLES15 to see the NVidia card on the host, how to install/enable passthrough (or some other ?) SW mechanism for it.
Any help/link/reference will be highly appreciated.
Thanks !Powered by Discourse, best viewed with JavaScript enabled"
498,dual-virtual-monitors-on-aws-t4-grid-gpu-cloud,"I have a G4dn.xlarge instance that is running a single GPU T4, I know it can handle 4 monitors on its own but im not able to access them as the server is in the cloud and i cant plug in “fake” displays.Is there a way to activate an extra display on the T4 card without using RDP. I want to just use Teamviewer but i need the 2 displays always active.ThanksHiUse DCV instead of Teamviewer. It’s free on AWS and you just use your browser instead of having to install another client.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
499,random-blackscreens-vgpu-vmware-horizon,"Hi all,we have random, rarely black screens in our vdi environment. Only a reboot of the affected VM will help to fix it.
Nvidia Support told us to upgrade vGPU driver from 13.2 to latest 13.4.
We using Nvidia M10 on VMware Horizon with Windows 10 - 20H2 and  grid_m10-1b profile and VMware ESX 7.0 U3dAfter upgrading we can still see a lot of these events in the nvidia esx logs+++++++++++++++++
2022-09-09T10:46:31.072Z Er(02) vthread-24234322 - vmiop_log: Assertion Failed at 0x14416cd7:397
2022-09-09T10:46:31.072Z Er(02) vthread-24234322 - vmiop_log: 12 frames returned by backtrace
+++++++++++++++++Does anybody know if it normal?Regards,
VM_MasterHi,
sounds like a known issue. NVES should be aware of this. Upgrading to 13.4 won’t fix it as the root cause is still under investigation. Please contact NVES once again to add your case to the list of affected customers.regards
SimonThanks Simon for this info.NVES told me that this is fixed in 13.4.
But I can’t find any information in the relase notes about this issue. So why is there no public information about it?I will talk again with NVES.Just send me your case ID with PM. Will route your case in the right direction. I’m not aware that this is fixed in 13.4.Hi Simon,did you get my PM? Any news regard this issue?Hi there @VM_Master / @sschaber  - are there any updates on this issue?We are running ESXi 7.0 U3g (20328353) and the latest 13.4 Nvidia vibs / guest drivers.Last week we had two instances of this.  All users on the same graphics card got a black screen - we had to move them to a different host and reboot them.  Obviously this is very disruptive!Hi,our Eng is working with high priority on this issue. We hope to have a fix soon. Unfortunately this is a very complex issue and therefore requires some time. Please keep your support ticket open or create a new one if already closed to get the information as soon as there is a fix available.Best regards
SimonThanks @sschaber  - great thanks, good to hear this is being actively worked on.  We have a case open and will follow up further there.
Kind regards, TomHi,good news. Our issue seems to be solved after upgrading to VMware GRID v13.4 (on all esx hosts and also on our VDIs).And we set this regkey on all VDIs from 1 to 0
HKLM\Software\Policies\VMware, Inc.\VMware Blast\config
PixelProviderForceViddCapture REG_SZ : 0ESX version: 7.0.3, 20328353
Horizon version: 2111, Agent 8.5.0We don’t have this random blackscreens anymore. Also the reconnect time is now faster.Powered by Discourse, best viewed with JavaScript enabled"
500,poor-performance-with-large-cad-files,"Just bought a new computer for Cad design. We work with large OEM cad files and I’m not sure why I am getting poor performance from this video card? I have the Quadro RTX 4000. any thoughts or help with settings for large cad file in the size of 1.5gb of dataThanks for the inputHiA few questions to help give a bit more detail …What’s the exact issue you’re experiencing?
What’s the full, detailed specification of the workstation?
What resolution are you running?
Where are your CAD files located?RegardsMGIntel(R) Xeon(r) E-2286G CPU @ 4.00GHz 4.01GHz
32.0 GB ram
x64
NVIDIA Quadro RTX 4000I am trying to work with cad files from GM. example…I receive large cad files lets say of a truck its engine the entire front, fenders, hood, all of the goodies… I could litterally make a truck from these files they send me…they are the exact cad files they use to manufacture the vehicle… so very detailed files, in the size of 1.5 GB and when I load them into my cad software (VISI) my computer struggles with dynamically rotating them. I had this problem on an older computer so I contacted dell and told them I need a bad boy computer with a video card that would handle these cad file I am getting and this is what they recommend I get. I use a 3DCONEXXION  spaceball/mouse to rotate the file on the screen…It is set to 1080p @ 1920x1080 and I am running 2 monitors.Is it my settings?? or something else.Thanks MickeyHiThanks for the additional details.That’s a good spec, can’t initially see any issues with that. 4GHz base with a 4.9GHz Turbo is right up there!I don’t have any experience with VISI unfortunately, so I’m unsure how it uses the hardware and which components are most relied on for performance gains, and trying to review / validate their system requirements was unhelpful as their Site seems out of date and they don’t have any useful specifications to go on.Can I please ask that you run this small monitoring utility: Releases · JeremyMain/GPUProfiler · GitHub and collect / review some metrics from your workstation when it’s running VISI and having issues. This will help guide you towards any component that might be struggling. What you can also do as well, is have the ""Windows Resource Manager"" running (not ""Task Manager"" as that only shows the CPU as a single entity) and this will show you the utilisation of each of your CPU Cores so that you can see if it’s a single threaded limitation.Purely as an application comparison, it may be worth downloading an evaluation of the current version of AutoCAD to see if that exhibits the same performance issues. This may be a non-starter depending on whether you have a corporate defined application stack.If you can’t get anywhere with the monitoring, it would be worth speaking to VISI Tech Support to see if there’s some application tuning that can be done to improve the performance (however that would typically mean there is a hardware limitation).Regardless of the above, a 1.5GB CAD file is a big file to deal with! It may need breaking down into smaller parts, but I do realise this sometimes isn’t an option as you want to see the entire model at the same time.I’d be really interested to see the hardware metrics and what kind of load it generates on your workstation if you’re able to share.RegardsMGthank you for the reply I will get you some data…Powered by Discourse, best viewed with JavaScript enabled"
501,error-0x00000116-on-nvlddmkm-sys-when-using-vgpu-passthrough-works,"Hello everyone.I have an issue with a POC for a customner that are trying out vGPU with a K2 Card. I have done everything according to the manual but when I add a vGPU instead of the Passthrough card I get a Error 0x00000116 BSOD on nvlddmkm.sys. Like I said using Passthrough works fine.I have don tests when using passthrough using GPU-Z, RedWay 3D Turbine, Unique etc etc. and I get the performance I want. But as soon as I switch to vGPU (no matter which one) the server BSOD.I know the HW is not in the HCL but I can’t see how that has anything to do with it but I might be wrong.Setup:Host:
P8Z77 -V PRO
Intel i7 4770 (non k)
32GB RAM
Intel Gigabit NIC
XenServer 6.2 SP1 HF4Guest:
Windows 2008 R2
4 vCPU
16GB RAM
NVIDIA GRID vGPU Software Release 331
http://www.nvidia.com/download/driverResults.aspx/74598/en-usAny ideas?RegardsJörgen PerssonHello Jörgen,the reason might be that the K2 is not certified for your Host. You can find all GRID certified servers at Page Not Found | NVIDIANVIDIA works very close with all vendors on that site to certify the GRID GPUs. GRID GPUs are different to other GPUs and sometimes require BIOS changes from the server vendor for example. The error you are mentioning might be a result of that.Erik Bohnhorst | Solution Architect – GRID
NVIDIA CorporationI know that the host itself is not certified but to make the customer pay for the hardware before them knowing that it acctually works is the reason for the POC. I guess then that the only way to show that it works is to leave it at Passthrough then?I just think it’s wierd since XenServer makes it ""hardware unaware"" with the XenServer tools and I can’t see how it then ""cares"" about the hardware XenServer is running on.If anyone else has any ideas please feel free to respond.//Jörgen PerssonPowered by Discourse, best viewed with JavaScript enabled"
502,odd-performance-blinks-inside-grid-xendesktop-vms,"I am running a VMWare 6.5 Farm with about 120 Grid Accelerated VDI.6 HP WS460c Blades with 4 x Tesla M6 in a C7000 HP Blade Chassis
VMWare 6.5 patched up to current
120 Windows 10 VDI using LTSB 2016 (1607)
Citrix Xendesktop 7.18
MCS image - Non Persistent VDI
Grid M6-1B Profiles on each VMOur primary office site is connected to a Co-Located data center by redundant 1Gb links. We typically see Latency and Round Trip time in session between 4-8ms. Each VM has 4 vCPU and 16GB of RAM, along with the GPU, and the disk runs on the VMWare Paravirtual Controller. Our Citrix Policy is setup to use the video codec on actively changing regions on high quality. We are using NVENC for moving images within the session.At random points throughout the day, users complain about their VDI freezing for less than a second, and then resuming. It’s very obvious when they are running AV materials, because both audio and video pause and then resume like nothing happened. Sometimes this freeze will cause the audio to desync from an online video on sites such as youtube or vimeo. Typing will also be delayed, and a number of words will suddenly run across the screen. All users see the issues occur, but it’s not something that happens at the same time to everyone.Storage is an all flash array, and as far as I can tell average read and write latency are under 1ms. Network load seems low, and according to our monitoring tool, we aren’t seeing dropped packets or spikes in round trip latency on our routers. CPU load on the VM’s and in the esxi host itself looks entirely within tolerable limits.We have one additional host that is used primarily for testing and updating our images, and upgraded it to the latest Grid 7.2 drivers, as we are on 5.x in production right now. This did not have a meaningful impact on the issue. The worst part about the problem is that I have yet to devise a method of reliably recreating the issue. I can hammer on a session with multiple videos and applications running simultaneously, and they won’t flinch. Yet other users complain that they have to watch their typing catch up with them multiple times per hour.When the issue occurs, the entire VM appears to freeze momentarily, and then resume. If anyone has any insight, I would greatly appreciate it.HiIf the entire VM freezes, then that sounds like a connectivity / networking issue to me. It doesn’t sound performance related, and your hardware specs sounds fine.4-8ms is very good, so it’s not latency related.What are the end point devices that are being used? Which version of Receiver / Workspace App do you have on them?Have you tried accessing the VMs from a different geographical location / over a completely different connection to see if it still occurs?RegardsBenI’ve dumped logs from every piece of networking equipment between the clients and the endpoints. I have yet to find so much as a dropped packet.The endpoints are Intel NUC Workstations with Intel i3-6100’s in them. They have 8GB’s of RAM and we run ThinKiosk on top of Windows 10 to deliver VDI. Citrix Receiver is 4.12, but we have been able to replicate the issue in testing on the latest Workspace 1812.Connecting to the VDI externally through our netscaler gateway doesn’t alter the situation.Well, that all sounds fine.RegardsBenYes, we’ve tried different Citrix video policies, and they all produced similar results.Typical users have two 1920x1080 monitors.We’ve tried multiple end points. We have some Mac, Linux, and PC clients in the office, and it’s universal.I’m beginning to think it might be a CPU ready time issue, but more testing is required.HiWhich CPUs are you running and what’s the over-commit ratio on them?Have you been through the BIOS settings to make sure they’re configured appropriately for your deployment and the same across all hosts? I appreciate that by checking that you may need to power cycle the Hosts, so it’s not always a quick / easy thing to check.Lastly, has this issue been there since the start of the deployment? Or has it gradually gotten worse over time / through updates or through additional user density?Sorry for all the questions, just trying to understand exactly what you’ve tried and the environment. As you can appreciate, there are many many variables within the stack that can cause issues.RegardsBenIt’s been worse since we added patches for Spectre and Meltdown to the hosts. We originally deployed these hosts with Windows 7, and eventually migrated to Windows 10. Performance degraded slightly with Windows 10, but these random pauses in the sessions didn’t start until after we deployed patches for Spectre and Meltdown.All the hosts have the CPU’s configured for the highest power profile possible, with C-States and P-States disabled. Each host has Dual Intel E5-2695 V4’s with 18 physical cores. Hyperthreading is enabled. We have about 82 vCPU’s configured on 72 logical processors. If you count the additional logical CPU’s in the calculation, we are at a 1.125:1 commit ratio. It goes up to 2.3:1 if you only count physical cores.A new wrinkle to this.Yesterday I deployed some machines to a hypervisor that is used for image updates and testing purposes, and discovered that the freezing disappears when I turn off NVENC for session encoding. Has anyone else experienced momentary pauses in their video stream in session while using the GPU to encode the stream? CPU Usage and overall utilization goes up in the session, which I’d like to avoid, but the random 1-2 second pauses have dissipated.HiThanks for the additional information.Regarding your BIOS tuning, I have a couple of articles that you may find interesting. The first one is a slightly older article that discusses Single Core vs All Core Turbo and would be applicable to your configuration. Note your Base Clock, All Core Turbo Clock vs Single Core Turbo Clock:Clock speeds on modern Intel processors are not straight-forward, a fact that is attested to by the several articles we have published on that topic in recent years. This can lead to confusion over what CPU to pick when configuring a new computer,...The second article was written a few weeks ago and discusses various BIOS settings to help engage Turbo:https://www.mycugc.org/blogs/tobias-kreidl/2019/03/07/tale-of-two-servers-bios-settings-affect-apps-gpuThe above aside, that’s an interesting discovery with NVENC. I’ve not experienced that issue before. Out of interest, have you tried monitoring the encoders directly on the GPU through nvidia-smi just to see how loaded up they are? Or, a nicer way to visualise the utilisation would be to use NGPUTOP:Yet another ncurses GPU utilization monitor inspired by htop - JeremyMain/ngputopRegardsBenHi Jake,i had a similar issue on our environment some month ago. Here it was the ctxgfx.exe which crashed some times.
You can reproduce it when you kill the mentiond process.The process will start new and the screen flickers one time. Check the application logging or montiro the process with sysinternals procmon.Br
MatPowered by Discourse, best viewed with JavaScript enabled"
503,sys-class-mdev-bus-cant-found,"Hello bros, Please help me,
In RHEL 8.6 OS, GPU = A5000.nvidia-smi

image1047×463 12.6 KB
lsmod | grep vfio

image988×148 5.49 KB
But, in cd /sys/class Can’t found mdev_bus directory

image1724×163 12.7 KB
Please help me and God bless you!Do you have SR-IOV enabled?
You need to run /usr/lib/nvidia/sriov-manage -e ALLI have the same problem on RHEL 9.
SR-IOV enabled,  /sriov-manage -e ALL  ran.I don’t know if the reason might be below but I’ve compared RHEL 9 to Alma linux 8.6 (that was the previous version of vGPU I ran) and have found the following:RHEL 9:lsmod | grep vfio
nvidia_vgpu_vfio         65536  0
mdev                           32768  1 nvidia_vgpu_vfio
vfio_iommu_type1       45056  0
vfio                               45056  3 nvidia_vgpu_vfio,vfio_iommu_type1,mdevAlma 8.6:lsmod | grep vfio
nvidia_vgpu_vfio           27099 0
nvidia                            12316924 1 nvidia_vgpu_vfio
vfio_mdev                      12841 0
mdev                             20414 2 vfio_mdev,nvidia_vgpu_vfio
vfio_iommu_type1         22342 0
vfio                                32331 3
vfio_mdev,nvidia_vgpu_vfio,vfio_iommu_type1If you compare the two  vfio_mdev is missing in RHEL.
We are talking to different version of the OS (haven’t ran Alma 9)…Any ideas?
Thanks.I’m having the same issue on Oracle Linux 9 on kernel 5.14.0-70.30.1.0.1.el9_0.x86_64 with A5000SR-IOV is enabled in the BIOS and I ran /usr/lib/nvidia/sriov-manage -e ALLlsmod | grep vfionvidia_vgpu_vfio       65536  0
mdev                   32768  1 nvidia_vgpu_vfio
vfio_iommu_type1       45056  0
vfio                   45056  3 nvidia_vgpu_vfio,vfio_iommu_type1,mdev
image1606×722 36.4 KB
Any Ideas?I found the solution, the issue is with the A5000 having It’s physical display-ports enabled.“Some supported NVIDIA GPUs don’t have vGPU enabled out of the box and need to have their display ports disabled. This is the case with our RTX A5000, and can be achieved by using their display mode selector tool”./displaymodeselector --gpumodeIt’s an interactive prompt and basically you need to select “physical_display_disabled” and then choose for which gpus, after that when executing /usr/lib/nvidia/sriov-manage -e ALL you should have some output, then reboot. I created a crontab entry so that this is executed on reboot, like so.@reboot root /usr/lib/nvidia/sriov-manage -e ALLBut you can also create a systemd unit to do this.Here are a bit more details regarding this issue.https://pve.proxmox.com/wiki/NVIDIA_vGPU_on_Proxmox_VE_7.xGreetings :)Hi,just to add, this is also documented here: https://forums.developer.nvidia.com/uploads/short-url/wgqrloFXITvrWtGMI0QAMQVaWyD.pdfThese are workstation GPUs and therefore not enabled by default for virtualization.regards
SimonI was able to program the card for virtualization, now I have weird issue I create 4 mdev of 6g each and I’m getting some weird issues,The devices on the screenshot that are as (rev a1) work, but the ones as (rev ff) don’t work.

image1368×1422 198 KB
On the (rev a1) lspci looks goodlspci -v -s 41:00.0
41:00.0 3D controller: NVIDIA Corporation GA102GL [RTX A5000] (rev a1)
Subsystem: NVIDIA Corporation Device 147e
Flags: bus master, fast devsel, latency 0, IRQ 268, IOMMU group 45
Memory at b2000000 (32-bit, non-prefetchable) [size=16M]
Memory at 26800000000 (64-bit, prefetchable) [size=32G]
Memory at 27c30000000 (64-bit, prefetchable) [size=32M]
Capabilities: [60] Power Management version 3
Capabilities: [68] Null
Capabilities: [78] Express Legacy Endpoint, MSI 00
Capabilities: [b4] Vendor Specific Information: Len=14 <?>
	Capabilities: [c8] MSI-X: Enable+ Count=6 Masked-
	Capabilities: [100] Virtual Channel
	Capabilities: [258] L1 PM Substates
	Capabilities: [128] Power Budgeting <?>
Capabilities: [420] Advanced Error Reporting
Capabilities: [600] Vendor Specific Information: ID=0001 Rev=1 Len=024 <?>
	Capabilities: [900] Secondary PCI Express
	Capabilities: [bb0] Physical Resizable BAR
	Capabilities: [bcc] Single Root I/O Virtualization (SR-IOV)
	Capabilities: [c14] Alternative Routing-ID Interpretation (ARI)
	Capabilities: [c1c] Physical Layer 16.0 GT/s <?>
Capabilities: [d00] Lane Margining at the Receiver <?>
	Capabilities: [e00] Data Link Feature <?>
Kernel driver in use: nvidia
Kernel modules: nouveau, nvidia_vgpu_vfio, nvidiaBut on the (rev ff) I get the following errorlspci -vv -s 41:01.0
41:01.0 3D controller: NVIDIA Corporation GA102GL [RTX A5000] (rev ff) (prog-if ff)
!!! Unknown header type 7f
Kernel driver in use: nvidia
Kernel modules: nouveau, nvidia_vgpu_vfio, nvidiaI did a bit of research and seems to be issue with power or thermal apparently but the card is idle, not doing much, plugged in a chassis in a data center.Hi folks,
I am having the same issue on “NVIDIA A100 80GB PCIe”. The mdev_bus directory hasn’t been created.
SR-IOV and IOMMU are enabled as well.Would it be the problem due to the Display mode enabled?
If yes, how can I disable it? As the A100 PCIs is not in the list of displaymodeselector supported  GPUs?Thank youHi everyone!If you have a problem with (rev ff), you also need to enable ACS and ARI in your BIOS. In my case of ASUS PRIME X570-P BIOS 4408:
Advanced > AMD CBS > NBIO Common Options > ACS Enable
Advanced > AMD CBS > NBIO Common Options > PCIe ARI SupportI meet the same problem.Is there any solution?I meet the same problem. After enabling sriov, it works.
But must A100 enable sriov to use grid vgpu?Hi,
I also meet the same problemon “NVIDIA A100 80GB PCIe”,.
I am having trouble using vGPU on Ubuntu KVM.
Is there any solution?Powered by Discourse, best viewed with JavaScript enabled"
504,ax800-dimensional-info-3d-cad-step-file,"The product brief here has some dimensional info but not enough. hpc-converged-accelerator-ax800-product-brief.pdf (widen.net)States NVIDIA Form Factor 5.5 Specification (NVOnline reference number 1063377)I need this document as well as a 3D STEP file of this product if possible so I can design a custom system to hold it.Powered by Discourse, best viewed with JavaScript enabled"
505,vgpu-with-q-profile-on-centos-7-x-cause-xorg-fail-to-load,"Hi,
i’m encountering a strange problem when creating a new virtual machine with a tesla P4 connected with vGPU tecnology.
My enviroment is configured with:-DELL R740
-NVIDIA TESLA P4
-SSD
-VMWARE ESXI FOR DESKTOP 6.7U3
-HORIZON VIEW 7.10 or 11
-NVIDIA vGPU version 9.2 or 10 (the problem appears with both versions)I need to configure a pool of linux vm (centos or ubuntu, but centos is preferable) for an High school and the student must connect using horizon view and use a 3d accelerated desktop.
The main problem is referred to the Xorg service that is unable to start after the reconfiguration using the command ""nvidia-xconfig""The error that appears is the following:
I’ve followed this steps to configure the vm:1-installed from ISO
2-configured the virtual hw
3-launched the following commandsBASIC INSTALL
yum -y update
yum install libappindicator-gtk3
sudo yum -y install gcc-c++
sudo yum -y install kernel-devel-$(uname -r)
sudo yum -y install kernel-headers-$(uname -r)
yum -y groupinstall ""GNOME Desktop"" ""Development Tools""
yum -y install kernel-devel
yum -y install epel-release
yum -y install dkms
Yum  -y install mcSE LINUX
Open the file /etc/selinux/config  
Change option SELINUX to disabled
Restart the machineBLACKLIST NOVEAU DRIVEREdit /etc/default/grub. Append the following  to “GRUB_CMDLINE_LINUX”
rd.driver.blacklist=nouveau nouveau.modeset=0Generate a new grub configuration to include the above changes.
grub2-mkconfig -o /boot/grub2/grub.cfgEdit/create /etc/modprobe.d/blacklist.conf and append:
blacklist nouveauBackup your old initramfs and then build a new one
mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r)-nouveau.img
dracut /boot/initramfs-$(uname -r).img $(uname -r)
RebootCheck if noveau is disabled
/sbin/lsmod | grep nouveauINSTALL NVIDIA DRIVER
sudo init 3
sudo service gdm stop
chmod +x NVIDIA-Linux-x86_64-xx.xx-grid.run
./NVIDIA-Linux-x86_64-xx.xx-grid.runsay no to automatic configuration to X service during setup (also tried but the problem persist)reboot4-after reboot I’ve checked the pci hw of th NVIDIA cardand tried the following commandsnvidia-xconfig --enable-all-gpus --use-display-device=none --busid=""PCI:02:02.0""
nvidia-xconfig --enable-all-gpus --separate-x-screens --busid=""PCI:02:02.0""The error is the same when I reboot or launch the startx command.5-The /etc/Xorg/xorg.conf configuration is the following:Section ""ServerLayout""
Identifier     ""Layout0""
Screen      0  ""Screen0""
InputDevice    ""Keyboard0"" ""CoreKeyboard""
InputDevice    ""Mouse0"" ""CorePointer""
EndSectionSection ""Files""
EndSectionSection ""InputDevice""
# generated from default
Identifier     ""Mouse0""
Driver         ""mouse""
Option         ""Protocol"" ""auto""
Option         ""Device"" ""/dev/input/mice""
Option         ""Emulate3Buttons"" ""no""
Option         ""ZAxisMapping"" ""4 5""
EndSectionSection ""InputDevice""
# generated from default
Identifier     ""Keyboard0""
Driver         ""kbd""
EndSectionSection ""Monitor""
Identifier     ""Monitor0""
VendorName     ""Unknown""
ModelName      ""Unknown""
Option         ""DPMS""
EndSectionSection ""Device""
Identifier     ""Device0""
Driver         ""nvidia""
VendorName     ""NVIDIA Corporation""
BoardName      ""GRID P4-2Q""
BusID          ""PCI:02:02.0""
EndSectionSection ""Screen""
Identifier     ""Screen0""
Device         ""Device0""
Monitor        ""Monitor0""
DefaultDepth    24
SubSection     ""Display""
Depth       24
EndSubSection
EndSection6-In the Xorg.conf I’ve tried to remove all the section leaving only the ""Device"" active but nothing change, the (EE) no screen found (EE) persist.
Tried mixed configuration leaving also ""screen"" and ""monitor"" active but the result is the sameCan anyone help me?
thanksAlready followed this topichttps://gridforums.nvidia.com/default/topic/962/nvidia-virtual-gpu-technology/m60-vgpu-with-xorg-quot-ee-no-devices-detected-quot-/post/3370/#3370Powered by Discourse, best viewed with JavaScript enabled"
506,microsoft-dda-and-rtx-a-4000-4500,"Good morning everyone,I seem to have run into an issue regarding Nvidias Licensing, sadly our Salesrep and Nvidia Partner was not able to give us a clear answer regarding the following Topic:Do we need any licensing to use DDA (Passthrough) with an Nvidia RTX A 4000 or 4500 to a VM that is an RDSH Server.If we would decide to use an RTX A 5000  instead, would that GPU require a licence ?We couldn’t really find any good information regarding that topic.You won’t need a license for A4000 and A4500 as these are pure RTX GPUs.
A5000 is a bit different as it could run in RTX mode as well as in Datacenter mode (vGPU support). So it would depend on the mode and the driver in use (RTX<–>vGPU driver)Hope this helpsThank you for your quick reply, that helps me alot.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
507,citrix-vda-disconnecting-and-no-reconnect-possible,"Hi folksWe have a case open for this with NVIDIA and they already acknowledged that this is a bug (internal tracking bug 3445082) since there are more customers with the same problem.When the issue occurs, the user experiences a sudden disconnect or a black screen within the Citrix session. After the disconnect, the VM itself is not in a hanging state and can be accessed via remote console. After this happens the user has no chance to reconnect to his session again and we have to force restart the Windows 10 VM.According to NVIDIA support, this only happens to Citrix VMs with 24GB memory or more. I just wanted to see if there is anybody elsa experiencing this problem and maybe we can exchange some information.Regards, CedyHi C3dywe recognized this behaviour aswell and fount it to be related with the NVIDIA vGPU driver drashing in the guest OS.
Check in the device manager of the affected VM if the GPU driver/device is loaded and without any error.RegardsHi GormetThanks for your answer and it always feels good to not be alone. Yeah the driver is definitly crashing inside the VM at some random point. In the meanwhile NVIDIA informed us that they were able to isolate the issue and provide a fix asap. Will keep you posted.Regards, CedyHello Cedy,is there anything new related to this issue?Greetings!Powered by Discourse, best viewed with JavaScript enabled"
508,nvidia-license-server-apache-struts-2-5-22-vulnerability,"Good afternoon all,I was wondering when the next version of the Nvidia License Server will be coming out to patch Apache Struts to at least 2.5.26. Tenable / Nessus is marking us for a high vulnerability due to his struts binary on our license server. Any information would be helpful. Thanks!Powered by Discourse, best viewed with JavaScript enabled"
509,licensing-server-dls-question,"Hello,The organization I work for setup a now legacy grid licensing server with some m60 cards back in 2018. Since the software has not been updated since then and we are building new hosts with newly purchased A40 cards, I was planning to create a new DLS using Nvidia Licensing V2.0 and move over our perpetual vWS licenses.That said, I have a couple questions:NLS V2.0.x says that the hypervisor that hosts the DLS must be “Microsoft Windows Server with Hyper-V 2019 Datacenter edition”. Am I to understand this must be Windows Server 2019 datacenter edition and that standard edition will not work?I cannot seem to find the updated vGPU or Windows driver software within the software downloads on the licensing portal. A few guides say it will be provided after the purchase of vWS licenses but since we purchased our licenses in 2018 I was wondering how we acquire vGPU 13.x or 14.x.Thank youDLS is a linux appliance. I would expect they tested it on DC edition which shouldn’t be relevant. So yes, works on Standard Edition.You need to have a valid SUMS for your licenses. If the maintenance is not valid any more you cannot download the latest software in the portal.Excellent, thanks! Seems maybe our licenses may be outdated so we will get more.Hi sschaber,Sorry to revive this but we have now been considering rolling out with Windows Server 2022. Will this be compatible with NLS V2.0.x or should we stick with 2019?Thanks againShouldn’t be relevant. You’re importing a linux appliance, that’s it. Never tested Server 2022 myself yet but don’t see any reason why it shouldn’t work.Powered by Discourse, best viewed with JavaScript enabled"
510,nvidia-driver-error-on-debian-rminitadapter-failed-0x231204,"Hello,While running a program that uses GPU (RTX 3060) in the Debian, the GPU is suddenly not connected.So when I did reboot at that machine, the GPU has to be connected again.Do you know the cause of this problem? Is it maybe the GPU’s hardware issue or crashed?This is error logs.Kernel: [2336314.019190] NVRM: GPU 0000:01:00.0: RmInitAdapter failed! (0x23:0xffff:1204)
Kernel: [2336314.019293] NVRM: GPU 0000:01:00.0: rm_init_adapter failed, device minor number 0
Kernel: [2336314.067783] NVRM: GPU 0000:01:00.0: RmInitAdapter failed! (0x23:0xffff:1204)
Kernel: [2336314.067830] NVRM: GPU 0000:01:00.0: rm_init_adapter failed, device minor number 0
…
…I meet the same problem in centos7. GPU RTX 3060， nvidia driver version is 470.86, I will update driver to 490.94. It may be a nvidia-drm.ko problem.

image703×323 21.2 KB
Powered by Discourse, best viewed with JavaScript enabled"
511,hyperv-w10-vm-rtx20-series-passthrough-from-w10-machine,"Hello All,I am trying to get my RTX 2070S GPU to show on HyperV W10 VM but I have not found any solution yet, is there please any information regarding this please? I am not quiet sure if this feature is available only to enterprise customers as I have heard that this feature is available on all supported GPUs with driver v465 and higher.This VM is supposed to be a place for me and couple of people to perform some basic renders.
Any help is welcome!Kr,
DominikExcuse me for this…but…does NVIDIA ever answer questions on this site???If you would check other threads you would see that you get an answer if there is something we can do to help. But if you expect a response to a Geforce question for vGPU then you have a totally wrong expectation!Powered by Discourse, best viewed with JavaScript enabled"
512,gpu-virtualization-design-help-required,"We want to deploy VMware Horizon with A100. We want to run AI and ML with parallel computing. Two nos of server each casting two A100 40GB GPU. Our requirement is as below:What would be the licensing and additional kit requirement to be count for the OEM order and for the Nvidia?Hey Anis,For VMs on A100 you will need to use our vCS license.  vCS is licensed per GPU so if you have two A100s you will need 2 vCS licenses.Prereqs for vGPU can be found here: Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software Documentation.best regards
DThanks for the information. Just to make little more understanding, if we set 2 nos A100 per server and we configure 3 host with the same hardware, can we assign all 6 GPU at a single VM managed by VMware Horizon with the vCS license or any additional license or kit may require? As these GPU will configure for the AI and ML.Also can you give an idea for the GPU bridging which may used to improve GPU to GPU communication speed to avoid PCI speed bottleneck?Small correction we don’t currently support multi-GPU A100 and VMWARE with vCS.  Support should be added in the next release of vGPU.  We do support multi-GPU A100 with RHEL in the current release.Thanks for the information. Just to make little more understanding, if we set 2 nos A100 per server and we configure 3 host with the same hardware, can we assign all 6 GPU at a single VM managed by VMware Horizon with the vCS license or any additional license or kit may require? As these GPU will configure for the AI and ML.You can only have a VM on single host.  So if your host has 2 GPUs then the max number of GPUs in the VM is 2.Also can you give an idea for the GPU bridging which may used to improve GPU to GPU communication speed to avoid PCI speed bottleneck?You can use NVLINK between the two GPUs in the VM.

image937×327 19.6 KB
How to buy nVlink for this card and where to buy. I am from Bangladesh. I was knocking to DELL but they are not offering vCS and nVlink Bridging. Can you help me on this please?Hi Anis, can you please write to me at (sasi at nvidia.com). I will connect you with a reseller.Powered by Discourse, best viewed with JavaScript enabled"
513,issue-with-licensing-license-response-fails-trust-criteria,"Hi,I run into issue with uploading BIN license file to License server. Error message I am getting is ""License response fails trust criteria"". From logs:08:34:40,995 WARN  srvpool-64 Resolved [com.flexnet.glservice.exceptions.LicensingFault: License response fails trust criteria]Using Nvidia License server 2019.11. I played with the licensing little bit. After first successful upload of the licenses, I tried to reinstall the server (MAC address is the same) and uploaded the BIN file again, but getting this error now. Tried to remove everything related to Nvdiia, including files in C:\Windows\ServiceProfiles\NetworkService\flexnetls\nvidia. Nothing has helped. Thanks for help in this matter.JoeHiReset your license server, then try generating a new license file from the Portal, download it and install it on the license server.RegardsMGSimply modify your license file in the portal, download and give it a try…Powered by Discourse, best viewed with JavaScript enabled"
514,tesla-zero-power-idle,"Apologies if this is a simple question and my Google-fu has failed me but…The docs for the Tesla K80 show that there is a “Zero-power idle” mode. In my mind that differs from being in P8 (idle) where each GPU draws in the region of 25W.  50W per card total is NOT zero, so this doesn’t seem like idle and zero-power idle are one and the same thing.The only other place that gives explicit mention of this feature (and it may not even be done at the GPU end) is IBM’s LSF documentation - specifically there is a setting LSB_GPU_POWEROFF_DURATION. The docs say that it is possible to power off a GPU when it is not in use to save power (doesn’t say if this is a whole slot or a single GPU).A cursory look through the NVML API shows some calls to read and set power states, spanning P0 to P15 (though the card seems to use P8 as the idle state), though no mention of powering off a GPU.There is the “drain” mode available in Linux via nvidia-smi but that looks to prevent new things from being run on the card - the power meter shows no change when cards are put into “drain” mode if the card was already idle to start with.Question is - how can one activate the zero-power idle feature of a Tesla card ?Many thanks,Pat.Powered by Discourse, best viewed with JavaScript enabled"
515,vgpu-vmotion-purple-screen,"Dear CommunityI have read about the “vGPU VM live vMotion” feature some time ago, and wanted to give it a shot today. Activated the feature in vCenter advanced settings and vmotioned a Citrix Test VM with a test user logged in to another host. the process was running for about 90 seconds, and then suddenly the target host purple screened. After cold booting the host, the VM was located on the new (target) host.I was wondering which errors I made, or maybe there are some requirements which I didn’t met.First things first: I have 5 hosts with two tesla T4 in each one. At the moment, vSphere ESXi and NVIDIA VIB drivers are not on the same build for one of the hosts. This is due to some problems last week with virtual machines on this host.The vMotion target host is on GRID host driver 460.73.02 and ESXi Build 6.7.0, 17700523, while the other four hosts are on GRID host driver 450.55 and ESXi build 6.7.0, 15160138.Could this possibly be the problem here, that host driver versions and/or ESXi builds are different? I didn’t find anything mentioned in the VMware documentation, so I thought to ask here in the Forums.Thanks in Advance.Same issue in our environment, same ESX, same graphics model, same Grid Driver. No workaround in place.Powered by Discourse, best viewed with JavaScript enabled"
516,error-43-when-i-virtualize-windows-10-with-bhyve-on-freebsd-13r-pass-thru-of-my-geforce-rtx-2080-ti-inside-the-vm,"Hello to everyone.I’m on FreeBSD 13R and I’ve virtualized Windows 10 with Bhyve. I’ve also passed thru to the VM my Geforce RTX 2080 ti. It is detected by WIndows 10 but I get the error 43. I shouldn’t get it,because on the websites below I’ve read that starting from the NVIDIA Game Ready Driver 465.89 the virtualization on the Geforce is supported.https://nvidia.custhelp.com/app/answers/detail/a_id/5173/~/geforce-gpu-passthrough-for-windows-virtual-machine-(beta)NVIDIA releases driver 465.89 removing a block on its GeForce GPUs allowing users to leverage GPU passthrough on a virtual Windows guest OS.
Est. reading time: 8 minutes
Below u can see some screenshosts :
Screenshot_20210901_1622141920×1080 128 KB


Screenshot_20210901_1622281920×1080 122 KB
Same here on 14 Current.Any hints?There is nothing that you can do to pass-thru correctly your nVidia graphic card on a Windows Vm because bhyve does not have implemented the needed software components,called “line interrupts for passed through devices”.Powered by Discourse, best viewed with JavaScript enabled"
517,dls-licensing-issue,"Hello. After installing the DLS according to this video Creating a License Service for NVIDIA AI Enterprise or Virtual GPU - YouTube, the virtual machine cannot get a license. In Powershell it only says:
NLS initialized
Can you help with it?Hi,this could have multiple reasons and without getting much more details on the configuration and vGPU setup it is almost impossible to help. Are you eligable for NVES? If yes, why not simply open a support ticket? If no, do you have a partner that may assist you in troubleshooting?Best regards
SimonNo, I’m not eligible for NVES, and I don’t have a partner either. That’s why I’m asking this question here. Ready to provide the configuration and everything you needGood starting point would be:
-Hypervisor/version
-hardware model/OEM
-OS in VDI/version
-vGPU version
-vGPU profile
-time in sync? (DLS and VDI?)
-logfile from DLS-Hypervisor/version
Microsoft Hyper-V Server 2019-hardware model/OEM
Dell PowerEdge r740xd, Tesla V100 16 GB-OS in VDI/version
Windows Server 2019 (remote desktops)-vGPU version
15.1-vGPU profile
Now is just Virtual Apps. But was RTX Virtual Workstation-time in sync? (DLS and VDI?)
No, because I don’t know how to sync time in DLS-logfile from DLS
Sorry, but I don’t know how to do it. I just can to login in DLS via Hypervisor console with login dls_diagnostics and password. But what to do further I don’t know. Can you you say how to do it?Get-Content -Path C:\Users\Public\Documents\NvidiaLogging\Log.NVDisplay.Container.exe.log -Tail 1 -WaitWhen I pasted token and start NVidia Conteiner LS then this command gave a result:
NLS initialized
NLS initializedand nothing elseTue May 30 11:01:58 2023:<2>:NLS initializedTue May 30 11:03:10 2023:<1>:Valid license settings not found. Please configure settings to use NVIDIA License System (NLS). NVIDIA Legacy License Server is not supported.Tue May 30 11:03:11 2023:<2>:Valid license settings not found. Please configure settings to use NVIDIA License System (NLS). NVIDIA Legacy License Server is not supported.Tue May 30 11:03:44 2023:<1>:NLS initializedTue May 30 11:03:46 2023:<2>:NLS initializedHi,is the client token at the right path?
Looks like there is no license information present.https://docs.nvidia.com/license-system/latest/nvidia-license-system-user-guide/index.html#generating-client-configuration-token-for-dls-instanceDocumentation for system administrators that describes NVIDIA Virtual GPU licensed products and how to configure licensing for them on supported hardware.sschaber, Hello.
I have the same problem with the DLS licensing server. In my opinion, I roll the errors described by a colleague above, they get compliance in the log "" (Info: NVIDIA Virtual Application - Error: The allowed time to process response has expired) The client key was installed correctly as in the video as indicated above by a colleague.
On questions of introductory data:
-Hypervisor/version
vsphere7 + vCenter 7
Dell PowerEdge r 750, A10 24 Gb
OS Windows Server 2022
vGPU version 15.2
vGPU profile
I conduct tests on 12a
-time in sync? (DLS and VDI?)
No, because I don’t know how to sync time in DLS
-logfile from DLSTue May 30 05:06:34 2023:&lt;1&gt;:NLS initialized Tue May 30 05:06:35 2023:&lt;2&gt;:NLS initialized Tue May 30 05:06:38 2023:&lt;1&gt;:Failed to acquire license from api.cls.licensing.nvidia.com (Info: NVIDIA Virtual Applications - Error: The...The licensing server deployed an OVA file (nls-3.0.0-bios.ova) on vCenter 7Pretty much a time out of sync issue. Please check the time of the DLS and the time on the VDI. It must be in sync otherwise the token cannot be processed properly.https://docs.nvidia.com/license-system/latest/nvidia-license-system-user-guide/index.html#dls-ntp-configurationcheck the current time with date command as example on the DLS applianceIndeed, the time on DLS does not coincide with VDI. Can I somehow change the time in the DLC? the created user does not have the right to this action.Just use the NTP configuration. With proper NTP the time shouldn’t be an issue.Good afternoon!
Thank you very much. After the NTP change, both on the Licensing Server and on the vm, All licenses became available! I’m surprised that this was the reason.
Good luck with your work!
lease1670×501 55 KB

Hello.Thank you very much for your response. You gave me the same article that I dealt with today. I created a FeatureType and set the FeatureType registry value to 2 - and the license came. But it says that this license ends in 1 day. Tell me, please, will another license come automatically the next day?This is not the license that will expire but the lease :)
That’s the default behavior. And yes, for sure you will a new lease the next day.Thank you very much, it’s very good, you do great things[spoiler]Thu Jun  1 09:21:22 2023:<2>:License acquired successfully from local trusted store. (Info: api.licensing.nvidia.com, NVIDIA RTX Virtual Workstation; Expiry: 2023-6-2 1:18:31 GMT)Thu Jun  1 10:25:06 2023:<3>:NLS initializedThu Jun  1 10:25:06 2023:<3>:License acquired successfully from local trusted store. (Info: api.licensing.nvidia.com, NVIDIA RTX Virtual Workstation; Expiry: 2023-6-2 1:18:31 GMT)Thu Jun  1 12:54:40 2023:<1>:License renewed successfully. (Info: api.cls.licensing.nvidia.com, NVIDIA RTX Virtual Workstation; Expiry: 2023-6-2 4:54:39 GMT)Thu Jun  1 16:30:48 2023:<1>:License renewed successfully. (Info: api.cls.licensing.nvidia.com, NVIDIA RTX Virtual Workstation; Expiry: 2023-6-2 8:30:47 GMT)Thu Jun  1 20:06:55 2023:<1>:License renewed successfully. (Info: api.cls.licensing.nvidia.com, NVIDIA RTX Virtual Workstation; Expiry: 2023-6-2 12:6:54 GMT)Thu Jun  1 23:43:52 2023:<1>:Failed to renew license from api.cls.licensing.nvidia.com (Info: NVIDIA RTX Virtual Workstation - Error: Could not resolve server address)Fri Jun  2 03:20:18 2023:<1>:Failed to renew license from api.cls.licensing.nvidia.com (Info: NVIDIA RTX Virtual Workstation - Error: Could not resolve server address)Fri Jun  2 06:56:54 2023:<1>:Failed to renew license from api.cls.licensing.nvidia.com (Info: NVIDIA RTX Virtual Workstation - Error: Could not resolve server address)Fri Jun  2 08:36:40 2023:<1>:Valid GRID license not found. GPU features and performance will be restricted. To enable full functionality please configure licensing details.Fri Jun  2 08:36:40 2023:<2>:Valid GRID license not found. GPU features and performance will be restricted. To enable full functionality please configure licensing details.Fri Jun  2 08:36:41 2023:<0>:License returned successfully. (Info: api.licensing.nvidia.com)Fri Jun  2 08:36:43 2023:<0>:End LoggingFri Jun  2 08:36:44 2023:<1>:End LoggingFri Jun  2 08:36:44 2023:<3>:End LoggingFri Jun  2 08:36:44 2023:<2>:End LoggingFri Jun  2 08:36:46 2023:<1>:NLS initializedFri Jun  2 08:36:47 2023:<2>:NLS initializedFri Jun  2 08:36:53 2023:<1>:Valid GRID license not found. GPU features and performance will be restricted. To enable full functionality please configure licensing details.Fri Jun  2 08:36:54 2023:<2>:Valid GRID license not found. GPU features and performance will be restricted. To enable full functionality please configure licensing details.Fri Jun  2 08:36:55 2023:<1>:Valid GRID license not found. GPU features and performance will be restricted. To enable full functionality please configure licensing details.Fri Jun  2 08:36:58 2023:<2>:Valid GRID license not found. GPU features and performance will be restricted. To enable full functionality please configure licensing details.Fri Jun  2 08:36:58 2023:<1>:License acquired successfully. (Info: api.cls.licensing.nvidia.com, NVIDIA RTX Virtual Workstation; Expiry: 2023-6-3 0:36:58 GMT)Fri Jun  2 08:37:08 2023:<2>:License acquired successfully from local trusted store. (Info: api.licensing.nvidia.com, NVIDIA RTX Virtual Workstation; Expiry: 2023-6-3 0:36:58 GMT)[/spoiler]Hello. Can you help one more time? Please tell me why the license was first updated, but then an error appeared? And when I restarted the Display Container, the license returnedIt seems that licenses began to come and return normally. Our network administrators simply turned on internet access at night. Thank youPowered by Discourse, best viewed with JavaScript enabled"
518,beginner-question-tesla-k80-or-similar-for-2d-3d-acceleration-on-dell-720xd,"I need some purchasing advice regarding Nvidia cards for VM graphics acceleration.  I’m building a home VM server as a multimedia content creation workhorse.  My intention is that anyone in the family can log into the appropriate VM from any machine in the house and do whatever project they are working on.I’m building 3 dedicated VMs right now (all Windows based)
2D graphics VM (photoshop, graphics, etc)
3D CAD/CAM & 3D printing (fusion360, artcam, vectric aspire, slic3r, blender, etc)
Video editing (adobe premier, after effects)This is a home project, so I’m attempting to keep it as budget friendly as possible.  I’ve been seeing the NVidia K80 24GB Keppler Cuda cards for $350.  On paper, these cards seem to be the biggest bang for the buck I could put in my system.  (Dell 720xd).  I haven’t been able to figure out if these cards will do 2D/3D graphics acceleration & video compression acceleration on virtual machines.  I found something like a white paper from a group that was using them for something similar, but otherwise I get the impression that these cards are used more for stuff like AI and super data crunching.  Nvidia marketing materials seem to recommend different cards too, but I’m not sure if that’s because I can’t pull up the same info from several years ago or not.Ultimately, my question is: is the K80 card a good option for server 2D/3D acceleration of virtual machines?
Is there a better option (something under $400 that’ll work in a Dell 720xd server)?(I’m aware of Dell’s official stance on graphics cards in this chassis.  I can keep it cool. I’m looking for options that will work whether or not they are officially supported.)HiThe K80 is Compute only and won’t do 3D. Also, it’s an extremely old architecture. Basically, don’t bother.The easiest way for you to do it is with a Quadro (or multiple Quadros) running in Passthrough (1 Per VM).There are plenty of Quadro options available depending on your budget. Here are some from the Pascal architecture that you can search for: Page Not Found | pny.com If you want something current, then you’re looking at the Turing architecture. (I’ve skipped Volta because you’ll be looking at GV100s which are expensive).RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
519,simple-question,"hi all,
I have a esxi 6.7 test system where I need to put two vm that need really basic 3d to display some non interactive data.
I know that old k1/k2 grid are unsupported with vgpu but if I put a k2 on the server and set passthrought of the two pcie chip of the k2 , one to first vm and one to the second can I get it work?
Vm can be any version of windows, gpu load is a simple directx app on one vm and a light cuda ( app run now for 1 minute once a day on a gtx1050 ) on the second.
This in for testing only, we need to try new app release before use.
thank’s in advance,
marco.Hi,and what is the question? If this will work? Yes, why not. For sure you can passthrough the GPU to the given VMs.regards
SimonHi thank for the reply.
So, without install any driver on esxi I can have two or four vm ( with k2 or k1 ) with 3d hw accelleration and I’m only limited to guest os support to k1 or k2 right ?
And this will surely work also on new esxi release ? For what I’ve understand the limit is only on the number of vm because I link any gpu of the card directly to the vm.
thank’s in advance,
marco.No, not supported on ESX6.7. You need to use 6.5 for getting support from VMWare. Not sure if it would work anyways.Powered by Discourse, best viewed with JavaScript enabled"
520,license-misstake-or-problem,"Hello,I have the following configuration.Windows Server 2016, Hyper-V, Tesla M10I have GRID PC and APP Licenses, but in the logs i see the message:Failed to acquire/renew license from license server. (Info: http://192.168.4.11:7070/request; GRID-Virtual-WS-Ext,2.0 - Error: [1,7E2,2,1[7000000B,0,702C7]]
Requested feature was not found.)Whats wrong? Wrong licenses?Hope anyone can help me!Regards
StefanCorrect. You need to use a A Profile. Currently you are using a Q profile.I have the same problem here, please advise?
Fri Jun  5 21:27:30 2020:<1>:Failed to acquire/renew license from license server. (Info: http://10.100.0.72:7070/request; Quadro-Virtual-DWS,5.0 - Error: [1,7E2,2,1[7000000B,0,702C7]]
Requested feature was not found.)Please include more details, Thanks in advance,Powered by Discourse, best viewed with JavaScript enabled"
521,failure-to-update-the-following-driver-versions,"Hello! There were problems with updating the drivers on the video card, (now there are 522.25) all versions that are not installed later. During the installation process, a black screen effect(low bright) (then three reboots and the laptop offers to boot in safe mode) I roll back to the stable version 522.25 (earlier versions also work).I tried to remove drivers via DDU, also tested the video card for endurance through 3dmark - without anomalies or problems. In general, there are no problems (on the current driver)
Help please.Laptop MSI GT73VR 6RE GTX1070Powered by Discourse, best viewed with JavaScript enabled"
522,licensing-reduced-capability,"I’m running VDI using DLS licensing, NVIDIA Virtual PC. If a client is unable to obtain a license it warns of running in “Reduced Capability”. I can find this term in the documentation, but not a explanation of what that exactly means? Is there a reference of what functionality or features are reduced? What does this effectively mean?Documentation for system administrators that describes NVIDIA Virtual GPU licensed products and how to configure licensing for them on supported hardware.Thanks!Powered by Discourse, best viewed with JavaScript enabled"
523,xendesktop-7-6-autocad-mouse-issues,"HiWe are running a series of POC’s for customers who use Autocad 2015.The POC hardware is a supermicro server with 2 K2’s.We have applied the policies shared by Jason (thx btw), and all Nvidia demos are working perfectly through HDX 3D pro.The VDI machines are running Windows 7 64 Bit, latest VDA hotfixes.Our issue, and showstopper, is with Autocad. What we experience is mouse lag and cursor problems. Sometimes the Windows cursor sits ontop of the acad cursor. Sometimes the cursor changes to a random Windows cursor, the problem is ""solved"" by moving the pointer out of the drawing area and then back.Autocad gives a warning at first startup regarding the hardware acceleration but sees the grafx Card and shows DirectX 11 is used.We are aware that GRID is not on the Acad 2015 hardware compatibility list.We have been experimenting with Acad 2016 to see if the problem is solved. But it is exactly the same. GRID not on the hw compatibility list here as well.If anyone has an idea to how this problem can be fixed or know someone who does, tell me! :)The cursor lag is as a result of the remoting protocols, and is compounded by the network conditions (ICA latency in particular).I’d suggest optimising the network to stabilise latency, ramping up the framerate, working with Citrix on the best way to improve this. (possible mouse timer tweaks in the registry for example.)try giving acad.exe his own core, and ctxcfg.exe another. also howmany vCPU’s does the machine have?AutoCAD can only use 1 core normally if it has to  share it with OS and ctxcfg.exe (Citrix’ compressor) it will be sluggish.HiWe are aware that GRID is not on the Acad 2015 hardware compatibility list.K260Q is on the certified listAutodesk is a global leader in design and make technology, with expertise across architecture, engineering, construction, design, manufacturing, and entertainment.jaccow makes some very valid points. Recommendation is that you should have at leas 4vCPU’s when delivering 3D workloads.oh Yes and for AutoCAD don’t forget to update the client’s drivers as well.I’ve found that a local old AMD card with a NVIDIA Grid in the XD sessions will give strange mouse issues.AutoCAD can be a server rendered cursor and you may find tweaking MouseTimer (as described here Performance Tip: Disabling Mouse Shadow for XenDesktop and XenApp | Citrix Blogs ) helpful.If the lag is down to the network I’d try to investigate why, if limited bandwidth you might find thinwire+ added by Citrix in XD 7.6 FP3 helps https://www.citrix.com/blogs/2015/10/09/a-big-leap-in-ica-protocol-innovation-for-citrix/ (see the comments below the blog from AutoCAD / CAD users on build to lossless success).If you are on high latency >70ms then it might be worth tuning the TCP/IP window as described in: CTX125027 – How to Optimize HDX Bandwidth Over High Latency Connections How to Optimize HDX Bandwidth Over High Latency ConnectionsDo let me know if anything helps and also if it doesn’t!
RachelThe single largest performance boost I get with acad.exe is setting CPU affinity. So pin the exe to one CPU. You’ll need to configure any shortcut the user launches the application from to do that, but the performance boost is very noticeable.Check out MouseTimer.  It’s a registry key on the client.  Makes autocad feel much more like a local program when you have a little latency between the user and the server.I had a link, but it looks like Citrix took the page down during their last restructuring; bummer – bet lots of my links are broken now.  The reg key should be:HKEY_LOCAL_MACHINE\SOFTWARE\Citrix\ICA Client\Engine\Lockdown Profiles\All Regions\Lockdown\Virtual Channels\MouseSince the artcile is down, I’m pulling from memory – I think the default value is 100 (it’s a *, but it translates to 100).  It’s a measurement in MS, so every 100ms all mouse actions will be collected and sent to the server.Drop this guy down to 30-40 ms, maybe a little more, and see if that makes a difference.  I have no idea how much of an impact it will be fore you, but it will generate more bandwidth…Hi Virge,Mousetimer default is 10, what you are doing is actually raising it - I wrote an explanation here: Performance Tip: Disabling Mouse Shadow for XenDesktop and XenApp | Citrix BlogsYou may also find this useful: Configuring Virtualised Autodesk and similar applications including XenApp GPU-sharing and tools for sanity checking DirectX/OpenGL usage | Citrix BlogsAutoCAD is very CPU heavy relative to GPU so often the CPU GHz is important.Best wishes,
RachelRachel,the whole legacy graphics vs DCR vs H264 vs codecs vs whatever else seems to be floating around is another one of the intricacies that just escapes me.Windows 7 - Which one do you like with AutoCAD
Windows 10 - Which one do you like with AutoCADWindows 7 - Which one do you like with Revit, SpaceGAss and Inventor
Windows 10 - Which one do you like with Revit, SpaceGAss and InventorSo many conflicting opinions… and do i want to use DCR ?And which compression do you like with XenDesktop 7.11 ?Many thanks.Lastly - is the new ""Relative Mouse"" setting on the receiver an advantage ?Scratch that - the relative mouse is no good for AutoCAD.Hi,we run serveral proof of concepts with main usecase autocad 2019/2020 with highly intensive, detailed files and drawings.I have seen multiple topics in front of Autocad Performance in Citrix Virtual Desktops, including this one, where some of you have suggested to use cpu affinity for better Performance (for autocad or ctxcfg.exe)Is it still necessary in 2020? Or is the behaviour better now with newer Autocad and Citrix Releases? What is your recommendation?We are not having much issues and the performance is okay in general. Mouse performance is always the major topic and some rendering and highly intensive tasks.Our most used config:Dell PowerEdge R740
2x Intel Xeon Gold 6146 CPU @ 3.20GHz (2x12 Cores)
4 NIVDIA Tesla T4 (TU104GL) with GRID T4-2Q ProfileRound about 28-30 VMs per Server.CVAD 1912 LTSR with Windows 10 1803/19094 vCPU and 16 GB RAM per VM on XenServer 8.1 with Citrix PVS Accelerator (2 GB Cache in RAM as vDisk Overflow Config)Endpoints are Windows Fat Clients with Workspace App or Windows 10 IoT Thin Clientsusing YUV444 (H.264) visually losless with 60 fps maximum with hardware encoding.Autocad in Standard Confiugration with server-rendered cursor and without disabling any potential features/options.all applications are using GPU-Acceleration as expected, CPU consumption is fine in general.I would be thankful about any contact or exchange about general sizing or best practices info in connection with Autocad, CPU, overall performance. (I am generally confirm about all things documented with MouseTimer, server-rendered cursor and so on. Also i’m aware of the several HDX-Policies and possibilities). Just want to have some impressions from others, also in connections with endpoints, used policies, potential tweaks or game changers. You also can send me some private message, for sure.Thanks in advance.JensHiSounds like you’ve done everything correctly, and as you don’t have any big issues it’s difficult to make any recommendations for changes.But if I were going to make any changes, I’d start with your CPUs. Server CPUs are always a compromise between Cores vs Clock Speed because of the requirement for User Density. A 3.2Ghz CPU today is considered low-end to average by physical Workstation standards that are designed to cater for your workload, because for your workload you would trade Cores for increased Clock Speed and 4.0Ghz or above would be standard for AutoCAD in a physical Workstation, but for a Server where you need those Cores to support additional Users 3.2GHz is a really good place to start.You mention you’ve run several POCs, so I’m assuming you’re not in Production. With that in mind, Intel launched some updated CPU models that are a better choice than those you are currently running.Xeon Gold 6256 - 12 Cores @ 3.6GHzIntel® Xeon® Gold 6256 Processor (33M Cache, 3.60 GHz) quick reference with specifications, features, and technologies.Xeon Gold 6246R - 16 Cores @ 3.4GHzIntel® Xeon® Gold 6246R Processor (35.75M Cache, 3.40 GHz) quick reference with specifications, features, and technologies.As for CPU affinity, I’ve never had to do this.What resolution are your monitors and how many do your users have?During the ""rendering and highly intensive tasks"", which component becomes the bottleneck?RegardsMGThanks for your answer. The CPU Infos confirm my thoughts and expactations, thanks for that. Perhaps this could be some addtional performance.-> Rendering is CPU related, the software takes in this case 100% with all cores, we have switched today from 4 vCPU to 8, now its agreable and okay to use and similar to local workstations.In the configuration which i have posted, we have  round about 28 Users (80+ in summary) per Server, and 7 VMs per GPU.All users have 2 monitors, most of them 1920x1200.Most usecases are smooth and better than on the old fat clients which are outdated.-> Only issues are AutoCAD related, with some lagging or bad user experience while doing certain workflows. In summary this specific users usecases are a little bit a question mark for the proof of conecpt.CPU, RAM and GPU-RAM are not too busy in this cases and there is no significant usage visible, end user latency and network is also not a topic.These are very complex drawings with a high number of objects. Users are making changes, adding lines, lots of copy paste stuff, lots of zooming in and out in the workflows. Then there are some lags, sometimes mouse performance is not the best as in comparison to other files or other programs.-> Things which i have in mind to try are disabling some autocad advanced features/options, playing a little bit with the NVIDIA graphic profile/system settings (performance/quality or a individual setting instead of the default which is ""Let the 3D Application decide"") or installing AutoCAD 2020 instead of 2019.Do you ever have had the need of customzing/tuning AutoCAD by itself or choosing individual NVIDIA Settings?HiThanks for the details.Increasing the CPUs Clock Speed would give you more performance, especially with more complicated models, and 3.2 to 3.6GHz should give a noticeable improvement.Something else that’s worth validating … When you have time outside of business hours (or during business hours if you have an empty server with the same Specification), try running the same workload but with only 1 user connected to the Server and see if there’s a performance or experience difference. The reason being that your CPUs now have a 4.5x overcommit on them, assuming all 28 users are running 8 vCPUs and there is nothing else running on the Servers, whereas previously is was closer to 2.3x. This would tell you whether you’d be better going for more Cores or increased Clock Speed. For example, with the 3.4GHz 16 Core CPUs mentioned previously, you’d get a slightly faster Clock, and reduce the overcommit to 3.5x if everything else stayed the same. It’s always worth knowing at what point your hardware’s performance starts to deteriorate, and if 2 or 3 people start rendering at the same time or with overlaps on the same Host, you could end up with peaky performance which is really frustrating, this is more likely to happen with increased vCPUs, so it’s worth keeping an eye on, especially if drawings start to become more complex.On the platforms I design, deliver and support, I always make sure they’re kept well up to date and are running the latest versions of Software and Operating Systems. vGPU drivers are always kept up to date as well. The Applications get treated a little differently, as moving to newer Applications can initially reduce productivity if there are significant differences between that and the previous version. It’s easy for me to just say run the latest Applications, when I’m not the person that will actually be using them. However, the recommendation to my customers is always try and run the latest versions of whichever Applications you use to take advantage of the latest features, performance and functionality. However, the users may (and probably will) need some time to adapt before any real performance metrics can be gathered. So to directly answer your question, if the users are happy to do so, then I would be running AutoCAD 2020 over 2019.For the NVIDIA Control Panel, I typically let the users decide what they want to tweak inside there. This is always going to be Application specific as to any benefits and as AutoCAD is typically CPU limited, modifying the NVIDIA Control Panel doesn’t always give much benefit in my experience. There are some basic settings inside AutoCAD that can make things run more smoothly, and there are plenty of random guides on the internet of things to try that relate to the entire Operating System. For example, have you run the Citrix or VMware Optimiser tools?If you’re not locked into those server specifications and this is still a POC, I think the biggest gain you’re going to see will be CPU related by going for a different model. If these are your production servers, then you’re effectively trying to turn things off to improve existing performance, so system wide optimisations are key, which is why I mention the Optimisation Tools.RegardsMGBasically we are caring very much about a clean and optimized image, so i would say that this is also on a good level.We are going now as result of the PoC with the 3.4GHz 16 Core CPU, and also for the productive environment there will be AutoCAD 2020 too, surely with all the latest drivers and updates. As you mentioned, first because of the ""more"" need of overcommitment, and also for a benefit with a litte bit more CPU clock speed. Application based optimization and handling with the NVIDIA Control panel is then a topic for the productive pilot afterwards.Thank you very much for sharing your point of view. Wish you all the best for the moment.HiYou’re welcome. I hope some of what has been discussed is useful. Please feel free to post back on here and let us know how you get on with the changes.Best of luck with the PoCRegardsMGPowered by Discourse, best viewed with JavaScript enabled"
524,nvlink-not-activating-on-vm,"We are using a GPU server with 8 HGX A100s.
We using VM configuration and GPU pass-through in qemu-kvm environment.However, there is a problem that NVLink is not enabled in the VM, so a workaround is needed. (If it is not a virtualization environment, NVLink operates normally.)$ nvidia-smi nvlink --status -i 0
GPU 0 A100-SXM4-40GB ~~~~~
Link 0: (inactive)
Link 1: (inactive)
Link 2: (inactive)
Link 3: (inactive)
…Our environment is as follows.Hypervisor kernel : 3.10.0-1160.21.1
qemu-kvm : 1.5.3-141
libvirtd : 3.2.0-14*VM environment
OS: Ubuntu 18.04 (4.15.0-126)
Framework : TensorFlow 2.4.1
Python: 3.7
CPU: AMD 7402 x 2
CUDA : 11 (Driver 450.102.04)
cuDNN : 8.0.2
TensorRT : 7.2.xI know it has been a while, did you ever figure this out?Powered by Discourse, best viewed with JavaScript enabled"
525,where-can-i-download-last-version-of-the-grid-sdk,"Hi, I see release notes from the 3.1.1 version of SDK, but I can download 2.3 only (for Windows). Could anybody  explains the situation with the most updated SDK version?Thanks :-)The newer versions of the GRID (Capture SDK), are not available from the NVIDIA public website.  Newer versions require that you are a registered partner in order to have access to newer versions of the GRID SDK.Hi eyoung, can you, please, provide some materials and/or links on how to become a NVIDIA registered partner? Thank you for reply.Please PM me your e-mail and I’ll forward to the right persons to get this process started.Hi eyoung,I need the newer versions of the GRID too,I had PM you my e-mail already.Please PM me your e-mail and I’ll forward to the right persons to get this process started.Hi eyoung,I need the newer versions of the GRID too,I had PM you my e-mail already.Hi eyoung,I need the newer versions of the GRID too.The latest NVIDIA Capture SDK 5.0 (formerly known as GRID SDK) is now available on the developer website.  In order to download it, you need to create a DesignWorks development account.  The website can be found here.https://developer.nvidia.com/capture-sdkHi,I am using a GRID SDK version 2.1 and would like to know if this version is supported on Windows 10. If not then please let me know if there is any compatible version available for Windows 10.Thanks :-)Powered by Discourse, best viewed with JavaScript enabled"
526,vgpu-display-rate-is-limited-at-60hz,"Why vgpu display rate in windows 10 vm is limited at 60HZ on qemu-kvm platform?Hi,this is just a default setting for the vGPU scheduler. You can remove the FRL on a per VM basis. Check our documentation.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
527,question-about-3d-rendering-with-quadro-k2200-tesla-k80,"Both Cards are installed correctly and are detected in Windows and the Render Program.In GPUZ i can see all the Data for GPU Frequenz and Memory  Load and all the stuff. If i start with rendering the GPUs from the K80 loads 100% and GPU Frequenz rises up to the max. so far so good…BUT why i can’t  see any faster render? Its rendering the same speed if i render only with the K2200
My fault or it is definitely not working?Powered by Discourse, best viewed with JavaScript enabled"
528,failed-to-acquire-quodra-virtual-data-center-workstation-license,"I am running a windows 2016 server with nvidia Tesla P4 and failed to acquire a quadro vitual data center workstation license.The nvidia license server has been configured (correctly).
At my license server I checked the server log files and it reads like following:14:40:24,830 WARN  [6C92BFAF02A0] Unable to handle request for feature GRID-Virtual-WS-Ext 2.0 count=1. Reason: FEATURE_NOT_AVAILABLE.
14:44:17,388 WARN  [6C92BFAF02A0] Unable to handle request for feature GRID-Virtual-WS 2.0 count=1. Reason: FEATURE_NOT_AVAILABLE.
14:44:19,457 INFO  [6C92BFAF02A0] Successfully handled request for feature Quadro-Virtual-DWS 5.0 count=1 correlationID=d9d688af-e0d7-4cc3-a316-e18277e15ee0.
14:44:21,812 WARN  [6C92BFAF02A0] Unable to handle request for feature GRID-Virtual-WS-Ext 2.0 count=1. Reason: FEATURE_NOT_AVAILABLE.
14:44:21,813 INFO  [6C92BFAF02A0] Feature Quadro-Virtual-DWS 5.0 was returned.And this message repeats its self and the client says it is ""acquiring license for quadro virtual data center workstation.""
I notice that one message in the log present above says ""Successfully handled request for feature Quadro-Virtual-DWS 5.0"" and I think the authentication should have been succeeded. So why is the client still unlicensed?Could someone please answer (maybe solve) this question? thx a lot.Powered by Discourse, best viewed with JavaScript enabled"
529,artifacts-after-vmotion,"Does anyone else experience artifacts after a vmotion? In particular in Office applications whole parts of the application render black and blocky.Windows 1903, Citrix 1906, vsphere 6.7 u1, m10 cards, 2b4 profiles with 3x 1920x1200 screensWhich vGPU version are you using? There are fixes for known issues in 8.1 and 9.1regards
Simon9.0 i’ll try 9.1 and report back9.1 seems to have resolved. will continue to monitor and report back in a week.Ok, thanks for the feedback. Good to hear (as expected) that 9.1 did the trick.Powered by Discourse, best viewed with JavaScript enabled"
530,quadro-rtx-6000-on-xen-hypervisor-poor-brush-performance-in-photoshop,"Hi, we have Server with Xen Hypervisor 8.2 LTSR, Nivida Quadro RTX 6000 wit 450.55 Software. XEN Desktop is 1912.  We publish VMs with Adobe Photoshop and RTX6000P-2Q vGPU. The Brush Performance is bad. It’s lagging and hangs. If I deactivate GPU Support all works fine.Any suggastion?Thanks TobiasPowered by Discourse, best viewed with JavaScript enabled"
531,can-i-bind-a-virtual-machine-to-an-hdmi-port-on-my-gpu,"Hi,I am looking to bind a virtual machine to an HDMI port on my GPU. Is there currently a way I can do that? So for example if I have 2 monitors one monitor displays my Host OS and the other monitor displays my Guest OS.Thanks.Powered by Discourse, best viewed with JavaScript enabled"
532,directx-function-error,"My graphics card is an Asus Gtx780 Strix and I have the latest drivers as well as directx 12.
However today I went to install a game and the error appeared.
I had previously installed others and current ones and they worked well.
I contacted EA and they advised me to contact Nvidia as the bug was related to the part of Nvidia that hadn’t fixed a bug yet.Hi Jorgemit9,Welcome to the NVIDIA developer forums.  I think your question would be best suited to our geforce gaming forums - NVIDIA GeForce Forumsthanks
:D:Powered by Discourse, best viewed with JavaScript enabled"
533,will-442-50-grid-drivers-be-out,"HiOnly 442.06 drivers are available at the moment.When 442.50 or 442.74 GRID drivers will be released ?ThanksCould you please be more precise for what reason you need these drivers? vGPU works in a different way. We release minor updates in specified timeframes and do not follow the Geforce gaming logic. I cannot say which driver version will be the next 10.2 minor release yetPowered by Discourse, best viewed with JavaScript enabled"
534,question-regarding-a40-vs-a6000-for-vmware-vgpu-server,"Hello,My company is interested in building (via SuperMicro) a VM server utilizing vGPU with a VMWare solution to create 6 to 12 VM’s (with each VM being either Windows 11 Pro or some Linux distribution) and utilizing between 4 to 8 GB of vGPU RAM (host OS will likely be Ubuntu Server Edition).We’re having SuperMicro build our system, and we specifically requested that they create the system with two Quadro A6000 with NVLink.They came back to us and stated the following:""I have finished discussing your GPU server configuration with our VMware Product Management concerning the AS -4124GS-TNR. It has been qualified onto the VMware Compatibility Guide, but this was performed with the NVIDIA A100, A40 and A30 GPUs. To make sure you receive complete support from VMware for the server in case of any issue, they are suggesting to use one of those GPUs (Qty. 2) in your configuration instead of the NVIDIA RTX A6000s.The server with VMware does provide support for vGPU and DirectPath I/O functionality.""Though I’m familiar with the A6000, I am not with familiar at all with the A40.My company needed the A6000 to provide multiple VM’s with at least 8 GB of vGPU memory (for 4K and 8K rendering). I’m worried however that moving to the A40 could be a problem, as the A40 seems more like a compute/CUDA card.Another problem with the A40 is that it:If anyone could help, I would greatly appreciate it (as my company is having me build a virtualized system, and I know very little about virtualized systems, let alone vGPU systems).I greatly appreciate any help anyone could provide.Thank you,
NelsonHi Nelson,In general you could use A6000 or A40. Both GPUs have the same GA102 chip on it. If you want to use virtualization with Horizon, why do you think the display ports are relevant? No matter if you use A6000 or A40, both GPUs need to be in DC mode to support vGPU which also means that the GPUs run in headless mode.
Now the main difference: A40 is a DC board and the default mode is already capable to run vGPU. A6000 instead is a workstation GPU and therefore needs to be modified to run vGPU at all (mode selector tool).
For a performance perspective, the A6000 has a slightly increased memory clock which results in maybe 5% better performance compared to A40 on specific use cases.
Having a passive cooling is not a disadvantage for server systems. Actively cooled boards quite often cause air flow irritations in servers and therefore the best option here should always be to run passive cooled GPUs.So the recommendation in your use case would be to use the A40 to have a fully supported stack.Best regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
535,a40-with-esxi-7,"I have two dell R740 hosts using Tesla P40 for horizon VDIs
a third host we bought came with an A40
In Vcenter it is only shown as GA100GL [A30 PCIe]
I tried different versions of the drivers like NVIDIA_bootbank_NVIDIA-VMware_ESXi_7.0.2_Driver_510.47.03-1OEM.702.0.0.17630552.vib
but I never got to a point where it even shows up in nvidia-smi
 → NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.I have enabled “SR-IOV Global Enable” in bios
I have set graphic settings to shared direct via vcenterI am not even sure if the card is supported the way I want it to work (we have a couple of windows 10 VDIs that I would like to be able to move to all 3 hostswhat else could I do?Hi,
please check with Dell first if you really got a A40. It sounds you got a A30 which is only usable for Compute (Linux only).
Also check with lspci | grep NVIDIA which hardware is present.Best regards
Simonof course you are correct! sorry! it is an A30!
when you say it is only usable for computation is that a temporary situation or will it never be usable as vGPU?and one more question: if our supplier would give us an A40 instead how good/bad could this work with the migration of VMs between the hosts with tesla P40 and the one with A40
would it be a better choice to get the older P40 again (assuming it would not cost less because they will not refund money)Hi,
A30 won’t ever support Windows. A40 does but you still won’t be able to use migration between P40 and A40. Migration only works between identical GPUs.
Our documentation says:In your case I would indeed try to get a P40 to mitigate all the issues you will face with mixing GPUsthank you!Powered by Discourse, best viewed with JavaScript enabled"
536,a6000-in-vgpu-13-0-and-esxi-7-0u2-failed-to-start-vgpu-instance,"Hi Team,I’m trying to use Nvidia A6000 in VMware 7.0u2 here. Now I met a issue that VM with vGPU profile cannot start. Anyone can help please? thanks!Error when starting VM with vGPU profileEnvironmentnvidia-smi outputvmware.log fileIf you need more information, please let me know.
Best reagrds.
KakaYes I can :) You need to change the GPU Mode first. A6000 is a workstation GPU and needs to be switched into displaymode off and Big BAR1 size.You will need to register for the ability to download the modeselector tool.NVIDIA Display Mode Selector Tool The NVIDIA Display Mode Selector Tool is a utility to set the desired display mode for NVIDIA A40, NVIDIA RTX A5000, NVIDIA RTX A5500, and NVIDIA RTX A6000 GPUs. Changing the display mode is supported for specific...Regards SimonThank you for your information.
I succeeded to deploy the vGPU instance by switching display mode(i.e. Disabled the multi display mode)By the way, the “Display Mode Selector Tool” did not run on EXSi (Of course, I have already installed the VIB on this host before I run this tool.).
So,  I changed the setting to path-though the GPU on EXSi and created the new instance with attaching the path-though A6000 and installed the NV driver, and then reboot. After boot-up, run this tool, reboot the EXSi, restored the gpu setting on EXSi and so on. This is so complexed…
Do you have a recommended way  to switch the mode after installing the vSphere?Best regards.
KakaUnfortunately there is no easy way to use the tool with ESX. Keep in mind that A6000 is designed for workstation and A40 for servers. For those customers with “special” use cases the additional effort with display selector tool needs to be taken.I am having the same issue. What do you mean by needs to be switched into displaymode off and Big BAR1 size?I have display mode disabled, is that sufficient? How do I adjust the BAR1 size?Display Mode                          : Disabled
Display Active                        : DisabledBAR1 Memory Usage
Total                             : 256 MiB
Used                              : 1 MiB
Free                              : 255 MiBThanks!You need to use the display mode selector tool!How do we verify it’s disabled after run the command?Check BAR1 size with nvidia-smi -q. It needs to show 64GB instead of 256MB.Hi, used the selector tool, but there is no option to change BAR1 to 64GB. How can I go about changing it to 64GB?You only have 2 options to change: BIG BAR = 64GB or medium BAR =8GB. Displayless mode is BIG BARregards
SimonHello Simon,
hi folks,i’ve used the displaymodeselector (RHEL 8 VM with GPU passthrough on vSphere 7u2)  to change the GPU Mode of an RTXA5000 to ‘disabled display’, for usage with vGPU/GRID.The tool claims no error, but after rebooting the ESXi, nvidia-smi still reports :[root@esxi3:~] nvidia-smi -i 0 -q | grep -i display
Display Mode                          : Enabled
Display Active                        : DisabledI’ve tried it several times but the ‘display enabled’ mode still persist, and therefore it is not possible to start any VM with vGPU/GRID Profile (c or q).
Error:  ""could not initialize plugin libnvidia-vgx.so for vGPU “nvidia_rtxa5000_8q”
VIB is 460,73.02, also tested wit 460.91 and 470.x, no change. ECC is disabled.Any ideas?Thanks in Advance,
OliverDisplay Mode always shows enabled. Relevant ist only the BAR1 size. Please post the output of BAR1.Regards Simon[root@esxi3:~] nvidia-smi -i 0 -q | grep -i BAR -C4
FB Memory Usage
Total                             : 24258 MiB
Used                              : 0 MiB
Free                              : 24258 MiB
BAR1 Memory Usage
Total                             : 32768 MiB
Used                              : 1 MiB
Free                              : 32767 MiB
Compute Mode                          : DefaultI forgot to mention in my 1st post:
VMX Settings were made too (pciPassthruMMIO ) and boot mode of the VMs is EFI .
Thanks,
OliverGPU Mode looks good. Did you enable SR-IOV? Shared Direct configured in vCenter?Hello Simon,
yes SR-IOV is enabled, Above 4 G Encoding too,
and also Shared Direct in vCenter.
Thats why im running out of ideas … ;-)
Thanks
OliverCan you post nvidia-smi  output from ESX host? Do you have vCenter also on 7.0.2?Hi Simon,vCenter is  latest Version on one of my ESXis, all ESXi are 7u2d.
I’ve also update Host BIOS to the latest version, SR-IOV is enable IOMMU works (dmesg logs)dmesg -i | grep iommu
…
TSC: 209076 cpu0:1)BootConfig: 711: iommuMapReservedMem = 1 (1)
2021-09-19T15:30:44.936Z cpu42:2097718)Loading module dma_mapper_iommu …
2021-09-19T15:30:44.939Z cpu42:2097718)Elf: 2060: module dma_mapper_iommu has license VMware
2021-09-19T15:30:44.939Z cpu42:2097718)Mod: 4789: Initialization of dma_mapper_iommu succeeded with module ID 2.
2021-09-19T15:30:44.939Z cpu42:2097718)dma_mapper_iommu loaded successfully.
…
2021-09-19T15:30:48.218Z cpu38:2097864)DMA: 1044: Protecting DMA engine ‘NVIDIADmaEngine’. Putting parent PCI device 0000:4f:00.0 (—THIS IS THE RTX-A5000 -----)  in IOMMU domain 0x4308162604e0.
2021-09-19T15:30:48.218Z cpu38:2097864)DMA: 687: DMA Engine ‘NVIDIADmaEngine’ created using mapper ‘DMAIOMMU’.
…But the error remains when starting a VM  attached to the RTXA5000 (c/q GRID profile):
“could not load plug-in libnvidia-vgx.so …”nvidia-smi output is belowThanks in Advance, Oliver==============NVSMI LOG==============Timestamp                                 : Sun Sep 19 15:45:57 2021
Driver Version                            : 470.63
CUDA Version                              : Not FoundAttached GPUs                             : 1
GPU 00000000:4F:00.0
Product Name                          : NVIDIA RTX A5000
Product Brand                         : NVIDIA
Display Mode                          : Enabled
Display Active                        : Disabled
Persistence Mode                      : Enabled
MIG Mode
Current                           : N/A
Pending                           : N/A
Accounting Mode                       : Enabled
Accounting Mode Buffer Size           : 4000
Driver Model
Current                           : N/A
Pending                           : N/A
Serial Number                         : 1321721023294
GPU UUID                              : GPU-8e853934-c60b-b92b-ba73-fd8d421663bd
Minor Number                          : 0
VBIOS Version                         : 94.02.6D.00.05
MultiGPU Board                        : No
Board ID                              : 0x4f00
GPU Part Number                       : 900-5G132-2500-000
Module ID                             : 0
Inforom Version
Image Version                     : G132.0500.00.01
OEM Object                        : 2.0
ECC Object                        : 6.16
Power Management Object           : N/A
GPU Operation Mode
Current                           : N/A
Pending                           : N/A
GSP Firmware Version                  : N/A
GPU Virtualization Mode
Virtualization Mode               : Host VGPU
Host VGPU Mode                    : SR-IOV
IBMNPU
Relaxed Ordering Mode             : N/A
PCI
Bus                               : 0x4F
Device                            : 0x00
Domain                            : 0x0000
Device Id                         : 0x223110DE
Bus Id                            : 00000000:4F:00.0
Sub System Id                     : 0x147E10DE
GPU Link Info
PCIe Generation
Max                       : 4
Current                   : 1
Link Width
Max                       : 16x
Current                   : 16x
Bridge Chip
Type                          : N/A
Firmware                      : N/A
Replays Since Reset               : 0
Replay Number Rollovers           : 0
Tx Throughput                     : 0 KB/s
Rx Throughput                     : 0 KB/s
Fan Speed                             : 30 %
Performance State                     : P8
Clocks Throttle Reasons
Idle                              : Active
Applications Clocks Setting       : Not Active
SW Power Cap                      : Not Active
HW Slowdown                       : Not Active
HW Thermal Slowdown           : Not Active
HW Power Brake Slowdown       : Not Active
Sync Boost                        : Not Active
SW Thermal Slowdown               : Not Active
Display Clock Setting             : Not Active
FB Memory Usage
Total                             : 24258 MiB
Used                              : 0 MiB
Free                              : 24258 MiB
BAR1 Memory Usage
Total                             : 32768 MiB
Used                              : 1 MiB
Free                              : 32767 MiB
Compute Mode                          : Default
Utilization
Gpu                               : 0 %
Memory                            : 0 %
Encoder                           : 0 %
Decoder                           : 0 %
Encoder Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
FBC Stats
Active Sessions                   : 0
Average FPS                       : 0
Average Latency                   : 0
Ecc Mode
Current                           : Disabled
Pending                           : Disabled
ECC Errors
Volatile
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Aggregate
SRAM Correctable              : N/A
SRAM Uncorrectable            : N/A
DRAM Correctable              : N/A
DRAM Uncorrectable            : N/A
Retired Pages
Single Bit ECC                    : N/A
Double Bit ECC                    : N/A
Pending Page Blacklist            : N/A
Remapped Rows
Correctable Error                 : 0
Uncorrectable Error               : 0
Pending                           : No
Remapping Failure Occurred        : No
Bank Remap Availability Histogram
Max                           : 192 bank(s)
High                          : 0 bank(s)
Partial                       : 0 bank(s)
Low                           : 0 bank(s)
None                          : 0 bank(s)
Temperature
GPU Current Temp                  : 34 C
GPU Shutdown Temp                 : 98 C
GPU Slowdown Temp                 : 95 C
GPU Max Operating Temp            : 90 C
GPU Target Temperature            : 84 C
Memory Current Temp               : N/A
Memory Max Operating Temp         : N/A
Power Readings
Power Management                  : Supported
Power Draw                        : 24.71 W
Power Limit                       : 230.00 W
Default Power Limit               : 230.00 W
Enforced Power Limit              : 230.00 W
Min Power Limit                   : 100.00 W
Max Power Limit                   : 230.00 W
Clocks
Graphics                          : 210 MHz
SM                                : 210 MHz
Memory                            : 405 MHz
Video                             : 555 MHz
Applications Clocks
Graphics                          : 1695 MHz
Memory                            : 8001 MHz
Default Applications Clocks
Graphics                          : 1695 MHz
Memory                            : 8001 MHz
Max Clocks
Graphics                          : 2100 MHz
SM                                : 2100 MHz
Memory                            : 8001 MHz
Video                             : 1950 MHz
Max Customer Boost Clocks
Graphics                          : N/A
Clock Policy
Auto Boost                        : N/A
Auto Boost Default                : N/A
Voltage
Graphics                          : 668.750 mV
Processes                             : NoneEverything looks OK from host side. I’m also running out of ideas :(Assure the BIOS and Firmware are absolutely up to date.
Enable SR-IOV for the A6000 in ESXi for the host (in vSphere Client).
MMIO base set to 2TB, low is 256GB,
ASPM – auto
4G decoding enable
Use a small Virtual Machine RAM amount, 8 or 16GB, not 32 or greater.Powered by Discourse, best viewed with JavaScript enabled"
537,grid-k2-with-memory-3-5gb-gpu-only,"Hi Team,
I just purchased a GRID K2, when i plug it in my server. I detected that it’s memory capacity only 3,5GB per physical GPU and i can’t power-on my VM on this card.
I have another K2 card on the same server with fully 4GB without any problem.
I also attach the screenshot of nvidia-smi command.
NVIDIA-SMI command: Imgur: The magic of the Internet
Power On VM error: Imgur: The magic of the Internet
My system is:Hope you can help me identify what happen and what i can do with this card before i return it to seller.Thanks and best regards,
Nguyen Thanh DanhHi,never seen this before. Please contact your reseller. BTW, K2 is EOL for almost 1 year now. Why did you buy a board that is EOL already?RegardsSimonThanks for your reply, i bought this K2 because it dont need additional license cost for user and it still match my requirements.
I wonder there are any related between bios setup or memory mode on this card?Thanks,
Danh Nguyeni have an GRID K2 Card wich ahs also an Power on Problem and also Only Reports 3500 MB amount of Memory in VMWare and via Nvidia-SMI. Have you solved it or just bought another one?best regardsRobertPowered by Discourse, best viewed with JavaScript enabled"
538,vgpu-software-for-direct-gpu-passthrough,"Hi everyone!
Surfing the web and the official vGPU software documentation I became a bit confused. I would like to clarify, do I really need vGPU software and vDWS or vCS license to just Passthrough the Tesla P100 card to one VM for computational purposes? Is it depend on the hypervisor vendor?Thanks in advanceHiIf you want to use vGPU (licensed under these versions: vApps, vPC, QvDWS, Virtual Compute Server), then yes, you need a license and you need a specific version of the software which is only available from the Licensing Portal.If you want to use Passthrough, and only intend to use it for Computational workloads (without graphical acceleration, because there won’t be any as it’s the wrong type of driver) then you don’t need a license, and you can download this driver from the normal NVIDIA Drivers site.RegardsMGThank you for your reply!
But now I am curious, if direct GPU Passthrough does not need vGPU Software (and license), why vGPU take 1 VirtualComputeServer license per GPU in Passthrough mode? Is there some advanteges of using Passthrough with vGPU Software over Passthrough without vGPU (I meen in respect to computational workload, because for graphics mode you have explained the difference)?If you want to use multi-vGPU or a fraction of a GPU then you are good to go with vGPU instead of Passthrough. In addition, as soon as you run vGPU you are eligable for support. Passthrough instead (with default Tesla driver) doesn’t include support.regards
SimonHivGPU allows you to share the GPUs resources between multiple concurrent VMs so you can run multiple workloads simultaneously. For example, instead of running the entire GPU inside 1 VM and doing nothing else until it’s finished its task, you could run 2 concurrent VM workloads with an 8C Profile, or 4 concurrent VM workloads with a 4C Profile etc etc. It really depends how intensive your workloads are as to how you share the GPUs resources. Also, as Simon mentions, you also get the benefits of NVIDIA support as well as having a much more flexible platform.RegardsMGThank you all for your responses!
I will consider different benefits that brings Virtual GPU Software. Perhaps Passthrough is not an optimal choice for my tasks.Powered by Discourse, best viewed with JavaScript enabled"
539,no-uvm-a30-mig-backed-vgpu,"Is UVM for MIG-backed vGPUs working? I added “enable_uvm=1” to my vgpu_param’s and can’t get it working. I get an “Operation not supported” error string when using cudaMallocManaged. Other vgpu_params, like “enable_profiling=1”, work perfectly fine.
I am using the latest vGPU (14.x) version, KVM, Ubuntu 20.04, A30, MIG-backed, and GPU pass-through.
Thanks.Powered by Discourse, best viewed with JavaScript enabled"
540,can-cuda-be-used-with-tesla-m10,"Hi,
I saw this post: https://gridforums.nvidia.com/default/topic/1170/general-discussion/m60-can-it-be-used-for-deep-learning-/I am running into a similar issue, but it’s about M10. I created a VM with GRID M10-8Q and I wanted to use cuda to accelerate computing when doing deep learning. But, I cannot find a driver for Tesla M10 here: Official Drivers | NVIDIA
I was suggested to use the M60 driver instead. But it didn’t seem to work. I tried ubuntu 16.04, cuda 8.0, and nvidia-diag-driver-local-repo-ubuntu1604-384.66_1.0-1_amd64.deb and I got an error when ran CUDA devicequery sample:
CUDA Device Query (Runtime API) version (CUDART static linking)
cudaGetDeviceCount returned 30
-> unknown errorI wonder if I can use cuda in a VM with Tesla M10 and what should I do if it is possible?Regards,
XiaoHiThat is not the right location to download GRID drivers. I don’t know why it’s still there, it adds nothing but confusion and causes problems.As linked to in the other post you mention, you need to go here: http://www.nvidia.com/object/grid-evaluation.html#utm_source=shorturl&utm_medium=referrer&utm_campaign=grid-eval and register for a GRID evaluation. This will then give you access to the (correct) drivers.With Maxwell GPUs, you have 2 ways of using CUDA. The first is with an 8Q profile, the second is by using Passthrough. However by using Passthrough, you lose the benefits of the GRID software which gains in features and functionality with each release …With the new Pascal GPUs (P4, P6, P40 and P100) and GRID 5 (available September 1st), you can use CUDA on all Q profilesSo in answer to your question:I wonder if I can use cuda in a VM with Tesla M10 and what should I do if it is possible?Yes you can, and all you need to do is use the correct drivers and choose either an 8Q vGPU profile or use Passthrough.RegardsBenThat is not the right location to download GRID drivers. I don’t know why it’s still there, it adds nothing but confusion and causes problems.Just as addition: As the Tesla M60 is in general a Compute board it is necessary that we provide drivers for Passthrough usage for compute purposes in the ""normal"" drivers download section.
But the Tesla M10 was especially built for GRID, so there is no real compute purpose and therefore no driver in the download section but in the GRID portal…RegardsSionHi,
Thank you for your reply. I have successfully installed cuda with the right driver. Thank you again!!RegardsXiaoHello,facing the same problem with a M10.
Register for the Grid Eval but there are only Driver for the virtualization.Where do I find the cuda drivers?Will use the M10 also with pass throughRegardsHeikoHi Heiko,and what is wrong with these drivers? For sure these drivers support CUDA…RegardsSimonHi Simon,the problem is, I only find the grid drivers for ESX, XEN, KVM but not the cuda drivers for in my case UBUNTU 16.4 LTS (a *.deb file) and the nv drivers to overwrite the noveau drivers.RegardsHeikoSo to be more precise. the graphics driver (in the physical world ""nv"" driver ) for the virtual Ubuntu machine that on which on top the cuda driver are unstalledIt’s now running. Thanks for helpingHello,I think I am having the  same problem as Heiko did.
I am running Hyper-V with M10 DDA Pass-Through to an Ubuntu18.04 VM.
The installation of the driver (NVIDIA-Linux-x86_64-460.32.03-grid.run) from the portal and adding the license worked fine so far (nvidia-smi shows a normal output). Where do I get a compatible CUDA Version for this driver?EDIT: Using the runfile and only installing the toolkits worked for me, deselect the driver!Containers with cuda also work fine now.Thanks,
NicolasHi … am trying to reuse a few M10s on a RHEL 8 server to run ML experiments - hopefully, using as current as possible versions of tflow and pytorch.Can anyone recommend a configuration for the versions of cuda and python that will support the M10.thanks,
VijayPowered by Discourse, best viewed with JavaScript enabled"
541,nvidia-vgpu-tesla-m10-firmware-flash,"I am asking this topic only by interest, because we have some stability issues with our Grid vGPU Tesla M10 cards.
Long ago we got from NVIDIA support a package to flash our cards, but in this special case we didn´t. Is it logical to deal with flashing the firmware in such cases. And how can we get current flash tools and firmware images, if there are any)Hi,
There is no flash option available. This is not necessary. If there would be a hardware related issue, we would provide such an option.Regards SimonPowered by Discourse, best viewed with JavaScript enabled"
542,problem-with-rtx8000-with-vmware,"We have configured as Dedicated Graphics card (vDGA) for a single VM on ESXI 6.5.Currently it getting detected in Device Manager, but nothing works,
we have installed third party tool like GL Viewer / FurMark / GPU Caps Viewer but RTX8000 doesnt get detected in it.HiSo you’ve used Passthrough to add the RTX8000 to a VM, then installed the standard Quadro driver available from the NVIDIA website (Official Drivers | NVIDIA) and it’s not working?Which remoting protocol are you using to connect to the VM?RegardsMGreally interested if you found a solution or what was the exact issue? can you update with anything Dattaprasad? thanks in advance. https://hilmabiocare.to/Powered by Discourse, best viewed with JavaScript enabled"
543,open-source-design-for-standalone-nvidia-tesla-k80-cooler,"Hi! I recently published designs for a standalone cooler for the Tesla K80. It seems like there has been a recent renewed interest in these cards due to the silicon shortage, but in all of the posts/videos about them the cooling is kind of an afterthought. There are a number of people on ebay selling coolers, but in many cases they didn’t fit my requirements. I needed a design that was compact enough to support having two k80’s (with coolers) installed in adjacent PCIe slots. I’ve been using this design for a number of months now, with two cards being used to train stylegan2 networks and haven’t run into thermal throttling issues. I figured I’d publish the designs to solicit feedback and potentially make things more usable for others and unblock aftermarket users of these cards.The design is based around 40mm fans controlled via a feedback loop with a Raspberry Pi Pico. Temperature is measured with a thermistor bolted to the outside of the GPU using the bolt pattern on the heat spreader. There’s an algorithm that tries to optimize fan speed to balance noise and cooling power.The github org is here, PRs are welcome. There’s also a blog post here that goes over the design rationale.(This is my first post on this board so apologies if it’s in the wrong location)Powered by Discourse, best viewed with JavaScript enabled"
544,enable-virtual-display-with-k1-nvsmi-showing-display-mode-disabled,"So I have 2 GRID K1 cards. The first one when passing through to a VM has a ""Generic Non-PnP Monitor"" attached to the K1. The nvidia control panel shows it as a VGA monitor.Now I have a second K1 card with slightly different firmware, which doesn’t have this monitor, and I can’t open the nvidia control panel, as it requires a monitor in order to open.Digging deeper I queried both adapters with nvsmi (nvidia-smi.exe -q) and found that on the first card, ""Display Mode"" and ""Display Active"" are both set to enabled, while on the card with no virtual monitor it has them disabled. This appears to be the setting that controls whether a virtual monitor appears.The problem is, I can’t for the life of me find out how to change this setting. My workload depends on a ""real"" monitor being attached. I’ve even tried different driver versions.I’m using KVM on debian. Any help is appreciatedPowered by Discourse, best viewed with JavaScript enabled"
545,gpu-profile-empty-vmware-esxi-6-7-0-15160138,"Hi,After a successfull installation of nvidia software and a boot in my ESXi Server, I tried to create a VM using the GPU Shared PCI (like it’s explained in quick start manual). However, unfortunently, after I added the Shared Device the GPU Profile field is empty and didn’t show a drop down as expected.Anyone knows the reason?I use the software version: NVIDIA-VMware-450.55-1OEM.670.0.0.8169922.x86_64.vibPowered by Discourse, best viewed with JavaScript enabled"
546,vgpu-driver-pairing-for-esxi-6-5-and-windows-10-query,"Hi,I’ve downloaded the vSphere 6.5 package that included these 2 drivers:NVIDIA-VMware-450.102-1OEM.650.0.0.4598673.x86_64.vib
452.77_grid_win10_server2016_server2019_64bit_international.exeThe version numbers are different, 450.102 vs 452.77 but it came from the same download package.  Documentation says to have the same version on the ESXi host and the Windows 10 virtual machine.  Like the “Dell EMC PowerEdge Servers with NIVIDIA GPUs and VMware vSphere” which says:“Download the NVIDIA guest driver installer package to the VM. Ensure that it matches the version of the installed NVIDIA VIB on ESXi”Can I pair the above 2 drivers in my current environment where ESXI is 6.5 U3 and VMs are Windows 10?Thanks.Host and guest driver version always defer :) Therefore we have the package to make sure you get the right versions.Ok, thanks.Powered by Discourse, best viewed with JavaScript enabled"
547,having-an-issue-applying-the-nvidia-rtx-gi-patch,"Hi everyone,  I am trying to get Nvidias RTX Global Illumination Plugin running.  I cloned their branch of the UE4 Build and downloaded the appropriate version of the patch for their 4.26.0.  However, whenever I copy the patch into the root directory...this are the errors when I check the patch in the windows prompt by the command: git apply --check RTXGI-NvRTX4.26.1.patcherror: patch failed: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.cpp:272
error: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.cpp: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.h:32
error: Engine/Source/Runtime/Renderer/Private/DeferredShadingRenderer.h: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/IndirectLightRendering.cpp:342
error: Engine/Source/Runtime/Renderer/Private/IndirectLightRendering.cpp: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/RayTracing/RayTracingLighting.h:14
error: Engine/Source/Runtime/Renderer/Private/RayTracing/RayTracingLighting.h: patch does not apply
error: patch failed: Engine/Source/Runtime/Renderer/Private/SystemTextures.h:11
error: Engine/Source/Runtime/Renderer/Private/SystemTextures.h: patch does not applyfacing the exact same problem. No solution found on the internet. Please help.same here please helpThis worked for me “open the patch file in Notepad++, go to Edit->EOL Conversions, select Unix (LF), save the file, and then try to apply the patch.”https://github.com/NVIDIAGameWorks/RTXGI/issues/35Powered by Discourse, best viewed with JavaScript enabled"
548,how-to-run-two-deep-learning-models-in-parallel-on-single-gpu,"I need to run to two Convolutional Neural Network models in parallel on a single NVIDIA 2080Ti. But I don’t know how to do it. Can anyone help me with this problem?HiYou’ve purchased a Consumer grade GPU which is not capable of being virtualised. What you’re asking for cannot be done on that GPU.In order to do what you’re asking, to provide the best choice in GPUs, you’ll need a ""rack mount"" server chassis. This will enable you use a Tesla V100, Quadro RTX 6000 / RTX 8000 or Tesla T4, all of which can be virtualised. Previous generation Pascal architectures are also available such as the Tesla P100 or Tesla P40. Earlier versions that support virtualisation would be Maxwell (M60) however this is unsuitable for your workload.The V100, T4, P100 and P40  are Passively cooled, meaning that you can’t run them in a typical ""tower"" workstation chassis as they do not have fans. The RTX 6000 / 8000 are Actively cooled (they do have fans), so you could run them in either a tower workstation or rack mount server.Whether you use a tower workstation or rack mount server, you’ll need a Hypervisor (VMware is best) along with its Enterprise Plus licensing (to allow GPU virtualisation) and the vGPU software from NVIDIA with Quadro vDWS licensing for each VM to enable you to share the GPU. You could use a cheaper Hypervisor such as XenServer or KVM, but you’ll lose features, functionality and usability. Basically, you get what you pay for …For future reference, here’s how NVIDIA list their product lines:GeForce - Consumer
Titan - Prosumer
Quadro - Professional
Tesla - DatacenterNeither the Consumer or Prosumer lines support virtualisation. Out of Quadro, only the RTX 6000 / 8000 support virtualisation. All Tesla support virtualisation.Honestly, it’ll be cheaper and easier for you to buy another identical workstation with 2080Ti and run them independently.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
549,memory-bandwidth,"
image753×762 183 KB
‘memory’ in the picture above means global memory?memory bandwidth is global memory bandwidth right?What do you mean with “global”?It is the global memory of Cuda’s programmable memory.
Another example is shared memory.Powered by Discourse, best viewed with JavaScript enabled"
550,reconnection-issues,"we are running citrix hypervisor 8.2 in combination with nvidea tesla t4 cards. We run into an issue that sometimes people cannot reconect to a disconnected session. At that moment the wmi queries cannot be read and the Vgpu card on the vm in perfmon has disappeared.The latest drivers from Nvidia for Citrix Hypervisor 8.2. (version 460.32.04) are installed on the hosts.Powered by Discourse, best viewed with JavaScript enabled"
551,pcie-slots-local-to-cpu-for-each-gpu,"With the HPE DL380 Gen10 PCIe slot 1 and 2 are local to each corresponding CPU socket. The NVIDIA documentation states that performance can be improved if you pin CPU to GPU on the same bus.  My understanding is that VMware schedulers do not understand PCIe locality so pinning CPU to GPU is a must if you want to go this route.Has anyone tested the performance gains you would expect in a VDI type environment by pinning CPU and GPU on the same PCIe bus?Thanks,Kevin.Powered by Discourse, best viewed with JavaScript enabled"
552,vgpu-for-consumer-hardware,"hi,since Nvidia decided 2021 to change their policy to enable geforce customers to passthrough their GPU for VMs, I was wondering if there are plans to enable geforce gpus to use vGPU for enthusiasts to use. Or is their hardware not capable to use sr-iov?Just to clarify, I’m not asking to support geforce gpus but it would be amazing if the feature was unlocked.
Any statement on that matter by nvidia would be appreciated.
Sorry if this was asked before but I couldn’t find anything recent, especially for Ampere or Ada GPUs.best regards,
ChrisHi,
There is a huge difference between PT and vGPU. vGPU requires a software stack on host and guest and is therefore a product that requires licensing to get the required software and support. In addition, there are features like motion support which needs effort to develop and maintain.
I don’t expect we will ever see vGPU for consumer grade GPUs.Regards Simonthanks for your response.I am aware that Nvidia has no interest to bring vGPU to consumer grade GPUs as part of the officially supported hardware since there would be a huge effort which would only serve a niche market and therefore won’t be affordable.Since I don’t know about details of the difference in hardware architecture and limitations of consumer grad GPUs, I’m asking more about possibilities to enable the community to use the existing software solution to achieve a basic functionality.As far as I understand for example the RTX 3090 uses the same base architecture as the RTX A6000 so I was wondering if the RTX 3090 has other hardware limitations or differences which would make it impossible or is this a locked feature in the firmware of the device because there is no official support from the software?I don’t expect a detailed answer, I rather want to suggest, if there are possibilities to enable the community to achieve basic working results by themselves without Nvidia spending a lot of resources this would be highly appreciated.Thanks for your time.Powered by Discourse, best viewed with JavaScript enabled"
553,mig-with-kvm-vm,"Hi,I am looking how to use MIG with multiple virtual machines (VMs). When we have multiple GPUs, we can attach different GPUs to different instances via PCI passthrough (OpenStack Docs: Attaching physical PCI devices to guests) in openstack and KVM environment. It seems that MIG works fine with Docker but it is not clear if it works with VMs too.From what I have been told by support you cannot passthrough single MIG instances to VMs. From what I have seen though, it does seem that you can create a VM with a full A100 and then partition that GPU inside the VM using MIG if that is what you are after.Standard vGPUs seem to work fine in community openstack so hopefully MIG-backed vGPU will eventually be supported. That would be great but I still need to get my hands on some A100 to test that it is actually possible (nvidia docs mention support to RHEL OS/OpenStack, not more generic stuff).Do ping back if you manage to get something going with MIG :)Hi Antonio,Thank you for your reply. Yes, it will be great if MIG-backed is also supported through PCI-passthrough or vGPU. We are still investigating this option.Recently, we are working on some A100 with Openstack and we are trying to integrate them with our Openstack. In contrast to legacy GPUs where type-PCI is considered in Nova configuration (at the controller and compute), with A100 only type-PF (Physical Function) or type-VF (Virtual Function) with sr-iov should be enabled.I will post here our finding regarding MIG technology and its integration with cloud environment (Openstack).Thanks for replying back and wanting to keep posting your findings here :)You mention that:In contrast to legacy GPUs where type-PCI is considered in Nova configuration (at the controller and compute), with A100 only type-PF (Physical Function) or type-VF (Virtual Function) with sr-iov should be enabled.In our openstack cloud we have GPUs like the V100 that are running with type-PCI to enable PCI-passthrough but I am not sure I fully understand what you mean. It seems to me that you are saying that you are not being able to do PCI-passthrough using the A100? Is that it? Could you please elaborate?No, we have managed to do PCI-passthough of A100 with our openstack platform. In nova configuration at the compute and api nodes, which is the case for any PCI card, you have to enable the PCI-passthrough in filter_scheduler and whitelist the card and define the pci alias. You have to enable IOMMU at the kernel and at the bios in order to allow the PCI address translation between the host and the guest. In contrast to the previous cards, like P100 and V100, where you do not have to specify device_type in their configurations.  In these legacy cards, device_type takes the value “type-PCI” by default. In case of A100 as it is sr-iov enabled device, you have to specify either “type-PF”  or “type-VF”. Otherwise, the card will be registered as type_PCI and then the nova scheduler will not find any valid hosts to select in the aggregate. Please take a look into the following links:https://mohamede.com/2019/02/07/pci-passthrough-type-pf-type-vf-and-type-pci/https://docs.openstack.org/nova/latest/admin/pci-passthrough.htmlIt is interesting that you say that. The T4 cards are also SR-IOV enabled devices (as far as I can tell from the product brief, page 4, table 3) and yet we did not have to change the device-type to neither “type-PF” nor “type-VF” for these cards to work properly in PCI-passthrough mode. I will definitely be paying attention to this when our A100s arrive though, thanks for sharing.You are welcome. Good luck with your A100 configuration. Please keep us updated if you manage to assign MIG slices or assign the whole card to the VM without specifying the card type. It could be related to Nova version.Sure I will update with our progress :)Hi,I’m also looking to expose MIG slices (card A30) to Openstack instances, @Antonio_Paulo, did you have any success? Timesliced is working just fine with mdevs but it looks like our use cases would benefit from MIG slicing@ETP1 NVIDIA still hasn’t delivered the A100s so we didn’t have the opportunity to try itHi, any update on this?Powered by Discourse, best viewed with JavaScript enabled"
554,rtx-a6000-vgpu-support,"Does the RTX A6000 support vGPU?  I see conflicting information from the product page vs the driver page:From, NVIDIA RTX A6000 For Powerful Visual Computing | NVIDIA , I see:
vGPU Software Support	NVIDIA GRID®, NVIDIA Quadro® Virtual Data Center Workstation,
NVIDIA Virtual Compute Server
vGPU Profiles Supported	1 GB, 2 GB, 3 GB, 4 GB, 6 GB, 8 GB, 12 GB, 16 GB, 24 GB, 48 GBBut from, Supported Products :: NVIDIA Virtual GPU Software Documentation , I see:Is there an ETA for when vGPU will be supported in the driver?Powered by Discourse, best viewed with JavaScript enabled"
555,assign-vgpu-licenses-to-users-with-gpo,"Hi, I’m successfully testing a server with a Tesla T4 and Windows 2019 RDS. We want to use the server for two different types of users, being: 1. Revit designers and 2. Office365 users.For obvious reasons, we want to be able to assign vGpu licenses to the first group only and let the standard gpu of the server handle the second group.Is there any documentation on how to work this out?Many thanks,Martin JansenHiYou’ll need two RDSH Servers to do this, one with a GPU, the other without. There is no way to separate GPU Users from Non-GPU Users on the same Host.Just so you’re aware, both of the use cases you’ve listed are GPU accelerated. Also, the GPU does more than just application acceleration, and it cannot be separated out by controlling which applications users have access to.RegardsMGThanks for the info MG! I guess we’ll just add an extra RDS for the office users then.Perhaps I can also ask a question on license requirements? We are going to use this server for interns that are part of an education program. We want to have about 16 users on the server max. Can we go for perpetual EDU licenses, or are there restrictions on how to use the EDU ones?HiPerpetual EDU Licenses are fine, make sure you also purchase SUMs as well though, that way you’re entitled to Support and Software upgrades.Regarding your license choice, for the Students using Revit, you may want to look at the QvDWS license depending on what they’re doing with the software, as the Quadro driver has a lot of optimisations in it for Professional software that the vApps / vPC driver does not.RegardsMGHi, we are planning to redo this setup, this time with a different approach. For this test we have 2 servers at our disposal, both HPE DL380 with 48 cores (@ 2.5Ghz) and 768Gb RAM each. One has two Tesla T4 boards, the other has one M10 board.The plan is to setup the first server as RDSH offering high end 3D apps like Revit Full and Lumion. We expect around 16 concurrent users accessing this environment.The second server will host around 42 users on RDSH that are only using Office apps and occasionally startup a Revit Lite app to do simple (mostly 2D) work.My question is, would this work with the hardware listed and what licensing would be required? My guess is the 42 lite users could do with Grid vApps right? Together with 16 QvDws licenses on the heavy server?Powered by Discourse, best viewed with JavaScript enabled"
556,a40-vmware-esxi-7-0-u3-with-vcenter-7-0-u1-with-vgpu-profiles,"Hi, is it possible to use Nvidia A40 with ESXi7.0 U3 and vCenter 7.0 U1. Currently we are unable to update vCenter. I was not able to start a VM ( Ressource unavailable ). I currently want to know is this issues relates with missing update from vCenter or is there any other issue ?Powered by Discourse, best viewed with JavaScript enabled"
557,esxi-6-7-tesla-v100-430-27-passthrough-not-working,"I want to passthrough the GPU to one single VM. But the VM does not starts with the Error:Module ‘DevicePowerOn’ failed.I configured it like in the nvidia documentation:
https://docs.nvidia.com/grid/5.0/grid-vgpu-user-guide/index.html#using-gpu-pass-through-vmware-vspherethe vt-d and the passthrough in ESXi host is active:
https://docs.vmware.com/en/VMware-Horizon-7/7.5/horizon-virtual-desktops/GUID-41547581-2CAC-40D2-AC9F-962E8D649B5E.htmlvt-d is 3, it means it is enabled (https://kb.vmware.com/s/article/1011712)passthrough is enabled:
VM settings, all memory is reserved, instead normal bios is efi:
i try some solution from the internet like set the svga.present=FALSE in VM-Options-Advanced, but the error message still thereHi hsler!I am exactly in the same situation as you (yeah, let’s cry together), also with a V100 (16GB) and the same error: ""Module ‘DevicePowerOn’ power on failed""I have a couple of questions:Best,
PabloI found the solution, just in case you’re still with this: Solved: Error: Module 'DevicePowerOn' power on failed when... - VMware Technology Network VMTNI would guess it is related to the amount of assigned system memory.
Check our product documentation with known limitations and enable the following key:
pciPassthru0.cfg.enable_large_sys_memPowered by Discourse, best viewed with JavaScript enabled"
558,getting-error-installing-nvidia-tesla-gpu-on-linux-virtual-machine,"HelloI am getting the below error while installing the NVIDIA Tesla latest Driver on a Red hat linux machine hosted on Vmware: → Unable to determine if Secure Boot is enabled: No such file or directory
ERROR: Unable to load the kernel module ‘nvidia.ko’.  This happens most frequently when this kernel module was built against the wrong or improperly
configured kernel sources, with a version of gcc that differs from the one used to build the target kernel, or if another driver, such as
nouveau, is present and prevents the NVIDIA kernel module from obtaining ownership of the NVIDIA GPU(s), or no NVIDIA GPU installed in this
system is supported by this NVIDIA Linux graphics driver release.Powered by Discourse, best viewed with JavaScript enabled"
559,licence-to-use-vpgu-with-hypervisor-rhel-kvm,"Hello,we have a server with 3 gpu v100, if i want to use it in a hypervisor with virtuals machines kmv qemu, i need the vgpu drivers.So for that, if i undestand, we have to buy 3 licences vcs.319.41 KBAnd after that, we don’t have any limit, i can make 4 vms with 3 vgpus per vm ?Access Red Hat’s knowledge, guidance, and support through your subscription.Thank you for the confirmation and any adviceCorrect!Powered by Discourse, best viewed with JavaScript enabled"
560,help-with-setup,"We are planning on buildning a new Remote Desktop-solution.
There will be two psysical hosts.
HP ML 350 Gen 10.
Dual CPU
>150 GB RAM.RDS will be Windows Server 2019 Standard.
Installed on bare metal, no virtual servers.
We are only using remote app through RDWEB.
Up to 100 users can be logged in to any of those RDS (50 per server).We dont use Autocad but are viewing alot of drawings in different applications.
So we need to boost the GPU-performance.We are looking at Tesla M10.
One for each RDS.Will that work?
Must we use another configuration? What in that case?
Will it be enough with one M10 per server?
What license do we need?
Are there any other GPU that will serve us better?All inputs are welcome.Thanks!HiYour choice in hardware would be ok (although I’d replace the M10s with T4s) if you were using virtualisation, but as you’ve said you want to use bare-metal then it’s not appropriate. I can’t actually remember the last bare-metal install I did, it would have been over 10 years ago though. Just out of interest, why don’t you want to use virtualisation? You’ve already picked out appropriate hardware for it? …The simplest, most cost effective solution would be to use the hardware you have selected, deploy a Hypervisor on each of the ML350s and run an RDSH VM on each of the GPUs on the M10 (4 VMs per ML350). That will easily handle 50 users per ML350 no problem at all, with capacity for a few more if needed. However, what I would do, is the same design, but as the M10 is pretty old now, I’d replace 1 M10 with 2 T4s. Depending on your Hypervisor choice, you could then either allocate an entire T4 to each RDSH VM having 2 RDSH VMs per ML350, or use vGPU to split each T4 in half to create 4 VMs and run 2 of them per T4 totalling 4 VMs. Virtualisation with T4s is my recommendation.Now let’s look at what happens when you run bare-metal … Firstly, your RDSH use case and hardware selection is going to be problematic. Multi-GPU with RDSH is a bad configuration and should be avoided as much as possible due to the nature of the workload and how RDSH uses the GPU. Your RDSH Server will not share the workload over 2 or more GPUs if that’s what you were hoping for. Despite the M10 having 4 8GB GPUs totalling 32GB, your RDSH Server will use only 1 of them, meaning that the system will only have 8GB of usable framebuffer to cater for your 50 users (not to mention encoding and processing). Basically, you’re going to run out of GPU resources before you get anywhere near your 50 user total. To be clear, certain applications can use Multi-GPU configurations, but they are not suited for RDSH deployments.Problem 1 with bare-metal, is that your RDSH Server will only make use of 1 GPU, so you’re going to need a bigger GPU, but that said, I’m not sure I’d want to put 50 users on any currently available single GPU, I’ve never even heard of any one doing that, I think it would be cost prohibitive.Problem 2 with bare-metal, is because of the user count you’re going to need something powerful (and expensive). Meaning that because you can’t use the correct low-end hardware you have to use high-end hardware for a lower-end use case to support your user density. I could suggest something like a Quadro P5000 or RTX 5000, but I’m not sure 16GB would be enough for 50 users. Realistically, you’re going to be looking at something with 24GB or more, so something like a P6000, P40, RTX 6000 or above. (It just gets silly for this type of use case).You could purchase 2 extra ML350s, downgrade the spec of each of them and aim for 25 users per RDSH and then you could opt for a 16GB GPU (you wouldn’t use a smaller GPU in this configuration because you’d have no flexibility). Again, the reason you’d do this, is because as you’re running bare-metal, the OS will only use 1 GPU so you need more Hosts.You already have the correct hardware for it (albeit with a GPU change to a pair of T4s) so unless there’s a solid justification for not using virtualisation, in my opinion you either need to scale out and purchase more ML350s or scale up with a larger single GPU and risk not over loading its resources.RegardsMGThank you for that wonderful answer. :)
Spot on what I needed to hear.I am open for a ESXi-solution.How about this configuration?
2 x HP ML 350 Gen 10.
Dual CPU.
>150 GB RAM.Installed with VMware Essentials Plus (latest version).
vCenter on a seperate machine.One Virtual RDSH (Windows Server 2019) per ESXi-host (to start with).
One ""Tesla T4 - 16 GB GDDR6 - PCIe 3.0 x16"" per host (to start with).Is that configuration ok?Or maybe it is enough with just one ""HP ML 350 Gen 10"" and boost up the RAM and add more T4 and install 3-4 virtual Server 2019?
Could that handle up to 90 RDSH-users?What license do I need for the T4-card?Sorry for a total newbie in this area.But I think I’m getting what you are writing.Each M10 (board) has 4 GPU á 8 GB.
Each virtual RDSH can handle one GPU (8 GB).
Therefore I must install four virtual RDSH on each Host to fully be able to use all the four GPU.Or I could use a T4 that could be used by one single virtual RDHS.
Or install two T4 on one Host and then install two virtual RDHS.My options are:
1.
One ESXi-host.
One M10 on that host.
Four virtual RDSH (each get one GPU á 8 GB).One ESXi-host.
Two T4 on that host.
Two or four virtual RDSH (If four the use vGPU to split the T4).Do you think one Host can manage 90 users?As I said, we are not using Autocad or any high end applikation.
But we are opening a lot of drawings through various applikations.
We are using Office 365, webbrowsing, a lot of drawings in PDF, DWG TrueViewer, BlueBeam Revu and some more smaller apps.Still my question about license remains.We use published Remote Desktop App through RDWEB only.i would really appreciate if you (or someone else) could give me some more answers.HiGreat, virtualisation is back on the table! That makes things much easier!Yes, the M10 has 4 8GB GPUs, and because you’re running RDSH you would use 1 of those for each RDSH VM, totalling 4 VMs. Depending on the resource requirements of your Apps and how your users use the system, each 8GB RDSH VM would support approximately 20 - 25 concurrent users. This is an industry average, your mileage will vary + / - which is why you should definitely run a POC before making any firm design decisions.VMware (vSphere) is top of the line, but it’s not cheap. For vGPU, you’ll need vSphere Enterprise Plus. This is why it’s important to understand the difference between Passthrough and vGPU and also understand your workload and how it will use the resources. If you were to use the M10, because of your workload and the fact the M10 is a Multi-GPU board, you’ll be assigning an 8GB GPU; does it matter if that GPU is Passthrough or vGPU? The answer is, it depends on the amount of flexibility and features you want from the system. If you just want to provide access to a GPU enabled RDSH VM and don’t need any additional features, then you can get away with Passthrough and Essentials licensing with the M10. If you were to use the T4 you would have to assign the whole T4 (due to not having VMware Enterprise Plus licensing), making them 16GB RDSH VMs, but you would need fewer of them to support your density. Does that make sense?For any VMware deployment, you really should be using vCenter. Without it, administering your vSphere Hosts becomes really limited. For vGPU however, it’s a prerequisite, but if you’re only using Passthrough, then you can get away without it, but it’s not something I’d ever recommend.Regarding your ML350 specs, which CPUs are you looking at using?To get started for your POC, you’d be looking at something like this for each RDSH VM with an M10 running in either Passthrough or vGPU:8 vCPU
32GB RAM
8GB GPU
SSD / All Flash StorageThat’s 128GB RAM total, leaving the rest for the Hypervisor, and you’ll be able to run 4 of those per ML350.If you were to go down the T4 in Passthrough route, then you’d be looking at a scaled up version of the above with something like this:12 vCPUs
48GB RAM
16GB GPU
SSD / All Flash StorageIn theory, you should need less of them as they’ll support a higher user density, and you’d tailor the vCPUs and RAM based on the POC results. If you were to use vGPU with the T4, then you’d be looking at the same specs as with the M10 but the T4 running as 8GB and supporting 2 VMs.Those specs are not definitive, and the final specs will be based on your POC results.If your ML350 is spec’d highly enough it will manage the 90 users (and above) without issue. But remember you should be providing N+1. If anything fails, you’ll impact a large percentage of users.Licenisng:Depending on your final configuration, you’ll need a combination of the following:vCenter Standard
vSphere Essentials / Enterprise Plus
Windows Server Standard
RDS CALs
vGPU vAppsIf you’re running Passthrough and have no intention of ever wanting vGPU, you can look at other Quadro GPUs and not pay any vGPU licensing. Because we’re now using virtualisation, we can have multiple GPUs in the same physical host (whereas with bare-metal, we can’t). You can now look at multiple Quadro P4000 or Quadro RTX4000 as these are single slot 8GB GPUs. You can run these in Passthrough and there is no NVIDIA licensing, however, these are still a bit much for just RDSH workloads, but you wouldn’t use anything smaller.If you wanted to use the M10 or T4, you would be looking at vApps licensing (regardless of Passthrough or vGPU). With the exception of vCompute, all other vGPU licensing is per Concurrent User, so you’ll need 100 vApps licenses.I hope that helps.Overall, and despite all the configurable options, my recommendation remains the same as my first post. Don’t try and skimp on features and functionality if you can afford them. Use the T4s running 8A vGPU Profiles.RegardsMGHello,I am reading this information, because I try to find out the best efford.
Cuurectly we have a customer with about 50 users on a RDSH server. It is working, but graphical performance for let say Google Maps is poor.
So we want to offer a new RDSH. We like RDSH because of the easy central management.
What would you advice? Which setup? One Hypervisor and 2 RDSH machines?
Basicaly we start with a HPE DL380 Gen10, 128Gb memory, dual CPU and 480Gb Mixed use SSD in raid 50.
Using server 2019 std.Powered by Discourse, best viewed with JavaScript enabled"
561,confused-about-best-deployment-of-rdsh-for-cad,"Hi all,We want to deploy a new Windows remote desktop session host on which the users will be able to use CAD software.
I have quite some experience with RDSH but not in combination with CAD software and after doing heaps of research I am really confused about which is the best way and how to license it.Our future scenario would look like:
2-5 concurrent users working on the RDSH and they will be using 3D CAD software.Regarding the server hardware we are planning on an HPE DL380 Gen 10, 128GB RAM, Xeon Gold 6226R and Nvidia RTX 6000 graphic card.Our aim is to get the most performance out of the system so the users can work smoothly with their CAD software.
If we install the the RDSH (session based) on bare metal would the users be able to fully utilize the graphic card? Are Nvidia licenses needed? If yes, which one?
Woud it maybe be better to virtualize the RDSH?Any help here would be greatly appreciated!
Thanks in advance!Kind regards,
Aktuatro1980Hi,No matter if you virtualize or install baremetal you would need vWS or vApps licenses depending on what you want to achieve. Only vWS licenses support CUDA so if you need CUDA, vWS is the route to go otherwise you should be OK with vApps licenses.
If RDSH is the right way to go with 3D apps is another topic. I wouldn’t do so but for some use cases it might be OK.regards
Simon@sschaber Thank you very much for your answer which already helped me a lot!!Are vApps licenses the correct choice when users are working with CAD software or do I need vDWS licenses? I have read conflicting information about this topic.If you think RDSH is not the right way to go, what else would you recommend? Maybe Citrix Virtual Apps and Desktop?Regards,
Aktuator1980As I said, the licensing mainly depends on the use case (3D app). Most 3D apps are not certified for RDSH and therefore the besser choice is to use Win10 VDI and Citrix XenDesktop as example. Which app do you have in mind? If you do not require CUDA you can use vApps licensing for most scenarios as you don’t benefit from ISV certifications on RDSH anyways.The CAD software that would be used on the server is “DDS-CAD”. However, I can’t find information if this software requires CUDA.
According to the vendor OpenGL support is needed.
As far as I understood, vApps would provide this feature, am I right?According to a PDF document from nvidia it says that vApps support a maximum resolution of only 1280 x 1024…really? can that be true? If yes then I think vApps is useless because today most users have a display with at least Full HD resolution… Or am I getting sometime wrong? Really starting to get desperate on that topicOK, just to make sure we won’t miss any features we have now decided to buy the vWS licenses.
Thank you very much for your support sschaber!However, I have one more (annyoing) questions ;)
There will also be “normal” users who log in on the mentioned terminal server (RDSH). These users won’t use CAD software but just normal office applications like Word, Outlook, ERP software etc. This software is not graphic intensive, therefore it would be kind of a waste if they grab an expensive vWS license. Is there a way to assign the vWS only to specific users?Thanks again!Hi,
in general the licensing on vApps is not enforced (just EULA based). Therefore the users won’t aquire a license. But there is no way to restrict the licensing to just a few specific users. All users on the RDSH host are able to use the GPU and therefore all users are required to have a license :(regards
SimonThanks a lot Simon! You really helped me out here!!
:-)Powered by Discourse, best viewed with JavaScript enabled"
562,external-gpu-compatibility-with-default-gpu,"URGENT NEED! hi I have MSI Raider GE78 HX 13V laptop with 1 Thunderbolt 4.0 port support and I want add eGPU. As default there is Nvidia GeForce 4080 Graphic Card but I want add  external GPU of NVidia RTX A6000. one has got memory type as GDDR6X another is GDDR6 memory type. is that suit use both of them in order to accelerate Machine Learning tasks ? those both are compatible to use them at the same time ?
also another question the Cuda support of RTX A6000 ? in GeForce I can handle CUDA but I wonder for RTX A6000 has got specific Cuda support.
and another question; what details should I pay attention to in order to run both of them seamlessly? do I skip any details ?
and last question; May I add external GPUs more than 1 into 1 GPU Dock Station and connect them 1 Thunderbolt 4.0 Port
my OS : Windows11.
I need answer swiftly please someone inform me if has got knowledgePowered by Discourse, best viewed with JavaScript enabled"
563,display-distortion-tesla-t4,"Hi there -Running Horizon View 7.13.1 desktops on Tesla T4 cards, on ESXi 7.0.3 (ProLiant DL385 Gen10 Plus v2 - AMD EPYC 7543 32-Core Processors).  Win 10 20H2 guests.  grid_t4-1b profiles for the VMs.  NVidia 14.1 for VIB and guest drivers, in process on moving to 14.2Users reporting display distortion - sometime a portion of the screen, sometime the whole screen.  See attached screenshot.Particularly seems to happen when the Tesla T4 card is using all 16 slots for the 1gb profile.  Has anyone seen anything similar?Occurring for users both in our office using iGel endpoints with Client 2203, and remotely using various client versions.Thanks,
Tom
Capture1438×533 237 KB
Should have added - often seems to affect all users on the same graphics card.  Seeing it on multiple different hosts.  Sometimes goes away on its own, other times had to move users to a different host.Sounds like FB exhaust. Can you please check the FB usage for the users affected? You may need to switch to 2GB FB insteadhi @sschaber  - thanks for the follow up - will give this a go and see if it helps for us.Powered by Discourse, best viewed with JavaScript enabled"
564,quadro-rtx-passive,"HiFor those interested, the NVIDIA Quadro RTX6000 and RTX8000 GPUs are now available in ""Passive"" configuration for Server OEMs that don’t support the ""Active"" versions.RegardsMGWho on your team is performing game streaming benchmarks on these new high class GPUs? I would love to reach out to them and discuss the tech details regarding utilization of these for deploying CloudXR to m own open source platform HMD. I realize I’m a little late responding but that has because I have spent the last couple years working with an AI startup under NDA and only recently has that contract come to completion.  I’m now able to pursue my passion for streaming GPU solutions. I’m reaching out to you and your company from almost every angle here. I’m really looking forward to hearing from you or some one from your team.Powered by Discourse, best viewed with JavaScript enabled"
565,nvidia-gpu-manager-appliance-for-vmware,"Not sure what subgroup this might go in… but I installed the vcenter server plugin and installed an API key… the plugin is working but fails when downloading selected drivers. It appears nvidia is using a 3rd party server farm for driver dl’s and they don’t provide whitelist info for those services in their (very limited) documentation, tried calling (was hung up on by an Indian call center that had no idea what I was talking about) and then tried opening a case and got a “send me your logs” form letter but the plugin does not have the “download logs” button they seem to think it does. Tried logging into the (ubuntu) appliance directly but the configured user doesn’t appear to have direct login access.Anyone fight through this already?Powered by Discourse, best viewed with JavaScript enabled"
566,saving-nvidia-settings-between-sessions,"HiXenDesktop 7.15 CU4, Grid K2, Win10 LTSC/LTSB VDI mcs random.The 3D software requires Nvidia 3D setting Global Presets to be set to ""3D App - Visual simulation"".This setting seems to be reset to Base profile when restarting the virtual machine.Is there a way to force this settings via gpo, script or registry when starting a virtual machine?Hi Oykleppe, we had kind of the same issue. We resolved this via a Script which sets the Settings over the NVIDIA WMI interface.Other ways are not possible as far as i know since the settings are not stored in any file or in a registry.Br
MatPowered by Discourse, best viewed with JavaScript enabled"
567,tesla-t4-nvenc-with-hyper-v,"Dear All,Is it possible to use Tesla T4 NVENC engine inside of the VM? Host is Windows Server 2016 and VM is Windows Server 2019 with Hyper-V.There are a number of inconsistencies:
1.) vGPU is supposed to be required, but not available for HyperV
2.) DDE is supported for Windows Server OS, but license still needed, even though vGPU not possible?
Same for Bare Metal, supported but license still needed. See here:Documentation for system administrators that describes NVIDIA Virtual GPU licensed products and how to configure licensing for them on supported hardware.Documentation for administrators that explains how to install and configure NVIDIA Virtual GPU manager, configure virtual GPU software in pass-through mode, and install drivers on guest operating systems.3.) When trying to install Tesla Drivers downloaded from here:Download the latest official NVIDIA driversAnd getting to this installer:Download the English (US) Data Center Driver for Windows for  Windows Server 2016, Windows Server 2019, Windows Server 2022 systems. Released 2022.6.6The installer reports:“Unsupported Windows version”when attempting to install in to the Virtual Machine with Windows Server 2019.5.) Microsoft gives instructions:Learn how to use DDA to deploy graphics devices in Windows ServerBut also says, that some GPU makers will not allow some devices to to work.Should it be possible to access Tesla T4 NVENC engine from within the VM as described? How?I can only confirm that NVENC works when the drivers are installed on the host, but it is not clear if any license is required. The Control Panel looks like this:
image958×707 29.3 KB
Thanks!
AtmapuriHi,For sure NVENC works works in a VM. You need the vGPU driver to make the VM work properly. DC driver only supports TCC mode on Windows.
Therefore there is no inconsistency but different features.
DC driver = TCC only
vGPU driver = full support (DirectX, OpenGL) and therefore requires a vGPU license (vWS)regards SimonDear All Simon,You need the vGPU driver to make the VM work properly.Except that on this page:Deliver Graphics Acceleration to Virtualization.Hyper-V is not listed as supported for vGPU. But we do not need GPU virtualization anyway. We only need a single dedicated GPU within one VM. Microsofts Discrete Device Assignment (DDA) is not the way to do it?“DC driver = TCC only”What is “DC Driver”?I have found the that “TCC Only” is “Tesla Compute Cluster Only”:Additional resources for NVIDIA Nsight VSE.Which states: “Current drivers require a GRID license to enable WDDM on Tesla devices.”Does NVENC work in TCC Mode or does NVENC count as a part of “Graphics”?Found this:If the software specifically supports NVENC in TCC mode, then it could work?How to enable Windows Server VM to run the TCC mode? Simply follow through with Microsoft DDA?Thanks!
AtmapuriHi Atmapuri,DC driver = datacenter driver :)DDA is the way to go with Hyper-V. DDA is supported with the vGPU driver.The NVIDIA vGPU software product support matrix.I never used NVENC in TCC mode (with DC driver) but I would assume that this should work. If it works you could use it without a vGPU license. If it doesn’t work you would need to use the vGPU driver (and a vWS license).
BTW: It doesn’t matter if Hyper-V is not supporting vGPU. You would also need the license to use DDA (Passthrough) or even baremetal. The driver makes the difference not the virtualization technology…Hope it is clear now.regards
SimonDear Simon,Thanks a lot for this info. This does add a few stones in to the mosaic. Still missing few pieces though:DC driver = datacenter driver :)1.) Ok, Then the DC drivers are downloadable from here:Download the latest official NVIDIA driversWhere it says: “Data Center/Tesla” in the dropdown box.And this is also what I have installed for now in to the host, just to check that Tesla is present and working.2.) In our case NVENC is to be used by a Windows Service and it should be running also while there is no user logged in or connected to the Windows VM via Remote Desktop or other desktop access software.There a number of articles on internet (10+ years old), which say that NVidia TCC solves this problem, but there is nothing about the NVidia vGPU driver.Additionally, in case of vGPU:
Which license would we need for this? You mention vAps and vWS, but vCS looks closer to me?
Which license covers NVENC and allows capability described above?BTW: It doesn’t matter if Hyper-V is not supporting vGPU.3.) If I go here:Deliver Graphics Acceleration to Virtualization.and try to register for a trial version of vGPU software, it is not possible to specify Hyper-V. And the Hypervisor field is marked as “required”. How to get the driver?Our machine is certified for vGPU (ProLiant DL380 Gen10) although we will only be using one card within one VM with it:Download NVIDIA GRID datasheets, guides, solution overviews, white papers, and success stories. Watch GRID videos, webinars, and webcasts.After pretending to use the VMware Sphere, I got to see this:
NvidiaCapture1904×1086 155 KB
And the questions would be:
a.) Is the Nvidia Microsoft Hyper-V 2016 Software to be installed in to the Host or in to the Guest?
b.) Is there any support from Nvidia Installer to Configure Microsoft DDA?Thanks!
AtmapuriPowered by Discourse, best viewed with JavaScript enabled"
568,ffmpeg-with-cuda,"Hi All,We are planning to develop a commercial product that uses FFMPEG for video processing like making part of video blur, slowing down part of video, merging 2 or 3 videos, HEVC decode and encode it to x264. To achieve this we are planning to use CUDA toolkit to enable NVidia hardware acceleration. I tried to compile FFMPEG with hardware acceleration from below URL.https://docs.nvidia.com/video-technologies/video-codec-sdk/ffmpeg-with-nvidia-gpu/index.html#compiling-for-windowsI was able to compile it successfully but whenever I try to use any of complex filters like boxblur or use options like baseline, I see errors likeUnable to parse option value “baseline”
No such filter: ‘boxblur’Can anyone let me know what are the complete build/configure options that I can use to achieve these video processing activities.Kindly help.Thanks in Advance,
SushmaPowered by Discourse, best viewed with JavaScript enabled"
569,nvidia-grid-vgpu-vmware-7-03-ampere-a-100,"Good evening, we bought 2 Ampere video cards NVIDIANVIDIA A100-PCIE-40GB but we can’t work in Nvidia Grid VGPU profile mode. The drop-down menu is empty.
The system used is VMware 7.0 Update 3 Enterprice Plus and the drivers installed are:
Nvidia-vmware_esxi_7.0.2_driver 470.63-1oem.702.0.0.17630552 NVIDIA VMwareAccept 2021-12-11
The cards are in Shared Direct mode.
Thank youHi,
You will need NVAIE for A100. VGPU doesn’t support A100/A30 anymore starting with vGPU 13.xRegards SimonI followed this guide,To enable developers to deploy AI/ML workloads on TKGS clusters, as a vSphere Administrator you set up the vSphere with Tanzu environment to support NVIDIA GPU hardware.I have nVidia licenses and I downloaded drivers from the site, but the problem remains
Immagine 2021-12-12 182648640×696 32.1 KB
Do you really have a NVAIE trial? You require the right .VIB from the NVAIE software to support A100. VGPU Trial and software won’t work.I’m using this version

Immagine 2021-12-12 2107581915×774 95 KB
Won’t work. As I ssid you need to request a NVAIE trial
https://www.nvidia.com/en-us/data-center/products/ai-enterprise-suite/ok thanksHi @utente994 @sschaber,
I have the same problem. Please help me what can I do to solve it.
Many thanksYou need NVAIE instead of vGPU.Powered by Discourse, best viewed with JavaScript enabled"
570,vgpu-guests-fail-after-restart-with-all-cuda-capable-devices-are-busy-or-unavailable,"Curious for any ideas, as we hit a roadblock. Any reason rebooting vmware RHEL VMs would start breaking nvidia-docker apps? Or how to fix ‘CUDA-capable devices are busy or unavailable’ + ‘gridd: failed to initialize RM client’ when nvidia-smi works and other VMs are able to use the GPU?Background:We had our hypervisor (vmware) + 2 guests RHELs (Q or C splitting GPU mem in half) + nvidia-docker CUDA app running fine on both. Namely, nvidia-smi running fine in the hypervisor/guest docker, Nvidia RAPIDS cuda context creation / compute / etc in docker.At some point, one of the GPU VMs was rebooted and the docker images failed to start.  Nvidia-smi did not work, yet it was fine in the hypervisor and the other VM, and licensing seemed fine in the other VM. We reinstalled the guest’s original gpu driver, restarted docker, and created the docker images, which immediately fixed nvidia-smi in the guest + docker… but then we saw “all CUDA-capable devices are busy or unavailable” errors whenever the docker app (RAPIDS) tried actually using the GPU.  In addition, checking gridd logs showed error “failed to initialize RM client”. The GPU reported itself to be in Default mode (shared), and reinstalling the nvidia-docker runtime did not help.More fun: We then took the second VM, that had been continuously working all along, and restarted it… and nvidia-smi broke at the guest level too.Hi Leo8,Thanks for posting.  I recommend that you open a support ticket so our support team can dig into the issue.thanks
DHappy to, any idea where? (This is on behalf of a F500 we’re working with, and we’re an Nvidia partner, and I was steered to this site before)Trying to find someone with the proper forum access to the enterprise portal. Meanwhile, if any pointers, would be appreciated – these systems were designed avoid surprises like this, so we’re curious.Powered by Discourse, best viewed with JavaScript enabled"
571,maya-2020-constantly-crashing-mouse-keyboard-camera-shortcuts-not-working,"Hi,
My colleagues at University of Melbourne have set up a virtual desk top in Windows 10, 64 bit environment, which is run RHEL-KVM with an attached GRID V100S-8Q. There is 8GB of vRAM. The driver version is 452.39 with 5120 CUDA cores and 38911 total available graphics. I have tried to install Autodesk Maya 2020.4 on this instance and have found that the mouse-keyboard camera shortcuts (ie alt + LMB, alt +MMB or alt + RMB) are not working, although the camera track, tumble and dolly commands do work from the hotbox menu. I tried reinstalling and updating the software and this did actually restore the keyboard-mouse shortcuts for a short time, but they reverted to the non-functional state again the same day. I’ve also found that Maya is really unstable and crashes constantly. I’m wondering whether the specs we have for the instance are sufficient to operate Maya 2020.4 please? If so, do you have any other ideas as to what might be going on please?
Thanks so much and best wishes,
MajaReset Maya to Default
Use this guide:  Reset Maya to Default
Preferences can be corrupted after extended use or after a crash, and continue to cause problems unless reset, which clears out the corrupted nodes.
Verify Hardware and Drivers, cookie clicker
Confirm that the Graphics Card is on the List of Certified Hardware for Maya, and that it meets the System Requirements (these will vary depending on the version of Maya being used).
Check that the Graphics Card Drivers are up-to-date (Windows and Linux).
Make sure that Maya is using the correct Nvidia graphic card: How to assign an NVIDIA GPU to Maya on Windows.Hi Henry,
Thanks for your reply. I’ll have a look at all the points you mention, but I think I have already investigated most of these. Also, I think there are some live links that are missing?
Thanks so much and best wishes,
MajaPowered by Discourse, best viewed with JavaScript enabled"
572,nvidia-a10-and-a16-launched,"NVIDIA Brings Powerful Virtualization Performance with NVIDIA A10 and A16 | NVIDIA BlogLet us know if you have questions about the new cards.The A16 GPU : Take Remote Work to the Next Level | NVIDIA is the replacement to the Tesla M10.  It has 4 GPUs on a single board and is aimed at high density VDI environments using out vGPU vPC licenses.Overview of new products - Login - #1 AI Conference | GPU Technology Conference | NVIDIAYou will need to register for GTC (which is free) to viewPowered by Discourse, best viewed with JavaScript enabled"
573,tesla-t4-windows-10-1803-could-not-update-drivers-from-10-0-441-66-to-any-newer-versions,"Hi,
i got a big problem updating my virtual Windows 10 clients. Initial i’ve setup an environment with multiple vSphere 6.7 hosts and NVIDIA grid drivers version 10.0. Now i want to update these hosts to a newer version because we have trouble with the graphic performance (black screens and driver crash in the guests). My first try was to update within the major version to 10.2. I put one host in maintenance and install the new host driver VIB. Check with nvidia-smi -> all fine. After them i used one VM to test the guest driver. Driver update failed. I uninstall the old driver, reboot the vm and install the new driver -> installation failed. I run this as administrator and i stopped the virus protection. After them i tried to update to version 11.0. My host is fine but the guest driver installation failed. I checked the same thing with two other VM’s -> same result.
If i deployed a new vm (same OS, drivers and so on) then the driver installation works. But i have around 100 exsisting VM’s - they could have all the same failure. I checked the filesystem with sfc /scannow and used dism to control that Windows isn’t damage. No hidden devices or something else. It’s very frustating.The installer logs show’s an error:I contacded the nvidia support but with different time zones it’s very long between any answers. Has anyone an idea what i can check?Let’s start with the basics.  How are you updating the driver?  Gui?  CMDline?  If command line what commands are you using to do the install? And on the windows 10 side, what OS release are you using, have you confirmed it’s supported by 10/11?If the above all looks good I’d try installing just the driver and seeing how it works.  Currently I do the below for our driver installs and it seems to workHi garyd,thanks for your reply. My goal is to update these drivers through CMDline. But since it failed i tried GUI installer too. My parameters are nearly the same as yours (without -passive and the packages).
My Windows 10 version (ver. 1803) are supported with driver version 10.X and 11.0.Now i tried your one. Extract the installer, run setup with your parameters and then reboot the vm. After reboot i could not see NVIDIA control panel and the device manager shows only a ""Microsoft Basic Display Manager"" instead of the NVIDIA Grid Display.That’s super odd.  I’d try to confirm that any Nvidia settings/folders/Registry items haven’t been left on the machine that could be blocking the install.Would also try installing with just the Display.Driver package to see if that can work.  Might make it easier to parse the logs to see if something seems off.  I don’t have any a t4 so i can’t help by doing a more thorough test here.
If no luck I’d definitely try to get a support ticket open, there may be a know issue that can fix this.Hi derhoeppi I know it’s been years but did you ever find a solution? I’m having the same problem now. Thx in advance!Powered by Discourse, best viewed with JavaScript enabled"
574,unable-to-increase-memory-on-esx-server,"Hi,
we’ve got an ESX guest server running Windows Server 2016 with an Nvidia Tesla M60 in compute mode attached as a PCI device.This is all running fine without any issues.The guest server has 256GB memory.When I increase the guest server memory to 320GB, and re-check the ‘Reserve all guest memory’ option the server won’t start - I get the error messages ‘Failed to register the device pciPassthru0 for 5:0.0 due to unavailable hardware or software support.’ and ‘Module ‘DevicePowerOn’ power on failed.’Has anyone got any ideas on what I can do to fix this please?thanks,TomI managed to fix this by updating the firmware on the host server.thanks,TomPowered by Discourse, best viewed with JavaScript enabled"
575,nvidia-dls-licensing-licensed-clients-gets-dropped-after-some-time,"Hello!
I am new to the community and wanted to ask if anyone has had any issues with their DLS deployment?In our organization, we deployed a couple of DLS v2.0.1 in clustered mode.  We have had it setup for several months now and it seemed to have been working fine however, we recently noticed some of our VM’s exhibiting performance issues.  We tracked down the issue to the VM’s vWS license somehow getting dropped/lost.  We can reboot the VM and will re-acquire the license but my understanding is that all license server clients that have acquired a license would attempt to renew when the lease reaches 15% of it’s life span.  It does not appear to be doing this consistently.  Just over the weekend, we rebooted all our VM’s - we have 55 of them.  We then confirmed that the DLS pool has provisioned all 55 licenses.  This morning, we came in that it appears that the DLS server is only reporting 12 licenses being “in use”.  Why did the the other 43 did not renew?  BTW, we have 70 vWS licenses so we have definitely covered our current operational needs.  If anyone can chime-in who have experienced this issue or can assist with troubleshooting, we would appreciate it!Hi, please raise a support ticket with NVES. This is exactly why you have support with our products. Our support can analyze the logs and hopefully figure out what going on.Best regards
SimonThank you - we’ll do!Powered by Discourse, best viewed with JavaScript enabled"
576,nvidia-display-container-right-click-menu-issue,"Nvidia Display Container seems to be crashing and affecting the Right Click menu not opening. The problem occurs when several users almost simultaneously log in to the Windows Server 2019 terminal server. But when they log in in turn (after the message “NVIDIA RTX Virtual Workstation license received” appears on each user), the right-click menu opens normally. Can you help with this?Known issue. Are you still on 15.1? Please update to the latest…It seems to be 15 installed. It need to consider this possibility. Now I used the ShexView utility, deactivated the Nvidia Cpl item. Now there is no Nvidia Control Panel, but it seems to Right Click works on all users. Thank you very much for your answerNVIDIA-GRID-Windows-525.85.05-528.24
NVIDIA-SMI 528.24       Driver Version: 528.24       CUDA Version: 12.0     ||-------------------------------±---------------------±---------------------+| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||                               |                      |               MIG M. ||===============================+======================+======================||   0  Tesla V100-PCIE… WDDM  | 0000553F:00:00.0 Off |                    0 || N/A   34C    P0    23W / 250W |    648MiB / 16384MiB |      0%      Default ||                               |                      |                  N/AOK, otherwise please update your software to the latest:

image883×225 21.7 KB
OK, otherwise please update your software to the latest:Thank you for confirming my actions in this case. I’m going to try version 15.2 (Complete vGPU 15.2 DDA GPU driver package for Microsoft platforms) for our hypervisor Windows Hyper-V Server 2019. Thank you very much for your replyUnfortunately, updating to version 15.2 did not resolve the issue. Therefore, I again used the ShexView utility. Maybe I’m doing something wrongPowered by Discourse, best viewed with JavaScript enabled"
577,tesla-v100-16-gb-problem,"Hello.My tesla v100 16 gb pcle card not starting.
To solve issue i need this card components list and pcb scheme if possible. If no one have can you share good quality picture of your 16 gb v100 card.
960×417 75.9 KB

Found it hard to locate even that card pcb picture on google. Can it be GPU processor who is bad ?Daily up. Still looking for information
Lets say cant find any information on this component. None for sale.
Nvidia not made that components for shure. Wonder there i can buy them.Powered by Discourse, best viewed with JavaScript enabled"
578,p2200-compatible-with-vcs-and-vdws,"Hello,I need to set up a test server to do VCS and VDWS for a client. For the prototype, I would like a graphics card with a reasonable cost for the customer. I thought about the P2200, is it compatible with these two technologies? Otherwise what do you advise me?
Regards,
Thank You,WesleyNo, you need a vGPU enabled GPU.Powered by Discourse, best viewed with JavaScript enabled"
579,gk20a-channel-timeout-handler-in-jetson-tx2,"Hi , In one of our projects with Jetson TX2 running with 32.5L4T, we see the below problem after few days of running the cuda based graphics application continuously.[27005.019288] nvgpu: 17000000.gp10b gk20a_channel_timeout_handler:1573 [ERR] Job on channel 502 timed out
[27005.030424] nvgpu: 17000000.gp10b nvgpu_set_error_notifier_locked:137 [ERR] error notifier set to 8 for ch 502
[27005.147316] nvgpu: 17000000.gp10b gk20a_channel_timeout_handler:1573 [ERR] Job on channel 503 timed out
[27005.158616] nvgpu: 17000000.gp10b nvgpu_set_error_notifier_locked:137 [ERR] error notifier set to 8 for ch 503
[27011.235220] nvgpu: 17000000.gp10b gk20a_channel_timeout_handler:1573 [ERR] Job on channel 505 timed out
[27011.246574] nvgpu: 17000000.gp10b nvgpu_set_error_notifier_locked:137 [ERR] error notifier set to 8 for ch 505
[27014.874996] INFO: rcu_preempt detected stalls on CPUs/tasks:
[27014.880693] 0-…: (4 GPs behind) idle=72b/140000000000002/0 softirq=685700/685711 fqs=2530 [27014.889212] (detected by 4, t=5255 jiffies, g=505571, c=505570, q=1271) [27024.350999] Kernel panic - not syncing: Watchdog detected hard LOCKUP on cpu 0 [27024.358234] CPU: 5 PID: 0 Comm: swapper/5 Not tainted 4.9.201-tegra #100
[27024.364934] Hardware name: quill (DT)
[27024.368599] Call trace:
[27024.371062] [] dump_backtrace+0x0/0x198
[27024.376468] [] show_stack+0x24/0x30
[27024.381525] [] dump_stack+0xa0/0xc8
[27024.386580] [] panic+0x12c/0x2a8
[27024.391378] [] watchdog_check_hardlockup_other_cpu+0x11c/0x120 [27024.398773] [] watchdog_timer_fn+0x98/0x2c0
[27024.404521] [] __hrtimer_run_queues5y+0xd8/0x360
[27024.410527] [] hrtimer_interrupt+0xa8/0x1e0
[27024.416277] [] tegra186_timer_isr+0x34/0x48
[27024.422025] [] __handle_irq_event_percpu+0x68/0x288
[27024.428463] [] handle_irq_event_percpu+0x28/0x60 [27024.434640] [] handle_irq_event+0x50/0x80
[27024.440213] [] handle_fasteoi_irq+0xd4/0x1c0
[27024.446044] [] generic_handle_irq+0x34/0x50
[27024.451789] [] __handle_domain_irq+0x68/0xc0
[27024.457619] [] gic_handle_irq+0x5c/0xb0
[27024.463016] [] el1_irq+0xe8/0x194
[27024.467895] [] cpuidle_enter_state+0xb8/0x380
[27024.473813] [] cpuidle_enter+0x34/0x48
[27024.479125] [] call_cpuidle+0x44/0x70
[27024.484348] [] cpu_startup_entry+0x1b0/0x200
[27024.490182] [] secondary_start_kernel+0x190/0x1f8
[27024.496445] [<000000008122b1a4>] 0x8122b1a4
[27024.500632] SMP: stopping secondary CPUs
[27025.707803] SMP: failed to stop secondary CPUs 0,5
[27025.712594] Kernel Offset: disabled
[27025.716084] Memory Limit: none
[27025.719142] trusty-log panic notifier - trusty version Built: 14:49:57 Jan 15 2021 [27025.753433] Rebooting in 5 seconds…
[27030.758140] SMP: stopping secondary CPUs
[27031.965311] SMP: failed to stop secondary CPUs 0,5
[0000.175] I> Welcome to MB2(TBoot-BPMP)(version: 01.00.160913-t186-M-00.00-mobile-03715cad) [0000.184] I> Boot-device: eMMC
[0000.191] I> sdmmc bdev is already initialized
[0000.196] I> pmic: reset reason (nverc) : 0x0
[0000.229] I> Found 19 partitions in SDMMC_BOOT (instance 3)
[0000.249] I> Found 34 partitions in SDMMC_USER (instance 3)
[0000.255] I> A/B: bin_type (16) slot 1
[0000.258] I> Loading partition bpmp-fw_b at 0xd7800000
[0000.263] I> Reading two headers - addr:0xd7800000 blocks:1
[0000.269] I> Addr: 0xd7800000, start-block: 44098752, num_blocks: 1
[0000.294] I> Binary(16) of size 534416 is loaded @ 0xd7800000
[0000.299] I> A/B: bin_type (17) slot 1
[0000.303] I> Loading partition bpmp-fw-dtb_b at 0xd79f0000
[0000.308] I> Reading two headers - addr:0xd79f0000 blocks:1
[0000.314] I> Addr: 0xd79f0000, start-block: 44102008, num_blocks: 1
[0000.340] I> Binary(17) of size 604720 is loaded @ 0xd796c400What could be the reason for this and how to handle this?Unfortunately you are in the vGPU forum. I really doubt that someone can help you here.Powered by Discourse, best viewed with JavaScript enabled"
580,nvidia-grid-tesla-p40-performance-issue-after-vgpu-driver-installation-on-vdi,"Hello NVIDIA Grid Forum,actually we are working on a project with cad virtualization.
i have a big performance issue with my Citrix/Nvidia Grid Infrastructure
the problem starts after we install the nvidia GPU drivers in the VMs/VDIs.
different applications are very slow after the driver installation
for example solidworks(CAD Application) oder a Sage Client(ERP Application)Before the installation everything is OK!!!this is our infrastructure:
2 x Dell PowerEdge Server 740
each server has two NVIDIA Tesla P40 Grid cards
we tested it on Xenserver 7.1 / 8.0 / 8.1 full patched
we tested it with vGPU 9.2 (431.79) und 10.1 (442.06)
the problem exists with different nvidia profiles 2Q or 12Q
the VMs working with Win10 1903, the problem is also there with Win10 1909
the problem exists with 32GB RAM or if you assign a lot of more RAM
the problem is also there with only one vm on the server at the same time
you can see the problem directly in the console or in a citrix session(same impact)we tried a lot of things but at the moment the ideas run out ;-(Do somebody have ideas for us or the same impact?thanks a lotZoranPowered by Discourse, best viewed with JavaScript enabled"
581,grid-m10-on-azure-hyper-v,"Hi,Our organisation is starting to use Azure servers to stream apps and create virtual desktops.  We are running Azure Nv12v3’s with the M60 cards in them.  As part of the agreement with Microsoft we get Grid licences for every GPU.Grid des not seem to be working though.   We are running an App called keyshot 9.3 that can render using GPU’s.  but Grid does not share the processing equally like I believe it should.  one guest/user on the VM will dominate the card while the other users on the machine will get virtually no GPU access.Please can you advise what the issue might be.Kind RegardsSimonHiAre your users sharing the same VM like an RDSH deployment? Or do you have multiple VMs with a GPU attached to each?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
582,what-driver-to-download,"Hi thereI have a customer that uses Citrix Hypervisor 8.2 and there are a bunch of virtual machines with GPU GRID M10-A8.I want to update the drivers which are apparently 472.98 (installed 14-02-2022). But if I download this package “NVIDIA-GRID-XenServer-8.2-450.236.03-450.236.01-454.14” the driver version included seems to be older??RegardsHello, are you looking for the latest vGPU drivers with Citrix Hypervisor 8.2?
The latest drivers are vGPU 15.2 (NVIDIA Virtual GPU (vGPU) Software Documentatio).Please look for the following entry in the NVIDIA Licensing portal (NVIDIA Licensing Portal) to download these drivers:Platform: Citrix Hypervisor
Platform version: 8.2
Product Version: 15.2
Description: Complete vGPU 15.2 package for Citrix Hypervisor 8.2 including supported guest drivers
Release Date: Mar 30, 2023Please feel free to let us know if you have any further questions.Thanks,
Lokesh BatraPowered by Discourse, best viewed with JavaScript enabled"
583,using-nvidia-mig-instances-to-start-x-servers-with-nvidia-xconfig,"We have a Ubuntu 22.04 server with 4 GPUs. We have been trying to use the feature for GPU partitioning. However, in our use case, we require the ability to render offscreen onto an X server with Vulkan (Unity applications). We have previously been using this command without MiG (reference):sudo nvidia-xconfig -a --allow-empty-initial-configuration --use-display-device=None \ –virtual=1920x1200 --busid {busid}But with MiG instances, there are no bus ids. Nvidia-xconfig doesn’t allow the use of MiG uuid instead of busid. So, we can’t spin up X servers with specific MiG instances. Is it possible to do this? If not, what are the alternatives?Hi,could you please give a bit more background? Which GPUs do you have? You are talking about MIG and rendering which is a bit odd.
MIG is only supported on A30/A100 GPUs which are compute only, so no rendering at all on these GPUs.
Not sure what you are going to achieve.regards
SimonWe have 4 A100 80 GBs. We are trying to partition GPUs and do rendering on a headless X server. We can already do that without MiG. We want to split it up so that multiple users of the server can better utilise the GPU resources.Powered by Discourse, best viewed with JavaScript enabled"
584,gpu-card-licenses-technology-vdga-etc-for-horizon-view,"Hello,I’m digging through the information on different NVIDIA sites. We’re creating a business case for physical GPU cards. We’re running Horizon View and have an average of 150 ccu’s. Of those users about 100 need basic GPU performance and about 50 need a higher amount of GPU performance. Is it even possible to have users with different amounts of available GPU power?What current technologies are there in terms of GPU sharing within VMware Horizon (vDGA etc.), which card(s) would work best for above scenario and which licenses would we need?I have found the following sources, but it is still quite unclear:NVIDIA GPU accelerators provide IT departments the graphics and compute virtualization resources needed to meet demands and scale across the enterprise.
A100, L40, L4, A30 and A16 seem to be worth looking into.and the buy-grid/ guide, which I can’t link because new users can only provide one single link per post…
The licensing model doesn’t make much sense without any context as to when which license is required. vPC, vWS, vPC and vApps. Or perhaps the licensing model when installing on-prem GPU cards is totally different?
It’s all just a big blur right now.Thanks for any clarification.Hi ST84,Thanks for the question.What current technologies are there in terms of GPU sharing within VMware Horizon (vDGA etc.), which card(s) would work best for above scenario and which licenses would we need?vGPU is NVIDIA’s technology for GPU sharing for virtual desktops.  vGPU is a licensed software and is licensed based on CCU.  For virtual desktops L4, L40, A16 or A40 would be the current options.  The “L” and “A” refer to different generations of GPU - “L” for ada Lovelace being the latest technology.For GPU sharing for compute tasks like HPC, AI, Deep Learning, the A100 and A30 can also be used but require a different licensing scheme called NV AI Enterprise.  I don’t think you are looking for this.Of those users about 100 need basic GPU performance and about 50 need a higher amount of GPU performance.vPC is our license/technology for basic GPU acceleration aimed at Knowledge workers i.e. users who are using Windows 10 OS and basic productivity is improved with GPU acceleration.  vPC can provide a better quality of experience to these users.  A16 is the most commonly used GPU for vPC installations.vWS is our license/technology for users who are running 3D graphics accelerated applications - i.e. anything ranging from AutoCad to more complex 3D applications like Maya.  This lengthy guide provides information on how to size a system sizing-guide-nvidia-rtx-virtual-workstation.pdf, although our basic advice is to ask what GPU do your users use now for these applications and then relate the physical GPU to vGPU profile proxy.   The GPU choice will depend on your user needs but vWS is supported on A16/L4 and L40.  A16 would be considered an entry level GPU.Assuming your definition of basic and higher amount of graphics usage matches ours you would be looking at 100 vPC licenses and 50 vWS licenses.To get started I recommend that you work with an NVIDIA partner who is familiar with vmware, NVDIAI vGPU and the various OEM server vendors who offer NVIDIA Certified Systems.   You can locate a partner here: Find an NVIDIA Partner | NVIDIA  Search via compentancy “NVIDIA Virtual Desktops”.A partner will be able to guide you through the various GPU options, density, server considerations, ESXi versions etc.-D-Hi DougT,what I’m trying to wrap my head around is:
Example;
We install two A40 cards in our hosts, what difference, other than the dollar amount, does it make if we now buy x-amount of vPC licenses or x-amount of vWS licenses? I guess what I’m trying to ask is, are the cards software-throttled based on what licenses we activate?Thanks!For GPU sharing for compute tasks like HPC, AI, Deep Learning, the A100 and A30 can also be used but require a different licensing scheme called NV AI Enterprise.Sorry to interject, but does this mean that the software required for sharing GPU compute resources remotely on the A100 is effectively unavailable to non-business customers?
For example, if I wanted to provide some friends with remote access to my A100 when they would like to experiment with some AI things, I would be unable to do so with the device I purchased for personal use?
Is it even possible for an individual to subscribe to AI Enterprise if they are not doing so through a business account, even if they were to pay whatever the price might be?
Does NVIDIA provide access to the features of products in any other manner when the features of a product otherwise require AI Enterprise? Or would customers purchasing these devices without AI Enterprise be stuck with an arbitrarily partial product?Powered by Discourse, best viewed with JavaScript enabled"
585,nvidia-dell-or-hp-tesla-t4,"Anyone know if the Dell OEM T4 (or HP version) will work in a SuperMicro server or is it locked to Dell gear?I am using the HPE Tesla T4 version in a Fujitsu workstation (a non Nvidia certified one) and vDGA works perfectly. I can’t get vGPU to work though if you’re looking for that.You can find a list of qualified servers for the T4 here: Qualified Server Catalog | NVIDIA  - filter on Supermicro and T4.We don’t lock T4s to specific server OEMs.  The reason for using a Dell T4 in a Dell server is that Dell can provide you full support for the server and GPU.Powered by Discourse, best viewed with JavaScript enabled"
586,tesla-v100-16-gb-currently-on-hyper-v-with-dda-any-advantages-using-quadro-vdws,"Hello.
I’m new to all this vGPU world and I received a server with 4 Tesla V100 (16GB). I had to install windows server 2019 with Hyper-V and configured it with Discrete Device Assignment (DDA) because, from what I read until now, there is yet no way for hyper-v to distribute the GPU across all VMs. But, I also read that a microsoft solution might be underway soon.Today I came across Nvidia vGPU. Supposedly, Quadro vDWS should be the software to install (the server hardware is fully supported), but does it still require Hyper-V with DDA? If so, does this mean I can only have 4 VMs using the 4 GPUs available? If that’s the case, I don’t understand the purpose of using Quadro vDWS. My goal is  is to make the 4 GPUs available to all existing VMs.
Thanks and regards
DavidHiThe problem is Hyper-V, not Windows, NVIDIA, the V100s or vDWS.If you switch Hypervisor to one that supports vGPU, you’ll have far more functionality available. XenServer, vSphere, KVM, AHV, they all work with vGPU. Hyper-V is the one that doesn’t. You’ll need to use DDA (Passthrough) if you want to carry on down that road, and yes, that will limit you to 4 VMs, 1 per GPU, as you can’t virtualise them (with Hyper-V).As for vDWS, that’s part of a 4 tier licensing model. vApps, vPC, vCS, vDWS. Each version allows different functionality, with vDWS being at the top.Out of interest, what was your planned use case?RegardsMGThanks for the reply. So if I understand it correctly, even if we buy the vDWS package it won’t be possible to make the 4 GPUs available for all VMs? But if so, I can’t see any advantage of using it with Hyper-V and still it is available for purchase?!On the ""NVIDIA VIRTUAL GPU PACKAGING, PRICING AND LICENSING"" document I read yesterday (from June 2019) Hyper-V is supported and the recommend license is Quadro vDWS.Although I was not consulted for que acquisition, this server is supposed to be used at a University for department for research.
Thanks and regards.
DavidHiAt the moment, the only option with Hyper-V is to allocate an entire GPU to 1 VM, or multiple GPUs to 1 VM. As there is no vGPU, there is no ability to run multiple VMs on a single GPU.Whether used in DDA (Passthrough) or vGPU, Tesla GPUs require a license depending on the use case and required functionality. With Graphical sessions, the licensing is per concurrent user. With Virtua lCompute Server, the licensing is per GPU. Have a look here for license functionality: Client Licensing User Guide :: NVIDIA Virtual GPU Software DocumentationAs you’re using Hyper-V, your options are limited to either allocating 1 V100 to 1 VM and having a total of 4 active VMs with 1 user on each. Multiple V100s to a single VM, or, you can use a VM with the RDSH role installed and a V100 attached and provide multi-user access like that to achieve greater density. Changing the Hypervisor will give you vGPU functionality.How many VMs do you have that require GPU access?RegardsMGThank you so much for the reply. For now we are using 3 VMs, but I guess it won’t be long to all 4 have their respective assigned GPU.In the link you providedTable 2. NVIDIA vGPU Software License Enforcement by Deployment TypeMicrosoft DDA for workstation or professional 3D graphics	Quadro vDWS	Software
Microsoft DDA for compute-intensive virtual compute servers Software See Note (4).
Microsoft DDA for PC-level applications	GRID Virtual Applications	EULA onlybut in this document https://images.nvidia.com/content/grid/pdf/Virtual-GPU-Packaging-and-Licensing-Guide.pdf (updated since yesterday with Red Hat KVM :) )There is this section.
I am using… I need this license…Microsoft
Hyper-V (DDA) Quadro vDWS
Previously in the same document VGPU software editions and entitlement also show Quadro vDWS as a more complete solution, am I right? Anyway, no one considered any licensing, so I guess users will have to use Hyper-V with DDA and none of the vDWS or Virtual Computer Server. GRID Virtual Applications seems the only one to be available for free.
If I got it right anyway…HiYes, QvDWS is the premium level license. This license covers everything the GPUs are capable of delivering, from performance to features and functionality. There is no higher level license.DDA / Passthrough will still require a license. Have a look at the table on Page 12 of your link above for guidance on specific use cases. You can either use vApps or QvDWS depending on your requirements. QvDWS will allow CUDA workloads and Quadro features, whereas vApps is for RDSH and more basic applications.Most expensive scenario, assuming 1 VM per GPU, you’ll need 4 QvDWS licenses, but we’re not talking about a lot of money in the big scheme of things. That said, in your post above you mention the workloads will be run at a University, therefore I assume you work in EDU, if that’s true, then you could be entitled to an EDU discount for any licenses, so check with your license provider before purchasing :-)RegardsMGHi.
Thanks again. yes I read about education licences.
The weird thing is that I have already at 2 people working with 2 linux VMs using the assigned GPU, and everything seems to be working fine. No one told me otherwise. I guess they might be using some other toolboxes/driver/open source software that doesn’t require any of these softwares?
Probably I can only get some more information during next week, as some of them are still on ""vacations"".
Thanks and regards.
DavidPowered by Discourse, best viewed with JavaScript enabled"
587,is-cuda-absolutely-necessary-to-run-nvenc-under-linux,"On Maxwell (example:M10) CUDA is available just in full-chip 8Q configurations. But as for I can understand, NVENC is not ""hardwired"" to CUDA units. So, if one could use NVENC directly, that could give much more flexibility since much more guests could be run simultaneously. Is that technically possible? Are there some samples or documentation?Didn’t get your question. Nvidia Encoder is a specific hardware ASIC on the GPU for defined Codecs. It has nothing to do with CUDA. And for sure it can be used for several simultaneous sessions. This is exactly what is done in the VDI space for Remoting protocols like Citrix HDX3D Pro or VMWare BlastPowered by Discourse, best viewed with JavaScript enabled"
588,xorg-log-file-var-log-xorg-0-log-does-not-exist,"I install NVIDIA gpu driver by NVIDIA-Linux-x86_64-525.89.02.run runfile, and when I exec nvidia-detect -v it prompt some warnings:It seems something about nvidia-xconfig, but I do not find the docs about how to set and run it.Powered by Discourse, best viewed with JavaScript enabled"
589,can-we-install-gpu-drivers-on-virgl,"virgl is the OpenGL renderer in Qemu guest OS when using -device virtio-vga-gl -display gtk,gl=on command line. Since virgl can delegate the rendering commands to host GPU, can we use virgl to emulate an nVidia GPU and install drivers as well as CUDA on it? PS, both the Host and Guest OS are Ubuntu 20.04.A full list of supported vGPU hypervisors and OSes are available here: Supported Products :: NVIDIA Virtual GPU Software DocumentationWe do not support Qemu or virgl.:D:Thank you for the crisp answer.Both being paravirtualization, WSL2 works much better than qemu in term of support of GPU and CUDA. Thanks a lot for cooperation between NV and MS.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
590,rdp-client-nvdia-tesla-m60-grid-card,"Hello everyone,
I’m planning an environment to delivery Win10 VDIs that will need to use 3D apps like AutoCAD and image processing. The customer would like to use Win10 VMs and Citrix Hypervisor to host them.In the user layer, they will receive a thinclient and will use a RDP connection to connect to Windows 10 VM (virtualized in Citrix Hypervisor with Tesla Grid configured).I’ve saw this in the NVidia documentation:Using Windows Remote Desktop (RDP) to access Windows 7 or Windows Server 2008 VMs running NVIDIA vGPU will cause the NVIDIA driver in the VM to be unloaded. GPU-accelerated DirectX, OpenGL, and the NVIDIA control panel will be unavailable whenever RDP is active. Installing a VNC server in the VM will allow for basic, low-performance remote access while leaving the NVIDIA driver loaded and vGPU active, but for high performance remote accesses, use an accelerated stack such as Citrix Virtual Apps and Desktops.From <Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software Documentation;Customer must use Citrix Virtual Apps and Desktops to delivery the VDIs?HiIf you’re using Citrix, then you won’t be using RDP (RDP is a Microsoft Protocol), you’ll be using ""HDX 3D Pro"" (which is a Citrix Protocol) and there’s no need to use VNC either.Also, don’t use M60 (Maxwell) GPUs in a new environment. Anyone building a new environment should be looking at T4 or RTX 6000 / 8000 GPUs, or a mix of them depending on the environment. These will be more cost effective, more flexible and provide much better performance. Although they will technically work in a new environment, Maxwell and Pascal architectures should now be used for existing environments where those specific architectures / GPUs have already been deployed and consistency is required for scaling up / out (although there’s an argument against doing that as well), and Volta is altogether a different use case.It sounds like you’re quite new to this type of technology. You should be planning to do this already, but I would strongly advise you run a POC with the customer and also get yourself a private test Lab so you can experience and familiarise yourself with these technologies before discussing them with customers first, it will make things a lot easier for you :-)RegardsMGThanks for your reply MrGRID!so, just to clarify… costumer doesn’t have Citrix Virtual Apps at this moment, so, I’ll propose a new lab with this technology and nvidia to them.Thank you so much to advance.HiBefore you design the POC environment, you need to gather some details and metrics from their existing physical workstations. You should have the specifications of the physical workstations (CPU, RAM, GPU, Storage), the resolution of the monitors and how many monitors are going to be used, a full list of all applications, and also some newly captured performance and utilisation metrics from these applications. That’s an absolute minimum. After you have those details, you can begin configuring the appropriate hardware specifications for the POC. At that point, you can also find out whether they are experiencing any performance limitations, you can then add performance where it’s needed into the POC specifications.As you’ve already mentioned AutoCAD and Image Processing, your CPU choice should have a fast base clock (3.0GHz +). Forget about Turbo, you’ll have a better, more consistent experience with a fast base clock. Depending on the application requirements (how it scales it’s performance) and how many users you plan to have on each Server, you may want to use a pair of these:Intel® Xeon® Gold 6254 Processor (24.75M Cache, 3.10 GHz) quick reference with specifications, features, and technologies.A 12 Core variant of the 3.1GHz CPU is available. Also, there’s a 3.3GHz 12 Core variant as well. Which version you go for will depend on how the applications perform, but your minimum base clock should be 3.0GHz.For the Image Processing, pay close attention to which components are used (whether it’s CPU (single threaded or multi threaded (if multi threaded, how many Cores can it make use of))) or does it use the GPU. If it uses the GPU, how much framebuffer and processing are used. If it’s heavy, you may want to look at an RTX 6000 / 8000 over a T4.As a heads up, currently, the latest vGPU release (vGPU 10) doesn’t support the latest XenServer release (XenServer 8.1). So when you’re ready to build the POC, make sure you check the current supported versions and if needed install XenServer 8.0. That will allow you to run  XenDesktop 1912, Windows 10 1909, and vGPU 10. You can then simply upgrade XenServer to 8.1 once it’s supported.RegardsMGHiJust to add … NVIDIA have now added support for XenServer 8.1 and vGPU 10, so you can ignore the last paragraph above.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
591,nvidia-a40-not-shows-mdev-supported-types-and-i-cant-create-vgpus-instances,"I have installed the nVIDIA software in Linux release 8.3.2011 with kernel 5.4.107 with T4 and V100 without problems, but when I install nvidia software in a system with A40 card I can’t create vGPUs instances.I installed NVIDIA-GRID-Linux-KVM-460.32.04-460.32.03-461.33 ok, but when I list /sys/bus/pci/devices/0000:41:00.0 there is not directory mdev_supported_types.In this path /sys/bus/pci/devices/0000:41:00.0  appears iommu and iommu_group directories and sriov* files that don’t appear in other installations with T4 or V100.Some ideas? Can you help me?nvidia-smi output is:[root@a40 ~]# nvidia-smi
Sun Mar 21 09:15:12 2021
±----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.04    Driver Version: 460.32.04    CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A40                 On   | 00000000:41:00.0 Off |                    0 |
|  0%   29C    P0    73W / 300W |      0MiB / 45634MiB |      0%      Default |
|                               |                      |                  N/A |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+mode compute is selected[root@a40 ~]# ./displaymodeselector --listgpumodesNVIDIA Display Mode Selector Utility (Version 1.48.0)
Copyright (C) 2015-2020, NVIDIA Corporation. All Rights Reserved.Adapter: Graphics Device      (10DE,2235,10DE,145A) S:00,B:41,D:00,F:00EEPROM ID (EF,6015) : WBond W25Q16FW/JW 1.65-1.95V 16384Kx1S, pageGPU Mode: Compute[root@a40]# ls /sys/bus/pci/devices/0000:41:00.0
aer_dev_correctable
aer_dev_fatal
aer_dev_nonfatal
ari_enabled
broken_parity_status
class
config
consistent_dma_mask_bits
current_link_speed
current_link_width
d3cold_allowed
device
dma_mask_bits
driver
driver_override
enable
i2c-5
i2c-6
iommu
iommu_group
irq
local_cpulist
local_cpus
max_link_speed
max_link_width
modalias
msi_bus
msi_irqs
numa_node
power
remove
rescan
reset
resource
resource0
resource1
resource1_wc
resource3
resource3_wc
revision
sriov_drivers_autoprobe
sriov_numvfs
sriov_offset
sriov_stride
sriov_totalvfs
sriov_vf_device
subsystem
subsystem_device
subsystem_vendor
uevent
vendori had the same problem with the a6000 - the manual does not really point it out that great but you need to do the following/usr/lib/nvidia/sriov-manage -e 00:D8:0000.0  - in your case it should be a other device id.once you did this it will create mdevs - i my case it created ~20 devices with device id +1 or so - meaning you cant use your original device id but need to take one of the others.i have to do this after each boot ( could do it permanent if i wanted too=)hope this helps youThanks Stefan,your solution has worked!!After doing “sriov-manage -e” appeared new directories in /sys/bus/pci/devices/$busThese directories have a different aproach than NVDIa says in his documentation. There is not “mdev_supported_types” directory, but it appears 32 directories “virtfn0” to “virtfn31”.In each virtfn* directory apperas a mdev_supported_types that contains all models of vGPU availables in this card.For example:If you create a mdev device instance:And if you create more instances, for example:If we have crated 3 instances:And for a maximum of 32 instances of type NVIDIA A40-1Q we have 29 instances availables over all the directories:I will that this strange behaviour could be explained by NVIDIA or solved in next releases of vGPU software.Can you help me I have the same problem with an A5000 the corresponding directory does not exist::Even after running the command:The /sys/bus/pci/drivers/nvidia/0000:41:00.0 folder exists, but I’m guessing this would not be the A5000 board ID, what can be done about it?Thanks.Did you use mode selector tool already? Otherwise the A5000 won’t work! Make sure you know what you are doing and have a second GPU that can serve as primary display device or your machine won’t be able to boot afterwards.Hi sschaber, how are you?I’m almost a year late on this question, but I’m still stuck on the same issue, now we have two RTX 6000 Ada’s which I need to enable vGPU support as mentioned before by running the command /usr/lib/nvidia/sriov-manage -e domain:bus:slot.function, no file is generated either, so the solution is to use the “mode selector tool” application, correct?Can you help me perform the procedure correctly to ensure the integrity of the device, or can you direct me on how we can get support to perform this procedure?Correct. Mode Selector Tool is required to change into DC mode with full BAR1 sizePowered by Discourse, best viewed with JavaScript enabled"
592,insufficient-resources-one-or-more-devices-pcipassthru0-required-by-vm-xxx-are-not-available-on-host-yyy,"HelloWe have four identical (Lenovo SR650) ESXi hosts with one Tesla P40 each, and four Win2016 server VMs with profile “grid_p40-4q”. They start up on separate hosts without a problem, but attempting a migration to a host with a GPU VM already on, it’s blocked with “Insufficient resources. One or more devices (pciPassthru0) required by VM xxx are not available on host yyy”.Initially the VMs had different profiles (-4q and -8q for example). Since I read in the thread Unable to start VMs with VGPU that this is not supported, I changed them to the identical profile, but it’s still not working.The P40 has 22.5 (or 24?) GB of video memory, right? So two (or even all four) VMs with grid_p40-4q profile (allocating 4 GB of memory each, right?) must work?Both vCenter and the hosts are on the absolute latest 7.0.2 releases and build numbers.Where’s the problem?Could you please disable ECC first and test again?
Nvidia-smi -e 0 should do the trick…Regards SimonNvidia-smi -e 0Nope. Disabled ECC on two of the four hosts and rebooted them, still doesn’t work.It’s also independent of vMotion, just powering on a second GPU-VM on the host with freshly disabled ECC (while one host was unavailable because of the reboot) did not work, with the same error message.vMotion of a powered-on GPU-VM to a host that has zero GPU-VMs works though.I disabled ECC on the hosts, but I see the same nvidia-smi command is also available within the VM. Where do you mean to use it…?And your VMWare placement policy? Most likely it is configured on performance instead of density.Nope, in case you mean this vSphere setting:Edit Host Graphics Settings
Default graphics type: Shared Direct
Shared passthrough GPU assignment policy: Group VMs on GPU until full (GPU consolidation)And it should not even make a difference in this case…?Hmm, running out of ideas. Would recommend to open a support ticket with NVES to check nvidia-bugreport.Regards SimonOpened a case a few days ago, had an one hour Webex session today. Everything looks configured correctly (except the “disable ECC” thing maybe), versions are up to date and identical across hosts and VMs, yet it does not work at all. Only one VM per GPU…We had a cases both with NVIDIA and VMware, without results - but it just works now! What has changed? vCenter was upgraded to build 18778458, that seemingly solved the issue!Or - maybe the setting vgpu.hotmigrate.enabled = true requires a restart of vCenter?? The documentation does NOT state this… Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software DocumentationHi, thanks for the feedback. Indeed, vCenter needs to be on the latest version to fix this. Our Eng is still working with VMWare on thisPowered by Discourse, best viewed with JavaScript enabled"
593,repo-installation-of-nvidia-drivers-on-esxi-linux-ubuntu-18-04-x86-64,"I am looking for a way to install the NVIDIA drivers and CUDA from a repo in an ESXi environment that has hardware access to an NVIDIA Tesla T4; in analogy to the installation process on physical PCs with a PCIe GPU. Is there such a way for ESXi with GPU, too?Example:Powered by Discourse, best viewed with JavaScript enabled"
594,envidia-geforce-210,"tengo un problema adobe after effects los controladores de la tarjeta son incompatibles con este programa, que puedo hacer para solucionar este problema si ya actualice los controladores de la tarjetaFor support questions, please visit the NVIDIA GeForce forumsGet the support you need.Powered by Discourse, best viewed with JavaScript enabled"
595,nvidia-tesla-m10-8a-cuda-availability,"Hi all, I’ve got a problem.I have a NVIDIA Tesla M10-8A vGPU, I’d like to know if CUDA is supported on this device.Here ( GRID Virtual GPU (nvidia.com)), on page 6 and 8, it is specified that CUDA is supported on Tesla M10-8A.Here ( Virtual GPU Software User Guide :: NVIDIA Virtual GPU Software Documentation), in section 1.3.3, it is specified that only 8Q vGPU types enable CUDA.I’m a little bit confused.Trying to run a pyTorch CUDA application (torch.version.cuda ‘11.3’):So, is CUDA supported on Tesla M10-8A vGPU or not? Or there are some particular constraints?Thank you allPowered by Discourse, best viewed with JavaScript enabled"
596,esxi-6-7-u2-tesla-m10-cannot-use-all-available-gpu-ressources,"Hi Guys.I have 3 Dell PowerEdge 740 servers with 2x Tesla M10 in each server. All hosts are running ESXi 6.7 U2 with ""NVIDIA-VMware_ESXi_6.7_Host_Driver"" vib in version 430.27-1OEM.670.0.0.8169922.Graphics type for all hosts is set to ""Shared Direct"".In general the GPUs and vGPUs are recognized by the guest operating system (Win Server 2016/2019) and can be used.But apparently there are 2 problems which have the same effect.With 3 hosts, 2x M10 in each host, I should be able to deploy 12 VMs with ""M10-8A"" profile. Right? Or 24 VMs with ""M10-4A"" profile, for example.But at the moment I only have the following vGPU assignments in the cluster:
3x M10-8A
1x M10-4A
3x M10-2AAnd I cannot start another VM with a ""M10-4A"" vGPU profile…If I look at the GPUs and which VMs are running on them, then I see that all GPUs except 1 have 0 bytes memory and all VMs on this host are running on the same GPU.The other 2 hosts show all available memory (8x 8 GB), but only 2 VMs are running on these hosts, each VM on a vGPU.I’m completely confused why I can’t start more virtual machines with vGPUs in this cluster.Maybe someone has an idea.Thank you all.HiIf you’re using the ""A"" profile with M10s, the only profile you should be running is 8A. Because of the type of use case recommended for the ""A"" profile, it makes no sense to run a smaller profile.What’s probably happened in your environment, is your vCenter vGPU setting is set for ""Performance"" instead of ""Density"" and it’s spread the VMs across your M10s so you can’t start another VM. Either allocate all your vGPU profiles to 8A or change the vCenter setting to ""Density"" and see if that helps.RegardsMGHi MrGRIDThank you very much for the prompt reply.I changed the ""Shared passthrough GPU assignment policy"" for each host from ""Spread VMs"" (performance) to ""Group VMs"" (consolidation). And at the moment it looks good. I will test it further.And I will also think about changing all profiles to 8A.Thanks again. :-)Powered by Discourse, best viewed with JavaScript enabled"
597,server-stucks-driver-15-1-when-vm-shutdown-with-2-or-more-vgpu,"Hi,We recently have installed 15.1 Drivers With LINUX  KVM drivers. Our chassis is a SuperMicro and GPU is an A16. In the documentation, is explained how to run multiple vGPU, in a single VM with an A16 GPU with q and c series. We made some test attaching from 2 to 10 vGPUs to a single VM and it works fine. But when the VM is shutdown, sometime we show in dmesg the following messages.
dmesg_vgpu.txt (16.8 KB)After this failure, if we try to run another VM the server comes stuck and the only thing that we can do is to reset it physically.When this occurs, the vGPU process in the server does not end. I had a walkthrough, so I didn’t need to reset the server, killing the vGPU process and reseting the GPU with nvidia-smi -r. This brings some problems, if im running another VM with a vGPU we need to stop it while it is working, so it has to start from the beginning. This makes the server not production ready, because we need to shut down VMs in production, and we shouldn’t stop production VMs.Powered by Discourse, best viewed with JavaScript enabled"
598,tesla-m10-esx-windows-rdsh-question,"Hello,So I purchased 3 new Fujitsu servers equipped with the Tesla M10 and have ESX V6.7 running on all of them.
After the initial purchase I realized that licenses where needed.
My plan is to install Windows 2019 Remote Desktop Services strictly for use with Wyse Thin Clients doing RDSH only.
There will be one RDS server installed on each ESX server, my hope was to just give our remote sessions a little boost in graphic performance cause in our current 2008 environment we get a bit of screen scraping.
From reading in the forums it appears my best setup will be doing Shared Direct and adding the PCI device to the guest (Pass Through).
Across all 3 servers there will be a total of around 150 workstations that connect via RDSH.
What kind of licensing will this require and is my approach proper?Thanks!Hi,
not sure how this should work properly with 1 RDSH VM per physical host. You would need at least 4 RDSH VMs per host to leverage the Tesla M10 (4GPUs in Passthrough each).
For your scenario you will need 150 vApps licenses if these 150 Users connect concurrently. Otherwise you will need the number of CCU.Hope this helps.Regards
SimonSimon,Correct, I would just leverage a single GPU per VM Guest RDSH which my hope is that would be much better than using the standard built in VMWare Graphics adapter and take some of the load off other resources.
Is this reasoning correct?
The reason for putting a single RDSH on each server is for redundancy (I won’t go into the whole enviroment and how it is setup). There is currently about 35 other servers spread across the deployment.We probably over purchased with the Tesla M10 considering our environment but I basically asked our provider to put a video card that could be leveraged for a RDS Guest in esx that was fully supported in this configuration and that is what was provided.Since it is on 3 different esx host and we have up to 150 user connect concurrently would the vApps cover all 3 NVIDIA M10 cards on the machines?HiJust so we understand this correctly, as you have ""about 35 other servers spread across the deployment"", your intention is to give your users a better graphical experience (on 3 RDSH VMs) and you’ll use these 3 RDSH VMs to add resilience in your entire deployment. You intend to try and support all 150 concurrent users using (only) 3 RDSH VMs? …Apologies in advance, but that does need some clarity, because (as Simon mentions above) 3 RDSH VMs with an 8GB GPU will not support 150 concurrent users.I would just leverage a single GPU per VM Guest RDSH which my hope is that would be much better than using the standard built in VMWare Graphics adapter and take some of the load off other resources.
Is this reasoning correct?YesWe probably over purchased with the Tesla M10 considering our environment but I basically asked our provider to put a video card that could be leveraged for a RDS Guest in esx that was fully supported in this configuration and that is what was provided.We can look in to this when you’ve confirmed the first question at the top :-)Since it is on 3 different esx host and we have up to 150 user connect concurrently would the vApps cover all 3 NVIDIA M10 cards on the machines?The NVIDIA License Server sits centrally to the deployment. All RDSH VMs will need to be able to contact the NVIDIA License Server. By doing so, all user sessions will be licensed correctly. Again, you mention 150 concurrent users, 3 RDSH VMs will not be able to support this.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
599,nvdia-tesla-t4-driver-always-error-this-device-cannot-start-code-10,"This error shows up under “device manager” in windows. I tried windows 10 and windows server 2022 on two different machines. One a workstation and the other Supermicro Server.The driver installed was 516.94-data-center-tesla-desktop-win10-win11-64bit-dch-international.exeThe error that shows is:This device cannot start. (Code 10)
Insufficient system resources exist to complete the API.Note both systems have plent of resources.

image (1)848×736 176 KB
Note that we tried also installing in ESXi and also the driver doesn’t seem to work.
nvidia-smi shows the follwoing
Device not foundAnybody know why no driver is recognizing the card properly?Hi,What is the use case? Seems to be a vGPU use case and wojld require the vGPU driver and licenses. Please try to start with a eval for vGPU and the vGPU driver.Regards SimonI have the same problem. I am using Telsa  P4. I am not using vGPU. just do CUDA operations.CUDA on Windows? It doesn’t matter if you use vGPU or not. Without vGPU driver you can only use TCC mode on Windows.Yes, I just use it to do some compute. I don’t need to use vGPU. When I try to use nvidia to adjust the mode I get the following error “`
C:\Windows\system32>nvidia-smi -g 0 -dm 1NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running. This can also be happening if non-NVIDIA GPU is running as primary display, and NVIDIA GPU is in WDDM mode.
`”
How should I fix it?Powered by Discourse, best viewed with JavaScript enabled"
600,mixed-vgpu-profiles,"Can someone confirm that mixed profiles are not supported on a single GPU?  I’m aware this was not supported in K1/K2 GPUs but hearing some mixed messages in regard to M6/M60 GPUs.Could you please explain what you achieve - One GPU as passthrough and reaming as vGPU profiles on single M60 card ?Hi Nealus,I can confirm that you still cannot mix different framebuffer size profiles with GRID 2.0 on the M60 and M6.What mixed messages are you getting?Hi - thanks for the responses.  I have tried different profiles on the M60/M6 and do indeed get the expected errors when booting the vGPU VMs in View.  I can’t be sure, but noted some discrepancy between the older GRID hardware and the new.  I must have been wrong, but thanks for the clarificationCan someone confirm that mixed profiles are not supported on a single GPU?thanksConfirmed.Mixed vGPU profiles on the same GPU will not currently work / are not currently supported.It’s not even something you can try, as the vGPU Manager on the Hypervisor will only allow a single vGPU profile on a GPU once a VM has been started.BenHi all,I wonder if you can still only use the same GPU profile on a GPU or has anything changed in the meantime?ThanksThere is no change yet. Only exception is A100 where you can run different profiles due to MIG feature.Powered by Discourse, best viewed with JavaScript enabled"
601,version-compatibility,"I have updated my host drivers to 15.0 and my question is if my Windows client still running 13.3 is compatible until I can update my master Windows client image to 15.0?Hi, the short answer is NO.
We support n-1 which means 14.x host is supported with 13.x guest driver.
Exception is LTSB release to LTSB release. Here we support the direct path to the next LTSB.regards
SimonOK, thanks. To elaborate further does this mean it’s not officially supported but would temporarily work. I actually have this running on my test cluster with 15.0 host and 13.3 client and both my server and Windows clients are running OK and using licenses from my DLS. The timing for me is tricky to update both at the same time. Is it better to update the client first to 15.0 and then the host? So the client is ahead of the host? Thanks.Well, this means it was not tested. Might work (as it obviously does in your case) but not supported.Powered by Discourse, best viewed with JavaScript enabled"
602,linux-kvm-vgpu-driver-470-63-fails-to-compile-on-linux-5-11-22,"Hello!We’re trying to install NVIDIA-GRID-Linux-KVM-470.63.01-471.68. But the kernel interfaces seem to have changed.Prior to upgrading this server using vGPUs we used linux 5.4. No problem there. In 5.11.22 we’re getting:Any help to address this is appreciated :)EDIT
Just noticed that they removed set_fs/get_fs in 5.10. So will there be an updated driver to address this issue?Best regards
Marcus NordenbergHi Marcus,Are you still having issues with this setup?  Not clear from your description which distribution of Linux KVM you are running.List of supported distributions are available here: Supported Products :: NVIDIA Virtual GPU Software DocumentationIt looks like you upgraded to a kernel version that is not compatible with vGPU 13.0.  We have released vGPU 13.1 since your posting which hopefully will resolve the issue.Recommend that you contact NVIDIA enterprise support if you continue to have issues.:D:Powered by Discourse, best viewed with JavaScript enabled"
603,nvidia-a100-support-vulkan,"Hi all,I am trying to run a kubernetes pod that contains AirSim and UnrealEngine inside.
We have three worker nodes, and each has one A100 PCIe GPU. I tried to start ‘Blocks’
environment, the script stops with the following message:The error message from vulkaninfo is following.My question isThank you so much,
mmLet me add the output of nvidia-smi:Thank you,
mmHi @miwa.egner ,
My GPU is A40, and I have encountered the same problem, did you solve it?Hi,
Could you provide more details to the setup please? A100 is only supporting Compute while A40 can serve as graphics device with the vGPU driver.Hi Mariaa, sshaber, thank you for your replies.Yes, I now found that A100 does not support graphics.
NVIDIA Multi-Instance GPU User Guide :: NVIDIA Tesla Documentationso this is a feature…MiwaPowered by Discourse, best viewed with JavaScript enabled"
604,redhat-8-6-release-broken,"Currently vGPU software package (NVIDIA-GRID-RHEL-8.6-510.85.03-510.85.02-513.46.zip) for Redhat 8.6 only supports a kernel version that is not available.
rpm -qp --scripts NVIDIA-vGPU-rhel-8.6-510.85.03.x86_64.rpm|grep “NV_MODULE_PATH=”
NV_MODULE_PATH=/lib/modules/4.18.0-369.el8.x86_64/extra/nvidiaThis kernel release has been removed from Redhat 8.6 due to CVE issues.
https://access.redhat.com/errata/RHSA-2022:0825The only kernel releases available are downgrade 4.18.0-348 or upgrade 4.18.0-372. Neither of these work with any of the vGPU Redhat 8.6 packages.Please fixPowered by Discourse, best viewed with JavaScript enabled"
605,get-vgpu-working-in-openshift-4-8-with-nvidia-operator-1-9-1-on-vmware,"Hi all,I have OpenShift 4.8.35 with NVIDIA GPU Operator 1.9.1 installed on VMware vSphere and I would like to configure the vGPU setup.
The ESX had A100 with 40GB installed and the drivers installed.
We have configured a new VM with profile NVIDIA GRID vGPU grid_a100-7-40c and joined that VM into OpenShift cluster.
I have installed the NFD and NVIDIA GPU Operator.
When the Operator tries to install the driver, the module can not be loaded because if fails due to the Device seems not to be supported by the driver in version 470.But I think there are further steps needed for the vGPU setup.
According to NVIDIA vGPU I have to build my own driver container image.
I have cloned the mentioned repo, setup the env vars, but when I try to build the docker image, I get the error:Have I to set up a CUDA VERSION as build arg?
But in which verison and why that is not mentioned in to detailed workflow?Thanks guysPowered by Discourse, best viewed with JavaScript enabled"
606,youtube-poor-performance,"Hello,Youtube looks terrible on our VDI’s, we don’t have any issue with CAD software and other stuff.We’re using Horizon 7.7 with a Tesla M60 (grid_m60_1q as profile).Did someone face the same issue?Any help will be highly appreciated, thanks in advanceBRs
SimoneHi,a bit more details would be helpful. What is terrible? Low FPS? Dropped frames? What is shown in stats for nerds?regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
607,does-the-aws-ec2-winserver-2022-rtx-virtual-workstation-have-official-support,"Is this forum the only support available?Thanks!Powered by Discourse, best viewed with JavaScript enabled"
608,i-want-to-know-more-about-quadro-rtx-6000,"I want to know detail about Quadro RTX 6000. such as maximun number of warps per SM(streaming multiprocessor) , Effective global memory bandwith.
Please explain in detail how I can get this information.check out the  NVIDIA-Turing-Architecture-Whitepaper.pdfSo,
I’m using the Quadro RTX 6000 and want to calculate Turing’s occupancy.Is it possible to calculate occupancy( active warps / maximum number of warps per SM) through CUDA occupancy calculator in Turing GPU?And, Where can I get details of Turing GPU like maximum number of warps per SM?Please explain to me.Is it possible to calculate occupancy( active warps / maximum number of warps per SM) through CUDA occupancy calculator in Turing GPU?yesAnd, Where can I get details of Turing GPU like maximum number of warps per SM?Turing Tuning Guide :: CUDA Toolkit Documentation (nvidia.com)Thx for replying.Can I know how much a kernel or a SM uses global memory bandwidth?What am I supposed to do?Otherwise, is there a maximum value of memory bandwidth that can be used by one SM?Powered by Discourse, best viewed with JavaScript enabled"
609,using-the-driver-of-linux-kvm-13-0vgpu-there-is-a-problem-with-the-display,"My physical server uses centos system, the driver is NVIDIA-Linux-x86_64-470.63-vgpu-kvm.run, I use Linux kvm to create a virtual machine, the operating system of the virtual machine is windows10 22H2, and the allocated vgpu is Tesla T4-2Q, download The vgpu driver is 471.68_grid_win10_server2016_server2019_server2022_64bit_international.exe, but I found a problem after I installed i

11348×1004 23.3 KB
Powered by Discourse, best viewed with JavaScript enabled"
610,multiple-devices-from-mig,"Let’s say that I got virtual GPUs(10GB × 8) from a single A100(80GB) using MIG.
If I select 5 virtual GPUs on k8s to run a Pod (single replica → single container), what will be shown from ‘nvidia-smi’ in the container?
Is there a single virtual GPU(50GB)? Or 5 GPUs(10GB each)?Powered by Discourse, best viewed with JavaScript enabled"
611,running-an-ue4-application-on-aws-g4-powered-by-tesla-t4,"Hi there,I’m trying to run an UE4 application on an AWS G4 ec2 (g4dn.2xlarge) instance powered by Tesla T4 to stream it using PixelStreaming and I get poor results.The application works in slow motion, when I connect to the stream I get about 24 fps.It worked fine on my workstation and I got about 50-60 fps.Note: both cpu and memory usage are relatively low (50% and 20%).Any thoughts?Hi DanielWhich connection protocol are you using to connect to AWS?RegardsMGHi MG,I’m using RDP.
The error occurs even when I’m running the game with the -RenderOffScreen parameter.Regards,
DanielHi DanielTry using a different protocol. AWS natively offers NICE DCV, or you can try an evaluation from Teradici (PCoIP Ultra) or Mechdyne (TGX).RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
612,please-enter-correct-information-unable-to-authorize,"Hello,I created a NVIDIA license server for vGPU, it works fine, but if I go to http://localhost:7070/licserver on login, I can’t login with my admin or root account, it says “please enter correct information unable to authorize”.VM CentOS 7.9
Tomcat 8.5.75
OpenJDK 1.8.0_262
NVIDIA License Server 2021.07.0.30193485ThanksPowered by Discourse, best viewed with JavaScript enabled"
613,performance-difference-p2000-vs-t4-2q,"Hello all,in my company a HDX environment was set up for the purpose of a home office.
The NVIDIA T4 is used as a virtual GPU.
This is used in the configuration 2Q (T4-2Q), meaning eight users share one card.Previously, we had desktop PCs that had an NVIDIA P2000.
My question is now, how far are performance losses here.
We employees notice that it runs much slower than before.
We work with very large assemblies.Our IT tells me that the T4 is more performant than the P2000.
I think so too, but not if you divide it by 8 people.
So everyone has only 2GB VRAM available, with the P2000 it was 5GB VRAM.The goal is to build a system that at least matches or exceeds the performance of the P2000. What would be necessary for this?Thanks in advance for your help.Hi,
In general the performance should be fine. The “magic” of vGPU is the scheduler so that every VM gets 100% GPU for the timeslice of the rendering job. But you need to make sure that the FB is sufficient. Please check with tools like GPUProfiler that you don’t run out of FB which will result in swapping into sysmem and reduces the performance massively. Or did you already test with 4Q profile to see if it runs better?regards
SimonHi Simon,Thank you for your quick reply.I should have given some more information before.
We use the vGPU to run Siemen NX11 on it.
It often happens that eight users turn their large models at the same time.
This would mean that in this case only 12.5% of the CPU performance is available for each user.
Does this still correspond to the performance of a single P2000?FB stands for frambuffer right?
I will pass on the tip to have IT take a closer look to see if this jumps into system memory.I have already mentioned changing the T4 profile from T4-2Q to T4-4Q or even T4-8Q. Unfortunately, there are not enough machines available at the moment to test this. I think it would help, but since more and more have to go to the home office, the test is currently not possible.I would have otherwise also thought that for our needs rather need an A40 than the T4.Thanks in advance for the further help.Thanks for the additional information. Which CPU are you using? Hopefully a CPU with >3Ghz Clock Speed? NX also requires a lot of CPU on the single thread.
You always have 100% GPU for each timeslice (1ms) interval, no matter if you run a single or multiple VMs on the same GPU. Even if you think they are doing the same tasks simultaneous it’s not the case in reality. I would rather assume that you run into FB (framebuffer) exhaust.
A40 would only help if you run bigger profiles. Best idea would be to add additional T4s but it is almost impossible to get one anymore.regards
SimonHi Simon,the CPU used is an Intel Xeon Gold 6226R @2.9GHz.
So this could be the bottleneck among other things, besides the framebuffer.What kind of CPU would you recommend, especially in terms of large assemblies? Just one that has more than 3GHz? Only 100MHz more will probably not be enough.When I have the answer, I will pass this on to our IT and then get back to you here and report what came out.By the way, 32GB are available as RAM.Many thanks in advance.Most customer try to have 3.2GHz but it is always a trade-off between number cores and clock speed. Therefore 2.9GHz is not that bad but most likely not comparable to the workstation they had before (3.6GHz or higher).
Yes, please check the FB usage as a starting point to discuss further options afterwards.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
614,idle-vms-losing-licenses,"Running Win10-1903 desktops on ESXi 6.7u3 and we’ve noticed that the nVidia license (virtual datacenter workstation) is being lost after a couple of days on idle VMs.Has anyone else experienced this?License server was on 2020.05-U1, LicenseInterval is set to 30 minutes, Instant Clones on Horizon 7.10Have you opened a support ticket with NVES? I don’t think this is something where the forum could really help. Would start with upgrading the license server to the latest one and also using Horizon 7.11 which introduced the MAC pool feature  (if I remember correctly) so that you don’t need to mess up with the LicenseInterval setting. I would strongly recommend to keep this setting to 24h.regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
615,maximising-performance-using-up-to-date-drivers-and-basic-system-tuning,"As this is the ""Benchmarking Section"" of the forum (and I don’t have a Blog), I thought I’d post some helpful hints here on how to add a little extra performance to your systems that some of you may not be using or may simply not be aware of.So, you don’t get much in this world for free these days. So with this in mind, I wanted to demonstrate the ""Free"" performance benefits of firstly keeping your drivers up to date and secondly using the tuning options that are built-in to the Nvidia drivers to release a little extra application performance. Now I’m not about to break any tuning records here, so don’t get overly excited, and there’s no “magic tuning” option that will get you unprecedented levels of additional performance. The fact still remains that once you’ve bought your hardware, your options for increasing its performance are limited, so you want to make sure you get the most out of it. But there are a few ways to increase performance in a couple of areas, and it’s free and it’s there, so why not use it.Drivers -Attached are 2 screenshots (""369.09 Drivers"" & ""369.49 Drivers"") I’ve taken from the same system showing the results of a basic benchmark run with the same settings before and after a driver upgrade (Yes, I like Redway at the moment because it’s quick an easy :-) https://gridforums.nvidia.com/default/topic/991/grid-vgpu-benchmarks/benchmark-competition-redway-turbine-just-for-fun-/ ). Bear in mind this is only a slight revision to the drivers, .09 > .49, it’s not a major release, so the increase in performance may be subtle and other applications may respond differently. Also, if you were upgrading from older drivers to current ones, rather than just a minor upgrade, you may get more of a notable performance boost. When running the benchmark to evaluate any performance differences, you’ll want to do it a few times to ensure the changes are positive. With mine, as you’ll see, some of the numbers are slightly less, but the total score at the bottom is higher. When I ran this a few times, those numbers for each area would always change very slightly, but the total score would always be higher with the newer driver.Obviously, the “369.09 Drivers” benchmark was run before the upgrade to the “369.49 Drivers”.Tuning -Attached are another 2 images (""369.09 Drivers - Tuned"" & ""369.49 Drivers - Tuned""), but this time I’ve used the built-in tuning options within the driver. These images are tuned before and tuned after the driver upgrade.To access these Tuning Options in a Windows Desktop OS, simply “Right Click” on the desktop and choose “NVIDIA Control Panel”. Here you are presented with lots of options, some of these will vary depending on your GPU. Select “Manage 3D Settings” on the left and you are presented with a variety of 3D Settings to modify. For less experienced users, to take some of guess work out of it, some of the more common application vendors have built-in profiles you can try (see the attached “NVIDIA Control Panel”). For more experienced users, you can manually configure settings and create your own profiles by either modifying the Base Profile or you can select your application manually and create a profile for it under the “Program Settings” tab.To access these Tuning Options in a Windows Server OS, you need to connect locally using something like TightVNC. If you can’t see the “NVIDIA Control Panel” when “Right Clicking” on the desktop, then you need to change the way you are connecting. The 3D Settings you change within the Server OS, apply to all users connected to the Server.What’s interesting is that even the (slightly) older drivers when tuned, can outperform the newer drivers when un-tuned. Although as said earlier, this is not a major release, and you would need to see what Nvidia has updated within the driver to understand any performance differences, but you can see the difference with a strait upgrade between un-tuned versions.When you compare the older, un-tuned drivers screenshot (369.09 Drivers) to the upgraded and tuned drivers screenshot (369.49 Drivers - Tuned), that’s not a bad little performance boost, especially as it’s free, and I dare say that further Profile tuning could unlock a little more, as all I’ve used is the built-in profile for that application for demonstration purposes.A little extra tuning outside of the NVIDIA Control Panel that some people seem to leave alone, is the Windows Power Management options. Don’t forget to set these to High Performance, then also go through and modify the settings to suit. After this, you’re on to tuning scripts / GPOs and customization’s which are outside of the scope of this post.For more advanced users, don’t forget to tune the system BIOS (and Hypervisor if you’re using one) accordingly, as nearly all hardware will ship in Balanced / Economy Mode, not High Performance. This alone can have a large impact on overall system performance and is a whole topic on its own, which I’ll go into in another post :-)Lastly, also bear in mind that different applications and systems may respond differently to any tuning, depending on how they scale and the type of resources they use to generate performance.The differences in performance shown in these images may not seem that dramatic, which it isn’t. However, when you look at the length some people go to, to optimize the Windows OS, every little bit counts, especially on multi-user systems. Plus it’s free and there’s a nice GUI, so why not use it :-)All the usual caveats about testing changes prior to release and testing drivers for application compatibility obviously apply ;-)


369.09 Drivers.jpg1022×795 168 KB


369.09 Drivers - Tuned.jpg1023×796 168 KB


369.49 Drivers.jpg1023×797 168 KB


369.49 Drivers - Tuned.jpg1022×796 168 KB


NVIDIA Control Panel.jpg957×942 148 KB
Before anyone posts… I haven’t forgotten to upload the images, the site is taking an eternity to scan the tiny .jpg files at the moment.Edit: That’s not bad, 20 minutes to upload 5 small .jpg files :-)Powered by Discourse, best viewed with JavaScript enabled"
616,the-text-blurred-in-output-h264-created-by-nvfbctoglenc,"Hello, There is a issue when running demo NvFBCToGLEnc of Capture_Linux_v8.0.8 or v7.1.9.
When the text color is Geen(ForeColor)/Black(BackColor)， the text in output.h264 created by NvFBCToGLEnc will blurred.
Should adjusting some nvfbc or nvenc paramter?

3560×746 114 KB
Default chroma subsampling behavior and not an issue. You would need to use YUV444 to remove chroma subsampling effectsThanks,  using YUV444,  the color is correct.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
617,vmware-overprovisoning-profiles-on-nvidia-tesla-p6-gpu,"Hello, pls consider a server with NVIDIA Tesla P6 GPU (16GB)  and Using NVIDIA Virtual PC Concurrent User license and VMware Horizon.
I need to create 20 Users/VMs that will work in different time shifts, they will never work all at the same time,
Is it possible to create 20 users, each user with 1GB profile ?
What happens if the 17th concurrent user tries to logon?
TksHi,
Not sure if I fully understand the request. The P6 is only capable to run 16 VMs with a 1GB profile. So how do you want to run 20 VMs on that GPU? Simply not possible.regards
SimonHello, I have 20 users but they will NOT work all at the same time. Let me try to explain better: I need to create 20 VMs, each with 1 GB profile, but they will not be powered on all at the same time, since the users work in different time shifts. But all the VMs must be created and ready to use the 1 Gb Profile, just a few will be powerd ON at the same time.
If this is not possible, is there any way (other license?) that allows what I’ve described?
tksOk, got it. For sure this is possible. As I said you can only run 16 VMs concurrently and you need 16 vPC licenses. We take only running VMs into considerationPowered by Discourse, best viewed with JavaScript enabled"
618,460-32-esxi-6-7u3g-horizon-8-1,"Hi,I updated our ESXi hosts to NVIDIA-VMware-460.32.04-1OEM.670.0.0.8169922.x86_64_vib and our Windows 10 Images to 461.33_grid_win10_server2016_server_2019_64bit_international.exe and now I can no longer provision any instant clone desktops. Its the usual UKNOWN_FAULT_FATAL - No GPU capable host available for provisioning with grid profile grid_m10-1b error.The VMs themselves won’t initialise the display driver and are falling back to the default Windows SVGA drivers. The hosts themselves won’t even run the nvidia-smi command (Failed to initialize NVML: Unknown Error).Both drivers are from the latest release - NVIDIA-GRID-vSphere-6.7-460.32.04-460.32.03-461.33.zip and are therefore at parity (one would assume!).Any ideas what I can do. We’re running Dell R740 servers with 4 x Tesla M10 cards in each.I now only have a single host left with all our VDI’s running on it!CheersCan anyone else out there who is using 12.0 or 12.1 drivers in vSphere confirm they are working for them. I have tried for 3 days now to get this working without any success. I have removed the VIBs rebooted, re-added the VIBS via the zip package with esxcli software vib install -d and just the vib itself with esxcli software vib install -v. DMESG shows no issues whatsoever as if the driver has loaded and vmkload_mod -l | grep nvidia confirms the driver is loaded…I have confirmed SR-IOV setting is enabled in the BIOS and IOMMU settings as well. Previous drivers work fine. Just not 12.0 or 12.1 which is a pain as we need Windows 10 20H2 support.Interestingly when the new drivers are loaded vSphere shows the memory available on the cards as 0.00B.HiIt sounds like the issue is with the VM side, not with Hypervisor side. Have you tried building a clean VM, install the new vGPU driver and Horizon agent with Direct Connect (save you creating a Pool on the Connection Server) and seeing if that works?What vGPU profile are you using on your VMs?I’m running 12.0 and 12.1 on multiple environments, but I’m running 7.0 U1C and 7.0 U2 so it’s not a fair comparison, but in those environments there are no issues.RegardsMGHi MG,Thanks for your input. Unfortunately as I described as soon as the VIBs are installed on the ESXI instances the ‘Graphics’ section under the host configuration in vSphere shows the GPU’s with 0.00B memory and the nvidia-smi command reports (Failed to initialize NVML: Unknown Error). Therefore the issue is likely with the drivers themselves and ESXi 6.7.0 (16713306).RegardsTomSorry its grid_m10-1b profile.Powered by Discourse, best viewed with JavaScript enabled"
619,command-tlt-not-found,"I strictly followed the instruction to install the Pre-requisites, also pretty sure that I can ran docker without the prefix ‘sudo’. When I tried to use the models mentioned in the following tutorial(Creating a Real-Time License Plate Detection and Recognition App | NVIDIA Technical Blog), I’ve got stuck at 
image1576×102 7.91 KB

So, I logged into this forums to see if I can find a solution and I did find a similar one where someone said to run ‘tlt info detectnet_v2 run cat /workspace/openlpr/SPECS_tfrecord.txt’. However, it just thorwn another problem saying that command ‘tlt’ not found.Powered by Discourse, best viewed with JavaScript enabled"
620,nvidia-vgpu-vfio-ko-unavailable-in-ubuntu-focal-20-04-packages,"I am unable to find the nvidia-vgpu-vfio.ko in Ubundu package for Focal 20.04.I have tried to install several milestones of the v470 (server, dkms, nodkms, headless, downloaded sources package and find for file like vfio), also on the ubuntu packages search engine, but I actually couldn’t find it.I have successfully used KVM guest with the manual driver installation from NVIDIA  (which provide the kernel module), but using a manual installation of this driver on dozen of servers is a kind of show stopper here, I would prefer to have it installed from a distribution package to ease deployment and management on the long term.Which Ubuntu package provide the nvidia-vgpu-vfio.ko module, and if not at all is there a reason to not providing it via Ubuntu packaging system ?Powered by Discourse, best viewed with JavaScript enabled"
621,how-to-completely-reset-any-kind-of-gpu-sharing-partition,"Greetings, I tried to do some GPU sharing (Parsec) etc and Partitioning with my RIG for a VM. And now I wanted to completely reset any kind of setting / parameter / sharing / partitioning of the GPU, what would be the way for me to do that?NOTE: I did delete all my VM’s and disabled Hyper-V. But I feel like it is still in some kind of sharing mode, and I want to remove it completely or at least check if it is still partitioned / shared.Thanks in advance.Powered by Discourse, best viewed with JavaScript enabled"
622,optimized-citrix-policy-for-vdi-with-tesla-m10-gpu,"Hello, we are deploying new VMWare ESXi 6.7 Update 3 hosts with Tesla M10 GPUs.  Each host has 2 M10 GPUs with the goal of 64 users per physical host.For VDI, we are using Citrix Virtual Apps and Desktops 1912 LTSR.Would someone please recommend the optimal Citrix policy settings for VDIs utilizing vGPU?  I have been searching quite a bit but unable to find any clear guidance.I have seen that the HDX 3D Pro setting should be enabled in a Citrix policy.Is there anything else?Overall I am looking to maximize the benefits for GPU for our VDI user base.  Thanks for any help you can offer.Powered by Discourse, best viewed with JavaScript enabled"
623,how-to-open-wddm-mode-supporting-graphics-acceleration-under-windows-for-p100,"Enviroment: Window 10 64x
GPU: Tesla P100I find the same question:谈一谈Tesla GPU在Windows环境中的图形表现we can make a simple summary:Tesla GPU + Tesla native driver only supports TCC mode on Windows platform, and cannot support graphics application acceleration.so i wangto know how to open WDDM mode (supporting graphics acceleration) under windows for P100

QQ图片20210126093615689×576 19.6 KB
HiYou need to use a vGPU driver to enable graphics on a Tesla GPU. Register here for a 90 day evaluation: NVIDIA Enterprise Account Registration and use the RTX Virtual Workstation license, that will allow you to use the GPU for graphical workloadsRegardsMGPowered by Discourse, best viewed with JavaScript enabled"
624,xmonad-and-nvidia-gpu-are-incompatible,"xmonad installed on jetson orin.
However, I put in the haskell program, xmonad, and logged in, but it fails with an error.The error was in /var/log/Xorg.0.log.
Is this a incompatibility between jetson and xmonad?less /var/log/Xorg.0.log/etc/X11/xorg.confThe error has disappeared.
However, after a few minutes of logging in with xmonad, it’s logged out./etc/X11/xorg.confInstead, it logs disconnected./etc/X11/xorg.confPowered by Discourse, best viewed with JavaScript enabled"
625,how-to-install-gpu-drivers-for-azure-stack-hci-22h2,"Hello,We have Dell AX-750 + Tesla M60. We are using Azure Stack HCI 22H2 and we are trying to install GPU drivers from NVIDIA-GRID-Azure-Stack-HCI-525.60.13-527.41Neither Windows Admin Centre’s GPUs extension or Devices → Drivers are able to install the drivers from \NVIDIA-GRID-Azure-Stack-HCI-525.60.13-527.41\Host_Drivers\Azure-Stack-HCI\Display.Driver folder. Either they get stuck “Searching for…” or stuck at “Update drivers…” and nothing happens at least for 15-20 minutes and I am sure the drivers should get installed in few minutes.We also tried to install the drivers using “pnputil -i -a nvgridswhci.inf” That says installation was successful but nothing seems to be happening. WAC still shows GPU using “Microsoft Basic Display Adapter” driver.Any ideas? I cannot find any documentation how those drivers should be installed.Hi,
you need to check the requirements. Supported GPUs for Azure Stack HCI are only Ampere based GPUs. M60 will never work with Azure Stack.regards
SimonThanks for the quick reply!Powered by Discourse, best viewed with JavaScript enabled"
626,nvidia-vgpu-on-vmware-7-0-2,"Hi , Good day,Do we need to have VMware Vcenter to see the NVIDIA vGPU profiles even we manage only 1 vmware Server Host?Thanks for the answersYesPowered by Discourse, best viewed with JavaScript enabled"
627,vgpu-license-cannot-be-acquired-on-windows-but-can-on-linux,"Hi there,I have an A10 and I made six A10-4Q vGPU instances on it. I have several VMs running either Linux or Win10.The Linux VMs are operating as expected and are able to acquire licenses without any problem.However, I’m experiencing consistent license acquisition failures on the Win10 VMs.So strange… any thoughts?Thanks,
Z ZPlease check the Log.NvDisplay.Container.exe.log file on the VM or send the file for analysis. Might have multiple reasons. Did you make sure that the time is correct on all VMs?Here’s the beginning of the log file (the rest of the file is just repetition of the same error).
The win10 VM time is the same as the host’s time.ThanksSun Jul 16 12:56:02 2023:<1>:Valid license settings not found. Please configure settings to use NVIDIA License System (NLS). NVIDIA Legacy License Server is not supported.Sun Jul 16 13:00:01 2023:<1>:NLS initialized
Sun Jul 16 13:00:05 2023:<1>:Failed to acquire license from api.cls.licensing.nvidia.com (Info: NVIDIA RTX Virtual Workstation - Error: The allowed time to process response has expired)
…Sun Jul 16 15:29:30 2023:<0>:End Logging
Sun Jul 16 15:29:30 2023:<1>:End LoggingHi,I would still assume that there is a time mismatch between the VM and the CLS. Please open a support ticket with NVES to get further support on this.Best regards
SimonOK, thanks for your reply. May I ask where I can find the CLS’s time? My Linux VMs seem synchronized with my host, and so do my Win VMs.CLS has the correct time (NTP synced). You need only check your end. Are your Windows VMs synced with NTP source?OK, thanks! That’s the problem. Cheers!This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
628,vcs-is-used-in-dls-instance,"Hi,
DLS instance use [NVIDIA Virtual Compute Server 9.0] and [NVIDIA Virtual Applications 3.0], and the license cannot be removed. I only use NVIDIA RTX Virtual Workstation.
image373×654 18.5 KB

image847×413 16.8 KB
I accidentally added these licenses(vCS,vApps), but the license is in use and cannot be removed.
Would you tell me how to delete? Why is the license used?A40 GPU
VMware ESXi v7.0.2
NVIDIA Virtual Compute Server-9.0
NVIDIA Virtual Applications-3.0
NVIDIA RTX Virtual Workstation-5.0Regards,
ReiYou need to return the licenses to the portal first and issue the right license afterwards. See our documentation for the required steps or open a support ticket with NVES for assistanceThank you for your reply. I will contact NVES team.This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
629,nvidia-settings-error,"Any help would be appreciated. Tried removing and reinstalling different versions, but that didn’t work.
nightfury@Clinomaniac:~$ nvidia-settingsERROR: NVIDIA driver is not loadedERROR: Unable to load info from any available system(nvidia-settings:67789): GLib-GObject-CRITICAL **: 21:53:02.070: g_object_unref: assertion ‘G_IS_OBJECT (object)’ failed
** Message: 21:53:02.074: PRIME: Requires offloading
** Message: 21:53:02.074: PRIME: is it supported? yes
** Message: 21:53:02.121: PRIME: Usage: /usr/bin/prime-select nvidia|intel|on-demand|query
** Message: 21:53:02.121: PRIME: on-demand mode: “1”
** Message: 21:53:02.121: PRIME: is “on-demand” mode supported? yes
nvidia-bug-report.log.gz (119.8 KB)Powered by Discourse, best viewed with JavaScript enabled"
630,vmware-vmotion-stun-times,"Hi,we are currently testing HPE DL385 Gen10 Plus servers equipped with T4s. Those are connected directly via two 25Gb Mellanox NICs for vMotion. Installed is ESXi 7.0 U2.
Unfortunately the stun times are higher than on the production servers running two 10Gb connections.
How can I further troubleshoot this issue?ThanksPowered by Discourse, best viewed with JavaScript enabled"
631,cannot-install-nvidia-driver-in-esxi-vm-with-vgpu,"I’m attempting to create VMs on ESXi 6.7 where vGPU has been installed on the hypervisor. So far, it has all ended in tears.I’ve successfully installed vGPU - as witnessed by running nvidia-smi after logging into the ESXi host via SSH. I utilized the latest vGPU for ESXi 6.7, which installed the NVIDIA driver 430.46.
The hardware is a Dell C4140 with four V100-PCIe cards.  The BIOS setting for MMIO base is 12TB.
I have all the GPUs configured as ‘Shared Direct’.
The VM I created has 8-cores and 64GB of memory (all reserved, of course). I selected an NVIDIA GRID vGPU as a Shared PCI device.
After loading the OS, the command ‘lspci |grep -i nvid’ shows that I have a single V100 (device 1db4).Installing CUDA always results in a failure when the install script attempts to install the driver.I’ve attempted this on SLES12 SP3 with the CUDA 9.1 installer, and SLES15 SP1 with the CUDA 10.1 installer.I’ve then attempted to load the driver directly using the associated install script.Have I missed a step? Am I using the wrong driver combo? What should I try next?FYI - these same machines work perfectly when the GPUs are in pass-thru mode without vGPU, and I install these same OS/CUDA combos on the VMs.I’d be happy to provide the error messages if that would be helpful.Thanks!I’ve made some progress.I was able to successfully install the grid driver via NVIDIA-Linux-x86_64-430.46-grid.run.  The trick is that it must be run prior to the CUDA install.  After installing the driver, you need to install CUDA without the driver.This works for SLES12 SP3, but not SLES15 SP1.The next problem is that none of the sample programs will run.nvidia-smi produces the following output:Fri Sep 20 16:38:13 2019
±----------------------------------------------------------------------------+
| NVIDIA-SMI 430.46       Driver Version: 430.46       CUDA Version: 10.1     |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GRID V100-8Q        On   | 00000000:02:01.0 Off |                  N/A |
| N/A   N/A    P0    N/A /  N/A |    528MiB /  8128MiB |      0%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+However, when I run the sample vectoradd, I get this:
[Vector addition of 50000 elements]
Failed to allocate device vector A (error code all CUDA-capable devices are busy or unavailable)!I ran a program that I wrote so that I could dig a little deeper.  After initializing the driver, it is able to find the GPU.  Here’s an output from my program:
********** GPU 0 Info *************
Device Name:          GRID V100-8Q
Max Threads per Block:1024
Max X Dim per Block:  1024
Max Y Dim per Block:  1024
Max Z Dim per Block:  64
Max X Dim per Grid:   2147483647
Max Y Dim per Grid:   65535
Max Z Dim per Grid:   65535
Shared Mem/Block:     49152
SMX Count:            80
warp Size:            32
Compute Capability:   7.0
Global Memory Bytes:  4294967295
PCI Bus ID:           0x2
PCI Device ID:        0x1
Unified Addressing    1Everything seems to be OK - except that when I try to create a CUDA context, it hangs.  It consumes 100% of a CPU core, but never returns.  My guess is that the CPU is being burned in some kind of polling loop.  The driver call that never returns is cuCtxCreate().Any ideas what to do next?Missing license?
Without a license you won’t be able to run CUDA :)Regards
SimonI downloaded the GRID Evaluation Edition from the NVIDIA Software Licensing Center.  I installed the binaries that were provided in the download.  There was no step in the installation process that requested an activation key, so I assumed that there was a countdown timer built into that edition.  Since I’ve only been attempting this for a couple weeks, I’m certain that the trial period is not expired.
Is there an extra step that is required for activation that I missed?
Like I wrote in my previous post, the driver call hangs - I’m not getting an error return code.Thanks!
DougI dug a little deeper using GDB and more printfs.  I’m getting an error code 999 (unknown error) as a response to cuCtxCreate().  Is that possibly a licence problem?What about reading our user guide? For sure you need a license and every step is properly documented.Documentation for system administrators that describes NVIDIA Virtual GPU licensed products and how to configure licensing for them on supported hardware.Apologies.
I had activation keys in hand, but had not yet used them.  I was led down the primrose path because everything installed and I was able to run nvidia-smi in the VM.  I read the sentence in the docs that said that performance is restricted without a license, but missed the sentence that says that CUDA is disabled until a license is provided.
I’ll get started on that.  Sorry for wasting your time.One suggestion: have an ‘Invalid or Missing License’ error code.Powered by Discourse, best viewed with JavaScript enabled"
632,can-we-use-nvidia-nvenc-gpu-hardware-acceleration-on-ffmpeg-under-lgpl,"We are developing a commercial product that is using FFMpeg to composite data onto a video stream and encode in h.265. We would like to use the CUDA toolkit to enable NVidia hardware acceleration in FFMpeg, to take advantage of our graphics card. Is it possible to do this and still remain within the FFMpeg LGPL open source licence?Hi,I don’t have an answer to your open source license question but I’m wondering why you would use CUDA toolkit for transcode? Why not using NVENC for transcode?I forgot to mention we are running on Windows 10.
We have a software based solution using the x265 encoder, but we wanted to user hardware acceleration to reduce the load on the CPU. I thought we had to use the CUDA toolkit to do this, after looking on the web for hints and tips.
Does hevc_nvenc use the hardware NVENC chip, without the CUDA toolkit, or is it a software solution?Hi,
for sure :) This is exactly the use case. No need to use CUDA for transcoding as long as you are OK with the presets given for the hardware encoder. Which GPU do you have?regards
SimonCurrently its an NVidia Quadro P2000 (Pascal GP107).Ok, that should work. Pascal already supports H265. You can check the capability here:
https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-newThanks for the pointers, we are building an hevc_nvenc library now to test on our hardware. It says its LGPL so this will suit us perfectly license wise. We just need to see how the processing load is split across the CPU and GPU.Thanks this works for us, NVidia hardware acceleration in FFMpeg under LGPL. Thank you.Happy to hear it’s working. What about the speed-up compared to CPU only ?There is a good question, we’ve proven it builds and encodes on the GPU, we are now performing a clean install/build to make sure none of our previous NVidia CUDA toolkit work was being used in our test. That will take a while, then we will look at speed.So we used a 30 minute video clip, an episode of “the sky at night”, 704x576 frame, data rate 15256kbps, frame rate 25fps, encoded as mpg.
Using a NVIDIA Quadro T2000 .
Using a release build of FFMpeg.
Hardware accelerated encode, hevc_nvenc, took 28 seconds (66 x normal speed) CPU 35%, GPU1 0%, GPU1 Encode 90%
Software encode, libx265, took 2 hours (0.23 x normal speed) CPU 65%, GPU1 2%, GPU1 Encode 2%.Wow, thanks for the feedback. Really impressive speed-up :)This topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
633,total-number-of-warps-the-gpu-can-run-at-once,"I want to know the total number of warps my GPU can run at once.I’m using Quadro RTX 6000.
According to https://images.nvidia.com/aem-dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf ,
Quadro RTX 6000 have 72 SMsAnd From https://docs.nvidia.com/cuda/turing-tuning-guide/index.html#sm-occupancy

image1039×176 13.1 KB
The TU102 (Turing) of the Quadro RTX 6000 can have up to 32 warps per SM.Right?Then, Quadro RTX 6000 can execute up to 2304(72X32) warps?Powered by Discourse, best viewed with JavaScript enabled"
634,using-tesla-m60-with-windows-2016-server,"HI ,I’ve got a Windows Server 2016 install on a Huawei server and after installing the driver the system appears to recognize that the M60 is installed.I want to make sure I’m using the P40 as my Display driver , Is there anything method i can verify ?On windows server 2016 , how can I verify that RDP able to use the GPU ?I can see the P40 in GPU-Z & Device manager in local , but I can’t see the P40 driver after RDP .I can’t run any 3DMark or this type of software to ensure i can use the Display card .Thank youPlease do not open multiple threads with the same topic. You can use GPUProfiler oder nvidia-smi to check if the GPU is used properly. If not you need to enable the local Windows policy to use the GPU for RDS sessionsPowered by Discourse, best viewed with JavaScript enabled"
635,mtbf-for-rtx-a6000,"Hello, I am looking to see if anyone has Mean Time Between Failure (MTBF) information for RTX A6000 or similar graphics cards. Approximate information is fine. We’re just trying to look at high dollar components and determine need for ordering back up stock and reorder points.Hi, sorry for the late reply. Just seen this now. MTBF is >800000h for this board.Any of documents support MTBF>800000 for ATX A6000 ?Documents are not externally sharable without NDA.800,000 hours? Is that correct? Considering this card has a blower fan, that number seems surprisingly high- that is over 91 years!Powered by Discourse, best viewed with JavaScript enabled"
636,discrete-device-assignment-for-hyper-v-issues,"Hello everyone,I hope everyone doing great.
I have Nvidia A40 (Model	GA102GL [A40]). I am Deploy graphics devices using 
nvidiaA40735×465 76.9 KB

VMs. After I attached graphic card to VM, install the driver for Nvidia A40 and I got this error :This device cannot find enough free resources that it can use. (Code12).If you want to use this device, you will need to disable one of the other devices on this system.**** I disabled and uninstalled HyperV graphic card on this VMm reboot and still not working. Any suggestion? ThanksSR-IOV enabled on the host? A40 requires SR-IOV…Did you also play with these?set-vm -vmname $vmname -GuestControlledCacheTypes $true
Set-VM -LowMemoryMappedIoSpace 3Gb -VMName $vmname
Set-VM -HighMemoryMappedIoSpace 64Gb -vmname $vmnameI also have the same issue.  Windows Server 2022, an A40 & trying to DDA it to a VM.Did you find the answer?I have confirmed SR-IOV is on.  I’ve also tried many different High MMIO values, inc 64GB as suggested.I found setting the high MMIO space to 65GB workedPowered by Discourse, best viewed with JavaScript enabled"
637,getting-windows-sub-system-linux-to-recognize-and-work-with-an-nvidia-egpu,"Hello –I am looking to conduct live, real-time basecalling of MinION nanopore data using an external GPU (Nvidia RTX4000). I’d like to set this up as a bash script in the WSL Ubuntu environment, but I am unsure how to get WSL to recognize the eGPU for computational analyses. Can anyone point me in the right direction to set this up?Thank you!Powered by Discourse, best viewed with JavaScript enabled"
638,3d-printing-from-the-cloud,"Hey everyone,We all know regular printing from the cloud. It’s just what you do when you hit the print button inside a VM, connected to a network printer. Now we can add the 3rd dimension to this type of workflow.Many of you CADers out there will already be using GRID-accelerated VDI sessions for your Solidworks or Autocad work. You’re already experiencing best-in-class DirectX or OpenGL CAD performance in a remote environment.…but how do you take the next step when you’re produce a physical prototype? You could download your model, and take it to the workshop. But what if you had a way to go directly from CAD-model-in-the-cloud to real-life object? Then you wouldn’t have to lug around huge (and possibly sensitive) CAD files, and versioning wouldn’t be an issue since you are always operating on the most up-to-date copy.With the help of GRID-accelerated VDI and a 3D printer, now you can.Today I conducted an experiment at the University of Melbourne’s 3D printing studio, and am very happy to report that it was a big success. I managed to hooked up an UP! Plus 2 printer to a VDI session running inside VMware Horizon View. My session was streamed to a Wyse P25 zero client end point.Here’s what I did.After plugging in the 3D printer’s USB cable into the zero client device, it immediately registered inside the VM. However, I needed to manually point Windows driver update to the location where Drivers folder inside where the manufacturer’s software had installed. Installation of the driver after that point was quick and pain-free.
Once done, the 3D printing software running inside the VM communicated perfectly with the 3D printer via the local USB connection.Inside my GRID-accelerated session everything was buttery smooth. Even loading up big models presented little challenge to the remote experience when I rotated and scaled within the software. Of course, if I needed any changes made, I could jump straight into Solidworks which I already had open in the background (in the same VDI session).Looking at the setup I was really quite amazed. If you trace the wires, it goes:Here was a 3D printer moving and interacting with the real world—building a physical object—being sent commands directly from the cloud. If I had a wireless setup, the printer would have been controlled out of thin air!With the power of CUDA running on GRID in the cloud, I could see this replacing bulky, power-hungry processing units on robots and other autonomous devices that need to make split-second decisions based on real-world inputs on the fly.I’ll report back as I conduct further experiments.
Please don’t hesitate to reach out to me via email or social media if you are interested in this area.Cheers,
MikeExternal MediaExternal Mediaso nice.Thank you for sharing, I was struggling a bit with getting my models to print from the cloud. This post I still found be helpful even though it is pretty old. I am newer to 3D printing and found this Tool box page to be pretty helpful for knowing what options there are out there for 3D printing when just starting out.Powered by Discourse, best viewed with JavaScript enabled"
639,nvidia-vmware-vsphere-6-7,"Hi,I have installed VMware-VMvisor-Installer-6.7.0.update02-13006603.x86_64, on my server and the vib to the supported NVIDIA-VMware_ESXi_6.7_Host_Driver-430.27-1OEM.670.0.0.8169922.x86_64.vib, download from the Nvidia Enterprise Website but the base machine will not start with vGPU.When running ‘nvidia-smi’ on the host, it’s shows the cards:[root@localhost:~] nvidia-smiTue Jul  2 09:35:54 2019±----------------------------------------------------------------------------+| NVIDIA-SMI 430.27       Driver Version: 430.27       CUDA Version: N/A      ||-------------------------------±---------------------±---------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  Quadro RTX 6000     On   | 00000000:1A:00.0 Off |                  Off || 34%   36C    P8   146W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+|   1  Quadro RTX 6000     On   | 00000000:1B:00.0 Off |                  Off || 34%   37C    P8   150W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+|   2  Quadro RTX 6000     On   | 00000000:60:00.0 Off |                  Off || 33%   36C    P8   137W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+|   3  Quadro RTX 6000     On   | 00000000:61:00.0 Off |                  Off || 34%   37C    P8   140W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+|   4  Quadro RTX 6000     On   | 00000000:B1:00.0 Off |                  Off || 34%   37C    P8   147W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+|   5  Quadro RTX 6000     On   | 00000000:B2:00.0 Off |                  Off || 34%   37C    P8   146W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+|   6  Quadro RTX 6000     On   | 00000000:DA:00.0 Off |                  Off || 33%   31C    P8   140W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+|   7  Quadro RTX 6000     On   | 00000000:DB:00.0 Off |                  Off || 33%   35C    P8   144W / 260W |    159MiB / 24575MiB |      0%      Default |±------------------------------±---------------------±---------------------+I changed the default GPU mode from “Shared” (vSGA) to “Shared Direct” (vGPU) via vCenter to enable vGPU support for VMs.Here is the error message:Failed to start the virtual machine.
Module ‘DevicePowerOn’ power on failed.
Could not initialize plugin ‘/usr/lib64/vmware/plugin/libnvidia-vgx.so’ for vGPU ‘grid_rtx6000-24q’
passthrough device ‘pciPassthru0’ vGPU ‘grid_rtx6000-24q’ disallowed by vmkernelThanks for your helpHiWhich server chassis are you running?What happens when you try a smaller profile? Try a 1Q and see if the VM powers on.Also …Have you disabled ECC? …Check it by running: nvidia-smi -qDisable it by running: nvidia-smi -e 0You’ll need to reboot the chassis after running this commandYou can also try adding the following to the VMs ""Advanced Configuration"":pciPassthru.use64bitMMIO= ""TRUE""pciPassthru.64bitMMIOSizeGB = ""64""RegardsBenHiMy server is a TYAN Model: B7109F77DV10E4HR-2T-NI check with 1Q and it’s same error.
I have disabled ECC
And i have added the following to the VMs ""Advanced Configuration""pciPassthru.use64bitMMIO= ""TRUE""
pciPassthru.64bitMMIOSizeGB = ""64""Always the same errorThanksHyssamHiJust checking … but when you added those entries, I assume you added the values without the quotation marks on each end? "" ""When you configured the VM, did you select the option on the VM to ""Reserve all guest memory"" ?Also make sure that the memory allocated to the VM vs the ""reserved memory"" values are the same. If you’ve changed the amount of memory allocated to the VM, you need to un-check, then re-check the ""reserved memory"" option, as it doesn’t automatically update and the VM will then fail to power on.I’ve had it in the past that when changing from ""Shared"" to ""Shared Direct"" a host reboot has been required. As although you can manually restart Xorg, sometimes this isn’t enough and a full reboot has made the difference.Something you could try just to see whether it’s vGPU or System related … Put one of the GPUs into Passthrough mode, replace the vGPU profile on the VM with it and try powering it on.RegardsBenHiI have added the values without the quotation marks;I have selected on the VM option ""Reserve all guest Memory""The reserve memory and the memory alloccated are the same.I have restarted manually xorg and ESXi.How put on of the GPUs ?thanksHyssamHiAs I can’t actually see how you’ve configured things, I’m not able to suggest anything else.Can you take a few screenshots of your VM configuration and also GPU configuration from vCenter and post it on here? Maybe that will show a configuration issue somewhere.RegardsBenVM configuration 










Vcenter configuration 






VMware ESXi configuration











Thanks for taking the time to do that.The VM has a lot of vCPUs added, but that won’t stop it powering on. Apart from that, the general config looks ok initially with no obvious issues to me.Have you made any changes in the BIOS? Can you have a look at the MMIO settings and make sure they’re configured correctly. I’ve not used a Tyan before, so am unsure what options are available, but here’s a reference on what you should be looking for: Incorrect BIOS settings on a server when used with a hypervisor can cause MMIO address issues that result in GRID GPUs failing to be recognized. | NVIDIARegardsBenJust to be sure, what license is your vcenter?Also, do you have a GPU profile that ends with: a
Does this work or does it give the same error?You are solved my problem, on the BIOS the intel VT for Directed I/O has been Disabled.I activated the option and my virtual machine works.Thanks for your helpHyssamNo worries, glad it’s now working :-)By the way … that’s a kick-ass configuration! Just out of interest, are you able to say what you plan to use it for?And FYI, you can put 4 of those RTX 6000s with the 24Q profile inside the same VM if using vGPU, as vGPU now supports Multi-GPU configurations with up to 4 GPUs (but you have to use the top profile, in this case 24Q). But if you switch to Passthrough, then you can put all of them inside a single VM !! … :-DRegardsBenIt’s to make a server certification(3D virtualisation) and all GPU are allocated inside a single VMthank you for allHyssamNice!Thanks for the informationBest of luck with your project!RegardsBenHi,  I am unable to download VIB  for ESXi  6.7 .I have TESLA V100d.Can anyone help.Powered by Discourse, best viewed with JavaScript enabled"
640,hyper-v-server-2016-t4-using-discrete-device-assignment,"HiWe have purchased a Nvidia T4 card to test performance with a dedicated GPU within an RDSH server, the Hyper-V host is 2016, the VM is 2019.Following a guide we have set the lowmemory and highmemory settings in Powershell.Disabled and dismounted the device from the host and then assigned the device to the 2019 VM.From within the VM I can see an “NVIDIA Tesla T4” and the “Microsoft Hyper-V Video” is disabled.Installed the NVIDIA driver which includes RTX and WMI.Currently the GFX doesn’t show in Task Manager, also if I run “DXDIAG” it references the “Microsoft Basic Display Driver” not the NVIDIA, so we seem to be missing a step.Use hardware graphics adapter for all Remote Desktop Services sessions is also enabled via GP.Do we need to install a licensing server for it to function correctly?  I am fine setting this up I just wanted to do some testing before going through that.I have seen mention of downloading a driver from the licensing portal, which I have done, does that need installing on the host, the VM or both?  Is that what I am currently missing?Any help appreciated.Many thanksAppologise I have just tried uninstalling the original driver from within the VM and installing the one downloaded from the portal and it is now showing up in Task Manager.We will commence testingPowered by Discourse, best viewed with JavaScript enabled"
641,grid-vgpu-enabled-desktops-will-not-power-up-on-esxi-6-5-host,"I’ll try not to make this long winded. On yesterday I reinstalled esxi 6.0 (dell r730 customized ver) on one of our GRID (m10/m60) enabled servers to see how it behaved with our new vsphere 6.5 server appliance. I found that after reinstalling the software, patching the server, and attempting to start a m10 or m60 enabled vm on it, the vm would move to one of the other grid servers in the cluster to power on. My first thought was to check the graphics and found that the active type for the graphics on the ""fresh install"" server was set to basic and the configured type was shared. On the 2 functioning servers in the cluster, the active type was shared and blank for the configured type. I also found that the xorg service would not remain started for more than a couple of seconds before stopping. There is no error when powering on a desktop (my guess was that this was because the vm moved itself to another server in the cluster).I needed to interact with the graphics in an attempt to change the active type and hopefully get the xorg service to start, so I upgraded the host to esxi 6.5. That allowed me to interact with the graphics and change them to shared/ shared direct, but not for the active type is still basic. Also, the xorg service will not stay on and stops itself as soon as I refresh the screen.The vms still jump off the server when powered on like it’s the plague. I have compared every other setting and it matches up. The biggest propblem is that the xorg won’t stay running. If I run nvidia-smi from the functioning servers, I get nvidia-smi: not found. But I get information from the other servers. I’m not really sure what to look at next as there are no graphic related errors appearing, but I feel like there is a checkbox somewhere or a setting that I am missing. Any help would greatly appreciated.Just another note. When I run esxcli hardware pci list –c 0x0300 –m 0xf on a working host, the module has nvidia listed, but on the host with the issue, the module is none.I got the command from this kb VMware Knowledge Base. It says it’s for 5.0, but I figured that it might mean something.Okay. Now I’m almost certain that it’s the vib. When I run esxcli software vib list from the working server, I can see the nvidia vgpu esxi host driver. I’m going to install it on the fresh server and see what happens.EDIT: Okay. That removed the basic active type and got the xorg service started. I rebooted, but the desktops I start on the server still jump to another one.Well, using the forum search would probably help. It’s not the VIB, it’s a bug with ESX6.0 U3 as I suspect from your description with xorg…
https://gridforums.nvidia.com/default/topic/1207/nvidia-virtual-gpu-drivers/vmware-esxi-6-0-update-3-support/RegardsSimonThanks for the reply. I saw that post and ran the gauntlet on that issue last year, but I am on 6.5 now and xorg service is now started and holds. I could try that process again, but it would seem that I wouldn’t need it if the service is not having an issue anymore, correct?Edit: I think I’m 99% of the way there. I turned off DRS on the cluster and the vms didn’t move off of the fresh install host. So, I’m guessing that there is something that needs to be tweeked in DRS.I came across the same problem today. Updated NVIDIA host drivers to GRID 12.2 (460.73) and active state stays on (Basic). ESXi version is 6.7.Tried to change the graphics host adapter type to direct shared, but xORG service is always stopping.The link provided above is no longer existing.Did you check the documentation and made sure you’re using the Nov Rollup for 6.7 at least?The NVIDIA vGPU software product support matrix.thanks for the information. I have read the requirements in the documentation prior the upgrade, but must have overlooked the rollup part. Will try that in a sec.Powered by Discourse, best viewed with JavaScript enabled"
642,whats-the-2-pin-header-in-top-of-the-grid-cards,"is there any information what the two-pin header on top / side of the GRID Cards is for? Next to the header is mostly a “high temp” sticker. Is this a breakout for a temperature reading?

grid21605×1003 320 KB
Powered by Discourse, best viewed with JavaScript enabled"
643,m60-on-esxi-no-profiles,"I’ve installed the VIB that shows up in the licensing portal, but the profiles aren’t showing up in the VM settings.  We’re runnin ESXi, 6.5.0, 7967591 (and View 7.2).  The vib appears to be installed properly, when I run:esxcli software vib list | grep -i nvidiaI get:NVIDIA-VMware_ESXi_6.5_Host_Driver  410.68-1OEM.650.0.0.4598673           NVIDIA              VMwareAccepted    2018-12-04However when I try to run:nvidia-smiI get:Failed to initialize NVML: Unknown ErrorI’ve verified the card is in graphics mode (as opposed to compute).I’ve seen a few comments suggesting that I may have the wrong VIB, but it is the only one offered in the licensing portal.  Does anybody have any ideas?Hi,you should run dmesg on your host to figure out what the issue is. I assume a BIOS issue with MMIO. Which server are we talking about? Dell R740?RegardsSimonHi Simon, thanks for responding.To answer your question, the server is a Cisco C240-M4SX.After I posted this message I ran across:Reading Time: < 1 minute Today I encountered the problem that the NVDIA driver couldn’t communicate with the M60 Tesla card in an ESX 6.5 environment.
Est. reading time: 1 minute
And as an experiment I enabled DirectPath, and at that point the profiles started showing up in the VM settings.  After disabling DirectPath again (and after rebooting) I get the following:xorg will try to start, and then stop.If anybody runs into this on ESXi 6.5, it turns out that there’s a problem with the size of the VIB being a little to big for ESXi.  Apply this patch:Keep up with what’s new, changed, and fixed in VMware vSphere 6.5 by reading the release notes!As I understand it, this should not be a problem on 6.7.Hello sschaber
i have same problem and run dmesg on my host ESXi 7.0 con servidor Dell R740
I get:
ALERT: NVIDIA: module load failed during VIB install/upgrade.
i want virtualized a GPU RTX Quadro 6000
so on my vcenter enviroment my graphix card is available but whitout memory
can you help mePowered by Discourse, best viewed with JavaScript enabled"
644,windows-server-2019-tesla-4-driver-model-unknown-when-running-dxdiag-do-i-need-a-grid-license,"I was instructed to ask here by Nvidia’s Windows support team if I needed a Grid license in order to use this card on this OS?Powered by Discourse, best viewed with JavaScript enabled"
645,problems-with-nvidia-k20x,"Hi there,I recently bought a k20x Tesla card.
Now I have got it today and wanted to power it up, but it does not get
recognized by the Mainboard at all.
Do I need a special build for it to work ?Maybe the power supply is not sufficient ?Any help on this topic would be appreciated.Thanks in Advance,Denis Muhic.Powered by Discourse, best viewed with JavaScript enabled"
646,nvidia-tesla-t4-gpu-and-esxi-6-5,"Hi Guys,I’ve recently installed a Nvidia Tesla T4 GPU in my server running ESXi 6.5.I’ve tried making a passthrough on all 32 addresses for the card on the list but when that happens and when I try to assign the card to a VM, the option the assign the PCI device is greyed out.I’e managed to to set a passthrough and make Active 1 address and than I was managed to assign this card to the VM.My question is:Does this mean that only 1 GPU core is assigned to the VM out of a possible 32?If so, any ideas how I’m able to assign all 32 cores of this card to the VM as when I try the option to add the PCI device to the VM is greyed out?Please advise.Kind RegardsGMSSFirst of all you should mention which host you are using. I assume there is something wrong with your BIOS as it seems you are seeing the SR-IOV virtual devices. You should change your BIOS to get a single T4 :)Regards
SimonHi Simon,Many thanks for your reply and apologies for not stating the host. It’s a Dell R620 running ESXi 6.5.Just so I understand, the reason why I’m seeing 32 addresses is because the SR-IOV in the BIOS is set to Disabled and hence it is enabling the Nvidia T4 to appear to have multiple physical PCI devices as oppose to just 1?Should I be changing the SR-IOV in the BIOS to Enabled in order to get just a single T4?Kind Regards
GMSSCorrect! Please give it a try.Powered by Discourse, best viewed with JavaScript enabled"
647,tesla-4-crashes-ml350-gen9,"Hi all,
nice to be onboard and hope someone can give me some help.
I am running a HP ML350 with ESXi 6.7 U3.
I just installed a TESLA 4 - just to figure out, that ESXi keeps crashing just after some minutes.
Did not dig inside the dump yet - but maybe no need to if anyone might faced the same issue.
btw. the system is running super stable without the card - and the card was actually also tested and running well in a DL380 Gen10 Server. Would appreciate any help…Also the card itself is recognized within ESXI (so it’s listed in HardwareSection) - but i could not do further tests as the systems fails after just being up some minutes. Help or advice really appreciated.Powered by Discourse, best viewed with JavaScript enabled"
648,xorg-service-wont-start-with-tesla-t4-470-63-driver,"Hi, good afternoon to everyoneI am writing this post, because we have some trouble setting up 3 Nvidia Tesla T4 graphics cards on a new server in VmWare, we cannot use the GPUs. The problem is related to the Xorg service, this service stopped on its own and is no longer running.Tech Information:
Driver version: Nvidia-SMI 470.63
Service: X.Org Server
Graphic Card Settings: Direct share
VMware Horizon:  8.0.0 build - 16592062
vSphere Client version 7.0.2.00400
putty_oiyzPddOaD851×975 29 KB
Can you help me with some information or documentation?Thanks.DavidAnd what is your issue with T4? The GPUs are properly recognizedHI @sschaber thanks for your reply. Sorry, but I understand that service was necessary for Graphic card works correctly.But i found this information about the Service X ORG: VMware Knowledge Basei made some tests and works correctly without the process X ORG are runningRegardsThanks for the update. Exactly what I expected :)Powered by Discourse, best viewed with JavaScript enabled"
649,tesla-m10-nview-desktop-manager-not-working,"Hello everyoneI have installed the latest ESXI6.7 driver (430.27) and set up vGPU (configuration file is M10-0B) for the virtual machine (windows 7 x64). The virtual machine can successfully install the driver and recognize the ""GRID M10-0B"" driver. , but I can’t start ""nView desktop manager"", when I try to start it, there is no responseI have already started the authorization server on the LAN, but I have not found any windows that can authorize the license in the virtual machine. What should I do?Please help me, thank you very much. :)what does nvidia-smi output if you run it from > C:\Program Files\NVIDIA Corporation\NVSMI>nvidia-smi.exePowered by Discourse, best viewed with JavaScript enabled"
650,power-cable-adaptor-question-for-tesla-m40-in-dell-c4130,"Hello - I am currently planning for an upgrade of the GPUs in my Dell C4130 from AMD models to Tesla M40.  In the C4130, the GPU power cable is this Dell P/N:DF5NR 	ASSY,CBL,PWR,DUAL GPU,MB,C4130This cable has one 8 pin connector, and one 6 pin connector for the GPU.From what I can see, the 8 pin input on the M40 is slightly different than the shape of the Dell DF5NR cable, and doesn’t seem to fit.  So my question is this.The Tesla GPU cards came with an adapter, NVIDIA P/N: 030-0571-000, what I can see, is that, the input for this adapter (the mail side) matches the 8 pin from the Dell cable.  Is the proper cabling then for this server/GPU combo just the 8 pin from the Dell cable to the NVIDIA adapter, and then to the GPU?Powered by Discourse, best viewed with JavaScript enabled"
651,nvidia-license-not-getting-acquired,"Hello,I have the following configuration.Windows 10 VDI, Xendeskop, Tesla M10 GM107GL
GRID M10-1b profile to all VDI’sI have GRID PC and APP Licenses, but in the logs i see the message:Failed to acquire/renew license from license server.Tue Feb  8 17:49:23 2022:<1>:Failed to acquire/renew license from license server. (Info: http://MGT.domain.local:7070/request; NVIDIA Virtual PC - Error: [1,7E2,2,1[7000000B,0,702C7]]
Requested feature was not found.)Whats wrong? Wrong licenses?Hope anyone can help me!Regards
BruceHi,
why not simply open a support ticket for your issue described? I’m sure the support can help to solve this.Best regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
652,no-video-output-a40,"I recently purchased a Dell PowerEdge R750 server with NVIDIA A40 graphics card. I installed the drivers and the card was showing up in the device manager but the software was unable to see or use the graphics card. After talking with tech support the indicated the card shipped in vGPU mode. I had to use a command line tool to enable physical display mode - 256MB Bar1. Also, I switched the windows nvidia driver to WDDM mode. After doing this it appears that the OS and applications can see the card. I checked using GPU-Z.However, I’m still having a problem with on of my software application. Also, I don’t get any video when I connect a monitor to the graphics card. I’d like to at least see video output before I continue to troubleshoot my software application (Anatomage InVivo 6).Powered by Discourse, best viewed with JavaScript enabled"
653,problem-installing-grid-driver-on-grid-server,"Installing CloudXR on MS Azure. During driver installation, an error occurs 1. The Graphics driver is not compatible with the version of windows. or 2. The Graphics driver could not find compatible hardware. or 3 Other installations running. Not sure of what graphics driver or hardware? Azure is using Windows 2019, 64-bit. What driver do I download? What product type to use? I Tried Nvidia RTX Quadro.Hello,I am moving your topic to the vGPU category for better visibility.Best,
Tom KThank you very much!Powered by Discourse, best viewed with JavaScript enabled"
654,nvidia-smi-failed-to-initialize-nvml-driver-library-version-mismatch,"Enviroment: VMWare Ubuntu 18.04
GPU: Tesla V100
GPU driver version: 440.133cuda10.2 install with https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocalAfter installing CUDA 10.2. The following error occured.$ nvidia-smi
Failed to initialize NVML: Driver/library version mismatchhow can i solve this problem?HiRemove the vGPU driver and CUDA from the VM and Host. Install the latest version of vGPU 11.x in both the Host and then the VM.vGPU 11.x comes with CUDA 11 already installed, there’s no need to change it.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
655,license-server-capability-response-host-id-does-not-match-expected-null-got-ethernet-xxxxx,"I get this error when i upload the lic file
Mac adress is correct
What can be the eissue?12:53:35,189 ERROR Trust startup failure:Unable to read anchor, status:FATAL.
12:53:35,196 ERROR Trust break detected at startup time:Unable to read anchor, status:FATAL.
13:00:46,956 WARN  Resolved [com.flexnet.glservice.exceptions.LicensingFault: Capability response host ID does not match. Expected null, got ETHERNET:2a8172a8679a]
13:09:23,884 WARN  Resolved [com.flexnet.glservice.exceptions.LicensingFault: Capability response host ID does not match. Expected null, got ETHERNET:2a8172a8679a]Regards Jeroen.Mcafee was blocking a sub process of the lic manager :(
resolved it nowPowered by Discourse, best viewed with JavaScript enabled"
656,multi-tenant-cloud-provider-rdsh,"We are looking to offer GPU to our customers.We have a multi tenant IAAS CLOUD environment build on VMware.We are looking to put a GPU in some servers and offer this to our workloadsOur 2 type of servers areMicrosoft RDSH, which we deploy as stand alone solutions for each customer
Citrix Xenapp, which we deploy with PVS (no relation to vCenter)From what I have found until now:Grid vPc is not an option as the profile is limited to 2 GB
Grid vApps is not an option as the profile is limited to resolution of 1280*1024From my understanding we could leverage Quadro vDWS in combination with Grid vApp licenseWould this also work on RDSH running on Hyper Visor ESXi?Hi,unfortunately this>>Grid vApps is not an option as the profile is limited to resolution of 1280*1024is misleading , because it’s only true for console access (to prevent misuse of A-profiles to be used with Server Hosted VDI)
Each and every logon to RDS/XenApp through the sessions stack using HDX/RDP will be able to use multi-monitor setups.You can run your VMs with A-profiles on top of ESXi.There is only the one or the other … Quadro vDWS (Q-Profiles) or vApps license (A-Profiles)
>>From my understanding we could leverage Quadro vDWS in combination with Grid vApp licenseFor just hosting published Apps / published Desktops on top of a multi-user OS choose the vApps license and you are fine.Cheers;
Ron.Powered by Discourse, best viewed with JavaScript enabled"
657,tesla-m40-12gb-passthrough-issue,"Hi Nvidia,Could you please help me with issue.
I owned Tesla M40 12GB card, and want to use as encode GPU in VM on ESXi 6.7 in Windows 10.When I enable passthrough in ESXi 6.7 U3, host needs to be rebooted.
After reboot GPU become disable in passthrough again, and VMware console asking to enable it again. And this is loop process which never ends, I have also FX3800; 4000 and 2000 Quadros, and ALL GPU’s works fine on same server with same ESXi 6.7 hypervisor.Do you have any idea why I can’t passthrough M40 on host, I’m not using multi-GPUs on the same server, just tested with another GPU’s issue not with Motherboard…Thanks
StasPowered by Discourse, best viewed with JavaScript enabled"
658,hp-dl380p-gen8-nvidia-grid-k1-error,"Hello,i´ve a Server HP DL380p Gen8 with a NVidia Grid K2 Card. I´ve installed XenServer 6.2 with all patches an the latest BIOS.I´ve assigned to a VM a vGPU trough the XenCenter GUI. When i try to start the VM i get following error:
Starting VM ‘VMNAME’ - Internal error: xenopsd internal error: Unix.Unix_error(20, ""open"", ""/sys/bus/pci/drivers/nvidia/bind"")I´ve launched following commands on the XenServer Console:
lsmod | grep nvidia -> no outputdmesg | grep NVIDIA
nvidia: module license ‘NVIDIA’ taints kernel.Can anyone help meThanks in advancedMartinHave you disabled the MMIO above 4G option in the BIOS?Hi Luke,I have exactly the same server and the same problem with the NVIDIA GRID K1.
Problem is I can not find the MMIO above 4G option in the BIOS, there is not such option in there.Any ideas?Thank youI have also found this BIOS guide that is for all Proliant Servers but it seems to be different from model to model:http://h20628.www2.hp.com/km-ext/kmcsdirect/emr_na-c00191707-18.pdfThe Memory Mapped IO Option is completely missing from the DL380p BIOS.
Can anyone help?Thank youI’d suggest checking with HP to see if there’s an earlier (or later) BIOS that returns this setting.Also, be aware that the next release of XenServer, currently in tech preview codename Creedence, eliminates the need for this setting as it moves to a 64 Bit  DOM 0 session.Hi all of you!Did you find a solutions to fix the Bios setting on the HP DL380p Gen8 Server.
I want to disabled the MMIO above 4G option in the BIOS. Is it possible on this machine?Hi guess,
I’ve a laptop in which I’m getting an error of wps pin,
How to resolve this issues?
Can anyone guide me on thisPowered by Discourse, best viewed with JavaScript enabled"
659,cant-get-m10-to-run-more-than-2-monitors-on-horizon-view-7-10,"Hey!We have a host running ESXi 6.7 with the Tesla M10 card.
We use Horizon View 7.10 and run the graphic card as shared PCI deviceWith two monitors everything works great! But we want users to have the option to use 4 monitors.I’ve been testing with the grid_m10-1q profile which supports 4 displays but when trying to connect with for example 3 monitors, the third display is stuck at the login screen while the two others looks fine but you cant do anything. This is with Blast.
With PCoIP it looks like two displays dragged over 3 of my monitors.Tried to uninstall the SVGA driver without any luck.Hope you can help with this or point me in the direction to get help :)Kind regards,
AleksanderHi AleksanderTo remove the vSGA driver, uninstall the Horizon Agent, the vGPU driver and VMTools. Reboot the VM and reinstall VMTools without the vSGA driver (Custom Install), then install the vGPU driver and lastly the Horizon Agent.I never install the vSGA driver when using vGPU. However, you may not need to do that to resolve your issue …You haven’t mentioned what resolution the monitors are, but regardless, ideally you should have a larger vGPU Profile than that, especially for 3 or 4 monitors. Start off with a large vGPU Profile (4Q / 8Q, it doesn’t matter at this stage) to remove that as a potential limitation, then once you have it working scale it back down until you find the right level for your use case.FYI - The VMware version of PCoIP is not very good, and not something I bother using. Don’t confuse that version with Teradici’s version of PCoIP and PCoIP Ultra, which are excellent!RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
660,error-when-allocating-multiple-vgpus-in-a-single-vm-with-ubuntu-kvm-hypervisor,"Although the vGPU document for Ubuntu KVM explains that multiple vGPUs are supported (within a limited situation), starting a VM with multiple vGPUs (have tried two and three vGPUs) returns an error.
Here is the link of the document: https://docs.nvidia.com/grid/latest/grid-vgpu-release-notes-ubuntu/index.html#multiple-vgpu-support
I have succeeded to start the VM with a single vGPU, and the nvidia-smi command in the VM shows the vGPU fine.
However, both time-shared vGPUs and MIG-enabled vGPUs fail to start the VM with multiple vGPUs.I am using Ubuntu 18.04.5 with kernel version 5.4.0-90-generic, and using the 13.x vGPU software.
nvidia-smi shows that the driver version is 470.82, so I think it is vGPU software v13.1.
I am using the Ubuntu KVM + QEMU v4.0 for the hypervisor, and also using Ubuntu 18.04 VM images.
Also, I am using the A100-pcie-40GB GPU.Here are some error messages when I run # virsh create vm.xmlAlso, my journalctl log shows that the first vGPU was initialized, but the second vGPU incurs an error,
which says that: multiple vGPUs in a VM not supported.The vGPU documentation also provides the steps to utilize multiple vGPUs in a single KVM-backed VM.
(Link: https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#adding-vgpu-to-red-hat-el-kvm-vm)How can I use multiple vGPUs in a single VM backed with Ubuntu KVM, as the document suggests?Any help would be very grateful, and thanks in advance.Hi,
I don’t have own experience with this setup but I found  a similiar issue with Ubuntu as guest where changing from BIOS to UEFI did the trick. Maybe worth a try?regards SimonHi,
I have exactly the same problem, but I am using Red Hat Linux 8.4 with KVM. Switching the boot option on the guest from BIOS to UEFI did not work. I hope someone can provide a workaround for this. We need more than one vGPU on the guest VM.Regards
MevludinPowered by Discourse, best viewed with JavaScript enabled"
661,tesla-m40-nvenc-not-initializing,"I have a system running windows 10 pro 21H1 with dual E5-2699v3’s, 64GB of 2133Mhz DDR4 and a Tesla M40. My goal for this system was to run VM’s in Hyper-V with GPU-P passthrough and stream the VM’s to clients over Parsec. Whenever a client attempts to connect, they either get a 14003 or 15000 error, meaning the host could not initialize the encoder. I’m assuming this is due to Nvenc not initializing, as parsec hosting also fails on the host OS. I’ve set the card to WDDM mode, and it can run Unigine Heaven very well on the host and VM’s, but Nvenc seems to not have been passed through. Any ideas?Thanks.Hi,
unfortunately M40 was never supported for graphics and should work only in TCC mode. For WDDM support in Windows you would need the vGPU driver for DC boards but M40 is not enabled.regards
SimonI know this isn’t an intended use case, But the standard Tesla driver has built in support for putting the card into WDDM, you just need another display device to route the rendered frames. I’m just trying to figure out why I’m getting this error in a virtual machine when all other graphics applications are getting full acceleration.ThanksPowered by Discourse, best viewed with JavaScript enabled"
662,how-to-connect-a-beckhoff-sps-with-jetson-nano-2gb,"We need to do a school project and need to connect a Beckhoff SPS with the Jetson Nano 2GB, does anyone already did something similar. In the end it should work with TCP/IP, LAN. Happy for every advice :)Powered by Discourse, best viewed with JavaScript enabled"
663,tesla-t4-low-fps-during-video-and-overall-session-latency,"GPU Tesla T4
CISCO UCS C240M5
VMware ESXI 6.7
CPU Xeon Gold 6146 x2
Citrix Xen Desktop 7.15
Citrix Receiver 1911
Citrix VDA 1912 LTSR
GPU Driver Version 441.66
vGPU Profile used - grid_t4-2b and also grid_t4-2a
ICA Network Latency is 1-2 MS
ICA Round Trip Time is 5-100 MS
Display is 3x 2560x1440p Monitors.  Same behavior with only 1x 2560x1440pPlayback via YouTube or any other stream is choppy, even at 1080pFPS is often around 15-18 which seems quite low.  I’ve tried both codecs (H.264 4:4:4 and H.264 2:2:0) (same behavior)If anyone has any insight or ideas, let me know.3.28 MBFirst of all it would be helpful to figure out the difference between rendered frames and remoted frames.
Check with ""nvidia-smi encodersessions"" how many frames are rendered and if you are properly using video codec with NVENC.Thanks - See the output below and images.GPU Session    Process   Codec       H       V Average     Average[root@HBC-DC1-ESX13:~] nvidia-smi encodersessionsHiYour encoding latency is all over the place, and it’s actually quite high. Can you try something not from YouTube. Use a local source, something loaded locally on to the VM to rule out your streaming source.What are you using as a Client and how is it connected to the network? If WiFi, use a physical cable. You may also want to try a completely different network connection as well. Ping times don’t tell the whole story.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
664,vgpu-14-0-xorg-issues-with-ubuntu-and-horizon-2111-1,"Hi,
Our vSphere hosts were upgraded to include the newest host driver version 14.0, and this apparently caused instability issues on vGPU enabled Linux guests running on earlier 13-series guest drivers. VMs started to crashing intermittently and this was something we had not seen before. Naturally the first thought remedy was upgrading the Linux drivers as well. However when applying Linux upgrade from the .deb package we got into a situation where Xorg doesn’t start anymore. Here is a relevant snippet from a Xorg.log. The Xorg session is started by VMware Horizon Agent 2111.1 so I cannot tell whether this is a VMware issue or Nvidia issue and which party to contact but anyhow it began with the driver upgrade and Horizon Agent reinstallation on top of it didn’t help. The GPUs are P100s, hosts are ESXi 7.0U3c and tested distributions are Ubuntu LTS 18.04 and 20.04.Powered by Discourse, best viewed with JavaScript enabled"
665,hey-ive-got-10-tesla-v100-32-gb-where-do-i-sell-them,"Hey so I buy storages and among the lockers I bought I came across 10 of the Tesla v100 32 gb and I am very out of my league here can someone help me get rid of these ?Powered by Discourse, best viewed with JavaScript enabled"
666,tesla-m10-on-dell-r740-server-2016-standard,"Hi,We have a Dell R740 with two Tesla M10 cards.  The Nvidia Grid (version 6.2) installs without issue except the reboot to complete the install freezes on the windows symbol.We have have patched windows to the latest level, tried an older version of vgpu driver and still the same issue.Prior to rebooting to complete the install the M10s appear in the device manager.Any ideas?ThanksHiWhich Hypervisor are you using?If you’re watching the VM through the Hypervisors VM Console, then the VMs normally freeze at that point once the GPU driver has been installed, this is normal behavior. Make sure you have RDP enabled on the VM so you can connect remotely after the GPU driver has been installed.RegardsBenHi,This is the installation of the grid software on the host OS and the post install reboot to complete the install.It freezes just before reaching the windows login.Ive done a clean install of Server 2016 with no hypervision role setup and still the same issueThanksPS we will be using HyperV direct attach once we have solved this problemI have tried change all Memory I/O options (56TB, 12TB and 512GB) options as wellHiSorry, I’ve never used Hyper-V, so no idea what’s required. Any of the other supported platforms, then I could help, but not Hyper-V I’m affraid.RegardsBenHi Ben,We are just trying to get the nvidia vGPU drive installed on a bare bones 2016 Server.  The driver simply will not install.ThanksJonHiIf this is your Hyper-V Host, and you’re going to be running 8 VMs on it using Passthrough / DDA, then why are you installing the NVIDIA driver on it?Again, sorry, I don’t use Hyper-V, so don’t know if Hyper-V requires it. But with the other Hypervisors (XenServer, vSphere, KVM), you only need to install the driver in the Hypervisor if you’re going to be using vGPU. If you’re going to be using Passthrough / DDA, then the driver has nothing to do, so there’s no point installing it. For Passthrough / DDA, the driver should only be installed in the VMs with GPUs attached, not on the Hypervisor.Does that help at all?RegardsBenHello all,Was there ever a solution to the problem JonP? I am having the exact same problemPowered by Discourse, best viewed with JavaScript enabled"
667,tesla-m10-for-deep-learning-without-virtual-machines,"I have an M10 on a server that I want to use for Deep Learning.I don’t need for it to be ran on any virtual machines.Is it possible to SSH into my server I have the M10 on and train models using scripts from the command line?Powered by Discourse, best viewed with JavaScript enabled"
668,connect-cloud-gpu-to-exact-process-application-not-to-entire-system,"Is there a way to connect cloud GPU to exact process but not to entire system? (eg just browser process to use cloud GPU instead of system GPU, but not affecting other applications)HiYou can’t link a GPU running in another system to yours in that way. I think the closest you could do to that would be to deliver your browser (or which ever Applications you wanted) as a ""Hosted Application"" running on a different system that had a GPU running in it. Something like Citrix or VMware can do that.RegardsMGHiYou can’t link a GPU running in another system to yours in that way. I think the closest you could do to that would be to deliver your browser (or which ever Applications you wanted) as a ""Hosted Application"" running on a different system that had a GPU running in it. Something like Citrix or VMware can do that.RegardsMGIt’s not suitable for me as it will take huge amount of server resourcesPowered by Discourse, best viewed with JavaScript enabled"
669,cant-access-nvidia-smi,"When i run my program, it says gpu device not found.
error: (-217:Gpu API call) no CUDA-capable device is detected in function ‘ManagedPtr’so i entered nvidia-smi and some other commands in terminal, and they all returned errors like this:
NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.What seems to be the issue here? I have run programs before, and never got this issue.Powered by Discourse, best viewed with JavaScript enabled"
670,huge-memory-leak-in-vgpu-processes,"Hey guys, there is a known memory leak bug when vgpu is used on xenServer
Control domain memory leak issue on Citrix Hypervisor 8.0 when GPU in use.Is there any date given when this bug will be fixed?Hi MartinNot sure about the LTSR fix for vGPU 8.2, it may be worth upgrading to vGPU 8.3 if you want to keep LTSR.Also, vGPU 10.1 is available if you’re going through an upgrade process, and it may be beneficial to move to that instead as it’s 2 branches newer than the LTSR and is supported until December 2020. I know it’s not an LTSR, but if the 8.3 version doesn’t resolve the issue, then this one should.RegardsMGOK, downloading 10.1, will post result. I hope it’s safe to upgrade it.Hi MartinYes, obviously make sure you’re on a supported version of XenServer before proceeding. I assumed that you’re running XenServer 8.0 or newer as this was the version referenced in the URL you posted above. If you are, then this should be fine.RegardsMGyes, we’re running Citrix Hypervisor 8.0.Maybe one more question related to memory leak, is it possible to reset/restart vgpu processes without restarting whole VM affected by vgpus processes consuming more and more dom0 memory? Would that work? Thanks.HiNo, you’ll need to restart the VM. If there’s a problem with compatibility, it’s best to resolve it rather than scheduled reboots or service restarts.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
671,gpu-v-gpu-pv-on-hyper-v-2019,"Has there been any update on when Microsoft Hyper-V 2016/2019 will support GPU-PV \ GPU-V (GPU Paravirtualization).Not at this stage. Sorry not having any positive news.Powered by Discourse, best viewed with JavaScript enabled"
672,nvidia-m60-m10-licensing-vms-question,"Hi Folks,We are currently working on a project to allow 6-8+ users to access a server remotely with GPU based virtual machines in an educational setting, I’ve looked at several solutions and am leaning towards the M60 in a DELL R740 server running Hyper-V as the hypervisor.I have limited understanding when it comes to the licensing side of this and my virtualisation experience is mostly on home labs with hyper-v and back in the day when Vsphere was just esx. So firstly I’ll ask if I’m correct in the way I understand it so far.Is it as simple as that? are there any costs I’ve not considered? as this is an educational project in conjunction with a UK university via an epic mega grant are there any educational licensing models?The ideal setup would be 8 VM’s with GPU resources that can be accessed by kids to run virtual workshops with, I have tried amazon appstream and even virtualised EC2 GPU instances but the cost is prohibitive long term. My personal thoughts are Nvidia is the way to go but I need to understand the licensing costs and options before pulling the trigger on a server and card. without going in to too much detail I have aspergers and irlens so masses of text and jumping backwards and forwards through pages is incredibly disorienting and I’ve tried and given up several times.So, one server, one Vgpu card, 8 virtual machines (or virtualised apps). best way to go?regardsJasonHi JasonIf you’re just getting started with vGPU my personal advice … Don’t use Hyper-V unless you have absolutely no other choice. It doesn’t support vGPU, so you’ll be looking at using VMs with the entire GPU passed through (DDA) to a single VM (think RDSH use case, unless you plan to give each user an entire GPU). Purely based on vGPU functionality, it is the least suitable Hypervisor for this technology at the moment.Regarding physical GPU choice as you’re yet to purchase and are just getting started (assuming you choose a different Hypervisor) stay away from the Maxwell architecture (M6, M10, M60) now as the architecture is pretty old. Unless you want to use Quadro features, those GPUs will work (there’s very limited Quadro support on Maxwell), but in my personal opinion it’s not worth testing with them due to the overall differences they have compared to the newer architectures. The oldest architecture you should be looking at is Pascal. You could opt for a single P40, but that would be overkill, so the alternative would be 2x P4. These are 8GB GPUs and you could run 4x VMs on each GPU with 2GB of Framebuffer. However, even Pascal is starting to show it’s age now in various areas, and for what you’re looking to do, I’d recommend you choose something from the current Turing architecture. With that in mind, my recommendation would be a single T4 running ""vPC"" licensing. As the T4 is a 16GB GPU, that will give you 8x VMs each with 2GB of Framebuffer.Alternatively, if you did want to run RDSH, you could do this and use the entire GPU in a single VM with multiple students all sharing the same VM concurrently, that would also open up the option to using Hyper-V again as well. That licensing model would then change to ""vApps"" and you’d use the 16A profile. You would be able to support a lot more than 8x students through this model, but you’re then into a RDSH vs VDI play, and that choice is up to you depending on the workload and how you want to manage it. There are reasons why you’d use one model over the other.When you buy your server, you can configure it with a GPU before ordering. This will give you a single vendor for support issues and also make sure you install the required ""GPU Enablement Kit"" (typically low profile CPU heat-syncs, cables etc) that are required when running GPUs. Don’t forget to configure the server so that you can add additional GPUs into it later, meaning make sure you have plenty of resources installed at time of purchase as this is the cheapest way to do it rather than retro fit additional RAM or swap out CPUs etc at a later date when you want more density.Regarding discount licensing for EDU, yes this is absolutely available. Speak to your IT Partner and they’ll be able to get you sorted out. If they’re not an NVIDIA Partner, you can have a look here to find one: Find an NVIDIA Partner | NVIDIARegarding connectivity, which Protocol were you planning to use to connect to the VMs? RDP won’t work, and basically Citrix, VMware, Teradici, Mechdyne are the most commonly used and all perform very well. They all have EDU pricing options as well.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
673,cuda-12-on-widows-server,"hello,
I installed cuda 12.0 for windows server 2019, and cudnn 8.8.1.3 on wnidows server 2019, when i want get Inference by my onnx model i get this error:2 0 2 3 - 0 4 - 0 4   1 4 : 0 3 : 2 6 . 6 4 7 3 8 0 8   [ E : o n n x r u n t i m e : D e f a u l t ,   p r o v i d e r _ b r i d g e _ o r t . c c : 1 3 0 4   o n n x r u n t i m e : : T r y G e t P r o v i d e r I n f o _ C U D A ]   D : \ a \ _ w o r k \ 1 \ s \ o n n x r u n t i m e \ c o r e \ s e s s i o n \ p r o v i d e r _ b r i d g e _ o r t . c c : 1 1 0 6   o n n x r u n t i m e : : P r o v i d e r L i b r a r y : : G e t   [ O N N X R u n t i m e E r r o r ]   :   1   :   F A I L   :   L o a d L i b r a r y   f a i l e d   w i t h   e r r o r   1 2 6   "" ""   w h e n   t r y i n g   t o   l o a d   "" C : \ U s e r s \ t o s a n d m \ A p p D a t a \ L o c a l \ P r o g r a m s \ P y t h o n \ P y t h o n 3 9 \ l i b \ s i t e - p a c k a g e s \ o n n x r u n t i m e \ c a p i \ o n n x r u n t i m e _ p r o v i d e r s _ c u d a . d l l ""Traceback (most recent call last):
File “”, line 1, in 
File “C:\Users\tosandm\AppData\Local\Programs\Python\Python39\lib\site-packages\onnxruntime\capi\onnxruntime_inference_collection.py”, line 360, in init
self._create_inference_session(providers, provider_options, disabled_optimizers)
File “C:\Users\tosandm\AppData\Local\Programs\Python\Python39\lib\site-packages\onnxruntime\capi\onnxruntime_inference_collection.py”, line 408, in _create_inference_session
sess.initialize_session(providers, provider_options, disabled_optimizers)
RuntimeError: D:\a_work\1\s\onnxruntime\python\onnxruntime_pybind_state.cc:537 onnxruntime::python::CreateExecutionProviderInstance CUDA_PATH is set but CUDA wasn’t able to be loaded. Please install the correct version of CUDA and cuDNN as mentioned in the GPU requirements page (Redirecting…), make sure they’re in the PATH, and that your GPU is supported.my onnxruntime version is 1.14.1Powered by Discourse, best viewed with JavaScript enabled"
674,grid-on-k2-for-esxi-6-7-driver,"my server system is esxi 6.7,server is dell r730xd,display card is grid on k2,now can’t find the k2 driver for esxi 6.7HiYou’re trying to use a GPU from 2012 / 2013 that’s been superseded 4 times, with a recent Hypervisor. It isn’t supported.You need a supported GPU (Maxwell or newer) or an older Hypervisor version (ESXi 6.5) in combination with GRID 4.x. That said, the GRID 4.x branch is only supported until December 2019 (just over 2 weeks as I write this).It makes far more sense to use a slightly newer GPU that has support for the foreseeable future, rather than using a superseded GPU with modern software stack.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
675,hardware-compatibility-and-requirements-for-vms-and-gpu-passthrough,"Hi, I would like to know if enabling a GPU in a VM using iommu/passthrough (a 1:1 setup, where the host is unable to use the gpu and it becomes available to only one VM) is in the realm of “vGPU” , which are the compatible nvidia cards, and if i need a “licensing server” for that License Server User Guide :: NVIDIA Virtual GPU Software License Server DocumentationI’m trying to run a few VMS (qemu - ubuntu 20.04) on a Host (ubuntu 20.04), and setup a kubernetes cluster on those vms, and use  nvidia-device-plugin to manage the gpu resources.The host has a  NVIDIA Quadro RTX P4000 card and i want to use it on a single vm (gpu passthrough).I did manage to configure the passthrough and install the nvidia-device-plugin so the graphics card is visible from the VM but when i run a container on it it freezes completely.thanks in advancePowered by Discourse, best viewed with JavaScript enabled"
676,dda-black-screen-console-vm-rdp-no-problem,"Hi!I have a “problem” with the VM console after implementing DDA.
When installed the drivers on the HyperV host and configured DDA on the host and assigned a GPU to the VM that part works fine.
After installing the drivers on the VM to install the GPU the drivers gets installed just fine.
But after installing and a reboot of the VM I cannot manage the VM through the hyper-V console and the screen goes black.
RDP on the VM works fine and the drivers are correctly installed on host and VM.
What am I doing wrong here?Also do I need a license?My setup is:Server 2016 Datacenter
Hyper-V
HP Proliant DL380.
Nividia Tesla M10
128 GB
Profile: Virtualisation Optimisation.I have tested version 4.7 NVIDIA GRID (on host and VM) and 6.2 NVIDIA Virtual GPU Software (on host and VM).Also I have used these PS command for DDA:#Configure the VM for a Discrete Device Assignment
$vm =   ""TS01""#Set automatic stop action to TurnOff
Set-VM -Name $vm -AutomaticStopAction TurnOff#Enable Write-Combining on the CPU
Set-VM -GuestControlledCacheTypes $true -VMName $vm#Configure 32 bit MMIO space
Set-VM -LowMemoryMappedIoSpace 3Gb -VMName $vm#Configure Greater than 32 bit MMIO space
Set-VM -HighMemoryMappedIoSpace 33280Mb -VMName $vm#Find the Location Path and disable the Device
#Enumerate all PNP Devices on the system
$pnpdevs = Get-PnpDevice -presentOnly#Select only those devices that are Display devices manufactured by NVIDIA
$gpudevs = $pnpdevs |where-object {$.Class -like ""Display"" -and $.Manufacturer -like ""NVIDIA""}#Select the location path of the first device that’s available to be dismounted by the host.
$locationPath = ($gpudevs | Get-PnpDeviceProperty DEVPKEY_Device_LocationPaths).data[0]#Disable the PNP Device
Disable-PnpDevice  -InstanceId $gpudevs[0].InstanceId#Dismount the Device from the Host
Dismount-VMHostAssignableDevice -force -LocationPath $locationPath#Assign the device to the guest VM.
Add-VMAssignableDevice -LocationPath $locationPath -VMName $vmKind regardsNothing wrong. Works as designed. It is normal that you cannot use the console afterwards!!!Hi sschaber,Thanks for the reply.
In this video the console works (look at 13:50 min): Discrete Device Assignment with a GPU in Windows 2016 TPv4 on Vimeo
Could you explain please. :)Thanks!Hi,I never tested K1 with 2016 but K1 was able to be the primary display device which is not possible for the current Tesla boards.
What’s the issue in using RDP?regards
SimonIn passthrough mode, I don’t believe it was any different with the K1 or K2. You still need a separate video board for the underlying server if used as a hypervisor, I’m pretty sure.Thanks for the help people!No problem in using RDP. Just thought I was doing something wrong here.Regards!Using a Geforce and Windows Server 2019 with DDA to a VM, I am able to use the console Window as well. Also, I can use the GPU as an extended desktop - so using console is very much possible.Powered by Discourse, best viewed with JavaScript enabled"
677,cant-load-nvenc-plugins,"Hello,I am facing a weird problem with the nvcodec elements, mainly the nvh265enc and nvh264enc plugins. I can run several pipelines simultaneously in the terminal using those elements and everything runs properly. But when I run a piece of cpp software that uses these elements I am no longer able to use them in the terminal.When I try to inspect the element, example:gst-inspect-1.0 nvh264enc
I have the following error:element plugin couldn’t be loadedNo such element or plugin ‘nvh264enc’Does anyone have any idea what may be causing this behavior?Thanks in advance,MiguelHi,
The plugins are named nvv4l2h264enc and nvv4l2h265enc. For more examples, please look at gstreamer user guideHello Dane,I am not using those plugins. I am using the nvcodec plugins: nvcodecHi,
The plugins are not supported on Jetson platforms. Please use the v4l2 plugins.My bad, I am using a 3060TI, I will change the posts topic. SorryPowered by Discourse, best viewed with JavaScript enabled"
678,cloud-gaming,"Hi Guys,I want to deploy a solution for gaming over cloud and I need to help yours.Firstly, which kind of Tesla or Grid GPU card I should buy for gaming solution? I got confused between GIRID and TESLA cards!!! I couldn’t understand which one of them is fit for my solution? (For start this project I have more than 100 concurrently users for playing high end PC game)Next question is server computability  , is there any sever that supported to install 8 or more GPU card? HP,DELL or…!?Thank You Guys :)Cloud Gaming is a very complex topic. As I can see you didn’t really investigate in the options and products available. First of all I would recommend to create a business plan and think about the costs of the solution compared to the expected revenue you get and you will recognize that this is a very tough calculation.regardsSimonDear Simon,Thank you for your quick answer:)Yes I know its very complex topic and I trying to complete my business plan and after that if it was investable we will stat to investing on this project.I visited to certified sever page that you sent to me and it helped me to find best server for my idea, thanks.just let me know, dose need to NVIDIA QUADRO® vDWS license for running high end gaming on VDI? because its charge us 250$ per CCU Annual Subscription!Best Regards,Hi,unfortunately yes. I assume you will need a 8GB Framebuffer profile to fullfill the AAA gaming requirements and in general this would be a vPC use case as you don’t need the Quadro driver features but vPC only allows to use 2GB of FB :(.Best regardsSimonPowered by Discourse, best viewed with JavaScript enabled"
679,pci-passthrough-of-p6-card-to-single-vsphere-vm,"A little confused as to what is required to both make this work and to be in compliance…I have a need to create a Windows server that has full access to a physical GPU.  Rather than purchasing a dedicated Windows server with a GPU, we want to use the VMware/Cisco blade infrastructure already in place for our datacenter environment.We just want to pass through the Tesla card to an instance of Windows Server and use the Tesla drivers in Windows, same as if it were a physical machine using the same card.  No virtual desktops, virtual applications, vGPU etc in use.  Is a Grid license needed for this?  When I contacted support, all I get is ""vGPU requires a license"" and a reference to the vGPU documentation.Thanks in advanceHiEven in Passthrough, you still need a license for a Tesla GPU unless the GPU is running in Compute mode. What’s the workload you’ll be running?Regards
MGTesla driver = no license
vGPU driver = licenseSo simple…Powered by Discourse, best viewed with JavaScript enabled"
680,tegra-3-datasheet-and-ram,"Good afternoon, there was a need to download the description of the Tegra 3 Technical Reference Manual, but I did not find it in the current or archived ones. Please help me if it is not deleted. Interested in the supported RAM memory, up to 2 gigabytes by this processor, what specific memory models are supported?. I did not find K4B4G1646B and 512 megabytes in size and H5TQ2G83CFR. Is it possible to post Datasheet Tegra 3 ?Powered by Discourse, best viewed with JavaScript enabled"
681,grid-licensing-for-vmware-horizon-7-12-using-instant-clones,"Hi All,Have a query around the licensing requirements for vGPU GRID Licenses required for using instant clones in VMWare Horizon 7.12.Given the way that horizon creates a parent vm for rapid deployment, do these parent virtual machines contact the Nvidia Licensing Server and consume a GRID license as well as the virtual desktop itself?I really hope not!!Thanks,JasonHi JasonvGPU is licensed per CCU, however it actually acquires a license when the VM is powered on and booted and sitting idle, not when a user logs in. When powered down, it should immediately release the license back into the Pool.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
682,vgpu-slowdown,"Hi,I am running ‘roberta-large-mnli’ on vGPU model for text classification.Initially the inference runs fine takes around 133 seconds for classification of 9810 texts.On running the script again after 10-15 minutes, vGPU gets dramatically slow to the point that the script does not finish even after 30 minutes. The issue gets resolved after restarting the VM.I also observed the same behaviour with another image processing CUDA application.GPU:  NVIDIA RTX A5000
vGPU Profiles tried: 6c and 12cHost OS: Ubuntu 20.04.6 LTS
Host Driver Version: 510.85.03
Device Virtualisation: SRIOV
Hypervisor: KVMGuest OS:  Ubuntu 20.04.5 LTS
Guest Driver: 510.85.02Is the VGPU licensed, i believe they become throttled if not licensed.Powered by Discourse, best viewed with JavaScript enabled"
683,may-i-ask-where-the-p100-sxm-interface-pin-definition-information-is-published,"I want to try to make a SXM to PCIE devicePowered by Discourse, best viewed with JavaScript enabled"
684,unable-to-install-nvidia-driver-in-p40,"Hardware Details:Model - DELL PowerEdge R730 iDRAC
RAM -  32GB
CPU - 12 Core
Graphics - Tesla P40I have installed VMware ESXI in the server and I tried creating VM.
The VM is created and GPU is utilised by pass through method.The following are the things which tested in the Dell serverOS - lubuntu 18.04.5 desktop version, Ubuntu 18.04.6 desktop version, Ubuntu 18.04.6 server version,
Ubuntu 16.04.7 desktop and server versions
CUDA - 10.2, 11.0, 11.2
NVIDIA Driver - 460.32.03, 450.172.01, 460.106.00, 440.118.02Initially I have installed OS in BIOS mode and later in one of the forum they mentioned to install OS in EFI mode to work on P40 machineReference  Link : https://forums.developer.nvidia.com/t/issue-with-installing-nvidia-graphics-driver/164329Then I have booted the OS in EFI mode and I can able to install CUDA in all OS versions but not able to install NVIDIA driver in all the OS and CUDA versionsThe error’s which im getting is
In Ubuntu 18.04.6 desktop and server versions and lubuntu OS 18.04.5 desktop version  while installing the NVIDIA driver im getting error asIn Ubunut 16.04.7 desktop and server versions while installing the NVIDIA Driver im getting the following error

image2022-3-18_11-50-3705×375 36.6 KB

image2022-3-18_11-53-8706×153 12.2 KB
Log File
nvidia-installer.log (29.7 KB)Can someone help me to solve this issueAlso I have tried Ubuntu 18.04.5 desktop and server version in EFI Boot option, the VM is not booting up when using EFI option it shows failed to connectDid you disable nouveau driver? Please check how to disable it before running the NV installer. Instructions how to do this should be found easily.yes I disabled the nouveau driver after that only I installed cuda and NVIDIA driversPowered by Discourse, best viewed with JavaScript enabled"
685,nvidia-tesla-t4-pass-through-esxi-7-0-2-display-settings-are-not-available,"NVIDIA Tesla T4 pass through on ESXi 7.0.2 not working when opening nvidia control panel, displays the following message: display settings are not availableany help will be much appreciatedIs the GPU properly detected/installed in device manager? Which driver has been installed?Hi,thanks for your reply.Yes, it is detected/installed in device manager,Latest driver available for Windows Server 2019Data Center Driver for Windows | 511.65 | Windows Server 2016, Windows Server 2019, Windows Server 2022 | NVIDIA511.65 WHQLregards.Well, datacenter driver for T4 doesn’t have the full feature set for WDDM. If you need full graphics support with T4 then you will need the vGPU driver and a vGPU license. The public driver is meant for compute use cases.Powered by Discourse, best viewed with JavaScript enabled"
686,tesla-v100-hyper-v-2019-device-cannot-find-enough-resources-code12-mmio-config,"Hello,
I have a server HPE Proliant DL380 Gen10, 512GB RAM, with inside a Tesla V100-PCIE-32GB.
Windows Server 2019 is installed.
We have configured the Hyper-V role and installed a VM with 320GB RAM.What we have done on the host is :Unfortunately, each time the VM starts I have this error message in the device manager :
This device cannot find enough free resources that it can use. (Code 12)
If you want to use this device, you will need to disable one of the other devices on this system.I have tried to change the MMIO to
3GB / 33000MB
2GB / 4GB (found on a blog but for Grid cards)
176Mb / 560Mb -> because the MS script listed the card as :
NVIDIA Tesla V100-PCIE-32GB
Express Endpoint – more secure.
And its interrupts are message-based, assignment can work.
And it requires at least: 48 MB of MMIO gap space
PCIROOT(36)#PCI(0000)#PCI(0000)
So I added 48 to the 128Mb / 512Mb from the default configuration.When changing the MMIO config, do I need to remove the card from the VM, change the config and reconnect the card to the VM or can I just change the config without doing anything to the VM ?No MMIO configuration solve the problem.
Can someone please help me ?Thanks in advance for your help.MarcHi Marc,I think I have exactly the same issue.  I have a 32Gb Tesla V100 being passed through using DDA on Hyper-V Windows 2019 Server. When the guest VM is Windows 10 it seems to work fine but when it is any version of Linux the kernel throws a MIMO error followed by the hv_vmbus failed to probe the device error.Did you get any answers to your issue?ThanksRobA combination of installing the latest kernel (5.0.0-1028-azure or 5.3.0-26-generic) on Ubuntu 18.04.03 LTS shuting down the guest. Increasing the high MIMO to 33Gb with:Set-VM -HighMemoryMappedIoSpace 33GB -VMName vm-nameAnd then restarting, fixed the issue.Hope that helpsRobA combination of installing the latest kernel (5.0.0-1028-azure or 5.3.0-26-generic) on Ubuntu 18.04.03 LTS shuting down the guest. Increasing the high MIMO to 33Gb with:Set-VM -HighMemoryMappedIoSpace 33GB -VMName vm-nameAnd then restarting, fixed the issue.Hope that helpsRobThis helped me a lot and I can confirm this for a guest vm running Ubuntu 20.04. LTSHey,which driver did you use? The grid or the “normal” one?Thx,Powered by Discourse, best viewed with JavaScript enabled"
687,having-problem-obtaining-licensed-from-the-dls-vsphere-7-0-u2,"I been having trouble in obtaining the vGPU licensed when I clone the first Vgpu Enable VM I created, I tried to reinstall the driver, create new feature type, repaste the client token from both DLS , but still now working

image1915×1030 267 KB
Powered by Discourse, best viewed with JavaScript enabled"
688,home-lab-question,"Greetings,I’m studying for some certifications and own a yearly VMware User Group (VMUG) evaluation license for the full VMware suite, including Horizon, ESXi, vCenter Server, etc etc etc. I wish to learn about vGPU’s and wanted to reach out for some advice.My goal is to learn how to set up multiple VM’s utilizing a single GPU, much like how the hypervisor can share a single CPU among multiple VM’s. Sadly, this doesn’t seem to be able to be done with consumer grade cards, so I’m looking at purchasing an older and affordable Quadro card for my home lab so I can learn this exciting technology.My concern is that I’ve learned that we’re required to download a special .vib driver to import into ESXi, however from my initial research it appears that these drivers seem licensed behind some enterprise login portal. Is this accurate?I was considering purchasing a Quadro 6000 or even a Quadro M4000 card off eBay. If I purchased one of these second-hand, am I able to get an ESXi 6.x driver for evaluation (academic) purposes? Would someone in my situation be better suited purchasing a different card? My limit is around $250.I would greatly appreciate if anyone could point me in the right direction regarding this. I have a lot of consumer CUDA devices laying around, however I don’t think they can work in a vGPU environment because the .vib’s are designed explicitly for the professional grade cards.Thank you very much for reading my post! Have a wonderful day!You are right with the exception of the old K1/K2 cards. There is a public driver available and you might also get one of these boards pretty cheap. With Quadro you could only test Passthrough but not vGPU. So I would recommend to check the boards mentioned above although they still might beyond your budget.
For Quadro in Passthrough you won’t need a specific driver, so no need to have the vGPU Enterprise Account.RegardsSimonDo I understand correctly that the only cards with a working public driver for utilizing vGPU sharing (one physical GPU shared among multiple ESXi VMs) are the following?NVIDIA GRID K1 (lower end GPU, 16GB RAM, less expensive)
NVIDIA GRID K2 (higher end GPU, 8GB RAM, more expensive)So, a used NVIDIA GRID K1 card is probably the cheapest card that will utilize this technology?Thanks for your response!Correct. For newer boards the licensing is required and you need a portal access for downloading the drivers. For sure you can request a trial account.nvidia.com/gridevalregardsSimonIs there any updated info on this? That grid eval link is dead. Considering changes to the remote workforce over the past year seems like this would be valuable for Nvidia to make accessible for people to learn.Deliver Graphics Acceleration to Virtualization.Powered by Discourse, best viewed with JavaScript enabled"
689,rtx-a5000-gpu-passthrough-linux-displaymodeselector-problems,"Firstly, I want to use my A5000 for GPU passthrough purposes on a Linux host. I only need one virtual machine at a time. Do I need to put the A5000 into displayless mode in order to use it for a GPU passthrough with KVM?Secondly, I downloaded the displaymodeselctor tool. I disabled my display manager, uninstalled the nvidia drivers, blacklisted nouveau and rebooted. Then I ran the tool to list the modes of the A5000. Unfortunately, it displayed the following:GPU ID:
Graphics Device      (10DE,1EB1,103C,12A0) S:00,B:09,D:00,F:00
GPU Mode: N/A
GPU ID:
Graphics Device      (10DE,2231,10DE,147E) S:00,B:0A,D:00,F:00
GPU Mode: N/AThe first GPU is my display GPU, a Quadro  RTX 4000. The second GPU is my RTX A5000.I believe the Linux displaymodeselctor said it was version 1.48. I have no Idea what version the windows exe proclaims. I will note that the modified dates of the tools(displaymodeselctor and displaymodeselctor.exe) differ by more than a month and the A5000 is pretty new. Does the Linux version of displaymodeselctor know nothing of the A5000 or am I missing something?Of course, none of that matters to me, if I can do a GPU passthrough without changing the A5000 to displayless mode.On a slightly different topic, do I need a vGPU licence to do a GPU passthrough with my A5000? I think that it is unnecessary, but I have found no clear answer? I have inquired about this to the vendor who sold me the A5000, but I have yet to receive an answer. I think the salesman would gotten back to me back if he thought he could sell a licence;-)Powered by Discourse, best viewed with JavaScript enabled"
690,installing-gpu-aware-openmpi-with-ucx-gdrcopy,"Hello,Does anyone have experience with intalling gpu-aware mpi from spack. I am trying to figure out the installing command in spack, but so far while the gpu-aware openmpi works nice, it is still slow and I suspect that is not using the `gdrcopy´library.CristianPowered by Discourse, best viewed with JavaScript enabled"
691,is-nvidia-linux-driver-440-56-supported-on-ubuntu-1804,"Hey Guys,I’m running into issues with getting vGPU working on an Ubuntu 1804 VM. Now for some context, I’ve got the Windows 10 VM working as expected already so I’m familiar with setting-up the VM for it to it working with VMware Horizon.I’ve followed the official Nvidia set-up guide for that driver version (10.1) and got the driver installed albeit some warnings during the installation such as:So the driver got installed, rebooted, nvidia-smi reporting the card is detected, but I can’t run nvidia-settings to license the vGPU. Running that command on the CLI throws the following:Launching it with -V spits out an additional warning aside from the Error above:I have a feeling its not supported as reviewing the VMware Horizon 7 set-up guide for Linux does not include commands for Ubuntu.Anyone else experiencing the same issue?Kind regards,
FrancisBy default, Ubuntu will use the open-source video driver Nouveau for your NVIDIA graphics card. An alternative to Nouveau is the closed source NVIDIA drivers, which are developed by NVIDIA. This driver provides excellent 3D acceleration and video card support.I got the same issueHow could I resolve it?Powered by Discourse, best viewed with JavaScript enabled"
692,tesla-m10-vgpu-with-spice,"We have a RHEL 7 server and have added a Tesla M10 video card. The server is running a spice server and user are logging in and getting an X  session. We would like for each X session started up to get a vGPU with 512 Megs. Does anyone know how we would go about doing that? P.S. the are no virtual machines involved in this. All the X sessions are just running on the server.Hi lphartm,Thanks for the question.  vGPU will only work with Virtual Machines - i.e. you need a supported hypervisor and guest OSs.With multiple Xsessions I do not know of a way to limit GPU memory.Doug, thanks for the information, I was afraid that’s what the answer wold  be.How ever, this is what is in your docs:In a bare-metal deployment, you can use NVIDIA vGPU software graphics drivers with Quadro vDWS and GRID Virtual Applications licenses to deliver remote virtual desktops and applications. If you intend to use Tesla boards without a hypervisor for this purpose, use NVIDIA vGPU software graphics drivers, not other NVIDIA drivers.To use NVIDIA vGPU software drivers for a bare-metal deployment, complete these tasks:Quadro vDWS 	Users of mid-range and high-end workstations who require access to remote professional graphics applications with full performance on any device anywhereIn a bare-metal deployment, you can use NVIDIA vGPU software graphics drivers with Quadro vDWS and GRID Virtual Applications licenses to deliver remote virtual desktops and applications. If you intend to use Tesla boards without a hypervisor for this purpose, use NVIDIA vGPU software graphics drivers, not other NVIDIA drivers.To use NVIDIA vGPU software drivers for a bare-metal deployment, complete these tasks:If you have Tesla GPU by default it has limited graphics capability - i.e. a single remote display output.  You can use the the vGPU driver (and license) to enable graphics support on that GPU in bare metal.We have customers who do that for vApps etc or needing to run accelerated graphics on single GPU.  This is equivalent of having workstation with a GPU that has physical display outputs - so in theory you could enable 4 X sessions on the GPU.  You would not be able to assign vGPU profiles on the system.Ok, thank you.Powered by Discourse, best viewed with JavaScript enabled"
693,geforce-software-licence,"Hello,I hope this finds you well and healthy,I am reaching out to ask for a clarification concerning the license for customer use of the Nvidia GeForce Software (Link: GeForce License):"" No Sublicensing or Distribution. Customer may not sell, rent, sublicense, distribute or transfer the SOFTWARE; or use the SOFTWARE for public performance or broadcast, or provide commercial hosting services with the SOFTWARE.""If I understand correctly, the license forbids data centers and owners/consumers from renting their GeForce GPUs (e.g. RTX) ?We are building a cloud computing startup very similar to LeaderGPU (website), iRender (website), and many others, that provide computing infrastructures/servers for machine learning and deep learning purposes, based on Nvidia GeForce GPUs.According to the official websites of LeaderGPU, they are renting GeForce RTX series and a member of the Nvidia Inception Program.So I am really confused if Nvidia is allowing startups but not big tech cloud providers? and if as a startup or even a consumer, am I allowed to rent GeForce Software/Card for commercial use, like hosting services?Thank you for your time and I look forward to hearing from you.You are right. We don’t allow Geforce usage in DC (except Blockchain). If customers do so they violate against the EULA.Powered by Discourse, best viewed with JavaScript enabled"
694,hdmi-60fps-input,"Hi Sir,Platform: Jetson Xavier™ NXThe GUI hangs after a certain period of time, and the system becomes very unstable as long as a certain software that handles image input is used to keep the system at a high load.
If the system is restarted manually, the screen will be black after the nVidia logo is displayed and there is no action at all.
They later found that this phenomenon is related to power mode select, the default “MODE_10W_DESKTOP” will occur, manually changed to “MODE_15W_6CORE” will not have problems.
Have you heard of similar problems in the past?If you change to capture the camera image from the USB interface corresponding to the UVC, it is normal to use the same command to get
Streaming Parameteres Video Capture .Thank you for your support.Powered by Discourse, best viewed with JavaScript enabled"
695,nvidia-vgpu-manager-support-vsphere-7-0-u3,"Hello,is there official support for vSphere 7.0 U3?HowdyVMWare has a compatibility page, you can check there.See link.Powered by Discourse, best viewed with JavaScript enabled"
696,nvidia-smi-couldnt-communicate-with-the-nvidia-driver,"I tried almost all the posts in this forum. But still I can’t make it work.
I am using ESXi 7.0 Update2 with the latest NVIDIA GPU Manager(vib). The guest os on OS in Ubuntu 20.04.4. The GPU is Tesla M60. I have  tried nvidia-driver-510,470,460. But none seems to work. I tried with gcc-9 and gcc-7 also. The below is the current info. Bug report is attached at the end. I have wasted 3 days on this issue. Any help is much much appreciated.  Thanks!nvidia-bug-report.log.gz (581.3 KB)Can someone please help?Hi,
first of all, can you run nvidia-smi from the host? What are you trying to achieve? Passthrough or vGPU? Are you using a supported hardware for the M60? Which profile did you assign to the VM if using vGPU? Can you start the VM with the profile assigned?
The bug report is meant for NV enterprise support so please don’t expect that someone in the forum will analyze the bug report.Hi, thanks for the response @sschaber.
We are using NVIDIA grid. Yes the harware supports it.
image822×220 19.4 KB
I forgot to mention that it’ working fine with Windows VMs.Yes, on host nvidia-smi is working.
image712×565 56.6 KB
As you are using vGPU 13.0 on the host, you should use 470.63.01 driver for the Linux guest. How many system memory did you assign to the linux VM? Sometimes you need to add the MMIO parameters to the VM config. See LaunchPad | NVIDIA Docs as an example how to properly setup a Linux guestYes. I have tried with 510, 470.103 and 460 drivers. But installing 470.63 drivers on the guest did the trick. That means the host and guest must have the same driver versions.
Thank you so much @sschaberThis topic was automatically closed 14 days after the last reply. New replies are no longer allowed.Powered by Discourse, best viewed with JavaScript enabled"
697,vdi-machines-with-nvidia-tesla-t4-profile-are-stuck-when-using-horizon-client,"Hello everyone…
I’m in the middle of a POC with Horizon VDI.
We are using the New Tesla T4 GPU card.
When i connect to a machine with the VMware Agent I cannot actually work on the machine, it freeze after 1 minute. On the HTML version it’s not happening.
On the other hand - i noticed that when i’m using the client to connect to a machine without GPU profile, it’s working, so it seems something with the driver maybe.I’m running the latest VMware Horizon 7.8.0
vCenter and ESXi 6.7 U1
8GB RAM for each VM (The option of ""Reserve all memory - all locked"" is enabled by best practice)What it could be?
I’ll appreciate your help.Thanks.Which OS/version? Which vGPU version?The VM machines OS is Windows 10 1803.
Driver installed on the VM’s OS: 412.31_grid_win10_server2016_64bit_international
VIB installed on the ESXi: NVIDIA-VMware_ESXi_6.7_Host_Driver-410.107-1OEM.670.0.0.8169922.x86_64An update:
It’s happening while i’m using the Blast protocol only. when I’m using PCoIP protocol it works fine.
I will add the Horizon GPO ADMX to my DC and i’ll try to debug the blast.Hey @MaorZ,I’m having the same problem with Windows 10 2016 LTSC, Horizon 7.8, and the 412.31 vGPU driver (m10-1q profile)… Did you find a resolution?Thanks,
JustinHi Guys,We running a POC with a Tesla T4 card.
Running on vmware 6.7 Update 2 and using at the moment the latest windows 2016 and vsphere 6.7 driver from nvdia
(NVIDIA-GRID_vSphere-6.7-418.66-418.70-425.31)When i start an VM (windows 2016) and a gpu profile the esx host will crash on a daily base (PSOD), panic requested by another PCPU and many 0x45 nr nvidia showed up.When i start the VM without the GPU profile attached on the Vm it will keep running.A known issue for the VM thats start with an installed nvidia driver in the OS , is that the console session turn black.somebody else having those issues or does somebody have a solution?thanks@brammetje I’d recommend you start a new thread as what you are describing sounds unrelated to this thread.In regards to this thread… I’ve been working with Nvidia and VMware support for many weeks now on this issue. I could replicate the screen freeze on initial Blast Extreme connection and subsequent reconnects with the 7.1 (412.16) and 7.2 (412.31) versions of the vGPU driver and Horizon 7.8 Agent (on both Windows 10 2016 LTSC and 2019 LTSC).Nvidia has provided a workaround that appears to work.
Create the following registry setting on the master image:
[HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\services\nvlddmkm]
""NVFBCEnable""=dword:00000001Based on Nvidia’s very detailed response to me (which I appreciate), it sounds like without this registry setting, the vGPU driver on first Horizon session thinks it’s not installed properly and does a reload which causes the screen to freeze… At which time a reboot of Windows is required to finish the driver reload… But in the case of my non-persistent instant clones, the VM is deleted when the user logs out so every connection is a first session. In my case, once I created the above registry setting on my master image, I no longer experienced the screen freeze on initial connection or the black screen on subsequent reconnects.Hopefully this is helpful to someone else.
Thanks,
JustinI can confirm this is still and issue, but the registry entry vdiguywi suggested works in the following environment:Windows 10 1903 64-bit
Horizon Agent 7.9
NVIDIA driver version 431.02Worked for me, M10, Windows 10 1903, Horizon 9. Thanks for sharing @vdiguywiAnyone ever get to the bottom of why this occurs? We are experiencing this issue but only on our T4s/P4s and not on our M10s. Any configuration changes we need to make?Hi ZdawsonThis is quite an old thread, can you confirm which vGPU, Horizon and OS versions you’re running?vGPU 11.0 was released last week, if you’re not already running it, I’d suggest you upgrade to that as a start and see if it helps.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
698,gpu-passthrough-on-aws-g4dn-metal-with-windows-server-2019-hyperv,"Hi, I’m trying to set up GPU Passthrough on an AWS g4dn.metal instance running Windows Server 2019 with HyperV and guest OS is latest Ubuntu 20.04.
The GPU on those instances are Tesla T4.The guidelines I’m following are from here:
https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#using-gpu-pass-through-windows-server-hyper-vI can successfully disable and dismount one of the GPUs and assign them to the VM. I can verify the GPU is assigned properly via Get-VMAssignableDevice -VMName Ubuntu and everything seems to be working fine until it fails to start the VM and I’m getting the following error message:Virtual Pci Express Port (Instance ID 02583E40-07CB-4C02-9CF4-B4D3A55868F9): Failed to Power on with Error 'The hypervisor could not perform the operation because the object or value was either already in use or being used for a purpose that would not permit completing the operation.'.Could someone explain if this is a problem with AWS BIOS settings or whether I’m doing a something wrong during the setup? I can provide further information / steps if necessary.P.S.: I also ran a script from Microsoft so check whether the T4 is available for DDA from here which gave good results for all 8 T4.Powered by Discourse, best viewed with JavaScript enabled"
699,how-to-buy-nvidia-virtual-gpu-solutions-subscription-perpetual-license-in-russia,"Hello!My name is Nikita Pavlov.We are a startup GameKocmoc from Russia.Tell me where in Russia I can buy a subscription “perpetual license” virtual workstation $450 perpetual license $100 sums per year???I don t understand how to buy this subscription in Russia?
Or should I buy from nvidia?Hello Nikita.
You can reach OCS(https://www.ocs.ru) distributor to get licenses. They responsible for license sell in Russia.Powered by Discourse, best viewed with JavaScript enabled"
700,question-on-vgpu-on-rtx,"I was wondering if the Quadro RTX 4000 and 5000 support vGPU functions?HiShort answer = NoOnly the RTX 6000 and 8000 support vGPU. You can use the 4000 and 5000 for Passthrough if you like though …RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
701,startup-problems-in-a-system,"I have some startup problem what can I do please help me to get laptop repair https://uaetechnician.ae/laptop-repair-servicesPowered by Discourse, best viewed with JavaScript enabled"
702,required-nvidia-quadro-series-in-place-of-nvidia-tesla-graphic-card,"I have create a instance from AWS marketplace and selected ""NVIDIA Quadro Virtual Workstation - WinServer 2019"". When i setup all the things and checked, it shows me Tesla in place of Quadro. I am purchasing it to run my software which is work on Quadro but not on Tesla. How can i get Quadro in place of TeslaI’m getting similar results with the WinServer 2016 edition. AMI seems to be installed with the Standard (DirectX) drivers, unless I’m looking in the wrong place. Any tips?https://i.paste.pics/bec3055e8a00fa5c99971fe5ba9d8666.pngHi Deepak, Wenzil,There is currently no way to get an actual NVIDIA Quadro GPU in AWS, only NVIDIA Tesla GPU’s, or a fraction of them (vGPU). In this specific case, that will be a NVIDIA Tesla T4.
The naming ""NVIDIA Quadro Datacenter Virtual Workstation"", or ""NVIDIA Quadro vDWS"" in short, only refers to the technology that NVIDIA uses to offer this ""virtual workstation"", not to the actual NVIDIA Quadro GPUs.
Also see: Virtual Workstations for Professional Graphics & IT | NVIDIA to learn more about the technology.Which software are you looking to run? In most cases, NVIDIA Tesla cards will actually be on the list of supported GPUs (HCL) for the software.Best,KoenraadPowered by Discourse, best viewed with JavaScript enabled"
703,vdws-license-restful-api-cannot-response-with-full-result,"I’m developing a web app that needs to display all the clients of the vDWS License server. According to the post https://gridforums.nvidia.com/default/topic/8985/xendesktop/xendesktop-failed-to-acquire-license/, I’m using the Restful API: http://licenseserver:7070/api/1.0/instances/~/clients, but the number of the clients is always less than 20 even if the license server has distributed 50 or more vDWS licenses.Could anyone here tell me how to get the full result of the clients? Thanks.Problem solved.URL should be:Powered by Discourse, best viewed with JavaScript enabled"
704,g4dn-xlarge-with-nvidia-rtx-virtual-workstation-vws,"We would like to use NVIDIA RTX Virtual Workstation with G4dn.xlarge as a node in EKS cluster.
Planning to create T4-4C x 4 vGPUs and utilize them to deploy 4 pods integrating with vGPU.Looking forward to some documents on NVIDIA RTX Virtual Workstation with EKS.Powered by Discourse, best viewed with JavaScript enabled"
705,information-about-licencing-for-quadro-rtx4000-and-rds-on-physical-dl360-gen10,"Hi, I am aware that for use a tesla T4 video card on my rdsh windows server 2016, i need to deploy a licence server a add a nvidia grid driver on that server (licence type vpc ou vws I believe).  These licence will me allow to get the wddm driver for windows and use this card for users on the rds server.
If I change the tesla by a quadro rtx4000, is that card would be wddm native ready or do I need a licence to make it works in the rds server  like the tesla?Any help would be  veryhelpful (I begin in this world of GPU for rds and It’s not very clear for me.IHi,You would need vApps licensing to be precise in case of RDSH and T4 GPU.
RTX4000 doesn’t require additional licensing as you can use the RTX driver which supports WDDM out of the box but you won’t get enterprise support.Best regards
SimonPowered by Discourse, best viewed with JavaScript enabled"
706,need-a-nvidia-vmware-esxi-7-0-host-driver-440-107-1oem-700-0-0-15525992-driver,"I am having A30 GPU and want to use in ESXi 7.0,  how can I get this driver to proceed.NVIDIA-VMware_ESXi_7.0_Host_Driver 440.107-1OEM.700.0.0.15525992 driverReference:Get the latest information on NVIDIA virtual GPU drivers.Howdy,
You have two options:Either way, you will need to have an account to get the drivers. See the help.Powered by Discourse, best viewed with JavaScript enabled"
707,can-i-use-2-tesla-v100-gpus-on-each-on-a-different-monitor-in-a-single-remote-session,"We are using Azure NC12s_v3 VMs that have 2 Tesla V100 GPUs.We would like to connect to such a VM and have 2 monitors - each dedicated to a different GPU. Is this possible?The reason for that is that we would like to have two instances of TouchDesigner, each working on a different GPU. TouchDesigner GPU affinity is driven by display - so if your display 1 is assigned to GPU 1, this is where the processing will take place.HiUnless the application can run multiple instances that allow you to specify which resources each one uses, what you’re asking for won’t work.Why not simply use 2 Azure VMs with 1 V100 on each and connect a session to each VM?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
708,installation-of-nvidia-driver-on-other-azure-vms-type,"Is it possible to install Nvidia driver on other types of Azure VMs apart from the N-series?? If so please someone should provide instructions to do so.I tried following instructions on different Microsoft link on how to install it but none worked. I downloaded different Nvidia drivers from Microsoft link.My Azure VM is 16GB RAM, Windows 10 and also the basic Azure VMs type.I’m trying to install the Nvidia driver on the Azure VM for a AI python project that requires itPowered by Discourse, best viewed with JavaScript enabled"
709,dell-730-with-m60-nvidia-smi-throwing-power-error,"Hello,3 brand new dell r730 with an m60 in each (factory shipped) each of them throwing the same error with nvidia-smi:Unable to determine the device handle for GPU 0000:05:00.0: Unable to communicate with GPU because it is insufficiently powered.
This may be because not all required external power cables are attached, or the attached cables are not seated properly.running latest esxi 3825889, applied Dell recommended BIOS settings as per http://www.nvidia.com/content/grid/pdf/grid-vgpu-deployment-guide.pdfinstalled latest grid driver: 361.45.09-1OEM.600.0.0.2494585 from licensing portalran gpumodeswitch on all hosts to switch all gpu’s to graphics mode and confirmed with lspci -n | grep 10de:
0000:05:00.0 Class 0300: 10de:13f2 [vmgfx0]
0000:06:00.0 Class 0300: 10de:13f2 [vmgfx1]A VM with vGPU starts on one host but not on another > Failed to start the virtual machine.
Module DevicePowerOn power on failed.
Could not initialize plugin ‘/usr/lib64/vmware/plugin/libnvidia-vgx.so’ for vGPU ‘grid_m60-0b’.
No graphics device is available for vGPU ‘grid_m60-0b’.maybe it’s just a wiring issue, I will have to check that tomorrow when going on siteThanksCheck they’re cabled correctly.The M60’s should have a 300W power connector, and not a standard 8 pin PCIe cable. I’m not sure if Dell has a specific cable, or whether they use the adapter cable that takes the feed from 2x PCIe cables to deliver 300W.That or underpowered PSU’s are the likely cause.Jason is right the Dell R720 and R730 require a GPU enablement kit including power cables https://qrl.dell.com/Files/en-us/Html/Manuals/R730/GPU%20Card%20Installation%20Guidelines=GUID-C3605F65-C4AE-4BEB-9A32-907A90753B81=1=en-us=.htmlI seem to recall it was something called a ""8pin to 8pin+6pin"" but this is one you need to go back to Dell on and check you have the right power supply and cables as per the GPU enablement kit.Hi Jason and Rachel,Thanks for your replies,It was a wiring issue, after connecting them as you instructed we don’t see the nvidia-smi issues anymore and we are now able to use vGPU on all hosts.They came from dell direct, so strange how one host was wired correctly and others not.Thanks,J. WirthHi @Technicalmt have you got any feedback on the specifics or a reference SR with Dell. I think I have one with a similar issue at the moment and am going back and forth with Dell support trying to resolve. Can you please provide and explanation or a photo of how the GPUs are cabled on a working config?Hi Everybody,I have the same issue with brand new DELL R730 server and vSphere 6.0 U2.
Each Server has 2x Nvidia M60 factory installed. But only one of the server is able to see and use both gpu boards. The others show the message ""Unable to communicate with GPU because it is insufficiently powered."".
I checked the BIOS and software components. I couldn’t find any difference. Please help. It’s for me actually not possible to check the cables inside the servers.Regards,
VM_masterBoth power supplies need to be working together (not redundant) wish I knew this before buying my r730xd. I’m running a K80 on esx6.7 2012vm. I would get purple screen of death about 30 min after starting the VM and my vendor explained this power caveat.Thanks for the sharing scp 096Powered by Discourse, best viewed with JavaScript enabled"
710,login-loop-after-installing-nvidia-driver-440-ubuntu-16-04-kernel-5-3,"I’m trying to install the NVIDIA drivers for a RTX2060 running ubuntu 16.04 (I need this ubuntu version for other programs). I downloaded the driver from NVIDIA (run file) and after the installation (with --no-x-check) I get a login loop in X session. I tried some solutions found in the forum by none of them solved the problem. I also see that it is recommended to run nvidia-bug-report.sh and attach the resulting .gz file. nvidia-bug-report.log.gz (198.7 KB)Any suggestions??Powered by Discourse, best viewed with JavaScript enabled"
711,mouse-performance-in-citrix-blast-virtual-desktops-running-vgpu,"Hi,This isn’t a specific question about GRID performance but thought it may have cropped up given the use of 4K panels and Q profiles running GRID.  We use predominantly P6-XX profiles, but the mouse behaviour remains consistently slow at higher res.  I’ve also posted a similar question elsewhere (VMware forum, Citrix, etc.)I’ve been working with Horizon virtualisation for a while now and over the past few months more and more clients we work with are looking into 4K panels.  I notice that using mid-range resolutions such as 1920x1200 and even 2560x1600 we see a fairly performant desktop, certainly with regard to mouse responsiveness.  However, upping resolution to 4K, the mouse performance degrades.  The responsiveness is the problem, where you feel you are dragging the mouse/window rather than pushing it.  I can’t measure the lag, but the instant response is not there.  This occurs irrespective of protocol (HDX, PCoIP, Blast) and is linked to higher resolutions.  We see this with vGPU accelerated and standard desktops - there is no load on the CPU host-side, and the network bandwidth is practically idle - it just appears to be a general lag.  Endpoints are a mix of Intel NUC, PCoIP Tera 2 zero clients, Windows 10 laptops, HP/Zotac/Dell thin clients.It makes sense that there is more pixels to cross for the same mouse/hand movement with 4K compared to UHD, but I having looked at the mouse options, such as increasing the speed of the cursor, this doesn’t translate when moving window, etc.I’ve also tried this on a 30Hz and 60Hz panel with the same results.  Does anyone else feel this or have any options that could improve the feel?ThanksHello,Have you tried with VMware Tools 10.3.10 ? In the resolve issues, there’s something related to mouseHave you tried setting max FPS to 60?Powered by Discourse, best viewed with JavaScript enabled"
712,virtualisation-for-cloud-game,"Hello,
I’m new to the forum, so I think I’m in the right place.
I’m researching the possibilities of cloud gaming and its costs for my thesis and also researching possible infrastructure solutions. Basically my topic is to use cloud technology to play one specific game and this game can only be played through cloud gaming. I’m also interested to know why no one is doing it yet.
I chose the Oracle infrastructure and its instance based on NVIDIA A10 Tensor Core. And then I faced the issue of virtualization.  As far as I understood, this is the process of splitting GPUs into virtual GPUs. But I did not find any information about the maximum number of virtual GPUs. In Oracle, the NVIDIA A10 Tensor Core has 24 GB of GPU Memory. Does this mean that I can create 24 vGPUs on one instance and thus have 24 clients for the game? I feel like I’m making a mistake somewhere. Is there something I should know? Maybe you have some thoughts on my topic.RegardsSerhiiHi,the topic is pretty complicated. You cannot simply choose a cloud instance with GPU and use vGPU. In general, you are right with the idea that you could share a A10 GPU with 24GB of FB into 24 vGPU instances with 1GB but this needs to be done with the right software stack and licenses and you would need access to the hypervisor to do so.regards
SimonI can’t just choose a cloud instance with GPU and use vGPU because there are licenses that restrict how I can use this vGPU? What specific licenses and software do I need to have for this?Powered by Discourse, best viewed with JavaScript enabled"
713,any-info-about-vgpu-vnc-server,"Is there anywhere some documentation about VNC, which ""disable_vnc=1"" is about? is it enabled by default? How to use it? Can not find anything about it. Thank you in advance!Powered by Discourse, best viewed with JavaScript enabled"
714,nvidia-tesla-k10-card-port,"Hello,I have a tesla k10 card, and it has a 4 pin connector on top. Tried to find in the documentation what it is, what it is for. (for connecting multiple cards together?)thanks,RonPowered by Discourse, best viewed with JavaScript enabled"
715,windows-2019-based-xenapp-vda-in-maximized-mode-freezes-upon-or-shortly-after-login-if-an-nvidia-grid-vgpu-is-present,"Guys,I thought I’d throw this into the group. After months of suffering from an occasional bug where people’s Citrix sessions seem to freeze I have been able to deduce the cause down to something related to the gpu acceleration. If I for instance edit one of the Vmware VDA machines and remove the gpu this problem does not happen at all anymore on that server. It also only happens when the user uses his Citrix Xenapp session in “Maximized” mode. The combination of these 2 factors seem to trigger it.Also interesting to note is that whenever the screen at the end user laptop or pc seems to freeze (like a glass screen you see a frozen picture of the current/latest screenrefresh) there is in reality no problem on the backend VDA server. The session never froze there or showed any hickup or error. As such a simple confirmed workaround is disconnect+reconnect to the session.So in summary this mystery feels like the Citrix is trying to switch codec or something similar in order to activate gpu acceleration and freezed at that point.ps: of course I have opened a Citrix case as well but I thought I would work both fronts as people here might have this problem too or recognise it.Hi,Can you give some more details about the versions you are using?Citrix VDA,
Hypervisor,
Grid software.Can you also look at your Citrix policies that you enable GPU and also within your Windows RDS policy that you enable GPU. Please look at this:
GPU acceleration for Windows multi-session OSRegards,SjoerdHi Sjoerd,I noticed I wrongfully noted 2016 as OS. We are using Windows Server 2019 in fact.
The problem behaviour was succesfully reproduced on VDA’s 1912, 1912 CU2 and 2012.
Hypervisor= VMware ESXi, 7.0.0, 15843807 running on HP ProLiant DL380 Gen10 with Nvidia T4 Adapters
Grid ESXi software = NVIDIA-SMI 450.89       Driver Version: 450.89       CUDA Version: N/A
Client side software driver= version 452.57 (inside the Windows server 2019 VDA server build)I’m checking your article in the meantimeHiI have a similar issue, except it does not only happen in fullscreen.If a user is running a windowed desktop session it freezes after a few minutes.Discconecting the session and reconnect to it and everything is working again (for a few minutes)Any news on that issue?Hi DiC,
which Citrix VDA are you using? Sounds like a Citrix issue or are you running at a resource limit (CPU load or FB exhaust)?regards
SimonHiWe are using 1912 LTSR CU2And i don‘t think it is a resource issue.It happens when only one session is connected to the server, just logged in to the desktop and doing nothing (CPU and GPU load is at 0-2%)I have further investigated this issue and it’s getting weird:The session isn’t realy freezing, it is just extremly (!) slow.
The clock in the taskbar of the session is running, but for 1 minute to run it takes about 10 to 20 minutes in realtime.
If i right-click the taskbar it takes minutes (!) to open the menu.Disconnect and reconnect to the same session helps, but just for a few minutes and the problem reappears…Dic,sorry but it sounds like your issue is nothing like the one I’m experiencing. You see in my issue nothing freezes on the server side nor becomes slow. In fact everything works fine on the server side whenever the end user experiences the “glass screen” effect so whatever it is is confined to the front end GUI experience so that sounds like a Citrix workspace app issue although it’s clearly dependent on the presence of a Nvidia vGPU adapter in the server side VDA.I get it upon new logons but also reconnects to existing sessions but the issue only happens for sessions in maximized mode, never in fullscreen mode.I was able to capture the and trace the issue both on client and server side. Citrix support is processing the trace logs right now as part of the case I have open.Powered by Discourse, best viewed with JavaScript enabled"
716,ubuntu-20-04-2-lts-nvidia-smi-has-failed-because-it-couldnt-communicate-with-the-nvidia-driver,"I’m getting : NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver this message whenever im running nvidia-smi.
I have have Ubuntu 20.04.2 LTS with gtx 1650.
Graphics driver -470Powered by Discourse, best viewed with JavaScript enabled"
717,vgpu-profile-doesnt-show-up-in-the-vcenter,"Hello,and namely I have the problem that in my vCenter (7.0.3) when adding the vgpu in my vm the dropdown menu is missing at “PCI-Devices”.I have a Tesla M10 installed and the settings in ESX look like this:Graphics → Active Type & Configured Type are both on Shared Direct.Host Graphics → Shared Direct & Spread VMspci passthrough disabledDirectpath shows me the card, but under vgpu I don’t have the option to select anything, I can only write in the field.anyone an idea?Update for the esx nvidia drivers (15.01) are installedPowered by Discourse, best viewed with JavaScript enabled"
718,a30-ai-driver-nvidia-aie-esxi-7-0-2-driver-required-vib-required-for-vmware,"Hi I am looking for vmware vib package for A30 AI driver NVIDIA-AIE_ESXi_7.0.2_Driver .
The account i have in https://nvid.nvidia.com/ doesnt have any AI related packages.
How can I get these driver?ThanksPowered by Discourse, best viewed with JavaScript enabled"
719,youtube,"Just set up my CVAD test environment with attached vGPU (T4). I see that the GPU is showing up and working, but youtube videos are still using only CPU and not the GPU. Any guesses on why? Not currently trying to do any offloading to the endpoint.Powered by Discourse, best viewed with JavaScript enabled"
720,esxi-6-5su3-nvidia-p4-no-pci-shared-device,"Problem:In ESXi (No vCenter) when I create a Linux VM (Ubuntu 18.04), I can’t see the PCI Shared device nor vGPU profiles.
I’m accessing from Web client, not sure what I’m missing?Server modelDell Inc.
Model PowerEdge R640
CPU	28 CPUs x Intel(R) Xeon(R) Gold 5120 CPU @ 2.20GHz
NVIDIA P4HypervisorESXi server No VCenter
ESXi 6.5.0 Update 3 (Build 13932383)I installed: NVIDIA-VMware_ESXi_6.5_Host_Driver-430.67-1OEM.650.0.0.4598673.x86_64.vib
I can see the driver via nvidia-smiI’m using this guide: 430.67-430.63-432.08-grid-software-quick-start-guide.pdfPowered by Discourse, best viewed with JavaScript enabled"
721,not-all-supported-vgpu-types-are-creatable-in-multi-gpu-hypervisor,"Dear Forum,I have two new Dell PowerEdge R740 Servers with 2 V100 PCIe 32GB cards installed and I am running RedHat Enterprise Linux 7.7 with the NVIDIA-vGPU-rhel-7.7-440.53 rpm package installed. This is running RedHat Openstack 13 (Queens) with the latest Zstream patches.[root@srv-p23-30 ~]# nvidia-smi
Wed Feb 12 14:31:27 2020
±----------------------------------------------------------------------------+
| NVIDIA-SMI 440.53       Driver Version: 440.53       CUDA Version: N/A      |
|-------------------------------±---------------------±---------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE…  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   27C    P0    24W / 250W |     51MiB / 32767MiB |      0%      Default |
±------------------------------±---------------------±---------------------+
|   1  Tesla V100-PCIE…  On   | 00000000:D8:00.0 Off |                    0 |
| N/A   26C    P0    24W / 250W |     39MiB / 32767MiB |      0%      Default |
±------------------------------±---------------------±---------------------+±----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
±----------------------------------------------------------------------------+Without any guest VMs running, If I query the GPU cards for CGPU supported types I get full list as expected:[root@srv-p23-30 ~]# nvidia-smi vgpu -s
GPU 00000000:3B:00.0
GRID V100D-1Q
GRID V100D-2Q
GRID V100D-4Q
GRID V100D-8Q
GRID V100D-16Q
GRID V100D-32Q
GRID V100D-1A
GRID V100D-2A
GRID V100D-4A
GRID V100D-8A
GRID V100D-16A
GRID V100D-32A
GRID V100D-1B
GRID V100D-1B4
GRID V100D-2B
GRID V100D-2B4
GRID V100D-4C
GRID V100D-8C
GRID V100D-16C
GRID V100D-32CGPU 00000000:D8:00.0
GRID V100D-1Q
GRID V100D-2Q
GRID V100D-4Q
GRID V100D-8Q
GRID V100D-16Q
GRID V100D-32Q
GRID V100D-1A
GRID V100D-2A
GRID V100D-4A
GRID V100D-8A
GRID V100D-16A
GRID V100D-32A
GRID V100D-1B
GRID V100D-1B4
GRID V100D-2B
GRID V100D-2B4
GRID V100D-4C
GRID V100D-8C
GRID V100D-16C
GRID V100D-32CHowever when I check for the capabilities, the first GPU lists only one type but the second GPU is what I expect to see:[root@srv-p23-30 ~]# nvidia-smi vgpu -c
GPU 00000000:3B:00.0
GRID V100D-2QGPU 00000000:D8:00.0
GRID V100D-1Q
GRID V100D-2Q
GRID V100D-4Q
GRID V100D-8Q
GRID V100D-16Q
GRID V100D-32Q
GRID V100D-1A
GRID V100D-2A
GRID V100D-4A
GRID V100D-8A
GRID V100D-16A
GRID V100D-32A
GRID V100D-1B
GRID V100D-1B4
GRID V100D-2B
GRID V100D-2B4
GRID V100D-4C
GRID V100D-8C
GRID V100D-16C
GRID V100D-32CSo what is happening is that no matter what GPU type I try to create my VM with it ends up just being GRID V100D-2Q within the VM.Is there something I am missing here? I apologize if this was already asked. I looked through a bunch of forum articles already and did not see anything.Thank You,SalvatorePowered by Discourse, best viewed with JavaScript enabled"
722,tesla-t4-by-wddm-without-a-virtual-machine,"Hello,
I have a question about Windows Server 2019 with Tesla T4. The PC contains Tesla T4 and Matrox G200e (on-board VGA) only.
I would like to use Tesla T4 ( with GRID driver and license ) by WDDM mode on Windows Server 2019 under NO VIRTUAL MACHINE environment such as VMware. I connect Windows Server 2019 via Microsoft Remote Desktop.
Is that possible? Must I prepare a VIRTUAL MACHINE environment?
Would you advise me?Regards
IchiroFor sure you can use a baremetal environment wirh Server OS and T4. And yes, you will need the vGPU driver for this setup to support WDDM on Windows and vApss licensing.Regards SimonThank you for reply, dear Simon,
In my understanding, a virtual machine includes “Hypervisor”. So, I also do NOT need “Hypervisor” under ""baremetal environment. Right?
Thanks,
IchiroCorrect. Baremetal=NO HypervisorPowered by Discourse, best viewed with JavaScript enabled"
723,p100-fan-shroud-screws,"Hi folks
What is the screw thread of the holes on the back of the P100, please? (I am about to fix a fan shroud and don’t want to strip the holes guessing what screw to use.)
Thanks!
RoddyPowered by Discourse, best viewed with JavaScript enabled"
724,cooler-speed-rtx-6000-on-esx-6-7,"Hello! How to manually increase the number of turns of the cooler on the RTX 6000. The card is installed in the server with ESXi 6.7 software. The nvidia-settings command is not defined.Powered by Discourse, best viewed with JavaScript enabled"
725,vcs-virtual-compute-server-guide-and-or-help-needed,"Hey,maybe I’m blind and I’m for sure new to this at all, but is there a documentation how to setup a virtual compute server? Is it even possible with the trial access?I thought, signing up for the 90 days trial will give me access to all the software and drivers I need which will also provide a needed documentation to setup up everything.
First problem (maybe just for my understanding) there is no explicit option for ""compute server"", just nutanix, redhat kvm, linux kvm, vsphere and citrix, which are virtualization products.
So does the vCS only work with virtualization? Then my question would be, what’s the difference between grid and vCS. I know, i can also have a graphic output for grid but I am not limited to it and can compute also.
I thought, I maybe can use a vGPU for docker or cuda applications like tensorflow-gpu, etc.?
I already installed the license server and uploaded a license file for Quadro-Virtual-DWS, which includes vCS, as far as i know.By the way, what is the difference between Linux KVM and RedHat KVM?
In the official documents is the only supported KVM method RedHat KVM.
But there are two different download products.I also just give it a ""try and error"" run and installed the linux-kvm stuff on centos and gentoo.
(I don’t have a RedHat installed and didn’t plan to use it. (again))
Both of them give me this error ""error: failed to send vGPU configuration info to RM: 6""
What is RM? RedHat Manager? Does it only work with RedHat?
Or is there a way to fix this?Maybe someone can shed light on my problems?Background:
I’m working on a project to make our lecture (university) python/tensorflow, etc. online usable.
At the moment we have some RTX 8000, RTX 6000 and some more are included in our ordering pipeline.
So I already have some cards to test with and it’s more or less a ground base for upcoming purchase decisions.Big thanks in advance and Greetings
MatthiasPS:
On my wishlist would be a generic (linux) vgpu driver, which provides the host with vgpu devices which can be used by any application as long as the driver can get an active license from the license server. Don’t know if it is applicable with the linux kernel. But I guess technically it is.Powered by Discourse, best viewed with JavaScript enabled"
726,cannot-watch-netflix-hulu-videos-in-vgpu-vm,"Hello,Whenever I try to play video from the Netflix or Hulu applications on Windows 10, it freezes the VM; navigating the applications (without pressing the play button) works OK.I have tried accessing the VM through both the VMware Horizon Client (on a Mac) and through two zero clients–one made by ViewSonic and another made by ClearCube.I’m using the VIB/Windows drivers from the NVIDIA-GRID-vSphere-6.7-440.53-440.56-442.0 release with a Tesla T4 using the NVIDIA GRID vGPU grid_t4-8q profile.In case anyone was wondering, switching to the VMware Blast protocol (vs PCoIP) seems to have remedied this issue.HiThe version of PCoIP that VMware have in Horizon should not be used today. It’s a legacy version which hasn’t been developed / updated in years and bares no resemblance to the current Teradici PCoIP protocol, which is extremely good.RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
727,pgi,"Run the same program with gpi. The gpu occupancy rate was 35% before, but now it is 19%. The calculation speed is much slower. What is the problem?Powered by Discourse, best viewed with JavaScript enabled"
728,tesla-t4-and-citrix-performance,"We have 2 x R740 (total output: 76 x 3.09 Ghz / 1,346 GB) each with 1 NVIDIA Tesla T4 (vGPU grid_t4-1a) and VMWare 7.03 with 16 Citrix servers (Citrix 7 1912 CU3) 140 users run on IGEL M350C thin clients.We are now planning to convert 70 users to 2 x 24 inch monitors. The graphics card is mainly used for Chrome and Zoom applications. Do you think the graphics card would do it or do we get into trouble?Hi,The sizing mentioned above is far away from our best practice and won’t work. You need at least 8GB of FB (T4-8A) for 20-30 CCUs. So you would need a few more T4s to serve the given user load. 1GB of FB is already allocated with the initial user on the Server OS and you should never exhaust FB on a RDSH VM!!!regards
SimonI am looking for consultant to assist us with installation of virtual windows servers with access to NVDIA GPU through virtualization.  Can somebody recommend me person who would be interested in such project?
vdanishevsky@nupsys.comPlease use the partner locator to find a certified partner in your region
https://www.nvidia.com/en-us/about-nvidia/partners/partner-locator/Powered by Discourse, best viewed with JavaScript enabled"
729,rdsh-2019-multiuser-esxi-6-7-u3-tesla-p4-vgpu-acceleration-not-working,"Hi,
I am contacting you because I have a configuration problem on my Windows RDSH server (multi users) 2019.
Here is my configuration :Hypervisor is a vsphere 6.7 u3, gpu manager is in version 440.53, I use the vGPU mode with a GRID P4 card and the profile is grid_p4-4a. I installed the graphics drivers in VM version 431.02.
I also selected the GRID P4 primary display in console mode.
When I connect a user on the server it has GPU acceleration, when another user connects it does not have GPU acceleration.
Is it possible to use vGPU acceleration in an RDSH (multi user) windows server 2019 environment?
What is wrong with my configuration ?regards,Hi VivienYou’ll find it a lot better to be running the 8A vGPU Profile for RDSH to allocate the full amount of Framebuffer to the VM.Have you enabled the following GPO setting for your RDSH VM:Computer Configuration\Administrative Templates\Windows Components\Remote Desktop Services\Remote Desktop Session Host\Remote Session Environment: Use the hardware default graphics adapters for all Remote Desktop Services sessionsAlso, what you you using to connect to the RDSH VM? RDP? Blast? HDX? PCoIP?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
730,can-someone-please-guide-me-in-resolving-the-issue-trtexec-onnx-model-onnx,"[06/30/2022-11:23:42] [E] Error[4]: [graphShapeAnalyzer.cpp::processCheck::581] Error Code 4: Internal Error (StatefulPartitionedCall/sequential/lstm/PartitionedCall/while_loop:7: tensor volume exceeds (2^31)-1, dimensions are [2147483647,1,16])
[06/30/2022-11:23:42] [E] Error[2]: [builder.cpp::buildSerializedNetwork::609] Error Code 2: Internal Error (Assertion enginePtr != nullptr failed. )
[06/30/2022-11:23:42] [E] Engine could not be created from network
[06/30/2022-11:23:42] [E] Building engine failed
[06/30/2022-11:23:42] [E] Failed to create engine from model.
[06/30/2022-11:23:42] [E] Engine set up failed
&&&& FAILED TensorRT.trtexec [TensorRT v8200] # ./trtexec --onnx=model.onnx
Segmentation fault (core dumped)I am working on a scream detection model and I converted a pb file to onnx using this code “”“python -m tf2onnx.convert --saved-model /home/hipe/Documents/code/training/model --output model.onnx “””
and when I try to create an engine for TensorRT with the onnx I am facing issues.
Below is my log when I run ./trtexec --onnx=model.onnx
&&&& RUNNING TensorRT.trtexec [TensorRT v8200] # ./trtexec --onnx=model.onnx
[06/30/2022-11:23:41] [I] === Model Options ===
[06/30/2022-11:23:41] [I] Format: ONNX
[06/30/2022-11:23:41] [I] Model: model.onnx
[06/30/2022-11:23:41] [I] Output:
[06/30/2022-11:23:41] [I] === Build Options ===
[06/30/2022-11:23:41] [I] Max batch: explicit batch
[06/30/2022-11:23:41] [I] Workspace: 16 MiB
[06/30/2022-11:23:41] [I] minTiming: 1
[06/30/2022-11:23:41] [I] avgTiming: 8
[06/30/2022-11:23:41] [I] Precision: FP32
[06/30/2022-11:23:41] [I] Calibration:
[06/30/2022-11:23:41] [I] Refit: Disabled
[06/30/2022-11:23:41] [I] Sparsity: Disabled
[06/30/2022-11:23:41] [I] Safe mode: Disabled
[06/30/2022-11:23:41] [I] Strict mode: Disabled
[06/30/2022-11:23:41] [I] Restricted mode: Disabled
[06/30/2022-11:23:41] [I] Save engine:
[06/30/2022-11:23:41] [I] Load engine:
[06/30/2022-11:23:41] [I] Profiling verbosity: 0
[06/30/2022-11:23:41] [I] Tactic sources: Using default tactic sources
[06/30/2022-11:23:41] [I] timingCacheMode: local
[06/30/2022-11:23:41] [I] timingCacheFile:
[06/30/2022-11:23:41] [I] Input(s)s format: fp32:CHW
[06/30/2022-11:23:41] [I] Output(s)s format: fp32:CHW
[06/30/2022-11:23:41] [I] Input build shapes: model
[06/30/2022-11:23:41] [I] Input calibration shapes: model
[06/30/2022-11:23:41] [I] === System Options ===
[06/30/2022-11:23:41] [I] Device: 0
[06/30/2022-11:23:41] [I] DLACore:
[06/30/2022-11:23:41] [I] Plugins:
[06/30/2022-11:23:41] [I] === Inference Options ===
[06/30/2022-11:23:41] [I] Batch: Explicit
[06/30/2022-11:23:41] [I] Input inference shapes: model
[06/30/2022-11:23:41] [I] Iterations: 10
[06/30/2022-11:23:41] [I] Duration: 3s (+ 200ms warm up)
[06/30/2022-11:23:41] [I] Sleep time: 0ms
[06/30/2022-11:23:41] [I] Streams: 1
[06/30/2022-11:23:41] [I] ExposeDMA: Disabled
[06/30/2022-11:23:41] [I] Data transfers: Enabled
[06/30/2022-11:23:41] [I] Spin-wait: Disabled
[06/30/2022-11:23:41] [I] Multithreading: Disabled
[06/30/2022-11:23:41] [I] CUDA Graph: Disabled
[06/30/2022-11:23:41] [I] Separate profiling: Disabled
[06/30/2022-11:23:41] [I] Time Deserialize: Disabled
[06/30/2022-11:23:41] [I] Time Refit: Disabled
[06/30/2022-11:23:41] [I] Skip inference: Disabled
[06/30/2022-11:23:41] [I] Inputs:
[06/30/2022-11:23:41] [I] === Reporting Options ===
[06/30/2022-11:23:41] [I] Verbose: Disabled
[06/30/2022-11:23:41] [I] Averages: 10 inferences
[06/30/2022-11:23:41] [I] Percentile: 99
[06/30/2022-11:23:41] [I] Dump refittable layers:Disabled
[06/30/2022-11:23:41] [I] Dump output: Disabled
[06/30/2022-11:23:41] [I] Profile: Disabled
[06/30/2022-11:23:41] [I] Export timing to JSON file:
[06/30/2022-11:23:41] [I] Export output to JSON file:
[06/30/2022-11:23:41] [I] Export profile to JSON file:
[06/30/2022-11:23:41] [I]
[06/30/2022-11:23:41] [I] === Device Information ===
[06/30/2022-11:23:41] [I] Selected Device: Quadro RTX 8000
[06/30/2022-11:23:41] [I] Compute Capability: 7.5
[06/30/2022-11:23:41] [I] SMs: 72
[06/30/2022-11:23:41] [I] Compute Clock Rate: 1.77 GHz
[06/30/2022-11:23:41] [I] Device Global Memory: 48601 MiB
[06/30/2022-11:23:41] [I] Shared Memory per SM: 64 KiB
[06/30/2022-11:23:41] [I] Memory Bus Width: 384 bits (ECC disabled)
[06/30/2022-11:23:41] [I] Memory Clock Rate: 7.001 GHz
[06/30/2022-11:23:41] [I]
[06/30/2022-11:23:41] [I] TensorRT version: 8204
[06/30/2022-11:23:42] [I] [TRT] [MemUsageChange] Init CUDA: CPU +321, GPU +0, now: CPU 332, GPU 334 (MiB)
[06/30/2022-11:23:42] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 332 MiB, GPU 334 MiB
[06/30/2022-11:23:42] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 467 MiB, GPU 368 MiB
[06/30/2022-11:23:42] [I] Start parsing network model
[06/30/2022-11:23:42] [I] [TRT] ----------------------------------------------------------------
[06/30/2022-11:23:42] [I] [TRT] Input filename:   model.onnx
[06/30/2022-11:23:42] [I] [TRT] ONNX IR version:  0.0.4
[06/30/2022-11:23:42] [I] [TRT] Opset version:    9
[06/30/2022-11:23:42] [I] [TRT] Producer name:    tf2onnx
[06/30/2022-11:23:42] [I] [TRT] Producer version: 1.9.2
[06/30/2022-11:23:42] [I] [TRT] Domain:
[06/30/2022-11:23:42] [I] [TRT] Model version:    0
[06/30/2022-11:23:42] [I] [TRT] Doc string:
[06/30/2022-11:23:42] [I] [TRT] ----------------------------------------------------------------
[06/30/2022-11:23:42] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[06/30/2022-11:23:42] [W] [TRT] parsers/onnx/onnx2trt_utils.cpp:392: One or more weights outside the range of INT32 was clamped
[06/30/2022-11:23:42] [W] [TRT] parsers/onnx/ShapedWeights.cpp:171: Weights StatefulPartitionedCall/sequential/dense/MatMul/ReadVariableOp:0 has been transposed with permutation of (1, 0)! If you plan on overwriting the weights with the Refitter API, the new weights must be pre-transposed.
[06/30/2022-11:23:42] [I] Finish parsing network model
[06/30/2022-11:23:42] [W] Dynamic dimensions required for input: lstm_input, but no shapes were provided. Automatically overriding shape to: 1x110x16
[06/30/2022-11:23:42] [E] Error[4]: [graphShapeAnalyzer.cpp::processCheck::581] Error Code 4: Internal Error (StatefulPartitionedCall/sequential/lstm/PartitionedCall/while_loop:7: tensor volume exceeds (2^31)-1, dimensions are [2147483647,1,16])
[06/30/2022-11:23:42] [E] Error[2]: [builder.cpp::buildSerializedNetwork::609] Error Code 2: Internal Error (Assertion enginePtr != nullptr failed. )
[06/30/2022-11:23:42] [E] Engine could not be created from network
[06/30/2022-11:23:42] [E] Building engine failed
[06/30/2022-11:23:42] [E] Failed to create engine from model.
[06/30/2022-11:23:42] [E] Engine set up failed
&&&& FAILED TensorRT.trtexec [TensorRT v8200] # ./trtexec --onnx=model.onnx
Segmentation fault (core dumped)Powered by Discourse, best viewed with JavaScript enabled"
731,cuda-c-training-from-nvidia,"I am from coimbatore, Tamilnadu, India. I would like to get CUDA C training from Nvidia in-person or online. How to contact them to know about courses duration / Fee, etc.I am working on optimization of CFD programs using GPU. I know the basics of CUDA, need a certified training.Hello @velumanijrfatmech,I suggest visiting our training page here: Deep Learning Institute and Training Solutions | NVIDIA
You might also try searching google for training resources in your region.Best regards,
Tom KPowered by Discourse, best viewed with JavaScript enabled"
732,proxmox-gpu-passthrough-issue-with-wddm,"Hi,Currently working on a issue that I haven’t come accross yet in these topics.
We are working on a system for customers with Proxmox and a Windows 10 VM.Current setup is with a Nvidia Quadro P620. We noticed that the GPU was recognized in the Windows VM, but didn’t show up in the taskmanager.After some research, we where made aware that the WDDM version on the VM is set to 1.3 and needs to be at least 2.0 in order for it to work.Does Anyone have any idea how to get this done?
Passthrough isn’t really detected and measurable this way for testing purposes.
Looking forward to getting this resolved.Kind regards,J.Powered by Discourse, best viewed with JavaScript enabled"
733,unable-to-install-nvidia-vgpu-driver-on-windows-2019-server,"Hi,
I’m unable to install the vGPU Display Driver on Windows 2019 Server.
Windows is running as VM on ESXi. Tried different versions (9.3 and 10.1)
No Problems with Server 2016.
Anyone ever seen this?best regards, karstenHiCan you give more details please?You’ve built a new VM with a vGPU attached > Installed VMTools without the vSGA option > Try to install the vGPU driver but it fails.What’s the error message?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
734,vgpu-for-autocad-rdsh-questions,"Hello Gurus,We have taken on a new client who has experienced considerable growth in the past 2 years. There are offices in multiple locations across the country (3 offices, approximately 30 employees total, for now) each office is connected with high-end Cisco/Meraki VPN gear.We are wanting to go ""server-less"" at the remote offices by way of thin-clients and having a single (or potentially dual, for redundancy) robust servers at the head office running Server 2019 and RDSH for the ""typical"" employees. They also have 3 engineers who need to use AutoCAD.I am not familiar with Nvidia products, but I have done quite a lot of reading on your forums. In theory, I should be able to use something like an M10 (quad GPU?) and allocate 1 core each to 4 virtual machines, correct?In this scenario, I would deploy a Windows Server 2019 RDSH VM - this would serve ~20 CCU’s, a few of these users need the capability to open, say, Google Earth. Google Earth does NOT respond well in a terminal server environment with no graphics hardware. Hence the possible solution of using 1 of the 4 gpu’s on the M10.And then, in addition, I would also like to deploy 3x Windows 10 Pro VM’s, and install AutoCAD on them, for the engineers, and then assign the 3 remaining gpu’s to each of these VM’s. Should this work?And then what about future growth? Let’s say a year from now they have 6-8 engineers needing to utilize AutoCAD. Is it simply a matter of slapping in another Nvidia M10 and assigning more cores to more VM’s?Thanks in advance, and my apologies of any of these questions have been answered before.Correct observation. And yes, you could add another M10 next year to react on additional growth. In addition to the hardware you will need vApps and QvDWS licenses.regards
SimonI realize there will be licensing costs involved. Thank you for the quick reply. I truly appreciate it.Would you recommend starting with an M10? Or is there something better suited to the proposed deployment?Are there any vendor-specific pre-configured servers you would recommend? We typically build our own servers in-house, my usual intel-based 1U-rackmount server will obviously not be ideal in this situation.For professional 3D (like AutoCAD) I would recommend Tesla T4. So it might make more sense to start with 2x T4HiJust to add to Simons comments, although the M10 is still available and fully supported, the fact the architecture is 3 generations superseded should not be overlooked. Bottom line, you’re buying old technology. In my opinion, unless you’re really looking to deliver the cheapest solution, in which case the M10 is perfect (note cheapest, not best), you’re better off with multiple T4s to replace it. The T4s are the latest (Turing) architecture. They support the latest codecs, have better encoding capabilities, more scheduler options, will be supported for longer, use less power and are just generally a more future proof investment over an M10. Also, if you’re running the latest GPU architectures, you can always take advantage of the latest software (vGPU) enhancements.As you have CAD users, making sure you select the proper hardware specifications is even more important. Although you can run CAD on an M10 using QvDWS licensing, it would be my last choice out of the current GPU lineup available. Also, as you’re supporting CAD users, don’t forget the CPU ClockSpeed is critical. Typically, nothing below 3.0Ghz.RegardsMGGentlemen, I appreciate the feedback immensely. And this is the exact kind of input I signed on for. I’ve deployed hundreds of terminal servers over the years, but I’ve never been asked for an AutoCAD capable remote environment.I will look into the T4 GPU’s as recommended.I typically utilize Intel Xeon Silver 4208’s which have a base clock of 2.10GHz and a turbo clock of 3.20GHz, but again, as you’ve seen these systems in production, I’m certainly open to suggestions.-RobSeriously with 2.1GHz? You can never ever count on turbo clock with server systems, therefore this CPU is totally useless for the use case given. As MrGrid mentioned already you should have at least 3Ghz for 3D use cases.HiPlease don’t use 2.1GHz for AutoCAD. Yes it will load and run etc, but the user experience will usually be poor when scrolling in and out, manipulating designs and objects. These CPUs are for entry level workloads, typically classed as ""Digital Worker"", not CAD.Forget about Turbo, there are way too many caveats to get it to work consistently and properly in a virtualised environment and just because the boost clock will go to 3.2GHz, doesn’t mean your users will always get that if or when it the CPU decides to boost. On a physical workstation with no hypervisor, sure, but on a virtualised environment, whole different thing. Then you’re into ""All Core"" vs ""Single Core"" boost and all sorts of other variables that make it deliver inconsistent performance. A far simpler approach is use a CPU with a faster base clock and forget about Turbo. The users will have a far more consistent experience, as the minimum they’ll be working with is 3.xGHz.Either of these two CPUs are fine, however, personally I’d go for the current version (Gen 2)Gen 2 - 18 Core 3.1GHzIntel® Xeon® Gold 6254 Processor (24.75M Cache, 3.10 GHz) quick reference with specifications, features, and technologies.Gen 1 - 18 Core 3.0GHzIntel® Xeon® Gold 6154 Processor (24.75M Cache, 3.00 GHz) quick reference with specifications, features, and technologies.I typically use the 18 Core variants because this gives more flexibility per Host and provides the best balance of Cores vs Clock (there are obviously other CPU variants with either higher Clock or Core count for more specialised use cases). With most OEMs supporting 6 > 8 T4s per Host, having 36 physical cores will allow you to provide the best experience and give you the most headroom for additional density (It’s far easier to add additional GPUs than change out the CPUs when you need additional capacity!).3.xGHz is a bit of a waste for typical Digital Workers, but, you need to look at the overall bigger picture for the hosting environment and whether you want to run RDSH and CAD Workstations on the same physical Hosts. It would be a slightly unusual configuration, but is completely possible and yes you can do it as the Workstations and RDSH VMs would run on different GPUs. Use the software to carve up the platform, not the hardware.Regarding how you support the RDSH and CAD VMs, you can do this in a couple of ways. You can either have two different CPU specifications in your hosting environment (one specification running 2.1GHz and the other running 3.xGHz CPUs) for each workload, or you can have a single specification environment where all hosts are the same and you control performance through the Hypervisor (as mentioned above, again using the software layer, not hardware). My preference would be the single specification as this gives you more flexibility in terms of resilience, migration, maintenance and manageability and it gives you a single price for scaling out the environment. You may or may not be using it, but this is something that Hyperconverged is really good for as everything comes in a single Node. Yes, Hyperconverged is overkill for just this customer, but looking at the bigger picture if you have multiple customers …For the RDSH VMs, allocate each of them the 8A vGPU Profile (8GB of FB) from the T4 (1x vApps license is required per CCU) and change the vGPU Scheduler to Fixed. Changing the Scheduler is really important for the RDSH VMs. Ensure that ""GPU Consolidation"" (named differently depending on the Hypervisor choice) is configured so that the RDSH VMs all end up on the same GPU. The alternative to that setting, depending on your Hypervisor choice, is that you can even select which vGPU Profiles run on which specific GPUs. For example, this means that you could have two T4s that will only run 8A vGPU Profiles, and all other T4s run other vGPU Profiles (except 8A).  What this does, is let you configure a different Scheduler (Best Effort or Fixed) on specific GPUs, and then specific VMs (CAD or RDSH) will only start on those GPUs and have appropriate access to them. You wouldn’t want the CAD VMs running a Fixed Scheduler for example.For the CAD VMs, do some homework first, it’ll save you a lot of issues in the long run. Find out what kind of monitor configurations the CAD users are currently running for a starter (1080P / 2x 1080P / QHD / 4K …) and whether there are plans to upgrade these in the future (if there are, factor that in now, not at a later date). This will at least give you an indication of which vGPU Profile to use initially. Unless they’re doing something crazy, you’ll more than likely be looking at between a 2Q or 4Q vGPU Profile (2GB or 4GB) (QvDWS license is required per CCU (for this specific use case, think of it as per Workstation, it’s easier)). If you’re unsure, go up in vGPU Profile size, not down! The reason for this is simple … If you go down in vGPU Profile size trying to cram on as many users as possible to hit your ROI, and then build out the environment with that specification based on a specific user density (defined by vGPU Profile size) and cost model, and your users suddenly start:… Then you now need to increase the vGPU Profile size by just one step (2Q > 4Q (on a T4)) because there wasn’t enough headroom in your original configuration. As a direct result, you now halve the density of your GPU (platform), meaning you now need to buy more physical servers, or you have to limit the customers in what they want to do, neither of which are good options. If unsure about monitor configurations, again, always go up, so configure for 4K, that way you know you’re going to be covered.Something else you’ll ideally want to do is monitor utilisation of the CAD users existing workstations to see how much resource they’re currently using before deciding on an overall CAD VM profile. You can do this with great little tool called GPUProfiler ( Releases · JeremyMain/GPUProfiler · GitHub ). This tool was created by a friend of mine (Jeremy Main) who works at NVIDIA and who manages and updates it. It’s a portable .exe so no installation is required, just set the amount of time you want it to monitor for and you can export the results in .csv to check resource utilisation (it’s a fantastic tool). This will give you a pretty accurate idea of how much resources are being used. Run this on as many CAD users workstations as possible to get the best range of metrics. Don’t forget to factor in headroom when you configure your spec based on any results!This is something I see a lot. Customers forget that if they get the vGPU sizing wrong by trying to save money at the POC stage, at best, it’s going to halve their server density in a production deployment when updates happen (which they will at some point). This is really important, and something that I hardly ever see talked about.Also remember that SSD / All Flash storage is now a defacto standard with VDI / RDSH. Sometimes NVMe is required, but only for higher performance workloads. Typically (there’s always the odd exception), mechanical spinning disks are now considered for bulk storage only.You haven’t mentioned which protocol you plan to use for the environment ? (HDX 3D Pro, Blast, PCoIP, TGX). You need to check with the CAD users about their peripherals (3d Space Mice, Tablets etc etc) and then make sure they are all supported with your chosen Protocol.Remember, if in doubt, go up in vGPU Profile size. You can always scale down if it’s too much, but you can’t (easily) go up if you start too low.Out of interest, which Thin Client solution are you planning to use?The whole point of my comments above and how I personally work, is to try and mitigate future developments and changes as much as possible so you don’t have to upgrade specifications for the foreseeable future. If you do, it will typically cause issues in one way or another. A lot of things that will cause future issues can be mitigated if taken in to account at the beginning of the deployment. There are always things that catch us out, but the majority of things can easily be planned for. There’s nothing worse than a customer coming along and asking for more performance from a newly deployed platform, only for the system architects / engineers to realise they don’t have it without significant changes.Apologies, I do tend to rattle on when I get going, but there’s a lot to consider and be aware of right from the start so the correct expectations can be set. When deployments under-perform or go wrong, those deploying it have a habit of blaming the technology which is rarely at fault, and it’s typically the person deploying it didn’t understand what they were doing. Not saying that’s the case here, just covering all bases :-)Best of luck! Let us know if you need any guidance.RegardsMGWow, what a summary!!!
Really appreciate your effort.Regards
SimonGood day once again.And holy-moly your input is invaluable.Clearly the Xeon Silver 4208 isn’t going to cut it. If I’m not going to use the Xeon Silver 4208, I was looking towards Xeon Gold 6244. I will continue to research and look into the processors you’ve recommended. 30 users will be typical ""knowledge workers"" and only 3 users will be ""power users"" requiring access to CAD software (for the time being) and obviously planning ahead/future-proofing as much as possible in the beginning will no doubt save headaches down the road.I am not presently entertaining the idea of building two servers with different hardware configs. If I’m going to build one ""cheap"" server for traditional terminal services, and then another ""expensive"" server for the engineers… I might as well just deploy a terminal server and get the 3 engineers really good desktops. Right now, every employee has their own desktop/laptop PC. Many of which are old and need replacing.I will try to sit down with the engineers and log their utilization. That’s a brilliant looking little app.I haven’t deployed spinning disks in any equipment for years. Worry not on that point. I typically use Samsung for my NVMe devices, and Intel Datacenter SSD’s for 2.5"" applications.I am presently planning to use HYPER-V for everything.For thin clients, either Dell/WYSE terminals or Lenovo. (There will also be several users working remotely using RDP for Mac or RDP on their windows based laptops.)Don’t apologize at all. I came here looking for a wealth of information, from people who have successfully implemented these systems. And I have not been disappointed or overwhelmed at all. Rattle on. Please.HiYou’ve gone a little bit too far the other way regarding CPU choice. Ideally you’re after a balance of Clock vs Cores unless it’s a specific workload you’re targeting. When you move much above 3.0GHz, you start trading Clock for Cores, which is why 3.0 / 3.1GHz is the sweet spot. You “could” look to configure the server with a single socket populated with the 18 Core / 3.1GHz. This would give you the base configuration to scale up when needed, but keep costs down initially. Obviously consider Memory and PCIe architecture at the same time during configuration.There’s a couple of ways in which to configure for 30 Concurrent Digital Workers. You can scale up or out. To scale up, you’ll need the whole T4 assigned to a single VM. Configure CPU and Memory accordingly dependant on testing. As a ball park, start with at least 8 vCPUs and 32GB Memory. Increase as required dependant on testing (I would expect you to need more than that, but those CPU and Memory amounts are a good place to start). My expectation would be that your limiting factor will ultimately be GPU Framebuffer, as this is a hard limit, and I would expect you to hit “approx” 40 > 50 Concurrent users (depending on applications, usage and OS optimisations) if you have a well optimised OS, really light workloads and single 1080P monitors on the client side, then 60 is a strong possibility. But if the users start pushing Google Earth around, you’ll be on the lower end of those numbers. There isn’t a definitive number as there are a lot of variables to consider, but you should be in that area. Much less than that and you have a configuration issue in the stack.The other option (scaling out) is going to be problematic. Unfortunately, out of all the Hypervisors available that support GPUs, Hyper-V is the worst choice for GPU virtualisation (in my opinion). Microsoft (for some reason) made a real mess of adding this. Hyper-V doesn’t actually support vGPU (Plan for GPU acceleration in Windows Server | Microsoft Docs). You can run GPUs in Passthrough (referred to by Microsoft as DDA) but you can’t share the GPU between multiple VMs. You either need to add the whole GPU to a VM, or none of it. That’s ok (it’s not really ok, but it works) with RDSH (kind of), but you’re limited to 1 VM per GPU. Now, if you were running an M10 which has 4 GPUs on it, you can run 4 RDSH VMs (each GPU passed through to a separate VM). But with a T4, where you’d typically split the GPU and run 2 8A vGPU Profiles to support 2 RDSH VMs, all you can do is allocate the whole GPU in Passthrough. So if you go down the Hyper-V route, you’re going to run into limitations very quickly.If you were just running RDSH VMs, this would be ok. Not ideal, but ok. As you could just use M10s to scale out, or a whole T4 to scale up. But you also want to support CAD VMs, and here’s your problem. With XenServer, vSphere, AHV or KVM, you can run all those CAD VMs (3 at the moment) on the same GPU, if they need a 4GB Profile, you have additional capacity for 1 more, if a 2GB Profile you could get 5 more on there. However, with Hyper-V, each CAD VM will need it’s own T4(!) and that’ll blow your cost model right out of the water.Great that you only use SSD / NVMe!Regarding Thin Client choice, make sure you test various models / specifications before deciding on a final model. WYSE, IGEL, 10Zig will all send you evaluations if you request them. It’s also well worth considering using something from NCOMPUTING ( https://www.ncomputing.com/ ) who will also send you one for testing. The NCOMPUTING clients are great little devices that are inexpensive and perform really well, they also have a management platform so can easily be configured before deployment. Regardless of which you select, don’t underestimate the importance of a “good” end point. Just because the back end has high performance components where the heavy lifting is done, doesn’t mean that the end point can be skimped on. Your choice in Protocol will also impact your choice in Thin Client. Treat the solution as an end-to-end system, and every component impacts the user experience.RegardsMGI will take what you’ve said regarding Clock Speed vs Cores/Threads to heart.30 users is the TOTAL number of employees at this point. I wouldn’t expect concurrent users to be above 20.Going with a single CPU for cost-savings isn’t much of a concern. At least not at this point. We’ll see where we’re at when I start putting the final numbers together. (As a side note, where can I see Nvidia licensing costs?)I also realize that HYPER-V is the ""worst"" hypervisor currently available, but, it’s what I’ve been using for over a decade, and I have no experience with VMware, Citrix, Linux, etc.I don’t mind the limitation of dedicating 1 physical GPU per VM. Hence why, initially, I asked about a quad-gpu (M10) to power 4 VM’s. Is there a card like the T4, but with multiple GPU’s per pcb?If I have to start re-thinking my methodology, I certainly will, as Leela’s office poster says; ""You gotta do what you gotta do.""HiYes, official pricing is available here: https://images.nvidia.com/content/grid/pdf/Virtual-GPU-Packaging-and-Licensing-Guide.pdf However, depending on your location (I’m UK based) I can provide you with a quote if needed, or you can use the NVIDIA Partner Locator ( Find an NVIDIA Partner | NVIDIA ) to find someone who you’re more familiar and comfortable with and / or local to.Going with the single populated socket approach is a good way to build in scalability at a later date but keeping setup costs at a minimum until that extra density or performance is needed. A single 18 Core / 3.1Ghz CPU would easily support your 30 (20 concurrent) users (including 3 CAD VMs). The largest expense outlay is always the first one. After that, components and resources can start to be shared and therefore scaling typically becomes cheaper than the initial outlay. Unless you need everything populated from the start, it’s better to start small but ensure you account for scaling up, otherwise just getting off the ground can be expensive.Hyper-V … When I say worst, it’s important to keep that in context. For GPU virtualisation where you want to share the GPU between multiple workloads or users (which is typically where everything is moving to now), yes, Hyper-V is currently the least favourable to use as Microsoft decided to do their own thing away from the other Hypervisor vendors (Remote-FX, which was limited anyway and still lacking full functionality, but has now been discontinued). Due to a technology shift, it’s now becoming difficult to find consistent uses cases for it where you can get the best out of the technology stack, as is proven in your use case. That said, GPU-P (GPU Partitioning) is coming. However, how this will work with Hyper-V and NVIDIA is unclear at the moment. I’ve not seen much about it to date, but it’s always worth keeping tabs on Azure for indications of what may feed down to Hyper-V in the future. If you wanted to use another Hypervisor but are unsure due to experience, there are ways around that …The only publicly available, supported, Multi-GPU boards are the M10 and M60. There is nothing newer than that which can be purchased with Multi-GPU. After Maxwell, NVIDIA moved to a more software defined offering. This allows for greater development and flexibility, you just need to get passed Maxwell to get the full benefits of it.If you wanted to use Hyper-V with the M10 and use 1 GPU per VM in DDA with scalability for adding more M10s again running in DDA (server dependant), then this will work, but at this stage it’s a limited solution (due to the functionality of Hyper-V and the age of the M10) and you won’t be getting the full benefits out of the technology, but importantly, it will work. Just be aware of the limitations :-)RegardsMGProviding the customer with a crippled solution to start, due to my own shortcomings, obviously isn’t ideal. Clearly this technology is rapidly changing, and staying ahead of the curve is difficult. It looks like the CPU’s are going to be far more expensive than the GPU’s any way you slice it. (I haven’t yet had a chance to look through the licensing costs).Sharing a T4 for the RDSH users doesn’t concern me. It’s not like 20 of them are going to be using Google Earth at the same time.Sharing a single T4 for 3x engineers all trying to use AutoCAD at the same time, however, does concern me. Is the card robust enough for that?HiBaring anything too out of the ordinary in terms of working habits (which is why it’s really important to monitor your customers utilisation and then have them test on a POC before finalising a specification), a single T4 will be more than capable of handling those CAD users. This is due in part to the way in which CAD users typically work, but also in combination with the latest Turing architecture and encoders, however as mentioned above, don’t skimp on the CPU base clock speed.If the CAD users are doing any design or ""creative work"" other than CAD (Rendering for example) then you will need to review the technology options just to be safe and make sure they’re still correct. Again, monitor their utilisation first (including all applications to make sure nothing’s been missed off the test) to confirm how much resource they currently use, then create your platform accordingly. A good indication is to look at their current hardware specifications. If they’re powerful, then they may be doing something resource intensive. If they’re low powered, then maybe they need an upgrade so they can work more freely, but it’s always nice when they move to a more powerful machine, so deliver this if possible.I did touch on this further up, but now you’ve mentioned Hyper-V and RDP connectivity to me, it’s just reminded me … Unless I’m mistaken (wouldn’t be the first time), I’m pretty sure RDP doesn’t support USB forwarding. What this could mean, is that if your CAD users use 3d SpaceMice (like these: 3Dconnexion UK - SpaceMouse, CadMouse, Drivers ) they may not work in your VMs due to RDP. It’s well worth speaking to your CAD users about their peripherals to make sure you know what they use. And those 3d SpaceMice are pretty much industry standard (they’re beautiful, very high quality, precision devices. I have one myself, it’s like working with a piece of jewellery). I’ve done a little digging for you, it would appear that the users in this forum may have a potential solution, although I can’t confirm or recommend it due to not having used it: Remote Desktop use of local Space Navigator - 3Dconnexion Forum Again, you may not need it and it may not be an issue anyway, but double check with all of the CAD users, and make sure you don’t get caught out by their peripherals.The main thing to be aware of with the RDSH users, is Framebuffer and Encoding. As you’ve worked with RDSH a lot, I’m sure you’ll understand just how much memory Google Chrome or other modern browsers can consume when they have multiple tabs open. Even things like MS Office ""expect"" there to be a GPU in the system and are looking to use it by default. When you monitor the GPU utilisation on a loaded RDSH server, you’ll be surprised where the limitations are :-)Don’t beat yourself up, it’s difficult to stay up to date as this kind of technology is evolving fast and we all have our shortcomings. Mine is Networking. I just never got in to it in my early days. I know what my platforms need from a Network and know the very basics, but configuring a Cisco Switch, Router or Firewall would leave me struggling. It’s just not my thing.I’m going to drop you a quick PM on here …RegardsMGto MrGRID: ""I also realize that HYPER-V is the ""worst"" hypervisor currently available, but, it’s what I’ve been using for over a decade, and I have no experience with VMware, Citrix, Linux, etc.""I do not see any difference between MS DDA and other pass-trough technics: all of them use the same PCIe functions for own goals.Only one difference exist: there is now any profiles to divide such cards (physical PCIe function) as nVidia T4 onto virtual PCIe functions resources like as it do for other hypervisors.Could anybody describe what does it mean word ""GRID"" in MS Windows Server driver without such profiles support?When T4 resources are able to partitioning in ESXi, Xen and KVM, why they are not able to be devided auch a manner for MS DDA?HiAs I mentioned in a previous post further up the thread, the term ""Worst"" needs to be kept in context. ""Worst"" being its overall graphics support. I’m sure Hyper-V may have other advantages, but as I solely work with GPU workloads, I stopped using it many years ago so am not able to articulate them.Passthrough and DDA are the same thing. It’s just Microsoft trying to look like they’re doing something different by calling it something else.When using vGPU, you do not pass the GPU through to the VM(s) (there is no PCIe Passthrough), you allocate a portion of the GPUs Framebuffer through the vGPU Manager and each VMs access to the GPUs resources is time-sliced using its Scheduler. This requires virtualisation, and this is the part that Microsoft do not support.For clarity, NVIDIA vGPU (originally named ""GRID"") is a package of components (Software and Hardware) that form the solution. By using specific GPUs with specific Software, you are using vGPU (GRID).With all of that said, if you look at what NVIDIA have done with the A100, then Microsoft might be an ok choice once NVIDIA release the new graphics line for Tesla and Quadro. We’ll have to wait and see what gets released …RegardsMGThe primary concern to know about with the RDSH clients, is Framebuffer and Encoding. As you’ve worked with RDSH a ton, I’m certain you’ll see exactly how much memory Google Chrome or other current programs can burn-through when they have different tabs open. Indeed, even things like MS Office ""expect"" there to be a GPU in the framework and are hoping to utilize it of coursePowered by Discourse, best viewed with JavaScript enabled"
735,launching-cuda-kernel-with-c-main-file,"HiI’m new to CUDA and was trying out the simple vector addition code. However, I’m not able to compile my code. For the sake of re-usability, I’ve defined a class Vector which basically holds the pointer to a dynamically allocated array and the length of the array (full code here). I’ve written my main function in a cpp file as follows:I’ve tested all the parts where I copy data to device and it’s working as expected however I’m not able to execute the kernel on device.addDevice function is present in vecAdd.cu file and it’s contents are as follows:When I compile main.cpp, I get the following errors:I don’t understand how I can resolve this issue. Hope somebody can help me.ThanksPowered by Discourse, best viewed with JavaScript enabled"
736,help-required-with-tesla-k40,"Hello there,
I have got a simple question.Will my Tesla K40 GPU run on a Maximus X Hero Mainboard ?
Any answers would be appreciated.Thanks in advance,Powered by Discourse, best viewed with JavaScript enabled"
737,video-transcoding-in-virtualized-environment-with-nvidia-gpu,"Hello, I read some topics in this forum, and based on those Q&As I`ll try to formulate my questions.We are running a virtualized environment today on HP blade servers BL460, virtualizing with vmware sphere 5.5. External Netapp Storage used.
We would like to build new 2 VMs on top of it with video streaming SW WOWZA running in them, that would use the GPU capability of NVIDIA M6 (with NVENC video-codec support). We are aware that HP WS460s blades must be used because technically same BL460 is not supported by HP from some reason. So we would buy two new WS460c blades. HA redundancy is the reason why two, so in case of a host failure the VM would restart on the other.
These VMs (two) would use all the GPUs memory, but would use only relatively small amount of host resources allocated (4vCPU, 32GB RAM each) - that is the reason we do not want to dedicate two hosts only for this HPComputing realtime video-transcoding stuff.Learn about accelerated video encoding requirements when using NVIDIA graphics cards with the Transcoder in Wowza Streaming Engine.Could you please advise me to decide:So, thank you very much, DanielHP WS460c datasheet with a list of supported GPUs:
https://www.google.cz/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjkvNew09DRAhXFBiwKHfetAJEQFggeMAE&amp;url=https%3A%2F%2Fwww.hpe.com%2Fh20195%2Fv2%2FGetPDF.aspx%2F4AA5-7517ENN.pdf&amp;usg=AFQjCNEhu88SEdiGzlT175xIHbGNvJ8XNg&amp;sig2=IyhZWboR_T6MsrKpmrQtWA&amp;bvm=bv.144224172,d.bGsHi Daniel,from the link provided I couldn’t find out if you’re going to run the software on client or server OS.
In general this is a passthrough use case and needs a vWorkstation GRID license for client OS. If you run it on a server OS a vApps license might be sufficient as you don’t need the Quadro features and would also be able to use passthrough with vApps and Server OS.RegardsSimonHello gentlemen, Im kindly surprised I have got 2 relevant answers just after returning to work after the weekend. Thank you very much for that!  Now Im going to dive into the topic, it looks it is going to be fun. :)Hi there. I’m interested in learning how this was resolved.  I have a similar question on the vGpu license needed for Plex video transcoding in a hyperV Win10 vm with a Tesla P4 passed through.  Want to avoid consuming a vWorkstation license if at all possible.RolandRoland, we did not built it at the end.After 4 years, I just suppose it was because of the price. DPowered by Discourse, best viewed with JavaScript enabled"
738,nvidia-container-toolkit-not-finding-items-on-path,"I have been working through setup of Dell XPS15 (RTX 3050) W11 WSL2-Ubuntu22.04LTS with CUDA 12.2 to run GPU workloads in containers.Steps to reproduce the behavior:tl;dr:
install ubuntu 22.04 in WSL2
install cuda 12.2 in WSL2
append relevant directories to PATH and LD_LIBRARY_PATH
install nvidia-cuda-toolkit
install docker
install nvidia-container-toolkit
generate the “Container Device Interface” config json
run vespa container and install vespa-onnxruntime-cuda
try to deploy an appExpected behavior
The app should read LD_LIBRARY_PATH, load libcublasLt.so.12, converge and deploy.Actual behaviour
Vespa app in container could not load library libcublasLt.so.12.
nvidia-container-toolkit.log shows a searching and not finding things.I followed steps to delete something in system32 and make the symlinks. search for windows subsystem for linux - WSL libcuda is not a symbolic link - Super User to see details.and also added to my ~/.profileEnvironment :
OS Name: Microsoft Windows 11 Pro
Version: 10.0.22621 Build 22621
System Model: XPS 15 9520
Processor: 12th Gen Intel(R) Core™ i7-12700H, 2300 Mhz, 14 Core(s), 20 Logical Processor(s)
BIOS Version/Date: Dell Inc. 1.13.1, 4/17/2023
SMBIOS Version: 3.4
BIOS Mode: UEFI
Total Physical Memory: 31.7 GBNVIDIA Studio Driver: 536.67
NVIDIA-SMI: 535.86.01WSL Linux kernel: 5.15.90.1-microsoft-standard-WSL2
WSL Distro Description: Ubuntu 22.04.2 LTS“CUDA Version”: 12.2
nvcc: Cuda compilation tools, release 12.2, V12.2.91 Build cuda_12.2.r12.2/compiler.32965470_0Vespa version
8.198.18I am inspecting the (see attached) /var/log/nvidia-container-toolkit.log and I would like assistance in interpreting all the missing libraries in the log. What is normal and abnormal about what it contains? How can I get it to find these libraries?
nvidia-container-toolkit.log (20 KB)Here is a detailed step-by-step document on my build process
system_buildC.txt (4.3 KB)Powered by Discourse, best viewed with JavaScript enabled"
739,after-upgrading-to-vgpu-13-0-vib-the-vsphere-a100-mig-vm-profiles-are-lost,"Today we just update vib from 12.3 to 13.0 on our vSphere 7.0.2. It seems after rebooting the server, vSphere is not able to run the VM anymore. It seems all the previous GPU profile is not valid  anymore.  We didn’t have any problem when we upgrade from 12.2 to 12.3. Any suggestions?This is what we have on the server right now:

image1217×813 247 KB


image905×983 205 KB
This is what we used to have on vSphere in vGPU 12.3:

image1064×1147 61 KB
But now, this profile is invalid. So I am not able to start my VM
vCS for ESX is now part of NVAIE offering. You need a special VIB. As existing customer you should get an upgrade path for NVAIE.regards SimonFrom our current release notes:And this is what you should have received:
snip
Dear Customer,
The vCS  licenses on ESXi  are not supported with vGPU 13.    However, there is a new product, NVIDIA AI Enterprise (NVAIE),  that has the same features (and more), and it is supported on vGPU 13 with ESXi.    A special offer for NVAIE is going out on it to all vCS customers by October 1st.     Please contact your account manager for more information.
snipPowered by Discourse, best viewed with JavaScript enabled"
740,p40-and-teamcenter,"Hi All
We are running a series of test’s for customers who use Teamcenter and Catia.
The hardware is a Dell R730 2 x Nvidia P40’s each server
The processor is Intel Xeon GOLD 6148 2.40 GHZThe storage is NetApp full flash.We are using XenDesktop 7.15.3 and XenServer 7.6.The VDI machines are running Windows 10 64 Bit 1803 with P40-3Q  card and vdi machines are running 8 vcpu’s.We have large size car drawings. Our engineers are designing the model with the Catia and wiewing with Siemens Teamcenter Visualization.Our issue: when we rotate the model, 2 seconds delay on first click. But after the first click, we have no problems when we want to rotate the model.
Our problem is that during the first click. This delay time increases when the model file grows.What can we do for this 2-second delay?First of all I would check the power state of the GPU with nvidia-smi to figure out if this may be related. You could for example run a youtube video in the background to see/force power state in P0 and try again. If the behavior is different then there are options to keep the GPU in higher power state.
Another issue is the weak CPU. 2.4Ghz is much to low for Catia and you won’t keep the GPU under load as the CPU is ""overloaded"" already.regards
SimonHi,I have similar issue with PTC Creo.CPUs are Intel® Xeon® Gold 6146 12C, 3.20 GHz.Is it possible to force P40 power state to P0 with nvidia-smi?Regards,KárolyPowered by Discourse, best viewed with JavaScript enabled"
741,license-manager-is-lost-on-grid-10-0-driver-441-66,"Hi,After upgraded to GRID 10 on our VMWare Horizon, found thgere’s no license manager on NVIDIA Driver, cause vGPU function is under degraded function, may someone help me? Many thanks!Guest OS is use on Windows 10 1703 & Windows 10 1909 with Quadro RTX 6000, Hypervisor is ESXI 6.7 update 3.

Found that GRID Package 9.2 didn’t have this problem, thanks!HiIs there a reason you’re changing the resolution ""inside"" a remote session like that? Why not just resize the Horizon Client?RegardsMGPowered by Discourse, best viewed with JavaScript enabled"
742,dell-poweredge-r730-and-m10-1q-zoom-video-lagging,"We are running test run using the nvidia M10 on our vmware cluster, and composer link desktop pool. The driver installed without no issues, and the cluster is configured according to the vmware documentation. However, during the first test run on one new vdi pool and a single computer, 16Gb of ram, up to 4 monitors, 4 cpus, profile currently being used M10-1q. And, when opening the zoom application, within the vdi, the video barely move. It is like slower than not having a GPU at all.HiCan you confirm that the that VM has successfully acquired a vGPU license?Also, 1GB of FB won’t be enough for 4x monitors, you’ll want to increase that to a larger profile. What resolution are the monitors?RegardsMGHi, at this time we only have two monitors. The resolution on these monitors is 1920x1020.HiAnd the licensing? …RegardsMGNo issues with the license. The issue is with any app (windows can or zoom) using the computer camera. There is like a four almost five seconds delay.HiYes, hence why I asked about the license being applied. If the VM can’t obtain a license, this will reduce the functionality and performance of the GPU and give the exact symptoms you are experiencing. But as you say it’s obtaining a license correctly, we can look at other areas.Is it using the GPU at all? I assume you’re running Windows 10 … Open Task Manager and look at the GPU utilisation. Does it actually get used on anything? Playing a YouTube Video? Encoding the Horizon session? etc etcRegardsMGYes, it is showing on task manager. When playing YouTube video, it shows very minimum CPU utilization. However, when using the windows cam application, or zoom application, the frames per seconds are reduced to almost 4 or 5 seconds delay. Like for example, if I hold my hand in front of the camera, and start to count one to five, the camera will not present the fingers movement for almost 4 seconds or 5 seconds.HiI’ve tried to replicate your issue in my Lab without going too far down the rabbit hole, but I can’t.I quickly built a clean Windows 10 20H2 VM. No Windows Updates. Installed VM Tools, vGPU 11.2 with an M10 1Q Profile,  Horizon Agent 2006 with Direct Connect, current Zoom client and connected directly to it and it works perfectly. Maybe 0.5 seconds lag, but this is completely untuned / optimized and out the box and I threw it together in 20 minutes.I use Instant Clone, not Composer as that’s pretty old now, so am unsure about the options it requires. Maybe check the vGPU settings in there to make sure it’s configured correctly?Other than that, try a clean build like mine above with Direct Connect and see if that works. If it does, then there’s a problem with your Composer settings / agent installation somewhere.You don’t mention which software versions you’re running, but check all your Software and Agent versions, make sure everything is running the latest. I’m running current versions of everything, and no issues, unless it’s with Composer which as said I don’t use.RegardsMGLinked or Instant Clone are just deployment methods, which have no impact on video performance whatsoever. How is this camera being used? Through USB redirection or an optimized way, for instance Zoom VDI plugin or VMware RTAV? USB redirection will get you very bad results, hence the question… Maybe this will help:Ensuring That Real-Time Audio-Video Is Used Instead of USB RedirectionPowered by Discourse, best viewed with JavaScript enabled"
743,usage-limit-error-in-deep-learning-institute-course,"Hello,I keep getting the following error message and could not even start the course that I paid for.“Usage Limit You have exhausted the lab time provided with your course enrollment.”I wrote an email to dli-support@nvidia.com a week ago but did not receive any response so far.  Can someone at Nvidia fix this issue? Thanks.Hello,Can you please tell me the name of the course? I can then adjust the time limit.Thanks,
TomThanks. It is: Accelerating CUDA C++ Applications with Concurrent StreamsYou should be good to go now.Cheers,
TomStill getting the same error :/Can you try logging out and back in?Did try that as well before sending you the last message. It is still in same condition.Okay. It seems to be starting now.Sometimes the user management system can be slow. Glad it is working for you now.The usage limit issue seems to be fixed now. Thanks.I am on Chromium browser in Linux.  The page is showing loading for past 5 minutes and still loading. May I know how long it typically takes to launch the course?Also, would you recommend any specific browser for Ubuntu for this course?Also, I suspect this is how most end up not having compute hours at all, possibly because the page loading almost never gets complete?Sorry, you are the first person I have seen complain about the page load time for DLI courses. I don’t have any experience running these courses on Linux, so I cannot comment on the best browser. Can you try from another system or browser?I tried Firefox in the meantime. It is again 5 minutes and counting. No progress yet. I will try next incognito mode and see if it helps.Incognito mode in Chromium browser + Ubuntu did not help either unfortunately :/Let me reach out to the DLI team and see if there are any know issues.
Thanks for your patience.I suspect if it is something with my account itself. I just tried Windows 10+ Chrome browser. It is still loading after 5 minutes. Can you please look into this?Finally! It took a very long time to load despite having a good internet connection here. I left the tab open and came back to see the course finally loaded up. I wonder if it was a wait due to compute availability on the cloud or something like that. I am sure there would be better way to get this launch process faster. Needs more testing across different geographies and time zones. Thanks for increasing the compute time at the beginning!I am sorry. The usage limit has been exhausted again. Could you please reset/extend the time? I was only 30% into the course.You are all set, I added another four hours.Thanks! It looks like the launch takes a good 10 minutes for this course. This is consistent across different browsers and OS. My internet seems to be fairly fast (but I do not see data download during the loading phase of the course). I kindly request you to bring attention of the course team about this delay in launch. Most times people might try, wait for a while, and assume things to be not working. This only would lead to unnecessary use of instances as the tab is left open assuming things to be still loading.Powered by Discourse, best viewed with JavaScript enabled"
744,trying-to-get-some-sample-applications-to-work,"Hello,I am trying to get some of the samples to work in the cuda toolkit. some/most work how I use them.However, I am using X11 forwarding, and for example the Mandelbrot sample code throws me an error:$  /usr/local/cuda-10.2/samples/bin/x86_64/linux/release/Mandelbrot
[CUDA Mandelbrot/Julia Set] - Starting…
GPU Device 0: ""Kepler"" with compute capability 3.0Data initialization done.
Initializing GLUT…
OpenGL window created.
Creating GL texture…
Texture created.
Creating PBO…
CUDA error at Mandelbrot.cpp:971 code=999(cudaErrorUnknown) ""cudaGraphicsGLRegisterBuffer(&cuda_pbo_resource, gl_PBO, cudaGraphicsMapFlagsWriteDiscard)""I assume that is because I am doing X11 forwarding, ""is there a way around it?""thanks,RonPowered by Discourse, best viewed with JavaScript enabled"
745,sriov-manage-e-virtfn-not-found,"Hello, In the user guide I type sriov-manage -e. but virtfn directory doesn’t create.
Does it have anything to do with whether the motherboard supports sr-iov?
Please help me!Powered by Discourse, best viewed with JavaScript enabled"
746,nvidia-rtx-virtual-workstation-video-editing-performance-not-usable,"I stood up a test workstation in AWS (detail below) to test video editing and collaboration.I connected via RDP. The specs prior to launch displayed 1GB of GPU memory in AWS console, but upon opening the servers’ Task Manager, the GPU apparently has 15GB of GPU memory.I installed Blackmagic Design DaVinci Resolve, my editing software, and uploaded a short, unedited video to test.Without making any modifications to the clip, playback of the video was very choppy. Do you have any ideas or suggestions?DaVinci Resolve WkStation
AWS Marketplace
NVIDIA RTX Virtual Workstation - WinServer 2019
Amazon Machine Image
By Ingram Micro
g4dn.2xlargeBest regards,
DJ—Hi.For video editing, RDP probably not good remoting protocol. You need have more interactive remoting protocol based on h.264 encoding.Thank you.
JasonNICE-DCV is the aws way to go about these workstationsSorry for bumping into an old conversation. One thing to consider is that even though the GPU has 15GB of memory, other factors may be at play that are causing the choppiness in playback.Powered by Discourse, best viewed with JavaScript enabled"
