UCLA researchers have just developed a deep learning, GPU-powered device that can detect cancer cells in a few milliseconds, hundreds of times faster than previous methods. “improvement in computational efficiency enables low-latency inference and makes this pipeline suitable for cell sorting via deep learning,” the researchers stated in a newly published paper in Nature. “Our neural network takes less than a few milliseconds to classify the cells, fast enough to provide a decision to a cell sorter for real-time separation of individual target cells,” the team explained.  The research and device have the potential to extract cancer cells from the blood as soon as they are detected, helping reduce the spread of the disease in the body. The device relies on both deep learning and photonic time stretch, an ultrafast measurement technology invented at UCLA, that can capture trillions of data points per second. The photonic time stretch technology is 1,000 times faster than today’s fastest microprocessors, the team explained. “Because of the extreme volume of precious data they generate, time-stretch instruments and deep learning are a match made in heaven,” said senior author Bahram Jalali, a UCLA professor of electrical and computer engineering at the UCLA Samueli School of Engineering.Also in use, is a technology called cytometry, which is the science of measuring cell characteristics. To accelerate the cell detection method, the team developed a deep convolutional neural network that directly processes the one-dimensional time-series waveforms from the imaging flow cytometer. This model automatically performs feature extraction, eliminating the image processing pipeline before the classifier, which helps reduce processing time. “We find that some features may not be represented in the phase and intensity images extracted from the waveforms, but can be observed by the neural network when the data is provided as the raw time-series waveforms,” the researchers explained.  “These hidden features, not available in manually designed image representations, enhance the model to perform cell classification more accurately.”In terms of accuracy, the model and device achieve more than 95% accuracy in the classification of OT-II white blood cells and SW-480 epithelial cancer cells. The classification model was trained on NVIDIA Tesla GPUs with the cuDNN-accelerated TensorFlow deep learning framework, using datasets for the target cell types. For inference, the team used an NVIDIA P100 GPU on the Google Cloud, with CUDA 10..0, cuDNN .7.4.1. Inference processing time on different hardware (ms/example)The new breakthrough opens up a new path for real-time label-free cell sorting, the researchers explained.“We don’t need to extract biophysical parameters of the cells anymore,” said Ata Mahjoubfar, a UCLA postdoctoral researcher and a co-author of the paper. “Instead, deep neural networks analyze the raw data itself extremely quickly.”Read more>