From a Jetson-based service robodog, to an algorithm that can instantaneously detect cancer in the blood, these are the top 10 AI developer stories that we covered this year on the NVIDIA Developer News Center. All of the developers featured in this video are using NVIDIA GPUs for both training and inference. UCLA researchers have just developed a deep learning, GPU-powered device that can detect cancer cells in a few milliseconds, hundreds of times faster than previous methods. “improvement in computational efficiency enables low-latency inference and makes this pipeline suitable for cell sorting via deep learning,” the researchers stated in a newly published paper in Nature. “Our neural network takes less than a few milliseconds to classify the cells, fast enough to provide a decision to a cell sorter for real-time separation of individual target cells,” the team explained.  The classification model was trained on NVIDIA Tesla GPUs with the cuDNN-accelerated TensorFlow deep learning framework, using datasets for the target cell types. For inference, the team used an NVIDIA P100 GPU on the Google Cloud, with CUDA 10..0, cuDNN .7.4.1. Read the full story>>This robot not only looks like a dog but he learns like one too! Researchers from Florida Atlantic University’s Machine Perception and Cognitive Robotics Laboratory have just developed Astro the robot dog. “Astro doesn’t operate based on preprogrammed code. Instead, Astro is being trained using inputs to a deep neural network – a computerized simulation of a brain – so that he can learn from experience to perform human-like tasks, or on his case, “doggie-like” tasks, that benefits humanity,” the researchers wrote in their project page. Astro is equipped with sensors, radar, cameras, a directional microphone and a set of NVIDIA TX2 Modules to process the sensory inputs. With the onboard GPUs, Astro is capable of performing up to four trillion computations a second. Read the full story>>Recently the Allen Institute for Artificial Intelligence announced a breakthrough for a BERT-based model, passing a 12th-grade science test.The GPU-accelerated system called Aristo can read, learn, and reason about science, in this case emulating the decision making of students. For this milestone, Aristo answered more than 90 percent of the questions on an eighth-grade science exam correctly, and 83 percent on a 12th-grade exam.To train the models, the team relied on NVIDIA P100 GPUs on the Google Cloud, using the organization’s Beaker.org research platform, as well as the AllenNLP research library, an open source PyTorch-based framework for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.For some experiments requiring more memory, the team relied on an in-house server powered by NVIDIA Quadro RTX 8000 GPUs.Read the full story here>How much dark matter is there in the universe? This AI model might have the answer.A team of physicists and computer scientists at ETH Zurich developed a deep learning-based model to estimate the amount of dark matter in the universe. This is the first time AI researchers have used this type of algorithm to analyze dark matter, the researchers said. As a first step, the team trained a convolutional neural network (CNN) on computer-generated data that simulates the universe. This was done using 16 NVIDIA P100 GPUs with the cuDNN-accelerated TensorFlow deep learning framework. Read the full story here>This year NVIDIA announced breakthroughs in language understanding that give developers the opportunity to more naturally develop conversational AI applications using BERT and real-time inference tools, such as TensorRT to dramatically speed up their AI speech applications. In the announcement, researchers and developers from NVIDIA set records in both training and inference of BERT, one of the most popular AI language models.
Training was performed in just 53 minutes on an NVIDIA DGX SuperPOD, using 1,472 V100 SXM3-32GB GPUs and 10 Mellanox Infiniband adapters per node, running PyTorch with Automatic Mixed Precision to accelerate throughput, using the training recipe in this paper.Inference on BERT was performed in 2 milliseconds, 17x faster than CPU-only platforms, by running the model on NVIDIA T4 GPUs, using an open sourced model on GitHub and available from Google Cloud Platform’s AI Hub.Read the full story here>>Researchers from Columbia University used deep learning to enhance speech neuroprosthesis technologies, that can result in accurate and intelligible reconstructed speech from the human auditory cortex. This research has the potential to one day help patients who have lost their ability to speak, communicate with their loved ones. Using NVIDIA TITAN and NVIDIA Tesla GPUs, with the cuDNN-accelerated TensorFlow deep learning framework, the researchers were able to develop deep learning models that made possible the production of  a computer-generated voice reciting a sequence of numbers with a 75% accuracy level.Read the full story here>>Researchers from the University of Washington and Facebook recently released a paper that shows a deep learning-based system that can transform still images and paintings into animations. The algorithm called Photo Wake-Up uses a convolutional neural network to animate a person or character in 3D from a single still image.Using NVIDIA TITAN GPUs and the cuDNN-accelerated PyTorch deep learning framework the researchers based their software on a pre-trained model called SMPL, which was first developed by a team at Microsoft and the Max Planck Institute for Intelligent Systems in Germany.Read the full story here>>To help recreate a lost Picasso painting, University College London researchers used deep learning to recreate parts of The Old Guitarist, one of Picasso’s most famous paintings from the Blue Period. During this period, dating back to the early 1900s, Picasso used blue in his paintings to convey the pain and solitude he experienced during this time. To bring the lost painting back to life – the researchers trained a deep neural network using NVIDIA V100 GPUs and the cuDNN-accelerated TensorFlow deep learning framework on a dozen images from Picasso’s blue period, including La Vie. This allowed the team to recreate an x-ray photograph taken in 1998, into an image that resembled Picasso’s style, revealing the lost woman in The Old Guitarist. Read the full story here>>NVIDIA’s viral real-time AI art sensation GauGan just won a “Best of What’s New Award” in the engineering category, Popular Science magazine announced this month. On the back-end, GauGAN is based on a generative adversarial network and trained on over one million real landscape images, using an NVIDIA DGX-1 system, with the cuDNN-accelerated PyTorch deep learning framework.Read the full story here>>If you like playing or watching team sports, you’ll probably find this AI’s latest creation fascinating. Developers from AKQA, a global innovation agency most known for working with major brands and public figures, trained a recurrent neural network and a deep convolutional generative adversarial network on over 400 sports with the aim of creating a new and original sport.Using NVIDIA Tesla GPUs for both training their neural networks and inference, the models generated over 1,000 different sport concept outputs, rules and gameplay outputs. And besides generated the new sport, they also trained their neural network on 10,400 logos to come up with their official Speedgate logo.Read the full story here>>