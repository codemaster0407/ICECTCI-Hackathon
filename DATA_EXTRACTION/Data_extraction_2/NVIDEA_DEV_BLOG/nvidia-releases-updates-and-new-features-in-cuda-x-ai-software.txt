NVIDIA CUDA-X AI is a deep learning software stack for researchers and software developers to build high performance GPU-accelerated applications for conversational AI, recommendation systems, and computer vision.Learn what’s new in the latest releases of the CUDA-X AI tools and libraries. For more information on NVIDIA’s developer tools, join live webinars, training, and “Connect with the Experts” sessions at NVIDIA GTC.Refer to each package’s release notes in documentation for additional information.NVIDIA Triton™ Inference Server is open source inference serving software that brings fast and scalable AI models to applications in production. It supports every framework, runs on every GPU- or CPU-based infrastructure on-premises, in the cloud and at the edge. Updates include: Download >>TensorRT is a platform for high-performance deep learning inference. This version includes:Get Started >>NVIDIA NeMo is an open-source toolkit for developing state-of-the-art conversational AI models. NVIDIA shared new speech processing research and tutorials using NeMo at Interspeech 2021, including: For links to all accepted research visit the NVIDIA Interspeech event page.Access additional tutorials from the NeMo GitHub repository and the NVIDIA Developer Blog.Download >>Maxine provides accelerated real-time video effects (VFX), audio effects (AFX), and augmented reality (AR) SDKs with state-of-the-art AI-based features for building virtual collaboration and content creation applications. Highlights from this release include:Get Started >>The NGC catalog is a hub of GPU-optimized containers, pretrained models, SDKs, and Helm charts designed to accelerate end-to-end AI workflows. Updates include:Explore NGC >>