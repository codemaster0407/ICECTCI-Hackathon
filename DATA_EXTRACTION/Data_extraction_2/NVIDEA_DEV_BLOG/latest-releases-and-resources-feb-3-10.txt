Our weekly roundup covers the most recent software updates, learning resources, events, and notable news. Software releasesThe redesigned nvCOMP 2.2.0 interface provides a single nvcompManagerBase object that can do compression and decompression. Users can now decompress nvcomp-compressed files without knowing how they were compressed. The interface also can manage scratch space and split the input buffer into independent chunks for parallel processing.What’s new:Download now: nvCOMP version 2.2.0CoursesThis free, 30 minute, online course is self paced and includes a sample notebook from the NGC TAO Toolkit—Conversational AI collection, complete with a live GPU environment.Learn more: Deploy a Text Classification Model Using Riva In this free one-hour course, participants will work through a demonstration of a common vehicle routing optimization problem at their own pace. Upon completion, participants will be able to preprocess input data for use by NVIDIA ReOpt routing solver, and compose variants of the problem that reflect real-world business constraints.Register online: Optimized Vehicle RoutingThis Deep Learning Institute workshop teaches you the fundamental tools and techniques for running GPU-accelerated Python applications using CUDA GPUs and the Numba compiler. This workshop is being offered Feb, 23 from 9 am to 5 pm PT.At the conclusion of the workshop, you’ll have an understanding of the fundamental tools and techniques for GPU-accelerated Python applications with CUDA and Numba, including:Register online: Fundamentals of Accelerated Computing with CUDA PythonWebinars Join NVIDIA experts at developer meetups Feb. 16 and 17, and find out how the Metropolis program can grow your vision AI business and enhance go-to-market efforts​.Learn how:Register online: How the NVIDIA Metropolis Program will Supercharge Your BusinessDive into NVIDIA inference solutions, including open-source NVIDIA Triton Inference Server and NVIDIA TensorRT, with a webinar and live Q&A, Feb. 23 at 10 a.m. PT. Learn how: Register online: A Flexible Solution for Every AI Inference Deployment