Learn what’s new in the latest releases of NVIDIA’s CUDA-X Libraries and NGC.NVIDIA Neural Modules is a new open-source toolkit for researchers to build state-of-the-art neural networks for AI accelerated speech applications. Early release of the toolkit includes:Download NowNVIDIA TensorRT is a platform for high-performance deep learning inference. This version of TensorRT includes:Download NowNVIDIA CUDA Deep Neural Network library (cuDNN) is a GPU-accelerated library of primitives for deep neural networks. This version of cuDNN includes:Download NowNGC provides containers, models and scripts with the latest performance enhancements. This month’s updates include:NVIDIA TensorRT Inference Server is an open source inference microservice that lets you serve deep learning models in production while maximizing GPU utilization. This version of TensorRT Inference Server includes:Download NowRefer to each package’s release notes for additional information.