This week’s Spotlight is on Diego Rivera, a senior software engineer at Hologic, Inc. Hologic is a leading developer of medical imaging systems and surgical products, with an emphasis on serving the healthcare needs of women throughout the world.NVIDIA: Diego, tell us about your role at Hologic.
Diego: I’m part of a team that has been able to deliver great solutions for breast cancer detection. I’m a lead engineer in design and implementation of GPU-accelerated high-performance applications in the areas of tomosynthesis (3D-mammography), digital mammography, computer-aided design, and specimen radiography systems.NVIDIA: What are some key challenges in your field?
Diego: With all the advantages of the digital era, film-based mammography has not yet vanished. Introducing a new modality such as tomosynthesis is challenging because the new capabilities have also led to new image management requirements (in areas such as storage, image reviewing and vendor viewing interoperability).Despite the challenges, the tomosynthesis modality has proved more advantageous in early detection of cancer cases than the usage of standard digital images and has the potential of reducing the number of false positives. Our goal is to enable everyone to embrace this medium.NVIDIA: What role does GPU computing play in your work?
Diego: It has allowed us to process and reprocess images in real time. The impact of this is that there is no wait time added for screening and diagnostic results, which in turn minimizes the patient’s anxiety.One of our objectives is to improve the patient experience by controlling dose and time in compression without sacrificing image quality. Real-time tomosynthesis would simply not be possible without GPUs. Our solution is deployed in a variety of hospitals and health care centers, including Massachusetts General Hospital and Bethesda Women’s Health Center.NVIDIA: What specific approaches did you use to apply the CUDA platform to your work?
 Diego: It depends on the problem. It can go from simple porting to finding a perfect balance among our computational units. In the end, it is all about thinking in parallel; taking yourself out of the sequential world and discovering different ways to look at a problem.Some of our algorithms are memory bounded. Through texturing and data layout optimizations for memory access, we have been able to get up to 248X faster than our baseline CPU code.We heavily use texture memory throughout our implementations because of its read performance and the graphical interoperability requirements of our solutions. The texture objects introduced in CUDA 5.0 have greatly improved our code development.In addition, NVIDIA Nsight analysis activity has helped us to graphically identify algorithmic slots, where we have tuned CPU/GPU co-scheduling through OpenMP/CUDA.NVIDIA: How did you first learn about CUDA?
 Diego: It was back in 2007, after the first release of CUDA. An email from my advisor, Dr. David Kaeli of Northeastern University, arrived in my inbox asking who wanted to do something cool with GPUs. I said yes! Then I fell in love with the huge potential of GPU computing.NVIDIA: Do you have advice for young people considering an engineering career?
Diego: Do you want to have fun? Do you want to feel your brain making new connections while solving a problem? Then be an engineer.Specifically, knowing about GPUs — and “thinking parallel” — can open a universe of opportunities where your knowledge will be important and appreciated. Plus it’s a great feeling to know that your work is making a difference in the world.Read more GPU Computing Spotlights.