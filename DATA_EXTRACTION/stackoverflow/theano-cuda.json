[
    {
        "question": "enter image description here I don't know how to solve the problem, although I searched google. My computer OS is win10. And following installed in a virtual environment. enter image description here enter image description here UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version &gt;= v5 and &lt;= v7. warnings.warn(\"Your cuDNN version is more recent than \" ERROR (theano.gpuarray): Could not initialize pygpu, support disabled RuntimeError: Could not load cudnn library. Check your cudnn installation. Maybe using the Theano flag dnn.base_path can help you. Current value \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1\"",
        "answers": [
            [
                "I had the same problem, and I solved it like this: Open dnn.py. (My path is : F:\\Anaconda3\\envs\\python2_7\\Lib\\site-packages\\theano) Add 'cudnn64_8.dll' in WIN32_CUDNN_NAMES. WIN32_CUDNN_NAMES = ['cudnn64_8.dll', 'cudnn64_7.dll', 'cudnn64_6.dll', 'cudnn64_5.dll']"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I installed cuda and cudnn following the instructions here: https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html following that I set up a conda environment with python3.8 and installed theano 1.0.4. Then I createa a .theanorc in my home directory: [global] floatX = float32 device = cuda0 force_device = True optimizer_including=cudnn [blas] ldflags = -L/usr/local/lib -lopenblas [dnn] include_path=/usr/local/cuda-11.3/include library_path=/usr/local/cuda-11.3/lib64 [cuda] root=/usr/local/cuda-11.3/ Since at first theano complained that it couldn't find cudnn.h, I linked all the cudnn stuff into the /usr/local/cuda-11.3/ directory. Following that I tried import theano in my python session, but I got: Can not use cuDNN on context None: cannot compile with cuDNN. We got this error: b\"/home/hadron/myutils/anaconda3/envs/myenv/bin/../lib/gcc/x86_64-conda_cos6-linux-gnu/7.3.0/../../../../x86_64-conda_cos6-linux-gnu/bin/ld: /usr/local/cuda-11.3/lib64/libcudnn.so: undefined reference to `memcpy@GLIBC_2.14'\\ncollect2: error: ld returned 1 exit status\\n\" and now I'm stuck here. Anyone can help? This is the output of nvidia-smi: (myenv) hadronmachine:~$ nvidia-smi Mon Apr 19 10:43:37 2021 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 465.19.01 Driver Version: 465.19.01 CUDA Version: 11.3 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce ... On | 00000000:01:00.0 Off | N/A | | 0% 38C P8 7W / 210W | 72MiB / 8119MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 0 N/A N/A 1080 G /usr/lib/xorg/Xorg 70MiB | +-----------------------------------------------------------------------------+ I am running ubuntu 20.04 and the output of uname -a is: Linux hadron01 5.4.0-53-generic #59-Ubuntu SMP Wed Oct 21 09:38:44 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux Ultimately I want to run Pymc3 w/ GPU support, which uses Theano as backend",
        "answers": [],
        "votes": []
    },
    {
        "question": "As the title clearly describes the situation I'm facing, I'm getting the following warning on Google Colab while using the Theano as the backend of Keras: WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library. So, how can I provide the the dynamic library used for blas for Theano on Google Colab? p.s. I've already installed the Theano package. The libgpuarray, and pygpu packages according to the official documentation. Software Stack: Keras version: 2.3.1. Python version: 3.6.9. Theano version: 1.0.4.",
        "answers": [
            [
                "could you try this? !wget -c https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh !chmod +x Anaconda3-5.1.0-Linux-x86_64.sh !bash ./Anaconda3-5.1.0-Linux-x86_64.sh -b -f -p /usr/local import sys sys.path.append('/usr/local/lib/python3.6/site-packages/') #install theano and pygpu !conda install theano pygpu It downloads a host of dependencies which are used for theano."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "This question is for Python2.7 with Keras as a front end. I have Microsoft Visual Studio 2017 and I believe I have all the tools it needs. I followed the instructions on install CUDA. I believe it is version 10, and I think it is installed correctly. I followed the tutorial video and got a similar result at the end for the sample test. I have now moved on to installing libgpuarray. I have completed the following steps and got this error: C:\\Windows\\system32&gt;cd C:\\Users\\Never\\Downloads\\libgpuarray C:\\Users\\Never\\Downloads\\libgpuarray&gt;cd Build C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;cmake .. -DCMAKE_BUILD_TYPE=Release -- Building for: Visual Studio 15 2017 -- The C compiler identification is MSVC 19.16.27034.0 -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x86/cl.exe -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.16.27023/bin/Hostx86/x86/cl.exe -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done CMake Deprecation Warning at CMakeLists.txt:26 (cmake_policy): The OLD behavior for policy CMP0063 will be removed from a future version of CMake. The cmake-policies(7) manual explains that the OLD behaviors of all policies are deprecated and that a policy should be set to OLD only under specific short-term circumstances. Projects should be ported to the NEW behavior and not rely on setting a policy to OLD. -- Looking for strlcat -- Looking for strlcat - not found -- Looking for mkstemp -- Looking for mkstemp - not found -- Found PkgConfig: C:/MinGW_w64/bin/pkg-config.exe (found version \"0.25\") -- Checking for one of the modules 'check' Tests disabled because Check was not found -- Configuring done -- Generating done CMake Warning: Manually-specified variables were not used by the project: CMAKE_BUILD_TYPE -- Build files have been written to: C:/Users/Never/Downloads/libgpuarray/Build I tried running C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;make next but it returned: 'make' is not recognized as an internal or external command,operable program or batch file. There is a make script in the folder above so I tried using it, with this result: C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;C:\\Users\\Never\\Downloads\\libgpuarray\\make.bat C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;REM This helps repetitive builds on windows C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;REM It needs the compiler you want to use to be available in the shell C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;REM and it will build a release version C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;del bld Could Not Find C:\\Users\\Never\\Downloads\\libgpuarray\\Build\\bld C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;mkdir bld C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;cd bld C:\\Users\\Never\\Downloads\\libgpuarray\\Build\\bld&gt;cmake .. -G \"NMake Makefiles\" -DCMAKE_BUILD_TYPE=Release CMake Error: Error: generator : NMake Makefiles Does not match the generator used previously: Visual Studio 15 2017 Either remove the CMakeCache.txt file and CMakeFiles directory or choose a different binary directory. C:\\Users\\Never\\Downloads\\libgpuarray\\Build\\bld&gt;cmake --build . --config Release Error: could not load cache C:\\Users\\Never\\Downloads\\libgpuarray\\Build\\bld&gt;cd .. I am not 100% sure what to do next. I don't want to tinker and break things further, any assistance would be appreciated, thank you.",
        "answers": [
            [
                "It looks like you are following the Linux instructions in the tutorial you linked. You should probably take a look at the Windows-specific instructions, considering you are building on Windows with Visual Studio. It sounds like you may have corrupted your CMake cache a bit by running the make.bat file, so it's probably best to delete your Build folder and start over: C:\\Users\\Never\\Downloads\\libgpuarray&gt;mkdir Build &amp;&amp; cd Build C:\\Users\\Never\\Downloads\\libgpuarray\\Build&gt;cmake .. From there, just follow the Windows-specific guidelines from the tutorial: It will generate a Visual Studio solution file for the version installed. To build the project open this file (.sln) and run the \u201cBuild All\u201d command after selecting the appropriate build type."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "While I am trying to call as_cuda_ndarray_variable function from from theano.sandbox.cuda that is wrote on separate basic_ops.pypython file that is called inside the init.py file. My python-2.7.16 andtheano-0.9.0. from theano.sandbox.cuda import as_cuda_ndarray_variable ImportError: cannot import name as_cuda_ndarray_variable",
        "answers": [
            [
                "Maybe you can try this: from theano.sandbox.cuda import * as cuda_ndarray_variable or import theano.sandbox.cuda as cuda_ndarray_variable"
            ],
            [
                "It appears that the function as_cuda_ndarray_variable is not defined directly within the theano.sandbox.cuda module. Try this instead: from theano.sandbox.cuda import basic_ops basic_ops.as_cuda_ndarray_variable(1.0) See the example here: http://deeplearning.net/software/theano/tutorial/using_gpu.html"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "What i want To run a simple python script like the following, but instead of the CPU I want it to use the GPU: import theano def some_convolutional_neural_network(): #Insert (theano) code here What I would like is a comprehensive instruction on how to achieve this, as the theano documentation is pretty complicated. For me and future readers, it would be nice if such a heuristic description was available. What i've tried First of all I've followed the Installation instructions for windows. Then I tried to enable theano to use my GPU. I've found a partial answer here and it seems the way to go is to either modify the environment variable THEANO_FLAGS or a configuration file called .theanorc is a configuration file. However, the documentation is unclear to me and I cannot find the environment var nor the config file anywhere. Any help would be greatly appreciated as I am rather stuck here. My specs: I am on windows 10, and I have a GeForce GTX 650 Ti.",
        "answers": [],
        "votes": []
    },
    {
        "question": "Under Windows 10, after successfully installing tensorflow gpu, and keras gpu, I installed theano gpu using: conda install theano pygpu Everything still worked fine, tensorflow gpu, keras gpu, etc. I ran simple example in theano, and on executing the line in jupyter, import numpy import theano.tensor as T from theano import function it gives a warning: WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain` C:\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory warnings.warn(\"DeprecationWarning: there is no c++ compiler.\" WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string. WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions. So I decided to install g++ using conda as it suggested: conda install m2w64-toolchain Now, when I run the same line in theano, import numpy import theano.tensor as T I get an error: You can find the C code in this temporary file: C:\\Users\\IVANFI~1\\AppData\\Local\\Temp\\theano_compilation_error_fq4oz7pp --------------------------------------------------------------------------- ImportError Traceback (most recent call last) C:\\Anaconda3\\lib\\site-packages\\theano\\gof\\lazylinker_c.py in &lt;module&gt;() 80 version, ---&gt; 81 actual_version, force_compile, _need_reload)) 82 except ImportError: ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True During handling of the above exception, another exception occurred: ImportError Traceback (most recent call last) C:\\Anaconda3\\lib\\site-packages\\theano\\gof\\lazylinker_c.py in &lt;module&gt;() 104 version, --&gt; 105 actual_version, force_compile, _need_reload)) 106 except ImportError: ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True During handling of the above exception, another exception occurred: Exception Traceback (most recent call last) &lt;ipython-input-12-29f575dfe616&gt; in &lt;module&gt;() 1 import numpy ----&gt; 2 import theano.tensor as T C:\\Anaconda3\\lib\\site-packages\\theano\\__init__.py in &lt;module&gt;() 108 object2, utils) 109 --&gt; 110 from theano.compile import ( 111 SymbolicInput, In, 112 SymbolicOutput, Out, C:\\Anaconda3\\lib\\site-packages\\theano\\compile\\__init__.py in &lt;module&gt;() 10 from theano.compile.function_module import * 11 ---&gt; 12 from theano.compile.mode import * 13 14 from theano.compile.io import * C:\\Anaconda3\\lib\\site-packages\\theano\\compile\\mode.py in &lt;module&gt;() 9 import theano 10 from theano import gof ---&gt; 11 import theano.gof.vm 12 from theano import config 13 from six import string_types C:\\Anaconda3\\lib\\site-packages\\theano\\gof\\vm.py in &lt;module&gt;() 672 if not theano.config.cxx: 673 raise theano.gof.cmodule.MissingGXX('lazylinker will not be imported if theano.config.cxx is not set.') --&gt; 674 from . import lazylinker_c 675 676 class CVM(lazylinker_c.CLazyLinker, VM): C:\\Anaconda3\\lib\\site-packages\\theano\\gof\\lazylinker_c.py in &lt;module&gt;() 138 args = cmodule.GCC_compiler.compile_args() 139 cmodule.GCC_compiler.compile_str(dirname, code, location=loc, --&gt; 140 preargs=args) 141 # Save version into the __init__.py file. 142 init_py = os.path.join(loc, '__init__.py') C:\\Anaconda3\\lib\\site-packages\\theano\\gof\\cmodule.py in compile_str(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols) 2394 # difficult to read. 2395 raise Exception('Compilation failed (return status=%s): %s' % -&gt; 2396 (status, compile_stderr.replace('\\n', '. '))) 2397 elif config.cmodule.compilation_warning and compile_stderr: 2398 # Print errors just below the command line. . collect2.exe: error: ld returned 1 exit statusompiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_158_Stepping_9_GenuineIntel-3.6.6-64/lazylinker_ext/mod.cpp:976: undefined reference to `__imp__Py_TrueStruct'Error'e undefined references to `__imp__Py_NoneStruct' followow Removing it conda remove m2w64-toolchain Doesn't help. It seems like theano is now permanently damaged. How do I restore theano to working?",
        "answers": [
            [
                "To revert to the original NumPy based mode just config theano not to use compiler. Create C:\\\\Users\\\\username\\\\.theanorc.txt file with: [global] cxx= More about theano config"
            ],
            [
                "I was losing hours on that topic. First, make sure Theano works on the ordinary CPU, using a compiler. Using m2w64-toolchain repeatedly killed the complete anaconda setup concerning theano. You will not only have to uninstall Anaconda, but also all artifacts which are left. The article from Xavier Dupr\u00e9 put me on the right track. So for CPU only just use conda install commands: conda install -c anaconda libpython conda install -c anaconda mingw conda install -c anaconda Theano conda install -c anaconda pymc3 at least then you have a proper compiling environment. BR, Alex"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I was trying to run this repository: https://github.com/WaqasSultani/AnomalyDetectionCVPR2018 In the Test_Anomaly_Detector_public.py I am stuck with error:theano.sandbox.cuda.use('gpu0') AttributeError: 'module' object has no attribute 'cuda'. I am using theano as backend This is Test_Anomaly_Detector_public.py: from keras.models import Sequential from keras.layers import Dense, Dropout, Activation from keras.regularizers import l2 from keras.optimizers import SGD ,Adagrad from scipy.io import loadmat, savemat from keras.models import model_from_json import theano.tensor as T import theano import csv import ConfigParser import collections import time import csv import os from os import listdir import skimage.transform from skimage import color from os.path import isfile, join import numpy as np import numpy from datetime import datetime from scipy.spatial.distance import cdist,pdist,squareform import theano.sandbox import shutil theano.sandbox.cuda.use('gpu0') seed = 7 numpy.random.seed(seed) def load_model(json_path): # Function to load the model model = model_from_json(open(json_path).read()) return model def load_weights(model, weight_path): # Function to load the model weights dict2 = loadmat(weight_path) dict = conv_dict(dict2) i = 0 for layer in model.layers: weights = dict[str(i)] layer.set_weights(weights) i += 1 return model def conv_dict(dict2): i = 0 dict = {} for i in range(len(dict2)): if str(i) in dict2: if dict2[str(i)].shape == (0, 0): dict[str(i)] = dict2[str(i)] else: weights = dict2[str(i)][0] weights2 = [] for weight in weights: if weight.shape in [(1, x) for x in range(0, 5000)]: weights2.append(weight[0]) else: weights2.append(weight) dict[str(i)] = weights2 return dict # Load Video def load_dataset_One_Video_Features(Test_Video_Path): VideoPath =Test_Video_Path f = open(VideoPath, \"r\") words = f.read().split() num_feat = len(words) / 4096 # Number of features per video to be loaded. In our case num_feat=32, as we divide the video into 32 segments. Note that # we have already computed C3D features for the whole video and divided the video features into 32 segments. count = -1; VideoFeatues = [] for feat in xrange(0, num_feat): feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096]) count = count + 1 if count == 0: VideoFeatues = feat_row1 if count &gt; 0: VideoFeatues = np.vstack((VideoFeatues, feat_row1)) AllFeatures = VideoFeatues return AllFeatures print(\"Starting testing...\") AllTest_Video_Path = '/newdata/UCF_Anomaly_Dataset/Dataset/CVPR_Data/C3D_Complete_Video_txt/Test/' # AllTest_Video_Path contains C3D features (txt file) of each video. Each file contains 32 features, each of 4096 dimensions. Results_Path = '../Eval_Res/' # Results_Path is the folder where you can save your results Model_dir='../Trained_AnomalyModel/' # Model_dir is the folder where we have placed our trained weights weights_path = Model_dir + 'weights_L1L2.mat' # weights_path is Trained model weights model_path = Model_dir + 'model.json' if not os.path.exists(Results_Path): os.makedirs(Results_Path) All_Test_files= listdir(AllTest_Video_Path) All_Test_files.sort() model=load_model(model_path) load_weights(model, weights_path) nVideos=len(All_Test_files) time_before = datetime.now() for iv in range(nVideos): Test_Video_Path = os.path.join(AllTest_Video_Path, All_Test_files[iv]) inputs=load_dataset_One_Video_Features(Test_Video_Path) # 32 segments features for one testing video predictions = model.predict_on_batch(inputs) # Get anomaly prediction for each of 32 video segments. aa=All_Test_files[iv] aa=aa[0:-4] A_predictions_path = Results_Path + aa + '.mat' # Save array of 1*32, containing anomaly score for each segment. Please see Evaluate Anomaly Detector to compute ROC. print \"Total Time took: \" + str(datetime.now() - time_before) My .theanorc file: [global] floatX = float32 device = cuda0 [gpuarray] preallocate = 1",
        "answers": [
            [
                "You can comment out this line. When you run please follow this THEANO_FLAGS=mode=FAST_RUN,device=cuda0,floatX=float32 python [...]"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'm using theano gpu on Google Colab and I get this error: ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.7 or higher required) I've set: import os os.environ[\"THEANO_FLAGS\"]=\"device=cuda, floatX=float32\" And changed the runtime type to hardware accelerator 'GPU' Could you please help me solving this issue? Thank you.",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am trying to execute this Github repository. When I run the build.sh file, I get the following error: gcc version is :gcc version 4.6.3 (Ubuntu/Linaro 4.6.3-1ubuntu5) nvidia-smi:NVIDIA-SMI 340.24 Driver Version: 340.24 Nvidia geforce 820 with computability is 2.1. rc/weight_acts.cu(1289): error: type name is not allowed src/weight_acts.cu(1290): error: type name is not allowed src/weight_acts.cu(1291): error: type name is not allowed src/weight_acts.cu(1292): error: type name is not allowed src/weight_acts.cu(1293): error: type name is not allowed src/weight_acts.cu(1294): error: type name is not allowed src/weight_acts.cu(1325): error: type name is not allowed src/weight_acts.cu(1325): warning: expression has no effect src/weight_acts.cu(1213): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=false, checkCaseBounds=false]\" (2214): here src/weight_acts.cu(1289): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=false, checkCaseBounds=false]\" (2214): here src/weight_acts.cu(1290): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=false, checkCaseBounds=false]\" (2214): here src/weight_acts.cu(1291): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=false, checkCaseBounds=false]\" (2214): here src/weight_acts.cu(1292): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=false, checkCaseBounds=false]\" (2214): here src/weight_acts.cu(1293): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=false, checkCaseBounds=false]\" (2214): here src/weight_acts.cu(1294): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=false, checkCaseBounds=false]\" (2214): here src/weight_acts.cu(1048): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1049): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1051): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1052): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1054): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1055): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1057): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1058): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_2_f_4_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=2, filtersPerThread=4, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2476): here src/weight_acts.cu(1213): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2480): here src/weight_acts.cu(1289): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2480): here src/weight_acts.cu(1290): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2480): here src/weight_acts.cu(1291): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2480): here src/weight_acts.cu(1292): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2480): here src/weight_acts.cu(1293): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2480): here src/weight_acts.cu(1294): warning: expression has no effect detected during instantiation of \"void conv_weight_acts_c_preload_pc_2_pt_4_f_3_r_32_c_3&lt;B_Y,B_X,pixelCache,pixelsPerThread,filtersPerThread,preloadCases,numColors,scale,checkCaseBounds&gt;(cudaTextureObject_t, cudaTextureObject_t, float *, int, int, int, int, int, int, int, int, int, int, int, float, float) [with B_Y=16, B_X=16, pixelCache=2, pixelsPerThread=4, filtersPerThread=3, preloadCases=32, numColors=3, scale=true, checkCaseBounds=false]\" (2480): here 61 errors detected in the compilation of \"/tmp/tmpxft_00001ed4_00000000-6_weight_acts.cpp1.ii\". 27 errors detected in the compilation of \"/tmp/tmpxft_00001ed5_00000000-6_filter_acts.cpp1.ii\". make: *** [obj/release/./src/weight_acts.cu.o] Error 2 make: *** [obj/release/./src/filter_acts.cu.o] Error 2 30 errors detected in the compilation of \"/tmp/tmpxft_00001ed3_00000000-6_img_acts.cpp1.ii\". make: *** [obj/release/./src/img_acts.cu.o] Error 2 --- cudaconvnet build.sh: 59: cd: can't cd to cudaconvnet --- make-data/pyext build.sh: 61: cd: can't cd to make-data/pyext BTW, I am using Cuda 6.0 on Ubuntu 12.04.",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm trying to run the this theano test and I'm having problems with my cudnn path. I remember passing the tests after installing cudnn but it seems that theano cannot find the path to cudnn. Is this an enviroment variable problem? Does anyone have a solution for it? whereis cuda gives me cuda: /usr/include/cuda.h /usr/local/cuda Running the test with THEANO_FLAGS=device=cuda0 MKL_THREADING_LAYER=GNU python test.py gives me ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/home/lucas/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 220, in &lt;module&gt; use(config.device) File \"/home/lucas/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 207, in use init_dev(device, preallocate=preallocate) File \"/home/lucas/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 110, in init_dev context.cudnn_handle = dnn._make_handle(context) File \"/home/lucas/miniconda2/lib/python2.7/site-packages/theano/gpuarray/dnn.py\", line 124, in _make_handle cudnn = _dnn_lib() File \"/home/lucas/miniconda2/lib/python2.7/site-packages/theano/gpuarray/dnn.py\", line 111, in _dnn_lib config.dnn.base_path) RuntimeError: Could not load cudnn library. Check your cudnn installation. Maybe using the Theano flag dnn.base_path can help you. Current value \"/usr\" [Elemwise{exp,no_inplace}(&lt;TensorType(float64, vector)&gt;)] Looping 1000 times took 3.294467 seconds Result is [1.23178032 1.61879341 1.52278065 ... 2.20771815 2.29967753 1.62323285] Used the cpu",
        "answers": [
            [
                "As the error sugested, I had to include the cudnn path in the THEANO FLAGS. That can be done in two ways: (1) Inline: THEANO_FLAGS=\"device=cuda0, dnn.base_path=/usr/local/cuda\" MKL_THREADING_LAYER=GNU python test.py or (2) including in the theano config file ~/.theanorc the following lines: [dnn] include_path = /usr/lib/cuda/include library_path = /usr/lib/cuda/lib64 I hope this helps someone else."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have installed theano using miniconda: conda install theano This installed libgpuarray: 0.7.6-h14c3975_0 mkl-service: 1.1.2-py27hb2d42c5_4 pygpu: 0.7.6-py27h3010b51_0 theano: 1.0.2-py27h6bb024c_0 I then run my program and get the message: Could not initialize pygpu, support disable [...] File \"pygpu/gpuarray.pyx\", line 658, in pygpu.gpuarray.init File \"pygpu/gpuarray.pyx\", line 587, in pygpu.gpuarray.pygpu_init GpuArrayException: Could not load \"libcuda.so\": libcuda.so: cannot open shared object file: No such file or directory So it cannot find libcuda. I get a similar message if I do python import pygpu pygpu.test() I've got a cuda installation in /opt/cuda. libcuda.so is there, under /opt/cuda/lib64. I have tried addign /opt/cuda/lib64 to my LD_LIBRARY_PATH without success. I have also tried multiple previous versions of theano and pygpu. It is still laughing in my face. It has been a few good hours of going back and forth without success.",
        "answers": [],
        "votes": []
    },
    {
        "question": "(theano_p27) ubuntu@ip-***-**-**-***:~$ device=cuda0,floatX=float32 GPUARRAY_CUDA_VERSION=80 python test.py WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions. ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/home/ubuntu/anaconda3/envs/theano_p27/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 227, in &lt;module&gt; use(config.device) File \"/home/ubuntu/anaconda3/envs/theano_p27/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 214, in use init_dev(device, preallocate=preallocate) File \"/home/ubuntu/anaconda3/envs/theano_p27/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 99, in init_dev **args) File \"pygpu/gpuarray.pyx\", line 658, in pygpu.gpuarray.init File \"pygpu/gpuarray.pyx\", line 587, in pygpu.gpuarray.pygpu_init GpuArrayException: cuInit: CUDA_ERROR_UNKNOWN: unknown error [Elemwise{exp,no_inplace}(&lt;TensorType(float32, vector)&gt;)] Looping 1000 times took 2.717710 seconds Result is [1.2317803 1.6187934 1.5227807 ... 2.2077181 2.2996776 Used the cpu I am trying to use Amazon Web Services EC2 to run a GPU and I am getting this error when I am trying to run a test to get my code to run my gnu but its giving me this error. Please help Edit: The code I am running is the test code from the Theano website from theano import function, config, shared, tensor import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], tensor.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, tensor.Elemwise) and ('Gpu' not in type(x.op).__name__) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu')",
        "answers": [
            [
                "In response to the followup comments. In order to configure and use an GPU on AWS with the Deep Learning AMI the following instances are recommended (source): Amazon EC2 P3 Instances have up to 8 NVIDIA Tesla V100 GPUs. Amazon EC2 P2 Instances have up to 16 NVIDIA NVIDIA K80 GPUs. Amazon EC2 G3 Instances have up to 4 NVIDIA Tesla M60 GPUs. Check out EC2 Instance Types and choose Accelerated Computing to see the different GPU instance options. In addition you can try Elastic GPUs. Finally, it order to use GPU instances you typically needed to install the appropriate drivers from the Nvidia site. Review the quoted text above for the GPU type. Download the driver and run it; for example: ./NVIDIA-Linux-x86_64-384.81.run You can also pass the -silent flag to install it with config management or otherwise. Also, keep in mind that you must install the drivers on the instance size you intend to use. If you create an AMI image where you installed the drivers on a p3.2xlarge and then try to run something on a p3.8xlarge you will likely need to re-install the drivers."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I suspect google colab is not using GPU, if I use theano as backend with Keras. Same code trains at the rate of ~4min per epoc, if back end is Tensorflow, but takes 7 hours per epoc with theano as back end. I did following steps to modify keras configuration !cp .keras/keras.json .keras/keras.json.tf !cp drive/MachineLearning/kerasJson/keras.json .keras/keras.json !cat .keras/keras.json keras.json for theano looks like { \"floatx\": \"float32\", \"epsilon\": 1e-07, \"backend\": \"theano\", \"image_dim_ordering\": \"th\", \"image_data_format\": \"channels_first\" } keras.json for tensorflow looks like { \"floatx\": \"float32\", \"epsilon\": 1e-07, \"backend\": \"tensorflow\", \"image_data_format\": \"channels_last\" } With theano backend same code timing looks like drive/MachineLearning/data/NLP/keras_spell_e2.h5 /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:268: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(&lt;generator..., steps_per_epoch=100, epochs=500, verbose=1, callbacks=[&lt;__main__..., validation_data=&lt;generator..., validation_steps=10, class_weight=None, workers=1, initial_epoch=0, use_multiprocessing=False, max_queue_size=10)` Epoch 1/500 2/100 [..............................] - ETA: 6:58:52 - loss: 0.5325 - acc: 0.4895 But with tensorflow, it takes 4-5 min drive/MachineLearning/data/NLP/keras_spell_e2.h5 /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:268: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(&lt;generator..., steps_per_epoch=100, epochs=500, verbose=1, callbacks=[&lt;__main__..., validation_data=&lt;generator..., validation_steps=10, class_weight=None, workers=1, initial_epoch=0, use_multiprocessing=False, max_queue_size=10)` Epoch 1/500 14/100 [===&gt;..........................] - ETA: 3:45 - loss: 0.5161 - acc: 0.4998 Any help?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have some complicated formula, which is easier to implement directly using CUDA code. On the other hand, I need to make use of the theano feature to build a neural network and train it separately. How can I safely use pycuda and theano together? The following code works on my machine: import numpy as np import pycuda.autoinit as cuauto import pycuda.driver as cuda import pycuda.compiler as cudacc import pycuda.gpuarray as gpuarray import theano import theano.tensor as T def get_pycuda_func(): mod = cudacc.SourceModule(\"\"\" __global__ void mul(double *dest, double *a, double *b) { const int i = threadIdx.x; dest[i] = a[i] * b[i]; } \"\"\") mul = mod.get_function(\"mul\") mul.prepare(\"PPP\") def f(a,b): N = len(a) gpu_a = gpuarray.to_gpu(a) gpu_b = gpuarray.to_gpu(b) c = gpuarray.empty((N,),dtype=np.float64) mul.prepared_call( (1,1,1),(N,1,1), c.gpudata, gpu_a.gpudata, gpu_b.gpudata ) return c.get() return f def get_theano_func(): a = T.vector('a') b = T.vector('b') c = a*b f = theano.function([a,b],c,allow_input_downcast=True) return f def get_cpu_func(): def f(a,b): return a*b return f if __name__ == \"__main__\": np.random.seed(12345) a = np.random.randn(400) b = np.random.randn(400) f_cuda = get_pycuda_func() f_cpu = get_cpu_func() f_theano = get_theano_func() for k in range(10): x = f_cuda(a,b) y = f_theano(a,b) z = f_cpu(a,b) print(k) print(np.allclose(x,z)) print(np.allclose(y,z)) Output: $ python3 test_theano_pycuda_simpler.py Using cuDNN version 7003 on context None Mapped name None to device cuda: GeForce GTX TITAN Black (0000:01:00.0) 0 True True 1 True True 2 True True 3 True True 4 True True 5 True True 6 True True 7 True True 8 True True 9 True True But if I make a more complicated theano computation, it does not work. The following DOES NOT WORK: import numpy as np import pycuda.autoinit as cuauto import pycuda.driver as cuda import pycuda.compiler as cudacc import pycuda.gpuarray as gpuarray import theano import theano.tensor as T def get_pycuda_func(): mod = cudacc.SourceModule(\"\"\" __global__ void mul(double *dest, double *a, double *b) { const int i = threadIdx.x; dest[i] = a[i] * b[i]; } \"\"\") mul = mod.get_function(\"mul\") mul.prepare(\"PPP\") def f(a,b): N = len(a) gpu_a = gpuarray.to_gpu(a) gpu_b = gpuarray.to_gpu(b) c = gpuarray.empty((N,),dtype=np.float64) mul.prepared_call( (1,1,1),(N,1,1), c.gpudata, gpu_a.gpudata, gpu_b.gpudata ) return c.get() return f floatX=theano.config.floatX def init_bias(size): tmp = np.random.rand(size) return theano.shared(np.asarray(tmp,dtype=floatX)) def init_weights(in_size,out_size): s = np.sqrt(2./(in_size+out_size)) tmp = np.random.normal(loc=0.,scale=s,size=(in_size,out_size)) return theano.shared(np.asarray(tmp,dtype=floatX)) def adam(params, gparams,learning_rate = 0.0001, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8): updates = [] t_pre = theano.shared(np.asarray(.0, dtype=theano.config.floatX)) t = t_pre + 1 a_t = learning_rate * T.sqrt(1 - beta2 ** t) / (1 - beta1 ** t) for (p,g) in zip(params, gparams): v = p.get_value(borrow = True) m_pre = theano.shared(np.zeros(v.shape, dtype = v.dtype), broadcastable = p.broadcastable) v_pre = theano.shared(np.zeros(v.shape, dtype = v.dtype), broadcastable = p.broadcastable) m_t = beta1 * m_pre + (1 - beta1) * g v_t = beta2 * v_pre + (1 - beta2) * g ** 2 step = a_t * m_t / (T.sqrt(v_t) + epsilon) p_update = p - step updates.append((m_pre, m_t)) updates.append((v_pre, v_t)) updates.append((p, p_update)) updates.append((t_pre, t)) return updates class test_network: def __init__(self,hidden=[100,100]): self.hidden = hidden self._create_params() self._create_train_func() self._create_func() def _create_params(self): hidden = self.hidden W0 = init_weights(1,hidden[0]) W1 = init_weights(hidden[0],hidden[1]) W2 = init_weights(hidden[1],1) b0 = init_bias(hidden[0]) b1 = init_bias(hidden[1]) b2 = init_bias(1) self.params = [ W0,W1,W2, b0,b1,b2, ] def predict(self,x): [ W0,W1,W2, b0,b1,b2, ] = self.params H0 = T.dot(x,W0) + b0 H0 = T.nnet.relu(H0) H1 = T.dot(H0,W1) + b1 H1 = T.nnet.relu(H1) ret = T.dot(H1,W2) + b2 return ret def _create_func(self): x = T.matrix('x') y = self.predict(x) self.f = theano.function([x],y,allow_input_downcast=True) def _create_train_func(self): y_in = T.matrix('y_in') x = T.matrix('x') y = self.predict(x) loss = T.mean((y-y_in)*(y-y_in)) grad_loss = T.grad(loss,self.params) updates = adam(self.params,grad_loss) self.train = theano.function(inputs=[x,y_in], outputs=loss, updates=updates, allow_input_downcast=True) def get_cpu_func(): def f(a,b): return a*b return f if __name__ == \"__main__\": np.random.seed(12345) a = np.random.randn(400) b = np.random.randn(400) f_cuda = get_pycuda_func() f_cpu = get_cpu_func() T = test_network() for k in range(10): x = f_cuda(a,b) z = f_cpu(a,b) print(k) print(np.allclose(x,z)) batch_size = 256 for k in range(1000): x = np.random.rand(batch_size) y = x*x x = x.reshape(batch_size,1) y = y.reshape(batch_size,1) loss = T.train(x,y) print(\"k=%d, loss=%g\" % (k,loss)) I would get: $ python3 test_theano_pycuda.py Using cuDNN version 7003 on context None Mapped name None to device cuda: GeForce GTX TITAN Black (0000:01:00.0) Traceback (most recent call last): File \"test_theano_pycuda.py\", line 160, in &lt;module&gt; x = f_cuda(a,b) File \"test_theano_pycuda.py\", line 32, in f gpu_b.gpudata File \"/usr/local/lib/python3.5/dist-packages/pycuda-2017.1.1-py3.5-linux-x86_64.egg/pycuda/driver.py\", line 447, in function_prepared_call func._set_block_shape(*block) pycuda._driver.LogicError: cuFuncSetBlockShape failed: invalid resource handle I am sure my test_theano_pycuda.py works because I have tested it by forcing theano to use CPU instead of cuda. (By modifying ~/.theanorc): From this. I bet it should be related to the problem that pycuda and theano are both creating a context within one process. In theano document, with gpuarray_cuda_context: pycuda_context = pycuda.driver.Context.attach() where does that gpuarray_cuda_context come from? Are there any workable example that I can test with?",
        "answers": [
            [
                "gpuarray_cuda_context here is just an existing context from a GpuArray Variable. For instance, you can find an example in theano/gpuarray/fft.py, where I think skcuda.misc.init() will call pycuda.driver.Context.attach() or do something similar."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "Using Theano backend. (57720L, 51L) (57720L, 5L) (850L, 51L) (850L,) WARNING (theano.gof.compilelock): Overriding existing lock by dead process '12224' (I am process '2516') what is the meaning of that, and how to deal with it.",
        "answers": [
            [
                "The reason for this warning message is due to force-stopping a previous execution which held a lock to the Theano cache; the new process detects this and acquires the lock for itself. You may simply ignore the message since it would not affect the performance. However, you may try deleting the theano cache folder as mentioned here."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "We had only one GPU installed with CUDA drivers and whenever one user runs the code, the whole memory is assigned to that user. And the other users are unable to use the GPU. Is there a way to get rid of this behavior?",
        "answers": [
            [
                "If you are using keras, add this at the beginning of your script: from keras import backend as K config = tf.ConfigProto() config.gpu_options.allow_growth=True sess = tf.Session(config=config) K.set_session(sess) This will prevent tensorflow to take all the memory as can be seen here. If you are using tensorflow without keras, add this: config = tf.ConfigProto() config.gpu_options.allow_growth = True session = tf.Session(config=config, ...) As shown here."
            ]
        ],
        "votes": [
            7.0000001
        ]
    },
    {
        "question": "When installing Theano anaconda automatically tries to install pygpu despite this being an optional dependency. I have deleted the .theanorc file from my windows user directory. Also when running my application Theano tries to load from the GPU. It's like it remembers somehow? conda install theano Fetching package metadata ............. Solving package specifications: . Package plan for installation in environment C:\\Users\\zebco\\Miniconda3\\envs\\py35: The following NEW packages will be INSTALLED: libgpuarray: 0.6.9-vc14_0 pygpu: 0.6.9-py36_0 theano: 0.9.0-py36_0 Proceed ([y]/n)? As you can see I've only specified to install theano yet conda wants to install everything including optional dependancies.",
        "answers": [
            [
                "Update: Usually, 'Optional Dependency' is an oxymoron. Something optional is not a dependency, a dependency is a software package another piece of software depends on to function for features. One may get by without a dependency if the dependency does not interact with the package except for one atomized feature which is not being used. As a beginner I would suggest you not take this path. I am not super familiar with Theano, but Theano can use the system's GPU to speed up its computations, and it seems to me pygpu and gpulibarray are what enable this functionality. Which means it is not optional. I believe pygpu is 'optional' if you do not wish to use the GPU for speeding up computation (only done if the GPU is powerful enough to be useful for this). The --no-deps command above allows you to install a package without its dependencies but that is rarely wise, unless one really knows what they are doing. As a beginner I would not recommend you go down this path yet. Conda was designed specifically to ensure scientific packages are easily managed with all necessary stuff installed without any fuss or muss. pip is a general python package manager, but is not built specifically for scientific packages. If you wish to install theano without installing its dependencies, then you have one of three options: use conda install theano --no-deps. Install it using pip instead of conda, using pip install theano. This will install theano, numpy, scipy and six but not pygpu and libgpuarray. Create a custom conda build file for Theano. Documentation is at: https://conda.io/docs/user-guide/tasks/build-packages/index.html Original Answer: You probably know this already but, use this command instead: conda install theano --no-deps This does not install dependencies of the package. If you already have the essential dependencies installed, as it would seem, this should work out for you. libgpuarray is a dependency of pygpu. With this command switch neither will be installed. Can you share the .yaml file that you edited?"
            ],
            [
                "Your assumption that pygpu is optional is dependent on the package manager you are using. Regular Python (pip) If you are using a direct Python install (obtained using brew or Python site) then you would be using pip to install theano. This basically comes from https://pypi.python.org/pypi/Theano/1.0.0 If you download the file and unzip it. Open setup.py, you will see below lines install_requires=['numpy&gt;=1.9.1', 'scipy&gt;=0.14', 'six&gt;=1.9.0'], So they are set as the dependencies for this package. Which means when you install theano you will also get numpy, scipy and six. Anaconda Python (conda) Now coming to Anaconda python. Anaconda doesn't use a package format that PyPI or pip uses. It uses its own format. In case of Anaconda you should be using conda to install the packages you need and not pip. Conda has channels which is nothing but a repository which has some packages available. You can install a package from any channel using below conda install -c &lt;channel-name&gt; &lt;package-name&gt; The default channel is conda-forge. If you look at the theano package over there https://anaconda.org/conda-forge/theano/files And download and extract it. There will be a info/recipe/meta.yml file. You will notice below content in the same requirements: build: - ca-certificates 2017.7.27.1 0 - certifi 2017.7.27.1 py36_0 - ncurses 5.9 10 - openssl 1.0.2l 0 - python 3.6.2 0 - readline 6.2 0 - setuptools 36.3.0 py36_0 - sqlite 3.13.0 1 - tk 8.5.19 2 - xz 5.2.3 0 - zlib 1.2.11 0 run: - python - setuptools - six &gt;=1.9.0 - numpy &gt;=1.9.1 - scipy &gt;=0.14 - pygpu &gt;=0.6.5,&lt;0.7 Which specifies that if you want to run this package then pygpu is also on of its dependencies. So conda downloads pygpu as a dependency which you though was optional (which is probably true if you were using regular python and pip)"
            ]
        ],
        "votes": [
            5.0000001,
            4.0000001
        ]
    },
    {
        "question": "I am installing libgpuarray v0.7.4. When I import theano, I got the following errors: I am using the version of: (1) Theano from github (rel-1.0.0rc1), (2) CUDA 9.0 (I am sure CUDA / cusolver works, I installed pycuda, scikit-cuda and could run them successfully) (3) cuDNN 7.0.3 (4) nvidia driver 384.90 Python 3.5.2 (default, Sep 14 2017, 22:51:06) [GCC 5.4.0 20160609] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. &gt;&gt;&gt; import theano Using cuDNN version 7003 on context None ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/usr/local/lib/python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py\", line 220, in &lt;module&gt; use(config.device) File \"/usr/local/lib/python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py\", line 207, in use init_dev(device, preallocate=preallocate) File \"/usr/local/lib/python3.5/dist-packages/Theano-1.0.0rc1-py3.5.egg/theano/gpuarray/__init__.py\", line 152, in init_dev pygpu.blas.gemm(0, tmp, tmp, 0, tmp, overwrite_c=True) File \"pygpu/blas.pyx\", line 149, in pygpu.blas.gemm File \"pygpu/blas.pyx\", line 47, in pygpu.blas.pygpu_blas_rgemm pygpu.gpuarray.GpuArrayException: (b'cuLinkCreate: CUDA_ERROR_JIT_COMPILER_NOT_FOUND: PTX JIT compiler library not found', 3) Any idea on how to resolve it? I want to make use of the GPU support of theano EDIT (reply to talonmies) I think pygpu could create a context over my GPU: $ DEVICE=cuda python3 Python 3.5.2 (default, Sep 14 2017, 22:51:06) [GCC 5.4.0 20160609] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. &gt;&gt;&gt; import pygpu &gt;&gt;&gt; pygpu.test() pygpu is installed in /usr/local/lib/python3.5/dist-packages/pygpu-0.7.4-py3.5-linux-x86_64.egg/pygpu NumPy version 1.13.3 NumPy relaxed strides checking option: True NumPy is installed in /usr/local/lib/python3.5/dist-packages/numpy-1.13.3-py3.5-linux-x86_64.egg/numpy Python version 3.5.2 (default, Sep 14 2017, 22:51:06) [GCC 5.4.0 20160609] nose version 1.3.7 *** Testing for GeForce GTX TITAN Black mpi4py found: False .EEEEEEEEEEEEEEEEEEEEEEEEEEE On the other hand, run nvidia-smi Mon Nov 13 15:39:35 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 384.90 Driver Version: 384.90 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX TIT... Off | 00000000:01:00.0 Off | N/A | | 28% 47C P2 94W / 250W | 102MiB / 6082MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 5562 C python3 91MiB | +-----------------------------------------------------------------------------+ I traced the code and found that the error appear from BLAS GEMM. I think there is no compiled code of my GPU and libgpuarray needs to compile on my machine. But somehow it cannot find the compiler. END OF EDIT",
        "answers": [
            [
                "I was experiencing similar issues, but I needed to create symlinks libnvidia-ptxjitcompiler.so.384.81 to point to libnvidia-ptxjitcompiler.so.1 libnvidia-ptxjitcompiler.so"
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "My pc specs are a GPU NVIDIA 1050ti in a windows 10. I installed the CUDA drivers (had to install visual studio with c++ tools) and run the tests, created a new conda environment with with theano and pygpu (python 3.6.3). Run the script: from theano import function, config, shared, sandbox import theano.tensor as T import numpy import time print(config.device) vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print('Looping %d times took' % iters, t1 - t0, 'seconds') print('Result is', r) if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') Everything worked (with the cpu running). Then I created a .theanorc.txt file and added to it: #!sh [global] device = cpu floatX = float32 I tried to run again the script and the result was. 5000 lines of some code followed by nvcc fatal : Cannot find compiler 'cl.exe' in PATH ['nvcc', '-shared', '-O3', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda\"', '-I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include\"', '-I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\include\"', '-I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\lib\\\\site-packages\\\\theano\\\\gof\"', '-L\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\libs\"', '-L\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\"', '-o', 'C:\\\\Users\\\\JoaquimFerrer\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.16299-SP0-Intel64_Family_6_Model_158_Stepping_9_GenuineIntel-3.6.3-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-lcublas', '-lpython36', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda\" -I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include\" -I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\include\" -I\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\lib\\\\site-packages\\\\theano\\\\gof\" -L\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\\\\libs\" -L\"C:\\\\Users\\\\JoaquimFerrer\\\\Anaconda3\\\\envs\\\\neural_nets\" -o C:\\\\Users\\\\JoaquimFerrer\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.16299-SP0-Intel64_Family_6_Model_158_Stepping_9_GenuineIntel-3.6.3-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -lcublas -lpython36 -lcudart') WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) gpu and then the output of the script running with cpu. I added cl to the path and now I can run it in the console but the output didn't change. Can someone help? Even with installing everything in a totally new way.",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have found this link Converting Theano-based Keras model definition to TensorFlow, but I do not use keras at all. Are there other ways to do that?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm using Theano with pygpu. Generally, it works well until, for reasons I still haven't managed to understand, it shows the following error once I try to import theano: ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/home/poko/Software/anaconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 220, in &lt;module&gt; use(config.device) File \"/home/poko/Software/anaconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 207, in use init_dev(device, preallocate=preallocate) File \"/home/poko/Software/anaconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 94, in init_dev **args) File \"pygpu/gpuarray.pyx\", line 651, in pygpu.gpuarray.init File \"pygpu/gpuarray.pyx\", line 587, in pygpu.gpuarray.pygpu_init GpuArrayException: cuInit: CUDA_ERROR_UNKNOWN: unknown error If I reboot my computer, it works well again, for a while (sometimes for days..). Now that situation is strange, given that such things either do work, or don't. I have not the faintest about what is generating the error, apart from observing from nvidia-smi that xorg and chrome do suck quite a lot of memory: +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 1332 G /usr/lib/xorg/Xorg 392MiB | | 0 2243 G cinnamon 110MiB | | 0 4927 G ...-token=39C210A3DFA14C5D81FA629C813B843D 154MiB | +-----------------------------------------------------------------------------+",
        "answers": [
            [
                "It turned out that I can get rid of the error just by unloading nvidia_uvm module, by doing: sudo rmmod nvidia_uvm after which, it will be automatically reloaded. Hope this helps should someone else incur in that problem."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I try to set the THEANO_FLAGS and then import Theano. This always results in an error. In [1]: import os In [2]: os.environ[\"THEANO_FLAGS\"] = \"cuda.root=/usr/local/cuda,device=cuda,floatX=float32\" In [3]: import theano ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/Users/anonymouse/anaconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 164, in &lt;module&gt; use(config.device) File \"/Users/anonymouse/anaconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 151, in use init_dev(device) File \"/Users/anonymouse/anaconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 60, in init_dev sched=config.gpuarray.sched) File \"pygpu/gpuarray.pyx\", line 634, in pygpu.gpuarray.init File \"pygpu/gpuarray.pyx\", line 584, in pygpu.gpuarray.pygpu_init File \"pygpu/gpuarray.pyx\", line 1057, in pygpu.gpuarray.GpuContext.__cinit__ GpuArrayException: Could not load \"/Developer/NVIDIA/CUDA-7.0/lib/libnvrtc.dylib\": dlopen(/Developer/NVIDIA/CUDA-7.0/lib/libnvrtc.dylib, 5): image not found How could I change the path \"/Developer/NVIDIA/CUDA-7.0/lib/libnvrtc.dylib\" to \"/usr/local/cuda/lib/libcuda.dylib\"?",
        "answers": [],
        "votes": []
    },
    {
        "question": "Hi i am new to python and tried to run script (https://github.com/detuvoldo/tagger), I replaced the 2 lines in utils.py because i am using Windows 10 and there were some path related issues. models_path = u\"\\\\\\\\?\\\\\" + os.path.abspath(u\".\\\\models\") eval_path = os.path.abspath(u\".\\\\evaluation\") The error is run train.py --train lstm/fold1/train --dev lstm/fold1/dev --test lstm/fold1/test WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 Using gpu device 0: GeForce GT 620M (CNMeM is enabled with initial size: 85.0% of memory, cuDNN not available) Model location: \\?\\E:\\New-Code\\tagger-master\\tagger-master\\models\\tag_scheme=iob,lower=False,zeros=False,char_dim=25,char_lstm_dim=25,char_bidirect=True,word_dim=100,word_lstm_dim=100,word_bidirect=True,pre_emb=,all_emb=False,cap_dim=0,crf=True,dropout=0.3,lr_method=sgd-lr_.005 Found 2573 unique words (48986 in total) Found 64 unique characters Found 27 unique named entity tags 858 / 289 / 286 sentences in train / dev / test. Saving the mappings to disk... Compiling... Starting epoch 0... 50, cost average: 101.645935 100, cost average: 83.234520 150, cost average: 82.757523 200, cost average: 69.019493 250, cost average: 64.411346 300, cost average: 62.836563 350, cost average: 60.969635 400, cost average: 58.851826 450, cost average: 49.994457 ID NE Total O I-LOC B-CTT B-OBJ B-LOC B-ACR B-INT B-PRC I-FACE I-PRC I-ACR I-OBJ B-FNUM I-FNUM I-DDIR B-FACEI-BEDNUM I-CTT B-DDIR I-INTB-BEDNUMB-BATHNUMI-BATHNUM I-FPOS B-FPOS I-BDIR B-BDIR Percent 0 O 9314 9175 0 63 14 0 0 62 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 98.508 1 I-LOC 2604 2602 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 2 B-CTT 478 245 0 233 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 48.745 3 B-OBJ 464 282 0 0 177 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 38.147 4 B-LOC 439 439 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 5 B-ACR 346 334 0 1 1 0 7 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2.023 6 B-INT 339 126 0 0 32 0 0 181 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 53.392 7 B-PRC 233 232 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 8 I-FACE 218 218 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 9 I-PRC 232 225 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 10 I-ACR 214 203 0 0 2 0 1 0 0 0 0 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3.271 11 I-OBJ 201 198 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 12 B-FNUM 170 156 0 0 5 0 0 8 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 13 I-FNUM 166 157 0 0 8 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 14 I-DDIR 170 169 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 15 B-FACE 120 120 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 16I-BEDNUM 103 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 17 I-CTT 103 98 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 18 B-DDIR 83 83 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 19 I-INT 57 56 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 20B-BEDNUM 57 57 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 21B-BATHNUM 44 44 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 22I-BATHNUM 45 44 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 23 I-FPOS 42 42 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 24 B-FPOS 37 36 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 25 I-BDIR 22 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 26 B-BDIR 6 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.000 9780/16307 (59.97424%) Traceback (most recent call last): File \"E:\\New-Code\\tagger-master\\tagger-master\\train.py\", line 221, in dev_data, id_to_tag, dico_tags, epoch) File \"utils.py\", line 284, in evaluate return float(eval_lines[1].strip().split()[-1]) IndexError: list index out of range Can you please suggest something that can help me solve the error? I am stuck for the last 2 months. Thanks",
        "answers": [
            [
                "I assume that you are running the script from the E:\\New-Code\\tagger-master\\tagger-master\\ directory and \"models\" and \"evaluation\" are right inside it. In this case, this should specify a path correctly: models_path = \"models\" eval_path = \"evaluation\" eval_temp = os.path.join(eval_path, \"temp\") eval_script = os.path.join(eval_path, \"conlleval\") If you see this error with this setting, the problem is with one of your \"eval.*.scores\" files, not path specification. I can't say for sure what is must contain, but at least provide its actual content."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "When I compile my python produce written with theano in Linux.I got a compile error in the picture.All path set well.This error suddenly appeared with no operation.",
        "answers": [
            [
                "I've seen such error when running Theano 0.9 with CUDA 8 and cuDNN 6. The error is fixed if using cuDNN 5.15 instead."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "When training either one of two different neural networks, one with Tensorflow and the other with Theano, sometimes after a random amount of time (could be a few hours or minutes, mostly a few hours), the execution freezes and I get this message by running \"nvidia-smi\": \"Unable to determine the device handle for GPU 0000:02:00.0: GPU is lost. Reboot the system to recover this GPU\" I tried to monitor the GPU performance for 13-hours execution, and everything seems stable: I'm working with: Ubuntu 14.04.5 LTS GPUs are Nvidia Titan Xp (this behavior repeats on another GPU on the same machine) CUDA 8.0 CuDNN 5.1 Tensorflow 1.3 Theano 0.8.2 I'm not sure how to approach this problem, can anyone please suggest ideas of what can cause this and how to diagnose/fix this?",
        "answers": [
            [
                "I posted this question a while ago, but after some investigation back then that took a few weeks, we managed to find the problem (and a solution). I don't remember all the details now, but I'm posting our main conclusion, in case someone will find it useful. Bottom line is - the hardware we had was not strong enough to support high load GPU-CPU communication. We observed these issues on a rack server with 1 CPU and 4 GPU devices, There was simply an overload on the PCI bus. The problem was solved by adding another CPU to the rack server."
            ]
        ],
        "votes": [
            10.0000001
        ]
    },
    {
        "question": "I'm trying to build a dcnn, but I got this error: ValueError: ('The specified size contains a dimension with value &lt;= 0', (-192, 1024)) And really, I don't have idea the reason of this error, here's my code: The data: c_X = open(\"C:/Users/PC/Desktop/Notebooks/Isabelle/mfcc_train_I_C_I_C_2.dat\", \"r\") c_y = open(\"C:/Users/PC/Desktop/Notebooks/Isabelle/phoneme_train_I_C_I_C_2.dat\", \"r\") c_X = np.fromfile(c_X, np.dtype('float32')) c_y = np.fromfile(c_y, np.dtype('int8')) c_X = c_X.reshape(886887,1120) c_X = c_X.reshape(c_X.shape[0], 1, 20, 56) c_y = one_hot(c_y) #c_y = np.append(c_y, np.zeros((374975,1)), axis=1) X_3 = apendice(Colere_X, c_X) y_3 = apendice(Colere_y, c_y) #print(c_X.shape, c_y.shape) print(X_3.shape, y_3.shape) (1123867, 1, 20, 56) (1123867, 38) This is my neural network implementation (the problem is here I think): model = Sequential() model.add(Conv2D(32, (3, 3), border_mode='valid', activation='relu',input_shape=(1, 20, 56))) model.add(Dropout(0.25)) model.add(Conv2D(32, (3, 3), border_mode='valid', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Conv2D(32, (3, 3), border_mode='valid', activation='relu')) model.add(Conv2D(32, (3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(1024, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(num_classes, activation='softmax')) # Compile the model model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Train the model start = time.time() model_info = model.fit(X_3, y_3, batch_size=100, \\ epochs=20, verbose=2, validation_data=(X_test, y_test)) end = time.time() Here the summary of model: _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_21 (Conv2D) (None, -1, 18, 32) 16160 _________________________________________________________________ dropout_16 (Dropout) (None, -1, 18, 32) 0 _________________________________________________________________ conv2d_22 (Conv2D) (None, -3, 16, 32) 9248 _________________________________________________________________ max_pooling2d_11 (MaxPooling (None, -2, 8, 32) 0 _________________________________________________________________ dropout_17 (Dropout) (None, -2, 8, 32) 0 _________________________________________________________________ conv2d_23 (Conv2D) (None, -4, 6, 32) 9248 _________________________________________________________________ conv2d_24 (Conv2D) (None, -6, 4, 32) 9248 _________________________________________________________________ max_pooling2d_12 (MaxPooling (None, -3, 2, 32) 0 _________________________________________________________________ dropout_18 (Dropout) (None, -3, 2, 32) 0 _________________________________________________________________ flatten_6 (Flatten) (None, -192) 0 ================================================================= Total params: 43,904 Trainable params: 43,904 Non-trainable params: 0 _________________________________________________________________ --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-17-589407073ff5&gt; in &lt;module&gt;() 13 model.add(Flatten()) 14 model.summary() ---&gt; 15 model.add(Dense(256, activation='relu')) 16 model.add(Dropout(0.5)) 17 model.add(Dense(num_classes, activation='softmax')) ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py in add(self, layer) 467 output_shapes=[self.outputs[0]._keras_shape]) 468 else: --&gt; 469 output_tensor = layer(self.outputs[0]) 470 if isinstance(output_tensor, list): 471 raise TypeError('All layers in a Sequential model ' ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py in __call__(self, inputs, **kwargs) 567 '`layer.build(batch_input_shape)`') 568 if len(input_shapes) == 1: --&gt; 569 self.build(input_shapes[0]) 570 else: 571 self.build(input_shapes) ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\core.py in build(self, input_shape) 823 name='kernel', 824 regularizer=self.kernel_regularizer, --&gt; 825 constraint=self.kernel_constraint) 826 if self.use_bias: 827 self.bias = self.add_weight(shape=(self.units,), ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py in wrapper(*args, **kwargs) 85 warnings.warn('Update your `' + object_name + 86 '` call to the Keras 2 API: ' + signature, stacklevel=2) ---&gt; 87 return func(*args, **kwargs) 88 wrapper._original_function = func 89 return wrapper ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint) 389 if dtype is None: 390 dtype = K.floatx() --&gt; 391 weight = K.variable(initializer(shape), dtype=dtype, name=name) 392 if regularizer is not None: 393 self.add_loss(regularizer(weight)) ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\initializers.py in __call__(self, shape, dtype) 206 limit = np.sqrt(3. * scale) 207 return K.random_uniform(shape, -limit, limit, --&gt; 208 dtype=dtype, seed=self.seed) 209 210 def get_config(self): ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\theano_backend.py in random_uniform(shape, minval, maxval, dtype, seed) 2189 seed = np.random.randint(1, 10e6) 2190 rng = RandomStreams(seed=seed) -&gt; 2191 return rng.uniform(shape, low=minval, high=maxval, dtype=dtype) 2192 2193 ~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\theano\\sandbox\\rng_mrg.py in uniform(self, size, low, high, ndim, dtype, nstreams) 854 raise ValueError( 855 \"The specified size contains a dimension with value &lt;= 0\", --&gt; 856 size) 857 858 else: ValueError: ('The specified size contains a dimension with value &lt;= 0', (-192, 256)) I will appreciate your help. Thanks in advance.",
        "answers": [
            [
                "This is a problem related to the channels ordering in Keras. You probably have set image_dim_ordering or image_data_format parameter in ~/.keras/keras.json to either tf or channels_last, depending on which version of Keras you are using. The problem is that the input_shape you provided is in the th or channels first order, which messes up how the dimensions are interpreted and produces negative dimension sizes. This would happen if you first used Keras with TensorFlow and then you switched to Theano. The solution is quite easy, you can either set the corresponding parameter in the keras.json config file to th or channels_first so it matches your file, or you change the input_shape of your data to (20, 56, 1). Both solutions should work and you should prefer the native channel ordering of the backend you are using (as it is slightly faster)."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I tried installing and using Theano with Cuda-9.0 on a P100 node. The installation itself went smooth, but I get Segmentation fault (see below). I tried with both Theano-0.9.0 and Theano-0.10.0beta1 in combination with libgpuarray/pygpu - 0.6.8 and 0.6.9. All of the cases result in segfault. Here is my setup: * RHEL 7 * GCC: 4.8.5 * CUDA: 9.0 * cuDNN: 5.1.5 * Python: 2.7.13 * cmake: 3.7.2 [bsankara@c460 ~]$ python Python 2.7.13 (default, Aug 10 2017, 07:33:11) [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. &gt;&gt;&gt; import theano -------------------------------------------------------------------------- A process has executed an operation involving a call to the \"fork()\" system call to create a child process. Open MPI is currently operating in a condition that could result in memory corruption or other system errors; your job may hang, crash, or produce silent data corruption. The use of fork() (or system() or other calls that create child processes) is strongly discouraged. The process that invoked fork was: Local host: [[52508,1],0] (PID 3946) If you are *absolutely sure* that your application will successfully and correctly survive a call to fork(), you may disable this warning by setting the mpi_warn_on_fork MCA parameter to 0. -------------------------------------------------------------------------- [c460:03946] *** Process received signal *** [c460:03946] Signal: Segmentation fault (11) [c460:03946] Signal code: Invalid permissions (2) [c460:03946] Failing at address: 0x3fff8d48f5b0 [c460:03946] [ 0] [0x3fff9cdf0478] [c460:03946] [ 1] /home/bsankara/software/ppc64le-08102017/lib/libgpuarray.so.2(load_libcuda+0x60)[0x3fff8631b5e0] [c460:03946] [ 2] /home/bsankara/software/ppc64le-08102017/lib/libgpuarray.so.2(+0x3f384)[0x3fff862df384] [c460:03946] [ 3] /home/bsankara/software/ppc64le-08102017/lib/libgpuarray.so.2(+0x41118)[0x3fff862e1118] [c460:03946] [ 4] /home/bsankara/software/ppc64le-08102017/lib/libgpuarray.so.2(gpucontext_init+0x90)[0x3fff862c7930] [c460:03946] [ 5] /home/bsankara/software/ppc64le-08102017/lib/python2.7/site-packages/pygpu-0.6.8-py2.7-linux-ppc64le.egg/pygpu/gpuarray.so(+0x2c974)[0x3fff8638c974] [c460:03946] [ 6] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(+0x101050)[0x3fff9cc61050] [c460:03946] [ 7] /home/bsankara/software/ppc64le-08102017/lib/python2.7/site-packages/pygpu-0.6.8-py2.7-linux-ppc64le.egg/pygpu/gpuarray.so(+0x54318)[0x3fff863b4318] [c460:03946] [ 8] /home/bsankara/software/ppc64le-08102017/lib/python2.7/site-packages/pygpu-0.6.8-py2.7-linux-ppc64le.egg/pygpu/gpuarray.so(+0x56530)[0x3fff863b6530] [c460:03946] [ 9] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyCFunction_Call+0x164)[0x3fff9cc31554] [c460:03946] [10] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x8e64)[0x3fff9ccc9484] [c460:03946] [11] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0xb40)[0x3fff9cccb360] [c460:03946] [12] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x8f04)[0x3fff9ccc9524] [c460:03946] [13] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0xb40)[0x3fff9cccb360] [c460:03946] [14] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x8f04)[0x3fff9ccc9524] [c460:03946] [15] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0xb40)[0x3fff9cccb360] [c460:03946] [16] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalCode+0x34)[0x3fff9cccb484] [c460:03946] [17] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyImport_ExecCodeModuleEx+0xe0)[0x3fff9cce8960] [c460:03946] [18] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(+0x188e50)[0x3fff9cce8e50] [c460:03946] [19] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(+0x18ad54)[0x3fff9ccead54] [c460:03946] [20] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(+0x18a540)[0x3fff9ccea540] [c460:03946] [21] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyImport_ImportModuleLevel+0x2f4)[0x3fff9cceb7b4] [c460:03946] [22] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(+0x15d038)[0x3fff9ccbd038] [c460:03946] [23] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyCFunction_Call+0x164)[0x3fff9cc31554] [c460:03946] [24] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyObject_Call+0x74)[0x3fff9cbc1ab4] [c460:03946] [25] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_CallObjectWithKeywords+0x68)[0x3fff9ccbfc68] [c460:03946] [26] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalFrameEx+0x3214)[0x3fff9ccc3834] [c460:03946] [27] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalCodeEx+0xb40)[0x3fff9cccb360] [c460:03946] [28] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyEval_EvalCode+0x34)[0x3fff9cccb484] [c460:03946] [29] /home/bsankara/software/ppc64le-08102017/lib/libpython2.7.so.1.0(PyImport_ExecCodeModuleEx+0xe0)[0x3fff9cce8960] [c460:03946] *** End of error message *** Segmentation fault Any help would be appreciated. Thanks.",
        "answers": [
            [
                "Grab a demo mpi c++ or c code from the web, and compile it with mpicc / mpic++. Check that the compiler works and the executable you made can run and can manage point to point communication between different nodes in the cluster. You probably used a wrong mpicc to compile theano and that compiler doesn't have binary compatibility with the library for inifiniband (or any hardware that connects the computers in a cluster). For example, if the InfiniBand library is compiled by gcc and theano is compiled by a mpicc that is based on the intel compiler then it won't work. You can set an environmental variable to ask the mpicc of openmpi to use another compiler. If you have multiple mpi implementations compiled by different compilers on that computer... Try to use ldd to find out which shared library object (those .so files) depends on which one. The best case is of course use the same compiler and same mpi wrapper for the compiler to compile everything, and wrap the files into several modules."
            ],
            [
                "The answer turns to be in the gcc version and libgpuarray. For some reason, gcc-4.8.5 has issues with the libgpuarray and that's what was causing segmentation fault. I installed gcc-5.4.0 in my user space and recompiled cmake and libgpuarray as well as others including theano and numpy (just to be sure) and then it doesn't have the Segmentation fault any more. The other change was that the cluster admins updated CUDA to 9.0.151 with new driver 384.66"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I am trying to configure theano to use gpu on my windows machine. I have set up .theanorc to use device= gpu but when I run some code that should utilize the gpu, I get the following error: Can not use cuDNN on context None: cannot compile with cuDNN. We got this error: c:\\users\\...\\appdata\\local\\temp\\try_flags_pt24sj.c:4:19: fatal error: cudnn.h: No such file or directory compilation terminated. Mapped name None to device cuda0: GeForce 840M (0000:03:00.0) I have checked my CUDA_PATH=C:\\Program Files\\NVIDIA\\v8.0 GPU Computing Toolkit\\CUDA to see whether cudnn.h is there or not, and I found it in C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\include",
        "answers": [
            [
                "Fixed this with following the installation guide https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-windows and adding LIBRARY_PATH to the PATH variable (pointing to your CUDA lib folder e.g. C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib)."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have followed the steps from here to enable gpu with theano on an Ubuntu 16.04 machine. I installed cuda toolkit, cudnn, drivers but I am still not able to get it to work. And when I run: from theano.sandbox import cuda cuda.use(\"gpu0\") I get the following exception: Exception: ('The following error happened while compiling the node', GpuCAReduce{add}{1}(&lt;CudaNdarrayType(float32, vector)&gt;), '\\n', 'nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -arch=sm_50 -m64 -Xcompiler -fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray -I/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray -I/usr/include -I/home/...thon2.7/site-packages/numpy/core/include -I/home/.../python2.7 -I/home/.../python2.7/site-packages/theano/gof -I/home/.../python2.7/site-packages/theano/sandbox/cuda -L/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray -L/home/... -o /home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/tmpYVhcOM/544270fe7a21a748315f83abfe0913cc.so mod.cu -lcudart -lcublas -lcuda_ndarray -lpython2.7', '[GpuCAReduce{add}{1}(&lt;CudaNdarrayType(float32, vector)&gt;)]') How can I fix this error? Here is the full error trace: Python 2.7.13 |Anaconda 4.4.0 (64-bit)| (default, Dec 20 2016, 23:09:15) [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. Anaconda is brought to you by Continuum Analytics. Please check out: http://continuum.io/thanks and https://anaconda.org &gt;&gt;&gt; from theano.sandbox import cuda &gt;&gt;&gt; cuda.use(\"gpu0\") WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 /home/.../python2.7/site-packages/theano/sandbox/cuda/__init__.py:556: UserWarning: Theano flag device=gpu* (old gpu back-end) only support floatX=float32. You have floatX=float64. Use the new gpu back-end with device=cuda* for that value of floatX. warnings.warn(msg) WARNING (theano.gof.compilelock): Overriding existing lock by dead process '8175' (I am process '2320') In file included from /home/.../python2.7/Python.h:8:0, from mod.cu:1: /home/.../python2.7/pyconfig.h:1190:0: warning: \"_POSIX_C_SOURCE\" redefined #define _POSIX_C_SOURCE 200112L ^ In file included from /usr/include/host_config.h:161:0, from /usr/include/cuda_runtime.h:76, from &lt;command-line&gt;:0: /usr/include/features.h:228:0: note: this is the location of the previous definition # define _POSIX_C_SOURCE 200809L ^ In file included from /home/.../python2.7/Python.h:8:0, from mod.cu:1: /home/.../python2.7/pyconfig.h:1212:0: warning: \"_XOPEN_SOURCE\" redefined #define _XOPEN_SOURCE 600 ^ In file included from /usr/include/host_config.h:161:0, from /usr/include/cuda_runtime.h:76, from &lt;command-line&gt;:0: /usr/include/features.h:169:0: note: this is the location of the previous definition # define _XOPEN_SOURCE 700 ^ In file included from /home/.../python2.7/Python.h:8:0, from mod.cu:1: /home/.../python2.7/pyconfig.h:1190:0: warning: \"_POSIX_C_SOURCE\" redefined #define _POSIX_C_SOURCE 200112L ^ In file included from /usr/include/host_config.h:161:0, from /usr/include/cuda_runtime.h:76, from &lt;command-line&gt;:0: /usr/include/features.h:228:0: note: this is the location of the previous definition # define _POSIX_C_SOURCE 200809L ^ In file included from /home/.../python2.7/Python.h:8:0, from mod.cu:1: /home/.../python2.7/pyconfig.h:1212:0: warning: \"_XOPEN_SOURCE\" redefined #define _XOPEN_SOURCE 600 ^ In file included from /usr/include/host_config.h:161:0, from /usr/include/cuda_runtime.h:76, from &lt;command-line&gt;:0: /usr/include/features.h:169:0: note: this is the location of the previous definition # define _XOPEN_SOURCE 700 ^ /usr/include/string.h: In function \u2018void* __mempcpy_inline(void*, const void*, size_t)\u2019: /usr/include/string.h:652:42: error: \u2018memcpy\u2019 was not declared in this scope return (char *) memcpy (__dest, __src, __n) + __n; ^ mod.cu: In member function \u2018int _GLOBAL__N__38_tmpxft_00000948_00000000_9_mod_cpp1_ii_ae46f2fe::__struct_compiled_op_544270fe7a21a748315f83abfe0913cc::run()\u2019: mod.cu:388:172: warning: format \u2018%d\u2019 expects argument of type \u2018int\u2019, but argument 3 has type \u2018size_t {aka long unsigned int}\u2019 [-Wformat=] ['nvcc', '-shared', '-O3', '-arch=sm_50', '-m64', '-Xcompiler', '-fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden', '-Xlinker', '-rpath,/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray', '-I/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray', '-I/usr/include', '-I/home/...thon2.7/site-packages/numpy/core/include', '-I/home/.../python2.7', '-I/home/.../python2.7/site-packages/theano/gof', '-I/home/.../python2.7/site-packages/theano/sandbox/cuda', '-L/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray', '-L/home/...', '-o', '/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/tmpYVhcOM/544270fe7a21a748315f83abfe0913cc.so', 'mod.cu', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lpython2.7'] Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"/home/.../python2.7/site-packages/theano/sandbox/cuda/__init__.py\", line 593, in use theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File \"/home/.../python2.7/site-packages/theano/sandbox/cuda/tests/test_driver.py\", line 32, in test_nvidia_driver1 profile=False) File \"/home/.../python2.7/site-packages/theano/compile/function.py\", line 326, in function output_keys=output_keys) File \"/home/.../python2.7/site-packages/theano/compile/pfunc.py\", line 486, in pfunc output_keys=output_keys) File \"/home/.../python2.7/site-packages/theano/compile/function_module.py\", line 1795, in orig_function defaults) File \"/home/.../python2.7/site-packages/theano/compile/function_module.py\", line 1661, in create input_storage=input_storage_lists, storage_map=storage_map) File \"/home/.../python2.7/site-packages/theano/gof/link.py\", line 699, in make_thunk storage_map=storage_map)[:3] File \"/home/.../python2.7/site-packages/theano/gof/vm.py\", line 1047, in make_all impl=impl)) File \"/home/.../python2.7/site-packages/theano/gof/op.py\", line 935, in make_thunk no_recycling) File \"/home/.../python2.7/site-packages/theano/gof/op.py\", line 839, in make_c_thunk output_storage=node_output_storage) File \"/home/.../python2.7/site-packages/theano/gof/cc.py\", line 1190, in make_thunk keep_lock=keep_lock) File \"/home/.../python2.7/site-packages/theano/gof/cc.py\", line 1131, in __compile__ keep_lock=keep_lock) File \"/home/.../python2.7/site-packages/theano/gof/cc.py\", line 1586, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File \"/home/.../python2.7/site-packages/theano/gof/cmodule.py\", line 1159, in module_from_key module = lnk.compile_cmodule(location) File \"/home/.../python2.7/site-packages/theano/gof/cc.py\", line 1489, in compile_cmodule preargs=preargs) File \"/home/.../python2.7/site-packages/theano/sandbox/cuda/nvcc_compiler.py\", line 405, in compile_str 'for cmd', ' '.join(cmd)) Exception: ('The following error happened while compiling the node', GpuCAReduce{add}{1}(&lt;CudaNdarrayType(float32, vector)&gt;), '\\n', 'nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -arch=sm_50 -m64 -Xcompiler -fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray -I/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray -I/usr/include -I/home/...thon2.7/site-packages/numpy/core/include -I/home/.../python2.7 -I/home/.../python2.7/site-packages/theano/gof -I/home/.../python2.7/site-packages/theano/sandbox/cuda -L/home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray -L/home/... -o /home/...ledir_Linux-4.10--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/tmpYVhcOM/544270fe7a21a748315f83abfe0913cc.so mod.cu -lcudart -lcublas -lcuda_ndarray -lpython2.7', '[GpuCAReduce{add}{1}(&lt;CudaNdarrayType(float32, vector)&gt;)]')",
        "answers": [],
        "votes": []
    },
    {
        "question": "I've been successfully using Theano on my Windows 10 box for about a year. Then Windows 10 forced me to update--- the \"Creatives\" mega-update. Immediately after this update, I began getting the following error when running code that uses theano: &gt; C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda\\cnmem.cpp(39) &gt; : fatal error C1083: Cannot open include file: 'Windows.h': No such &gt; file or directory The full error output is shown below: C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(17) : warning C4005: 'PyString_Check' : macro redefinition C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(63) : see previous definition of 'PyString_Check' C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(18) : warning C4005: 'PyString_FromString' : macro redefinition C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(65) : see previous definition of 'PyString_FromString' C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(19) : warning C4005: 'PyString_AsString' : macro redefinition C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(72) : see previous definition of 'PyString_AsString' C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(20) : warning C4005: 'PyString_FromStringAndSize' : macro redefinition C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(66) : see previous definition of 'PyString_FromStringAndSize' C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(21) : warning C4005: 'PyString_Size' : macro redefinition C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(74) : see previous definition of 'PyString_Size' C:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda\\cnmem.cpp(39) : fatal error C1083: Cannot open include file: 'Windows.h': No such file or directory ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 --use-local-env --cl-version=2013 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\sandbox\\cuda -IC:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\numpy\\core\\include -IC:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\include -IC:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gof -o C:\\Users\\David\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.15063-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\cuda_ndarray\\cuda_ndarray.pyd mod.cu -LC:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64\\libs -LC:\\Winpython\\WinPython-64bit-3.4.4.6Qt5\\python-3.4.4.amd64 -lcublas -lpython34 -lcudart') mod.cu",
        "answers": [],
        "votes": []
    },
    {
        "question": "When I import keras using theano as backend, I get the following error: nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). nvcc fatal : Cannot find compiler 'cl.exe' in PATH And here is the full error stack: &gt;&gt; import keras C:\\SPB_Data\\.keras\\keras.json Using Theano backend. 1 #define _CUDA_NDARRAY_C 2 3 #include &lt;Python.h&gt; 4 #include &lt;structmember.h&gt; 5 #include \"theano_mod_helper.h\" 6 7 #include &lt;numpy/arrayobject.h&gt; 8 #include &lt;iostream&gt; 9 10 #include \"cuda_ndarray.cuh\" 11 12 #ifndef CNMEM_DLLEXPORT 13 #define CNMEM_DLLEXPORT 14 #endif 15 16 #include \"cnmem.h\" 17 #include \"cnmem.cpp\" 18 19 //If true, when there is a gpu malloc or free error, we print the size of allocated memory on the device. 20 #define COMPUTE_GPU_MEM_USED 0 21 22 //If true, we fill with NAN allocated device memory. 23 #define ALLOC_MEMSET 0 24 25 //If true, we print out when we free a device pointer, uninitialize a 26 //CudaNdarray, or allocate a device pointer 27 #define PRINT_FREE_MALLOC 0 28 29 //If true, we do error checking at the start of functions, to make sure there 30 //is not a pre-existing error when the function is called. 31 //You probably need to set the environment variable 32 //CUDA_LAUNCH_BLOCKING=1, and/or modify the CNDA_THREAD_SYNC 33 //preprocessor macro in cuda_ndarray.cuh 34 //if you want this to work. 35 #define PRECHECK_ERROR 0 36 37 cublasHandle_t handle = NULL; 38 int* err_var = NULL; 39 40 ///////////////////////// 41 // Alloc and Free 42 ///////////////////////// 43 44 static int g_gpu_context_active = 0; 45 46 47 PyObject * 48 CudaNdarray_Dimshuffle(PyObject* _unused, PyObject* args); 49 static PyObject *CudaNdarray_get_shape(CudaNdarray *self, void *closure); .. ... The rest of the file . ... 5370 if (CudaNdarray_alloc_contiguous(*arr, nd, dims, fortran)) 5371 { 5372 if (allocated) 5373 { 5374 Py_DECREF(*arr); 5375 *arr = NULL; 5376 } 5377 return -1; 5378 } 5379 return 0; 5380 } 5381 5382 5383 /* 5384 Local Variables: 5385 mode:c++ 5386 c-basic-offset:4 5387 c-file-style:\"stroustrup\" 5388 indent-tabs-mode:nil 5389 fill-column:79 5390 End: 5391 */ 5392 // vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:textwidth=79 : 5393 =============================== nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). nvcc fatal : Cannot find compiler 'cl.exe' in PATH ['nvcc', '-shared', '-O3', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda\"', '-I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include\"', '-I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\include\"', '-I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\theano\\\\gof\"', '-L\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\libs\"', '-L\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\"', '-o', 'C:\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-3.5.3-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-lcublas', '-lpython35', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda\" -I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include\" -I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\include\" -I\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\theano\\\\gof\" -L\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\\\\libs\" -L\"C:\\\\Anaconda3\\\\envs\\\\tensorflow\" -o C:\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_69_Stepping_1_GenuineIntel-3.5.3-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -lcublas -lpython35 -lcudart') How to fix this? ** I am running from conda environment installed on windows-10 machine and I made sure that the path of c1.exe is added and when I type nvcc in cmd it is recognized: &gt;nvcc nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). nvcc fatal : No input files specified; use option --help for more information",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm running Python27 x32 and getting this error: Could not load \"nvrtc64_75.dll\": %1 is not a valid Win32 application. I've also tried with cuda8. As I realized, NVRTC docs list x64 as a requirement: NVRTC requires the following system configuration: Operating System: Linux x86_64, Linux ppc64le, Linux aarch64, Windows x86_64, or Mac OS X. (nvrtc64_75.dll really does have 0x8664 in IMAGE_FILE_HEADER and 0x20b (pe32+) magic.) I'm trying to use libgpuarray's pygpu with theano and I've previously built it with Win32 mingw. My understanding now is that I'll need to install an x64 version of python and start from there. I know I could use conda instead and the docs in libgpuarray talk about msvc, btw. it worked with mingw so far. Am I interpreting this right? Is NVRTC really have no working Win32 edition? edit: got the same %1 is not a valid Win32 error with conda x32 and msvc (no real surprise here).",
        "answers": [
            [
                "Just as the documentation you linked indicates, NVRTC requires a 64-bit environment."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have two models (theano scripts) I want to train and evaluate. I have two GPUs I can use to train them. How can I run a model on each GPU at the same time?",
        "answers": [
            [
                "When running your script you can choose where your progam will run with THEANO_FLAGS: THEANO_FLAGS='device=gpu0' python script_1.py THEANO_FLAGS='device=gpu1' python script_2.py change gpuX for each gpu (eg. gpu0,gpu1,gpu2...)"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I am trying to run a theano simple code on Ubuntu 16.04 with Cuda 8.0 on NVIDIA 1060 GPU within a python virtual environment created by anaconda. The following is my theanorc file: [global] floatX = float32 device = cuda The code I am trying to run is a short sample from theano website: from theano import function, config, shared, tensor import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], tensor.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, tensor.Elemwise) and ('Gpu' not in type(x.op).__name__) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') And when I run the code I get a bunch of warnings and the following error: ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/eb/.theano/compiledir_Linux-4.8--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray -I/home/eb/anaconda2/envs/deep/lib/python2.7/site-packages/theano/sandbox/cuda -I/home/eb/anaconda2/envs/deep/lib/python2.7/site-packages/numpy/core/include -I/home/eb/anaconda2/envs/deep/include/python2.7 -I/home/eb/anaconda2/envs/deep/lib/python2.7/site-packages/theano/gof -L/home/eb/anaconda2/envs/deep/lib -o /home/eb/.theano/compiledir_Linux-4.8--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.13-64/cuda_ndarray/cuda_ndarray.so mod.cu -lcublas -lpython2.7 -lcudart') Can not use cuDNN on context None: cannot compile with cuDNN. We got this error: /tmp/try_flags_M8OZOh.c:4:19: fatal error: cudnn.h: No such file or directory compilation terminated. Mapped name None to device cuda: GeForce GTX 1060 6GB (0000:01:00.0) Surprisingly, the code RUNS and print the desired output as follows: [GpuElemwise{exp,no_inplace}(&lt;GpuArrayType&lt;None&gt;(float32, (False,))&gt;), HostFromGpu(gpuarray)(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.365814 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the gpu I was wondering if I am missing a Theano config or something? Any idea on what's going wrong? p.s. All libraries have been installed in my python virtual env except for Cuda library which is installed on system level. --Thanks",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have followed the instructions to install Theano an GPUArray from source (git versions), in the system folders (not as a user). The GPUArray tests run just fine without errors. The problem is Theano only works with GPU if I run as root. Running the example to test gpu: (python35) rll@ip-30-92:~$ THEANO_FLAGS=device=cuda python temp.py ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/usr/local/lib/python3.5/dist-packages/theano/gpuarray/__init__.py\", line 179, in &lt;module&gt; use(config.device) File \"/usr/local/lib/python3.5/dist-packages/theano/gpuarray/__init__.py\", line 166, in use init_dev(device, preallocate=preallocate) File \"/usr/local/lib/python3.5/dist-packages/theano/gpuarray/__init__.py\", line 73, in init_dev context.cudnn_handle = dnn._make_handle(context) File \"/usr/local/lib/python3.5/dist-packages/theano/gpuarray/dnn.py\", line 83, in _make_handle cudnn = _dnn_lib() File \"/usr/local/lib/python3.5/dist-packages/theano/gpuarray/dnn.py\", line 70, in _dnn_lib raise RuntimeError('Could not find cudnn library (looked for v5* or v6*)') RuntimeError: Could not find cudnn library (looked for v5* or v6*) [Elemwise{exp,no_inplace}(&lt;TensorType(float64, vector)&gt;)] Looping 1000 times took 3.201078 seconds Result is [ 1.23178032 1.61879341 1.52278065 ..., 2.20771815 2.29967753 1.62323285] Used the cpu If run as root it works, although there is still an error related to cuDNN not being able to identify the devices maybe: (python35) rll@ip-30-92:~$ sudo THEANO_FLAGS=device=cuda python3 temp.py Can not use cuDNN on context None: cannot compile with cuDNN. We got this error: b'/tmp/try_flags_bg7m03hd.c:4:19: fatal error: cudnn.h: No such file or directory\\ncompilation terminated.\\n' Mapped name None to device cuda: TITAN X (Pascal) (0000:01:00.0) [GpuElemwise{exp,no_inplace}(&lt;GpuArrayType&lt;None&gt;(float64, vector)&gt;), HostFromGpu(gpuarray)(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.390976 seconds Result is [ 1.23178032 1.61879341 1.52278065 ..., 2.20771815 2.29967753 1.62323285] Used the gpu There are 2 Titan X on this machine. Works fine with Tensorflow. I am not using .theanorc file, but I have set both: (python35) rll@ip-30-92:~$ echo $LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64 (python35) rll@ip-30-92:~$ echo $CUDA_ROOT /usr/local/cuda-8.0/ I did everything as per the instructions, and despite some warnings there were no errors. I don't think it is a permissions error on the compile dir .theano, because if I chown the .theano dir the behaviour is the same. How can I fix this?",
        "answers": [
            [
                "I have finally found the problem. There is an aspect missing in the instructions to install Theano which is that you have to verify if LIBRARY_PATH is set and add the cuda libraries to it (note that it is not the LD_LIBRARY_PATH). If it is not set just export it and you will be good to go. So for temporary fix: export LIBRARY_PATH=/usr/local/cuda-8.0/lib64 To persist it may depend on the system, but in general you can add to the /etc/environment, adding a line: LIBRARY_PATH=/usr/local/cuda-8.0/lib64 This fixed the message when root, and fixed cuda for the regular user."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "It's driving me crazy. I'm following this guide to install the required libgpuarray. But I keep on getting errors. In this guide: cd &lt;dir&gt; rm -rf build Build mkdir Build cd Build cmake .. -DCMAKE_INSTALL_PREFIX=~/.local -DCMAKE_BUILD_TYPE=Release make make install DEVICE=\"&lt;test device&gt;\" make test cd .. # Run the following export and add them in your ~/.bashrc file export CPATH=$CPATH:~/.local/include export LIBRARY_PATH=$LIBRARY_PATH:~/.local/lib export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/.local/lib python setup.py build python setup.py install --user cd DEVICE=\"&lt;test device&gt;\" python -c \"import pygpu;pygpu.test()\" I'm supposed to reference my gpu in DEVICE=\"&lt;test device&gt;\". However I tried everything here: gpu, gpu0, etc but it still cannot find any GPU... I get the following errors: $python setup.py build Traceback (most recent call last): File \"setup.py\", line 15, in &lt;module&gt; raise Exception('cython is too old or not installed ' Exception: cython is too old or not installed (at least 0.25 required) which I just ignore since my pip is not able to install a lower version than the one that is globally installed, although I'm using virtualenv. And finally I get this error: $DEVICE=\"gpu0\" python -c \"import pygpu;pygpu.test()\" ERROR: Failure: ValueError (Unknown device format:gpu) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/usr/local/lib/python2.7/dist-packages/nose/loader.py\", line 418, in loadTestsFromName addr.filename, addr.module) File \"/usr/local/lib/python2.7/dist-packages/nose/importer.py\", line 47, in importFromPath return self.importFromDir(dir_path, fqname) File \"/usr/local/lib/python2.7/dist-packages/nose/importer.py\", line 94, in importFromDir mod = load_module(part_fqname, fh, filename, desc) File \"/home/myUser/.local/lib/python2.7/site-packages/pygpu-0.6.5-py2.7-linux-x86_64.egg/pygpu/tests/test_tools.py\", line 5, in &lt;module&gt; from .support import (guard_devsup, rand, check_flags, check_meta, check_all, File \"/home/myUser/.local/lib/python2.7/site-packages/pygpu-0.6.5-py2.7-linux-x86_64.egg/pygpu/tests/support.py\", line 32, in &lt;module&gt; context = gpuarray.init(get_env_dev()) File \"pygpu/gpuarray.pyx\", line 634, in pygpu.gpuarray.init (pygpu/gpuarray.c:9407) File \"pygpu/gpuarray.pyx\", line 583, in pygpu.gpuarray.pygpu_init (pygpu/gpuarray.c:9073) ValueError: Unknown device format:gpu ---------------------------------------------------------------------- Ran 7 tests in 0.002s FAILED (errors=7) Edit: Ok, so it compiles now when using \"cuda0\" DEVICE=\"cuda0\" python -c \"import pygpu;pygpu.test()\" but still the computation seems to fail: ====================================================================== FAIL: pygpu.tests.test_blas.test_rgemmBatch_3d(16, 16, 9, 16, 'float32', ('f', 'f', 'c'), (False, False), False, 1, True, True, 0.6, 0.6) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/usr/local/lib/python2.7/dist-packages/nose/case.py\", line 197, in runTest self.test(*self.arg) File \"/home/myUser/.local/lib/python2.7/site-packages/pygpu-0.6.5-py2.7-linux-x86_64.egg/pygpu/tests/support.py\", line 39, in f func(*args, **kwargs) File \"/home/myUser/.local/lib/python2.7/site-packages/pygpu-0.6.5-py2.7-linux-x86_64.egg/pygpu/tests/test_blas.py\", line 225, in rgemmBatch_3d numpy.testing.assert_allclose(cr, numpy.asarray(gr), rtol=1e-5) File \"/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py\", line 1392, in assert_allclose verbose=verbose, header=header) File \"/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py\", line 739, in assert_array_compare raise AssertionError(msg) AssertionError: Not equal to tolerance rtol=1e-05, atol=0 (mismatch 99.9565972222%) x: array([[[ 364.203369, 258.57843 , 282.774231, ..., 322.785706, 185.089233, 300.292389], [ 203.502457, 226.207962, 202.701843, ..., 213.377808,... y: array([[[ 239.617569, 217.584824, 167.131165, ..., 211.116486, 313.409271, 244.467926], [ 248.086868, 237.813416, 164.860977, ..., 216.871902,... ---------------------------------------------------------------------- Ran 7292 tests in 177.637s FAILED (failures=137)",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm trying to use Keras with the Theano backend inside a virtual environment. The error I'm getting is: ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.5: cannot open shared object file: No such file or directory shown here: (hyperproj) $ python &gt;&gt; import theano ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.5: cannot open shared object file: No such file or directory WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available (error: cuda unavailable) This is what I've done so far: $ screen $ conda create -n hyperproj python=2.7 anaconda $ source activate hyperproj (hyperproj) $ conda install numpy (hyperproj) $ conda install keras (hyperproj) $ conda install theano (hyperproj) $ cd $HOME (hyperproj) $ cd .keras/ (hyperproj) $ vim keras.json This is what keras.json looks like now (I changed the tensorflow backend to the theano backend): { \"image_dim_ordering\": \"th\", \"epsilon\": 1e-07, \"floatx\": \"float32\", \"backend\": \"theano\" } I need to modify (or create) my .theanorc file: (hyperproj) $ vim ~/.theanorc After several tutorials, it looks like this: [global] floatX=float32 device=gpu0 [nvcc] fastmath=True [cuda] root = /usr/local/cuda-7.5 Someone said I may need to check my .bashrc file and modify my $PATH. Here's what that looks like now (after, for example, this): # Added by Canopy installer on 2016-06-20 # VIRTUAL_ENV_DISABLE_PROMPT can be set to '' to make bashprompt show that Canopy is active, otherwise 1 VIRTUAL_ENV_DISABLE_PROMPT=1 source /mnt/data/user/pkgs/enthought/canopy-1.5.1/bin/activate # added by Anaconda2 2.5.0 installer export PATH=\"/export/mlrg/user/anaconda2/bin:$PATH\" # added by Anaconda2 4.1.1 installer export PATH=\"/mnt/data/user/pkgs/anaconda2/bin:$PATH\" #added to fix the theano libcudnn issue export PATH=/usr/local/cuda/bin:/usr/local/cuda/lib64:$PATH export LD_LIBRARY_PATH=\"/usr/local/cuda/lib64/:$LD_LIBRARY_PATH I have CUDA 7.5, Ubuntu 14.04, g++ version 4.8.4. How can I resolve the error?",
        "answers": [
            [
                "Strangely, the problem was solved by logging out and logging back in again. When I logged in, I did this: $ screen $ source activate hyperproj (hyperproj) $ which nvcc #gave me /usr/local/cuda/bin/nvcc (hyperproj) $ cd /usr/local/cuda/lib64 #checked that I have libcublas.so (hyperproj) $ cd $HOME (hyperproj) $ python Python 2.7.13 |Anaconda custom (64-bit)| (default, Dec 20 2016, 23:09:15) [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. Anaconda is brought to you by Continuum Analytics. Please check out: http://continuum.io/thanks and https://anaconda.org &gt;&gt;&gt; import keras Using Theano backend. WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 Using gpu device 0: GeForce GTX TITAN Black (CNMeM is disabled, cuDNN not available)"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I had installed using conda and the terminal is giving me an error about GPU but I am not using a GPU. &gt;&gt;&gt; import theano &gt;&gt;&gt; import numpy &gt;&gt;&gt; import matplotlib &gt;&gt;&gt; import sidekit And this throws the following error: Import theano WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again. Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"/home/adit/miniconda3/lib/python3.5/site-packages/sidekit/__init__.py\", line 166, in &lt;module&gt; from sidekit.libsvm import * File \"/home/adit/miniconda3/lib/python3.5/site-packages/sidekit/libsvm/__init__.py\", line 37, in &lt;module&gt; from sidekit.libsvm.svm import * File \"/home/adit/miniconda3/lib/python3.5/site-packages/sidekit/libsvm/svm.py\", line 324, in &lt;module&gt; fillprototype(libsvm.svm_get_sv_indices, None, [POINTER(svm_model), POINTER(c_int)]) File \"/home/adit/miniconda3/lib/python3.5/ctypes/__init__.py\", line 360, in __getattr__ func = self.__getitem__(name) File \"/home/adit/miniconda3/lib/python3.5/ctypes/__init__.py\", line 365, in __getitem__ func = self._FuncPtr((name_or_ordinal, self)) AttributeError: /usr/lib/libsvm.so.3: undefined symbol: svm_get_sv_indices",
        "answers": [
            [
                "The Theano warning is not the reason of why you can't import Sidekit though. Sidekit will not be imported because it cannot locate the libsvm library file, which Sidekit requires you to install manually. Check out the Sidekit guide and this question for a solution."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I am trying to make Theano use the gpu on my Linux machine. It works from the command line, but not from Pycharm. Both are using Python 3.5 from the same folder of my machine. I am testing this script: from theano import function, config, shared, tensor import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], tensor.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, tensor.Elemwise) and ('Gpu' not in type(x.op).__name__) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') If I run it from the command line, it works fine: THEANO_FLAGS=device=cuda0 /home/jon/anaconda3/bin/python check_theano_cuda.py Looping 1000 times took 0.840969 seconds Result is [ 1.23178032 1.61879341 1.52278065 ..., 2.20771815 2.29967753 1.62323285] Used the gpu If I run it from PyCharm, I get this error: ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/home/jon/anaconda3/lib/python3.5/site-packages/theano/gpuarray/__init__.py\", line 164, in &lt;module&gt; use(config.device) File \"/home/jon/anaconda3/lib/python3.5/site-packages/theano/gpuarray/__init__.py\", line 151, in use init_dev(device) File \"/home/jon/anaconda3/lib/python3.5/site-packages/theano/gpuarray/__init__.py\", line 60, in init_dev sched=config.gpuarray.sched) File \"pygpu/gpuarray.pyx\", line 614, in pygpu.gpuarray.init (pygpu/gpuarray.c:9419) File \"pygpu/gpuarray.pyx\", line 566, in pygpu.gpuarray.pygpu_init (pygpu/gpuarray.c:9110) File \"pygpu/gpuarray.pyx\", line 1021, in pygpu.gpuarray.GpuContext.__cinit__ (pygpu/gpuarray.c:13472) pygpu.gpuarray.GpuArrayException: Error loading library: 0 In PyCharm, I have modified the run configuration's environment variables to device=cuda0, which I was hoping would duplicate what is happening from the command line version. But that doesn't work. I have tried making a file at ~/.theanorc file, but it does not work. It contained: [global] device = cuda0 floatX = float32 What else could I try to make this work? My installation must be OK as it runs from the command line.",
        "answers": [],
        "votes": []
    },
    {
        "question": "The problem is that I can't import theano. I know there's several other questions about same issue but none of them have worked for me and usually they are either with older versions or different OS. I've been trying to fix this for a few days now and I've tried every fix and trick I can find so I can't figure out anything else to try anymore than to ask here. If I try python3 -c \"import theano\" without sudo, I get the following: ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 164, in &lt;module&gt; use(config.device) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 151, in use init_dev(device) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 68, in init_dev context.cudnn_handle = dnn._make_handle(context) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/dnn.py\", line 86, in _make_handle raise RuntimeError(\"error creating cudnn handle\") RuntimeError: error creating cudnn handle With sudo I get ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 164, in &lt;module&gt; use(config.device) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 151, in use init_dev(device) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/__init__.py\", line 66, in init_dev avail = dnn.dnn_available(name) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/dnn.py\", line 175, in dnn_available if not dnn_present(): File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/dnn.py\", line 158, in dnn_present dnn_present.avail, dnn_present.msg = _dnn_check_version() File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/dnn.py\", line 131, in _dnn_check_version v = version() File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gpuarray/dnn.py\", line 339, in version profile=False) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/compile/function.py\", line 326, in function output_keys=output_keys) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/compile/pfunc.py\", line 486, in pfunc output_keys=output_keys) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1795, in orig_function defaults) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/compile/function_module.py\", line 1661, in create input_storage=input_storage_lists, storage_map=storage_map) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/link.py\", line 699, in make_thunk storage_map=storage_map)[:3] File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/vm.py\", line 1047, in make_all impl=impl)) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 935, in make_thunk no_recycling) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 839, in make_c_thunk output_storage=node_output_storage) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1190, in make_thunk keep_lock=keep_lock) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1131, in __compile__ keep_lock=keep_lock) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1586, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/cmodule.py\", line 1159, in module_from_key module = lnk.compile_cmodule(location) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1489, in compile_cmodule preargs=preargs) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/cmodule.py\", line 2325, in compile_str return dlimport(lib_filename) File \"/Users/np/miniconda3/lib/python3.6/site-packages/theano/gof/cmodule.py\", line 302, in dlimport rval = __import__(module_name, {}, {}, [module_name]) ImportError: dlopen(/Users/np/.theano/compiledir_Darwin-16.5.0-x86_64-i386-64bit-i386-3.6.1-64/tmp3r02thlc/m3d1cf20adb1014f04986e6a344a55bde.so, 2): Library not loaded: @rpath/libcudnn.6.dylib Referenced from: /Users/np/.theano/compiledir_Darwin-16.5.0-x86_64-i386-64bit-i386-3.6.1-64/tmp3r02thlc/m3d1cf20adb1014f04986e6a344a55bde.so Reason: image not found I know this is a problem with dynamic linking but I can't figure out why it isn't working. I have tried the following: disabled SIP Reinstalled CUDA and cudnn probably around 10 times now cudnn files are in both /Developer/NVIDIA/CUDA-8.0/lib and /usr/local/cuda/lib Reinstalled python, conda, theano, pygpu also around 10 times now Compiled libgpuarray from scratch Rebooted few times to make sure it's not that Executed update_dyld_shared_cache to see if it was a cache issue Tried to link libcudnn.6.dylib with install_name_tool to pygpu .so's but didn't do anything Here are my paths from .zshrc: export CUDA_HOME=/usr/local/cuda export DYLD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/extras/CUPTI/lib export LD_LIBRARY_PATH=$DYLD_LIBRARY_PATH export PATH=$CUDA_HOME/bi:$DYLD_LIBRARY_PATH:$PATH .theanorc [global] floatX = float32 device = cuda force_device = True allow_gc = False optimizer_including=cudnn [cuda] root = /usr/local/cuda [dnn] enabled = True include_path=/usr/local/cuda/include library_path=/usr/local/cuda/lib Version numbers: macOS 10.12.4 CUDA 8.0 and cudnn 6.0 Python 3.6.1 Theano 0.9.0 libgpuarray 0.6.4 pygpu 0.6.4",
        "answers": [
            [
                "I was finally able to crack this by moving libcudnn* files to /usr/lib. I have absolutely no idea why pygpu wasn't able to work with /usr/local/cuda/lib. Without sudo I still get the RuntimeError: error creating cudnn handle error but now it works at least with sudo. Though now I'm fighting with Segmentation fault: 11 but I'm guessing that's a different issue. Theano is an absolute..."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I want to use theano with GPU ,and I use the following script to test if GPU is working: import os os.environ['THEANO_FLAGS'] = \"device=gpu0\" import theano from theano import function, config, shared, tensor import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], tensor.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, tensor.Elemwise) and ('Gpu' not in type(x.op).__name__) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') but I get the following result: WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 /usr/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:556: UserWarning: Theano flag device=gpu* (old gpu back-end) only support floatX=float32. You have floatX=float64. Use the new gpu back-end with device=cuda* for that value of floatX. warnings.warn(msg) Using gpu device 0: GeForce GT 720 (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 6021) /usr/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:631: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.1. warnings.warn(warn) [Elemwise{exp,no_inplace}(&lt;TensorType(float64, vector)&gt;)] Looping 1000 times took 3.424644 seconds Result is [ 1.23178032 1.61879341 1.52278065 ..., 2.20771815 2.29967753 1.62323285] Used the cpu My Question What does the result mean? and How do I make it work to use the GPU?",
        "answers": [
            [
                "I had similar issue with new version of theano. You can try with THEANO_FLAGS=\"floatX=float32,device=gpu,nvcc.flags=-D_FORCE_INLINES\" python test_gpu.py"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I have installed theano using pip install theano, which was finished successfully. After typing import theano, I got the following warning message WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available (error: Unable to get the number of gpus What does it mean and how to resolve this issue? Thanks.",
        "answers": [],
        "votes": []
    },
    {
        "question": "I tried this keras tutorial. I'm using theano on my other project, so I changed keras to use theano and not tenorflow. But when I run this tutorial I get this error first: nvcc fatal : Cannot find compiler 'cl.exe' in PATH And after some time, in the first Epoch (out of 3), on the sample number 13056 (out of 25000) i get this error: File \"test_keras.py\", line 28, in model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\keras\\models.py\", line 845, in fit initial_epoch=initial_epoch) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\keras\\engine\\training.py\", line 1485, in fit initial_epoch=initial_epoch) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\keras\\engine\\training.py\", line 1140, in _fit_loop outs = f(ins_batch) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\keras\\backend\\theano_backend.py\", line 1094, in call return self.function(*inputs) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\theano\\compile\\function_module.py\", line 898, in call storage_map=getattr(self.fn, 'storage_map', None)) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\theano\\gof\\link.py\", line 325, in raise_with_op reraise(exc_type, exc_value, exc_trace) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\theano\\compile\\function_module.py\", line 884, in call self.fn() if output_subset is None else\\ File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\theano\\scan_module\\scan_op.py\", line 989, in rval r = p(n, [x[0] for x in i], o) File \"C:\\Users\\domi1_000\\Anaconda3\\envs\\Pyhon27\\lib\\site-packages\\theano\\scan_module\\scan_op.py\", line 978, in p self, node) File \"theano/scan_module/scan_perform.pyx\", line 445, in theano.scan_module.scan_perform.perform (C:\\Users\\domi1_000\\AppData\\Local\\Theano\\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_58_St epping_9_GenuineIntel-2.7.12-64\\scan_perform\\mod.cpp:5259) MemoryError: Apply node that caused the error: forall_inplace,cpu,grad_of_scan_fn}(TensorConstant{500}, Subtensor{int64:int64:int64}.0, Elemwise{tanh}.0, Alloc.0, InplaceDimShuffle{0,2,1}.0, Elemwise{Composite{(i0 - sqr(i1))}}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, Alloc.0, Alloc.0, Alloc.0, TensorConstant{500}, Subtensor{::, int64:int64:}.0, Subtenso r{::, :int64:}.0, Subtensor{::, int64::}.0, Subtensor{::, int64:int64:}.0, InplaceDimShuffle{1,0}.0, InplaceDimShuffle{1,0}.0, InplaceDimShuffle{1,0}.0, Alloc.0, InplaceDimShuffle{1,0}.0) Toposort index: 148 Inputs types: [TensorType(int64, scalar), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorTy pe(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(int64, scalar), TensorType(float32, matrix), TensorType(float32, matrix) , TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matr ix)] Inputs shapes: [(), (500L, 64L, 100L), (500L, 64L, 100L), (500L, 64L, 400L), (500L, 100L, 64L), (500L, 64L, 100L), (500L, 64L, 400L), (500L, 64L, 100L), (500L, 64L, 100L), (501L, 64L, 100L), (501L, 64 L, 100L), (2L, 100L, 400L), (), (100L, 100L), (100L, 100L), (100L, 100L), (100L, 100L), (100L, 100L), (100L, 100L), (100L, 100L), (100L, 400L), (100L, 100L)] Inputs strides: [(), (-25600L, 400L, 4L), (25600L, 400L, 4L), (102400L, 1600L, 4L), (-25600L, 4L, 400L), (25600L, 400L, 4L), (-1600L, 800000L, 4L), (-25600L, 400L, 4L), (-25600L, 400L, 4L), (25600L, 4 00L, 4L), (25600L, 400L, 4L), (160000L, 1600L, 4L), (), (1600L, 4L), (1600L, 4L), (1600L, 4L), (1600L, 4L), (4L, 1600L), (4L, 1600L), (4L, 1600L), (1600L, 4L), (4L, 1600L)] Inputs values: [array(500L, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(500L, dty pe=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] Outputs clients: [[], [], [Subtensor{int64}(forall_inplace,cpu,grad_of_scan_fn}.2, Constant{1})], [Subtensor{::int64}(forall_inplace,cpu,grad_of_scan_fn}.3, Constant{-1})]] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that do es not work, Theano optimizations can be disabled with 'optimizer=None'. This also happened to me on my other project, but there problem was dimension mismatch. It couldn't match node with dimensions 300x200 to node with dimension 100x100. Any help would be really appreciated.",
        "answers": [
            [
                "it says what it says. your GPU reached memory limit . If you are using Theano as backend try setting CNMeM and cuDNN. how much memory does your GPU have?"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I was using keras + theano to predict labels from a VGG pre-trained model on NVidia TK1. I am getting a faster prediction time from CPU than from GPU in predictions. If my memory is correct, prediction also involves a lot of number crunching in a repetitive way. I don't understand why CPU would be slower here though. Does anyone have a good explanation? The GPU detail line: Using gpu device 0: GK20A (CNMeM is enabled with initial size: 75.0% of memory, cuDNN Version is too old. Update to v5, was 2000.) Here comes the profiling result of the prediction: Class --- &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Class name&gt; 39.5% 39.5% 0.019s 6.42e-03s C 3 3 theano.sandbox.cuda.blas.GpuDot22 24.8% 64.3% 0.012s 6.04e-03s C 2 2 theano.sandbox.cuda.blas.GpuCorrMM 16.4% 80.8% 0.008s 1.33e-03s C 6 6 theano.sandbox.cuda.basic_ops.GpuElemwise 7.8% 88.5% 0.004s 1.89e-03s C 2 2 theano.sandbox.cuda.blas.GpuDownsampleFactorMax 4.2% 92.7% 0.002s 2.03e-03s C 1 1 theano.sandbox.rng_mrg.GPU_mrg_uniform 3.8% 96.4% 0.002s 4.57e-04s C 4 4 theano.sandbox.cuda.basic_ops.GpuContiguous 2.3% 98.8% 0.001s 5.66e-04s C 2 2 theano.sandbox.cuda.basic_ops.GpuFromHost 0.5% 99.3% 0.000s 2.51e-04s C 1 1 theano.sandbox.cuda.nnet.GpuSoftmaxWithBias 0.5% 99.8% 0.000s 2.39e-04s C 1 1 theano.sandbox.cuda.basic_ops.HostFromGpu 0.1% 99.8% 0.000s 1.37e-05s C 3 3 theano.sandbox.cuda.basic_ops.GpuReshape 0.0% 99.9% 0.000s 9.54e-06s C 2 2 theano.sandbox.cuda.basic_ops.GpuSubtensor 0.0% 99.9% 0.000s 4.35e-06s C 4 4 theano.tensor.elemwise.Elemwise 0.0% 99.9% 0.000s 5.01e-06s C 2 2 theano.sandbox.cuda.basic_ops.GpuDimShuffle 0.0% 100.0% 0.000s 3.26e-06s C 3 3 theano.compile.ops.Shape_i 0.0% 100.0% 0.000s 4.53e-06s C 2 2 theano.tensor.opt.MakeVector 0.0% 100.0% 0.000s 5.96e-06s C 1 1 theano.tensor.elemwise.Prod 0.0% 100.0% 0.000s 3.10e-06s C 1 1 theano.tensor.elemwise.DimShuffle ... (remaining 0 Classes account for 0.00%(0.00s) of the runtime) Ops --- &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Op name&gt; 39.5% 39.5% 0.019s 6.42e-03s C 3 3 GpuDot22 24.8% 64.3% 0.012s 6.04e-03s C 2 2 GpuCorrMM{valid, (1, 1)} 11.2% 75.5% 0.005s 1.36e-03s C 4 4 GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)] 7.8% 83.3% 0.004s 1.89e-03s C 2 2 GpuDownsampleFactorMax{(2, 2),True} 4.2% 87.4% 0.002s 2.03e-03s C 1 1 GPU_mrg_uniform{CudaNdarrayType(float32, 4D),inplace} 3.8% 91.2% 0.002s 4.57e-04s C 4 4 GpuContiguous 2.9% 94.1% 0.001s 1.43e-03s C 1 1 GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)] 2.3% 96.5% 0.001s 5.66e-04s C 2 2 GpuFromHost 2.3% 98.8% 0.001s 1.12e-03s C 1 1 GpuElemwise{Composite{Switch(i0, (i1 * i2 * i3), i2)}}[(0, 2)] 0.5% 99.3% 0.000s 2.51e-04s C 1 1 GpuSoftmaxWithBias 0.5% 99.8% 0.000s 2.39e-04s C 1 1 HostFromGpu 0.1% 99.8% 0.000s 1.60e-05s C 2 2 GpuReshape{4} 0.0% 99.9% 0.000s 9.54e-06s C 2 2 GpuSubtensor{::, ::, ::int64, ::int64} 0.0% 99.9% 0.000s 5.01e-06s C 2 2 GpuDimShuffle{x,0} 0.0% 99.9% 0.000s 4.53e-06s C 2 2 MakeVector{dtype='int64'} 0.0% 99.9% 0.000s 9.06e-06s C 1 1 GpuReshape{2} 0.0% 99.9% 0.000s 4.17e-06s C 2 2 Elemwise{Composite{((i0 + ((i1 + i2) // i3)) // i3)}}[(0, 2)] 0.0% 100.0% 0.000s 5.96e-06s C 1 1 Prod{acc_dtype=int64} 0.0% 100.0% 0.000s 5.96e-06s C 1 1 Elemwise{Cast{float32}} 0.0% 100.0% 0.000s 5.01e-06s C 1 1 Shape_i{0} ... (remaining 4 Ops account for 0.02%(0.00s) of the runtime) Apply ------ &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;#call&gt; &lt;id&gt; &lt;Apply name&gt; 36.4% 36.4% 0.018s 1.77e-02s 1 33 GpuDot22(GpuReshape{2}.0, dense_5_W) 15.7% 52.1% 0.008s 7.64e-03s 1 18 GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0) 9.1% 61.2% 0.004s 4.44e-03s 1 28 GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0) 5.7% 66.9% 0.003s 2.76e-03s 1 25 GpuDownsampleFactorMax{(2, 2),True}(GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0) 4.2% 71.0% 0.002s 2.03e-03s 1 20 GPU_mrg_uniform{CudaNdarrayType(float32, 4D),inplace}(&lt;CudaNdarrayType(float32, vector)&gt;, MakeVector{dtype='int64'}.0) 3.6% 74.6% 0.002s 1.74e-03s 1 34 GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](CudaNdarrayConstant{[[ 0.5]]}, GpuDot22.0, GpuDimShuffle{x,0}.0) 3.2% 77.8% 0.002s 1.54e-03s 1 22 GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuCorrMM{valid, (1, 1)}.0, GpuReshape{4}.0) 2.9% 80.7% 0.001s 1.43e-03s 1 23 GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)](GPU_mrg_uniform{CudaNdarrayType(float32, 4D),inplace}.1, CudaNdarrayConstant{[[[[ 0.80000001]]]]}) 2.7% 83.4% 0.001s 1.29e-03s 1 36 GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](CudaNdarrayConstant{[[ 0.5]]}, GpuDot22.0, GpuDimShuffle{x,0}.0) 2.3% 85.7% 0.001s 1.12e-03s 1 31 GpuElemwise{Composite{Switch(i0, (i1 * i2 * i3), i2)}}[(0, 2)](GpuFromHost.0, CudaNdarrayConstant{[[[[ 1.25]]]]}, GpuDownsampleFactorMax{(2, 2),True}.0, GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)].0) 2.2% 87.8% 0.001s 1.06e-03s 1 14 GpuContiguous(GpuSubtensor{::, ::, ::int64, ::int64}.0) 2.2% 90.0% 0.001s 1.06e-03s 1 35 GpuDot22(GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, dense_6_W) 2.1% 92.1% 0.001s 1.01e-03s 1 30 GpuDownsampleFactorMax{(2, 2),True}(GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0) 2.0% 94.1% 0.001s 9.61e-04s 1 3 GpuFromHost(convolution2d_input_1) 1.8% 95.9% 0.001s 8.71e-04s 1 29 GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuCorrMM{valid, (1, 1)}.0, GpuReshape{4}.0) 1.6% 97.4% 0.001s 7.58e-04s 1 15 GpuContiguous(GpuSubtensor{::, ::, ::int64, ::int64}.0) 1.0% 98.4% 0.000s 4.72e-04s 1 37 GpuDot22(GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, dense_7_W) 0.5% 98.9% 0.000s 2.51e-04s 1 38 GpuSoftmaxWithBias(GpuDot22.0, dense_7_b) 0.5% 99.4% 0.000s 2.39e-04s 1 39 HostFromGpu(GpuSoftmaxWithBias.0) 0.3% 99.8% 0.000s 1.70e-04s 1 19 GpuFromHost(Elemwise{Cast{float32}}.0) ... (remaining 20 Apply instances account for 0.25%(0.00s) of the runtime)",
        "answers": [
            [
                "It turns out that when keras + theano is doing prediction, the first time is the slowest. After loading the model with keras.models.load_model, the model appears not totally in memory yet, and the fist prediction call will handle the rest of the setting up. After the first prediction, the rest of the predictions goes super fast. The fist prediction for the VGG model takes 3 secs or so, but the subsequent predictions take .15 to .2 seconds. All good now."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have a linux system with three gpus. I am using keras with theano to run cnn's, In the past when I was using Theano 8.+ , I was able to assign a particular gpu to jupyter notebook window using the following: import theano.sandbox.cuda theano.sandbox.cuda.use(\"gpu2\") This allowed me to run three versions of the same cnn model using different hyper-parameters. I very recently updated both keras (to 2.0) and theano ( to 0.9). This required me to setup the gpuarray backend. Running just one jupyter notebook with a model works fine. gpu1 is selected by theano. However when I startup a second notebook with the same model, theano tries to use the gpu assigned to the first notebook, causing a memory usage problem and ultimately causing the cnn model to run on the cpu rather than using one of the available two remaining gpus. Is there a way to select the gpu that I wish the run on each jupyter notebook in theano 0.9 as I was able in theano 8.+",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am trying the LeNet5 on theano using cuda 8.0 windows 10 GTX 770M, and it seems the params cannot be updated correctedly. When I import theano, I will get this error: Can not use cuDNN on context None: cannot compile with cuDNN. We got this error: c:\\users\\yanjun~1\\appdata\\local\\temp\\try_flags_8n7fhy.c:4:19: fatal error: cudnn.h: No such file or directory compilation terminated. Mapped name None to device cuda: GeForce GTX 770M (0000:01:00.0) I have installed cudnn 5 to my cuda 8.0 by copying the files to \"NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\", but still the same error shows. Is it because theano cannot compile the cudnn\uff0c both conv2d and pool_2d cannot work properly\uff1f As result\uff0c my error rate keeps around 90% while training. Did I install cudnn correctly? I just followed the instructions on theano's documentation, but no .so* file in the zip. I've tried the cpu mode, it can be trained properly but really really slow. Hope you guys could help me out of this where I am stuck for servel days. Many thanks!",
        "answers": [
            [
                "I had a similar problem when migrating to the new theano back-end, and fixed it with the following steps (inside my conda environment). Update theano with conda update theano and get pygpy with conda install -c rdonnelly pygpu. I'm installing a RC package since it gave less issues. Check if you need to make changes to your code here Since I was using keras, I did not have to do so. Change theanorc from device = gpu to device = cuda0. If you went to the above link, you might have already done so. Add to the bottom of your theanorc file: compiler_bindir = C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin [cuda] root = C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0 [dnn] library_path = C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\lib\\x64 include_path = C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\include"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I installed theano on WIN10, and it can be imported using CPU. My graphics card is GTX1080. I installed CUDA8.0. Here is nvcc -V information: And I also run the deviceQuery.cpp in cuda samples, result = PASS. Here is the result: I also configured the .theanorc.txt\uff1a But when I import theano, it comes 2 warnings and Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005) Traceback (most recent call last): File \", line 1, in File E:\\Anaconda\\lib\\site-packages\\theano__init__.py, line 116, in theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File E:\\Anaconda\\lib\\site-packages\\theano\\sandbox\\cuda\\tests\\test_driver.py, line 41, in test_nvidia_driver1 raise Exception(The nvidia driver version installed with this OS Exception: The nvidia driver version installed with this OS does not give good results for reduction.Installing the nvidia driver available on the same download page as the cuda package will fix the problem: http://developer.nvidia.com/cuda-downloads CUDA8.0 driver version is 376.51, and I indeed installed this version. I don't know where going wrong. Can you help me to solve this problem? Thank you very much!",
        "answers": [
            [
                "Got same problem during instalation of theano following this guide. Beat this with installing top anaconda(5.0.0), creating environment with NOT top python (3.5 when top is 3.6) and installing NOT top cuda(8.0 when top is 9.0). I'm not sure it helps you, but it can helps some people in future."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I use theano 0.9.0, CUDA 8.0.61, gcc version 4.9.3, NVIDIA UNIX x86_64 Kernel Module 375.39, Ubuntu 16.04.2 LTS and I have a geforce 1060. CUDA works as I have done the tests. But whenever I do the gpu test with theano (http://deeplearning.net/software/theano/tutorial/using_gpu.html) I get this error : ImportError: ('The following error happened while compiling the node', GpuElemwise{exp,no_inplace}((float64, vector)&gt;), '\\n', 'libnvrtc.so.7.5: cannot open shared object file: No such file or directory', '[GpuElemwise{exp,no_inplace}((float64, vector)&gt;)]') Which is really silly as I have CUDA 8, not CUDA 7.5 so of course it cannot find libnvrtc.so.7.5. How can I tell theano that I'm using CUDA 8 and not CUDA 7.5 ? I have this overly complicated setup to my .bashrc : export PATH=\"/usr/local/cuda-8.0/bin:$PATH\" export LD_LIBRARY_PATH=\"/usr/local/cuda-8.0/lib64\" export CUDA_HOME=/usr/local/cuda-8.0 export CUDA_ROOT=/usr/local/cuda-8.0 export CPATH=\"$CPATH:~/.local/include\" export CPATH=\"/usr/local/cuda-8.0/include:$CPATH\" export LIBRARY_PATH=\"$LIBRARY_PATH:~/.local/lib\" export LIBRARY_PATH=\"/usr/lib/nvidia-375:$LIBRARY_PATH\" export LIBRARY_PATH=\"/usr/local/cuda-8.0/lib64:$LIBRARY_PATH\" export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:~/.local/lib\" and my .theanorc is : [nvcc] flags=-D_FORCE_INLINES [global] device = cuda0 [cuda] root = /usr/local/cuda-8.0/",
        "answers": [
            [
                "You can't. Either install CUDA 7.5 or install a version of the framework built against CUDA 8. There is no way to make what you are trying to do work."
            ],
            [
                "Edit: You should perhaps not insist on trying to make this work, given that your card is Pascal-generation and CUDA 7.5 is pre-Pascal. With that in mind... While @talonmies' answer is correct, at least one (and probably more) of the following things should actually get Theano working for you: Add a package repository for newer versions of CUDA targetted at *buntu 16.04 Xenial: deb http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu xenial main deb-src http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu xenial main put these file named, say /etc/apt/sources.list.d/graphics-drivers-ppa-xenial.list - but remember to remove/update it if you upgrade to newer version of *buntu. This should give you access to CUDA 7.5. Make sure not to install an older nVIDIA driver version, though. Manually install CUDA 7.5. You can download it from here. Adjust the settings mentioned in your question to point at /usr/local/cuda-7.5. Again, make sure you don't also install an older nVIDIA driver. Follow the installation instructions here. I'm not sure there's much more in there other than using pip, but maybe there is. Caveat: I've never used Theano myself."
            ]
        ],
        "votes": [
            1.0000001,
            -0.9999999
        ]
    },
    {
        "question": "I'm trying to use Theano with gpu. My OS is Ubuntu 16.04 Firstly, typing import theano will result in Using cuDNN version 5110 on context None Mapped name None to device cuda0: GeForce GTX 1080 (0000:01:00.0) To see if my GPU is being used I try test from theano documentation My ~/.theanorc is [global] device = cuda0 floatX = float32 [nvcc] fastmath = True In this case test says: [GpuElemwise{exp,no_inplace}(&lt;GpuArrayType&lt;None&gt;(float32, (False,))&gt;), HostFromGpu(gpuarray)(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.191431 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the cpu But using old backend with device = gpu0 says: [GpuElemwise{exp,no_inplace}(&lt;CudaNdarrayType(float32, vector)&gt;), HostFromGpu(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.199280 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the gpu So I think something goes wrong with cuda. How can I check if its ok? Why \"context\" is \"None\"? Why does test say \"using cpu\" ?",
        "answers": [
            [
                "try to replace cuda0 with cuda. I was having the same warning-like text after importing theano: Using cuDNN version 5110 on context None Mapped name None to device cuda: GeForce GT 750M (0000:01:00.0) I went ahead and trained a DNN, I can see the speed is much faster than I ran my code on CPU before. So, I guess the text doesn't mean GPU is not working."
            ]
        ],
        "votes": [
            6.0000001
        ]
    },
    {
        "question": "I got the error: Problem occurred during compilation with the command line below: /usr/bin/g++ -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -fPIC -I/scratch/user/tools/anaconda2/lib/python2.7/site-packages/numpy/core/include -I/scratch/user/tools/anaconda2/include/python2.7 -I/scratch/user/tools/anaconda2/lib/python2.7/site-packages/theano/gof -L/scratch/user/tools/anaconda2/lib -fvisibility=hidden -o /home/user/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.3.1611-Core-x86_64-2.7.13-64/tmpAKnaE0/d16654b784f584f17fdc481825fd2cca.so /home/user/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.3.1611-Core-x86_64-2.7.13-64/tmpAKnaE0/mod.cpp -lpython2.7 ['nvcc', '-shared', '-O3', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden', '-Xlinker', '-rpath,/home/user/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.3.1611-Core-x86_64-2.7.13-64/cuda_ndarray', '-I/scratch/user/tools/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda', '-I/scratch/user/tools/anaconda2/lib/python2.7/site-packages/numpy/core/include', '-I/scratch/user/tools/anaconda2/include/python2.7', '-I/scratch/user/tools/anaconda2/lib/python2.7/site-packages/theano/gof', '-L/scratch/user/tools/anaconda2/lib', '-o', '/home/user/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.3.1611-Core-x86_64-2.7.13-64/cuda_ndarray/cuda_ndarray.so', 'mod.cu', '-lcublas', '-lpython2.7', '-lcudart'] In file included from /home/user/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.3.1611-Core-x86_64-2.7.13-64/tmpAKnaE0/mod.cpp:2:0: /usr/include/c++/4.8.2/iostream:38:28: fatal error: bits/c++config.h: No such file or directory #include ^ compilation terminated. after installing theano Theano (0.9.0) on Centos 7 with Cuda 8.0. It looks like bits/c++config.h can not be found. However, it has been compiled in /usr/include/c++/4.8.5/i686-redhat-linux/bits/ atomic_word.h c++allocator.h c++io.h cpu_defines.h ctype_inline.h error_constants.h gthr-default.h gthr-posix.h messages_members.h os_defines.h stdtr1c++.h basic_file.h c++config.h c++locale.h ctype_base.h cxxabi_tweaks.h extc++.h gthr.h gthr-single.h opt_random.h stdc++.h time_members.h Thanks",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have the following: Python 2.7.5 RHEL 7.3 with FIPS enabled Lasagne (0.2.dev1) Theano (0.9.0) I installed Theano and Lasange with pip without issue, but when I import lasange I receive an error related to FIPS: $: python Python 2.7.5 (default, Aug 2 2016, 04:20:16) [GCC 4.8.5 20150623 (Red Hat 4.8.5-4)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. &gt;&gt;&gt; import lasagne ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: error:060800A3:digital envelope routines:EVP_DigestInit_ex:disabled for fips Is there some workaround known or available? Unfortunately I have to have FIPS enabled. I'm just starting out with Theano and Lasagne so I apologize if I need additional help to troubleshoot.",
        "answers": [
            [
                "As of now, it looks like md5 hashing is hardcoded into the library and has been acknowledged by Theano developers: https://github.com/Theano/Theano/issues/5757 Update: May 25, 2017 I have modified the theano code so it uses sha256 instead of md5. This has resolved the FIPS issues I've been experiencing and has not slowed down any computation I've been running. You can review the pull request here: https://github.com/Theano/Theano/pull/5916 and you can download my changes here until it is merged: https://github.com/dareneiri/Theano , if indeed it is accepted."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "Problem I always have used theano normally. WIth CUDA and CUDNN and CNMEM. I have an XTITAN. Actually I ran my code on the university server. Im trying to install libgpuarray but the tests #10 and #11 fails. What should i do ? Extra-Information nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2016 NVIDIA Corporation Built on Tue_Jan_10_13:22:03_CST_2017 Cuda compilation tools, release 8.0, V8.0.61 nvidia-smi Fri Mar 17 18:35:45 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 367.48 Driver Version: 367.48 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX TIT... Off | 0000:02:00.0 On | N/A | | 22% 36C P8 15W / 250W | 69MiB / 12204MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 GeForce GTX TIT... Off | 0000:82:00.0 Off | N/A | | 22% 43C P8 16W / 250W | 1MiB / 12206MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 GeForce GTX TIT... Off | 0000:83:00.0 Off | N/A | | 22% 30C P8 14W / 250W | 1MiB / 12206MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 1437 G /usr/bin/Xorg 40MiB | | 0 3011 G gnome-shell 27MiB | +-----------------------------------------------------------------------------+ How Im installing libgpuarray rm -rf build Build mkdir Build cd Build cmake .. -DCMAKE_INSTALL_PREFIX=~/.local -DCMAKE_BUILD_TYPE=Release make make install ... (myVE) andromeda@REDACTED:~/private/libgpuarray/Build$ cmake .. -DCMAKE_INSTALL_PREFIX=~/.local -DCMAKE_BUILD_TYPE=Release -- The C compiler identification is GNU 4.9.2 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Looking for strlcat -- Looking for strlcat - not found -- Looking for mkstemp -- Looking for mkstemp - found -- Found PkgConfig: /usr/bin/pkg-config (found version \"0.28\") -- checking for one of the modules 'check' -- Looking for ck_assert_ptr_ne -- Looking for ck_assert_ptr_ne - found -- Found MPI_C: /usr/lib/libmpi.so;/usr/lib/x86_64-linux-gnu/libdl.so;/usr/lib/x86_64-linux-gnu/libhwloc.so -- Configuring done -- Generating done -- Build files have been written to: /home/andromeda/private/libgpuarray/Build (myVE) andromeda@REDACTED:~/private/libgpuarray/Build$ make Scanning dependencies of target gpuarray [ 1%] Building C object src/CMakeFiles/gpuarray.dir/cache/lru.c.o [ 2%] Building C object src/CMakeFiles/gpuarray.dir/cache/twoq.c.o [ 3%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_types.c.o [ 4%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_error.c.o [ 5%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_util.c.o [ 6%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer.c.o [ 7%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_blas.c.o [ 8%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_collectives.c.o [ 9%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_array.c.o [ 10%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_array_blas.c.o [ 11%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_array_collectives.c.o [ 12%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_kernel.c.o [ 13%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_extension.c.o [ 14%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_elemwise.c.o [ 15%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_reduction.c.o [ 16%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_cuda.c.o [ 17%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_blas_cuda_cublas.c.o [ 18%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_collectives_cuda_nccl.c.o [ 19%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_opencl.c.o /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c: In function \u2018cl_free_ctx.part.5\u2019: /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c:223:15: warning: \u2018blas_ops\u2019 may be used uninitialized in this function [-Wmaybe-uninitialized] blas_ops-&gt;teardown((gpucontext *)ctx); ^ /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c: In function \u2018cl_deinit\u2019: /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c:223:15: warning: \u2018blas_ops\u2019 may be used uninitialized in this function [-Wmaybe-uninitialized] /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c:215:22: note: \u2018blas_ops\u2019 was declared here gpuarray_blas_ops *blas_ops; ^ [ 20%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_blas_opencl_clblas.c.o [ 21%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_blas_opencl_clblast.c.o [ 22%] Building C object src/CMakeFiles/gpuarray.dir/gpuarray_strl.c.o [ 23%] Building C object src/CMakeFiles/gpuarray.dir/util/strb.c.o [ 24%] Building C object src/CMakeFiles/gpuarray.dir/util/xxhash.c.o [ 25%] Building C object src/CMakeFiles/gpuarray.dir/util/integerfactoring.c.o [ 26%] Building C object src/CMakeFiles/gpuarray.dir/loaders/dyn_load.c.o [ 27%] Building C object src/CMakeFiles/gpuarray.dir/loaders/libcuda.c.o /home/andromeda/private/libgpuarray/src/loaders/libcuda.c: In function \u2018load_libcuda\u2019: /home/andromeda/private/libgpuarray/src/loaders/libcuda.c:46:9: warning: unused variable \u2018v\u2019 [-Wunused-variable] float v; ^ [ 28%] Building C object src/CMakeFiles/gpuarray.dir/loaders/libnvrtc.c.o [ 29%] Building C object src/CMakeFiles/gpuarray.dir/loaders/libcublas.c.o [ 30%] Building C object src/CMakeFiles/gpuarray.dir/loaders/libnccl.c.o [ 31%] Building C object src/CMakeFiles/gpuarray.dir/loaders/libopencl.c.o [ 32%] Building C object src/CMakeFiles/gpuarray.dir/loaders/libclblas.c.o [ 33%] Building C object src/CMakeFiles/gpuarray.dir/loaders/libclblast.c.o Linking C shared library ../../lib/libgpuarray.so [ 34%] Built target gpuarray Scanning dependencies of target gpuarray-static [ 35%] Building C object src/CMakeFiles/gpuarray-static.dir/cache/lru.c.o [ 36%] Building C object src/CMakeFiles/gpuarray-static.dir/cache/twoq.c.o [ 37%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_types.c.o [ 38%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_error.c.o [ 39%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_util.c.o [ 40%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer.c.o [ 41%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_blas.c.o [ 42%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_collectives.c.o [ 43%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_array.c.o [ 44%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_array_blas.c.o [ 45%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_array_collectives.c.o [ 46%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_kernel.c.o [ 47%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_extension.c.o [ 48%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_elemwise.c.o [ 49%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_reduction.c.o [ 50%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_cuda.c.o [ 51%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_blas_cuda_cublas.c.o [ 52%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_collectives_cuda_nccl.c.o [ 53%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_opencl.c.o /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c: In function \u2018cl_free_ctx.part.5\u2019: /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c:223:15: warning: \u2018blas_ops\u2019 may be used uninitialized in this function [-Wmaybe-uninitialized] blas_ops-&gt;teardown((gpucontext *)ctx); ^ /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c: In function \u2018cl_deinit\u2019: /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c:223:15: warning: \u2018blas_ops\u2019 may be used uninitialized in this function [-Wmaybe-uninitialized] /home/andromeda/private/libgpuarray/src/gpuarray_buffer_opencl.c:215:22: note: \u2018blas_ops\u2019 was declared here gpuarray_blas_ops *blas_ops; ^ [ 54%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_blas_opencl_clblas.c.o [ 55%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_blas_opencl_clblast.c.o [ 56%] Building C object src/CMakeFiles/gpuarray-static.dir/gpuarray_strl.c.o [ 57%] Building C object src/CMakeFiles/gpuarray-static.dir/util/strb.c.o [ 58%] Building C object src/CMakeFiles/gpuarray-static.dir/util/xxhash.c.o [ 59%] Building C object src/CMakeFiles/gpuarray-static.dir/util/integerfactoring.c.o [ 60%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/dyn_load.c.o [ 61%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/libcuda.c.o /home/andromeda/private/libgpuarray/src/loaders/libcuda.c: In function \u2018load_libcuda\u2019: /home/andromeda/private/libgpuarray/src/loaders/libcuda.c:46:9: warning: unused variable \u2018v\u2019 [-Wunused-variable] float v; ^ [ 62%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/libnvrtc.c.o [ 63%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/libcublas.c.o [ 64%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/libnccl.c.o [ 65%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/libopencl.c.o [ 66%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/libclblas.c.o [ 67%] Building C object src/CMakeFiles/gpuarray-static.dir/loaders/libclblast.c.o Linking C static library ../../lib/libgpuarray-static.a [ 68%] Built target gpuarray-static Scanning dependencies of target check_array [ 69%] Building C object tests/CMakeFiles/check_array.dir/main.c.o [ 70%] Building C object tests/CMakeFiles/check_array.dir/device.c.o [ 71%] Building C object tests/CMakeFiles/check_array.dir/check_array.c.o Linking C executable check_array [ 71%] Built target check_array Scanning dependencies of target check_blas [ 72%] Building C object tests/CMakeFiles/check_blas.dir/main.c.o [ 73%] Building C object tests/CMakeFiles/check_blas.dir/device.c.o [ 74%] Building C object tests/CMakeFiles/check_blas.dir/check_blas.c.o Linking C executable check_blas [ 74%] Built target check_blas Scanning dependencies of target check_buffer [ 75%] Building C object tests/CMakeFiles/check_buffer.dir/main.c.o [ 76%] Building C object tests/CMakeFiles/check_buffer.dir/device.c.o [ 77%] Building C object tests/CMakeFiles/check_buffer.dir/check_buffer.c.o Linking C executable check_buffer [ 77%] Built target check_buffer Scanning dependencies of target check_buffer_collectives [ 78%] Building C object tests/CMakeFiles/check_buffer_collectives.dir/main.c.o [ 79%] Building C object tests/CMakeFiles/check_buffer_collectives.dir/device.c.o [ 80%] Building C object tests/CMakeFiles/check_buffer_collectives.dir/communicator.c.o [ 81%] Building C object tests/CMakeFiles/check_buffer_collectives.dir/check_buffer_collectives.c.o Linking C executable check_buffer_collectives [ 81%] Built target check_buffer_collectives Scanning dependencies of target check_collectives [ 82%] Building C object tests/CMakeFiles/check_collectives.dir/main.c.o [ 83%] Building C object tests/CMakeFiles/check_collectives.dir/device.c.o [ 84%] Building C object tests/CMakeFiles/check_collectives.dir/communicator.c.o [ 85%] Building C object tests/CMakeFiles/check_collectives.dir/check_collectives.c.o Linking C executable check_collectives [ 85%] Built target check_collectives Scanning dependencies of target check_elemwise [ 86%] Building C object tests/CMakeFiles/check_elemwise.dir/main.c.o [ 87%] Building C object tests/CMakeFiles/check_elemwise.dir/device.c.o [ 88%] Building C object tests/CMakeFiles/check_elemwise.dir/check_elemwise.c.o Linking C executable check_elemwise [ 88%] Built target check_elemwise Scanning dependencies of target check_error [ 89%] Building C object tests/CMakeFiles/check_error.dir/main.c.o [ 90%] Building C object tests/CMakeFiles/check_error.dir/check_error.c.o Linking C executable check_error [ 90%] Built target check_error Scanning dependencies of target check_reduction [ 91%] Building C object tests/CMakeFiles/check_reduction.dir/main.c.o [ 92%] Building C object tests/CMakeFiles/check_reduction.dir/device.c.o [ 93%] Building C object tests/CMakeFiles/check_reduction.dir/check_reduction.c.o Linking C executable check_reduction [ 93%] Built target check_reduction Scanning dependencies of target check_types [ 94%] Building C object tests/CMakeFiles/check_types.dir/main.c.o [ 95%] Building C object tests/CMakeFiles/check_types.dir/check_types.c.o Linking C executable check_types [ 95%] Built target check_types Scanning dependencies of target check_util [ 96%] Building C object tests/CMakeFiles/check_util.dir/main.c.o [ 97%] Building C object tests/CMakeFiles/check_util.dir/check_util.c.o Linking C executable check_util [ 97%] Built target check_util Scanning dependencies of target check_util_integerfactoring [ 98%] Building C object tests/CMakeFiles/check_util_integerfactoring.dir/main.c.o [100%] Building C object tests/CMakeFiles/check_util_integerfactoring.dir/check_util_integerfactoring.c.o Linking C executable check_util_integerfactoring [100%] Built target check_util_integerfactoring ------------------ Then : (myVE) andromeda@REDACTED:~/private/libgpuarray/Build$ make install [ 34%] Built target gpuarray [ 68%] Built target gpuarray-static [ 71%] Built target check_array [ 74%] Built target check_blas [ 77%] Built target check_buffer [ 81%] Built target check_buffer_collectives [ 85%] Built target check_collectives [ 88%] Built target check_elemwise [ 90%] Built target check_error [ 93%] Built target check_reduction [ 95%] Built target check_types [ 97%] Built target check_util [100%] Built target check_util_integerfactoring Install the project... -- Install configuration: \"Release\" -- Installing: /home/andromeda/.local/include/gpuarray/array.h -- Installing: /home/andromeda/.local/include/gpuarray/blas.h -- Installing: /home/andromeda/.local/include/gpuarray/collectives.h -- Installing: /home/andromeda/.local/include/gpuarray/buffer.h -- Installing: /home/andromeda/.local/include/gpuarray/buffer_blas.h -- Installing: /home/andromeda/.local/include/gpuarray/buffer_collectives.h -- Installing: /home/andromeda/.local/include/gpuarray/abi_version.h -- Installing: /home/andromeda/.local/include/gpuarray/config.h -- Installing: /home/andromeda/.local/include/gpuarray/elemwise.h -- Installing: /home/andromeda/.local/include/gpuarray/error.h -- Installing: /home/andromeda/.local/include/gpuarray/extension.h -- Installing: /home/andromeda/.local/include/gpuarray/ext_cuda.h -- Installing: /home/andromeda/.local/include/gpuarray/kernel.h -- Installing: /home/andromeda/.local/include/gpuarray/types.h -- Installing: /home/andromeda/.local/include/gpuarray/util.h -- Installing: /home/andromeda/.local/lib/libgpuarray.so.2.0 -- Up-to-date: /home/andromeda/.local/lib/libgpuarray.so.2 -- Up-to-date: /home/andromeda/.local/lib/libgpuarray.so -- Installing: /home/andromeda/.local/lib/libgpuarray-static.a And the test : (myVE) andromeda@REDACTED:~/private/libgpuarray/Build$ DEVICE=cuda2 make test Running tests... Test project /home/andromeda/private/libgpuarray/Build Start 1: test_types 1/11 Test #1: test_types ....................... Passed 0.01 sec Start 2: test_util 2/11 Test #2: test_util ........................ Passed 0.01 sec Start 3: test_util_integerfactoring 3/11 Test #3: test_util_integerfactoring ....... Passed 0.67 sec Start 4: test_reduction 4/11 Test #4: test_reduction ................... Passed 8.30 sec Start 5: test_array 5/11 Test #5: test_array ....................... Passed 3.13 sec Start 6: test_blas 6/11 Test #6: test_blas ........................ Passed 3.49 sec Start 7: test_elemwise 7/11 Test #7: test_elemwise .................... Passed 25.22 sec Start 8: test_error 8/11 Test #8: test_error ....................... Passed 0.02 sec Start 9: test_buffer 9/11 Test #9: test_buffer ...................... Passed 4.77 sec Start 10: test_buffer_collectives 10/11 Test #10: test_buffer_collectives ..........***Failed 0.87 sec Start 11: test_collectives 11/11 Test #11: test_collectives .................***Failed 0.85 sec 82% tests passed, 2 tests failed out of 11 Total Test time (real) = 47.37 sec The following tests FAILED: 10 - test_buffer_collectives (Failed) 11 - test_collectives (Failed) Errors while running CTest Makefile:117: recipe for target 'test' failed make: *** [test] Error 8 (myVE) andromeda@REDACTED:~/private/libgpuarray/Build$",
        "answers": [
            [
                "According to the github libgpuarray issues : The last two tests require nccl and will fail if it's not present. If you're not trying to use nccl, you can ignore those failures. \u2014 https://github.com/Theano/libgpuarray/issues/383#issuecomment-287491789"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I configure the GPU under home/.theanorc as follows bash-4.1$ cat .theanorc [global] floatX = float32 device = gpu0 [lib] cnmem = 1 Running the program gives the following warning message, how to solve this problem? python train.py Using Theano backend. WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.",
        "answers": [
            [
                "The warning regarding the cuda backend can be mitigated by following the steps in the provided link (https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29) This is only a warning and the code should run event if you don't fix it. For the error you first need to make sure that nvcc compiler is installed and the path is setup correctly. assuming the installation is in the directory /usr/local/cuda-7.0 you need to do the following export PATH=/usr/local/cuda-7.0/bin:$PATH and export LD_LIBRARY_PATH=/usr/local/cuda-7.0/targets/x86_64-linux/lib:$LD_LIBRARY_PATH"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "System: Ubuntu 16.04.2 cudnn 5.1, CUDA 8.0 I have theano installed from git (latest version). When I run the generate sample from https://github.com/yusuketomoto/chainer-fast-neuralstyle/tree/resize-conv, it reports back out of memory whether CPU or GPU is used. python generate.py sample_images/tubingen.jpg -m models/composition.model -o sample_images/output.jpg -g 0 WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 /home/ubuntu/Theano/theano/sandbox/cuda/__init__.py:558: UserWarning: Theano flag device=gpu* (old gpu back-end) only support floatX=float32. You have floatX=float64. Use the new gpu back-end with device=cuda* for that value of floatX. warnings.warn(msg) Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105) Traceback (most recent call last): File \"generate.py\", line 45, in &lt;module&gt; y = model(x) File \"/home/ubuntu/chainer-fast-neuralstyle/net.py\", line 56, in __call__ h = F.relu(self.b2(self.c2(h), test=test)) File \"/usr/local/lib/python2.7/dist-packages/chainer/links/connection/convolution_2d.py\", line 108, in __call__ deterministic=self.deterministic) File \"/usr/local/lib/python2.7/dist-packages/chainer/functions/connection/convolution_2d.py\", line 326, in convolution_2d return func(x, W, b) File \"/usr/local/lib/python2.7/dist-packages/chainer/function.py\", line 199, in __call__ outputs = self.forward(in_data) File \"/usr/local/lib/python2.7/dist-packages/chainer/function.py\", line 310, in forward return self.forward_gpu(inputs) File \"/usr/local/lib/python2.7/dist-packages/chainer/functions/connection/convolution_2d.py\", line 90, in forward_gpu y = cuda.cupy.empty((n, out_c, out_h, out_w), dtype=x.dtype) File \"/usr/local/lib/python2.7/dist-packages/cupy/creation/basic.py\", line 19, in empty return cupy.ndarray(shape, dtype=dtype, order=order) File \"cupy/core/core.pyx\", line 88, in cupy.core.core.ndarray.__init__ (cupy/core/core.cpp:6333) File \"cupy/cuda/memory.pyx\", line 280, in cupy.cuda.memory.alloc (cupy/cuda/memory.cpp:5988) File \"cupy/cuda/memory.pyx\", line 431, in cupy.cuda.memory.MemoryPool.malloc (cupy/cuda/memory.cpp:9256) File \"cupy/cuda/memory.pyx\", line 447, in cupy.cuda.memory.MemoryPool.malloc (cupy/cuda/memory.cpp:9162) File \"cupy/cuda/memory.pyx\", line 342, in cupy.cuda.memory.SingleDeviceMemoryPool.malloc (cupy/cuda/memory.cpp:7817) File \"cupy/cuda/memory.pyx\", line 368, in cupy.cuda.memory.SingleDeviceMemoryPool.malloc (cupy/cuda/memory.cpp:7592) File \"cupy/cuda/memory.pyx\", line 260, in cupy.cuda.memory._malloc (cupy/cuda/memory.cpp:5930) File \"cupy/cuda/memory.pyx\", line 261, in cupy.cuda.memory._malloc (cupy/cuda/memory.cpp:5851) File \"cupy/cuda/memory.pyx\", line 35, in cupy.cuda.memory.Memory.__init__ (cupy/cuda/memory.cpp:1772) File \"cupy/cuda/runtime.pyx\", line 207, in cupy.cuda.runtime.malloc (cupy/cuda/runtime.cpp:3429) File \"cupy/cuda/runtime.pyx\", line 130, in cupy.cuda.runtime.check_status (cupy/cuda/runtime.cpp:2241) cupy.cuda.runtime.CUDARuntimeError: cudaErrorMemoryAllocation: out of memory - import theano.sandbox.cuda.basic_ops as sbcuda sbcuda.cuda_ndarray.cuda_ndarray.mem_info() (500105216L, 11995578368L) - lspci -vvv |grep -i -A 20 nvidia 00:04.0 3D controller: NVIDIA Corporation GK210GL [Tesla K80] (rev a1) Subsystem: NVIDIA Corporation GK210GL [Tesla K80] Physical Slot: 4 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &gt;TAbort- &lt;TAbort- &lt;MAbort- &gt;SERR- &lt;PERR- INTx- Latency: 0 Interrupt: pin A routed to IRQ 11 Region 0: Memory at fd000000 (32-bit, non-prefetchable) [size=16M] Region 1: Memory at 400000000 (64-bit, prefetchable) [size=16G] Region 3: Memory at 800000000 (64-bit, prefetchable) [size=32M] Region 5: I/O ports at c000 [size=128] Capabilities: &lt;access denied&gt; Kernel driver in use: nvidia Kernel modules: nvidia_375_drm, nvidia_375 What exactly do those numbers mean? Theano/Chainer only has access to ~500MB of VRAM?",
        "answers": [
            [
                "I managed to fix the issue by completely uninstalling theano. I was confused as to why importing chainer displayed the theano warnings, but it was doing that. Uninstalling theano allowed the chainer script to work."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "So I have the following situation: computer with 3 graphic cards python script using Keras with Theano backend and multiple threads I specified the device to use in .theanorc as described in the documentation. The python script is of this form (still working on a standalone example): import theano from threading import Thread ... class Test(Thread): def run(self): #calculations with Keras test = Test() test.start() test.join() Starting the script Theano uses the specified device but after some time a second python thread appears on one of the other graphic cards (and uses up resources). The second thread seems to ignore the config as its running on the wrong GPU and isn't allocating ram as specified by the CNEM flag. This should not be possible according to the documentation as everything that forks from the thread that started the Theano calculation should be running on the same device (ensured by importing Theano right at the beginning). After some poking around I found out that this behavior stops when I don't run my Keras code in a separate thread. So before I start creating Github issues I would like some pointers what's most likely: Is this a bug in Theano? Is this a bug in Keras? Is this a bug in my own code? @3. My whole project doesn't create separate Python processes (confirmed over process list) and doesn't change any Theano configuration. Any idea what could even cause this kind of behavior?",
        "answers": [
            [
                "Device(gpu) setting of a thread is independent with other threads in the same process. Look this for more details. I haven't found a way to set device for current thread in Theano. I use obsoleted cuda_ndarray back end, there is no way to do this, but I don't know if there is a way to do this in gpuarray back end. I do some workaround: import numpy as np import theano from theano import Apply from theano import tensor as T from theano.scalar import Scalar from theano.sandbox.cuda import GpuOp, nvcc_compiler class SetGpu(GpuOp): ''' Set device(gpu) for current thread. ''' def c_compiler(self): return nvcc_compiler.NVCC_compiler def make_node(self, gpu_id): dummy_out = Scalar(\"int32\")() return Apply(self, [gpu_id], [dummy_out]) def __str__(self): return \"SetGpu\" def c_support_code_apply(self, node, nodename): return \"\" def c_code(self, node, nodename, inps, outs, sub): gpu_id, = inps dummy_out, = outs return \"\"\" int _gpu_id = *((int*)PyArray_DATA(%(gpu_id)s)); %(dummy_out)s = _gpu_id; cudaError_t err = cudaSetDevice(_gpu_id); if(err != cudaSuccess){ PyErr_Format(PyExc_RuntimeError, \"Cuda err:\\\\\"%%s\\\\\" when calling cudaSetDevice(%%d).\", cudaGetErrorString(err), _gpu_id); return 0; } \"\"\" % locals() def set_gpu(gpu_id): if not hasattr(set_gpu, \"f\"): set_gpu_op = SetGpu() gpu_id_var = T.iscalar() dummy_out = set_gpu_op(gpu_id_var) set_gpu.f = theano.function([gpu_id_var], [dummy_out]) _dummy_out = set_gpu.f(gpu_id) if __name__ == \"__main__\": def test(): set_gpu(5) print \"Test thread is using gpu %d.\" % theano.sandbox.cuda.active_device_number() print \"Main thread is using gpu %d.\" % theano.sandbox.cuda.active_device_number() from threading import Thread thread = Thread(target=test) thread.start() thread.join() So let's call this file set_gpu.py here is what I get running it: python set_gpu.py WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10). Please switch to the gpuarray backend. You can get more information about how to switch at this URL: https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5110) Main thread is using gpu 0. Test thread is using gpu 5."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I've spent a few days trying to use my GPU with theano in Windows, but I've encountered several problems and after trying everything I've found in Google it still doesn't work. The error I get is the following one: =============================== nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). mod.cu nvcc error : 'cl.exe' died with status 0xC0000135 ['nvcc', '-shared', '-O3', '--compiler-bindir', 'D:\\\\Programas\\\\Visual Studio\\\\2012\\\\VC\\\\bin', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda', '-ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include', '-ID:\\\\Anaconda2\\\\include', '-ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\gof', '-o', 'C:\\\\Users\\\\axelp\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.13-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-LD:\\\\Anaconda2\\\\libs', '-LD:\\\\Anaconda2', '-lcublas', '-lpython27', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 53, 'for cmd', 'nvcc -shared -O3 --compiler-bindir D:\\\\Programas\\\\Visual Studio\\\\2012\\\\VC\\\\bin -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda -ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -ID:\\\\Anaconda2\\\\include -ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\gof -o C:\\\\Users\\\\axelp\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.13-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LD:\\\\Anaconda2\\\\libs -LD:\\\\Anaconda2 -lcublas -lpython27 -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) Information about my installation: I've installed CUDA v8.0 from the official NVidia site My GPU is a GEFORCE GTX 960M I've installed Visual Studio 2012. I previously tried to used the 2015 and 2017 versions, but I got a lot of errors (if I remember correctly, it stated that the architecture was unsupported) and saw that this one has better support. In case it matters, I didn't select the default directory (as it's on the SSD and I always try to save space on it), but on the regular HDD. I use Windows 10 Home 64 bits My Python version is the 2.7.13 from Anaconda I've created a .theanorc.txt file in my User root directory with the following content: #!sh [global] device = gpu floatX = float32 [nvcc] compiler_bindir=D:\\Programas\\Visual Studio\\2012\\VC\\bin My theano version is 0.8.2 Does anyone know how to solve it? Of course, don't hesitate to ask if I need to provide more information. Thank you so much in advance for your help!",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am a beginner in deep learning/theano/keras.I'm trying to figure out how to use multiple gpus on windows 7. I've had success installing Theano,keras(as described in this post How do I install Keras and Theano in Anaconda Python on Windows?) and using one gpu. I want to use both my gpus Following are the details of configs and versions Python - 2.7(Anaconda-4.3.14,Windows-64bit) ,CUDA - 7.5.17 ,Theano - 0.9.0rc3 ,keras - 1.2.2 ,pycuda - 2016.1.2+cuda7518 ,gpu - Geforce GTX 480(2 of them) Theano configuration is as below .theanorc.txt [global] floatX = float32 device = gpu [nvcc] flags=-LC:\\ProgramData\\Anaconda2\\libs compiler_bindir=C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin [lib] cnmem=0.8 Currently I'm able to use only one GPU and I am getting memory error as below when I try to fit the model MemoryError: ('Error allocating 411041792 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).', \"you might consider using 'theano.shared(..., borrow=True)'\") Does using 2 gpus solve the problem(if yes, how do I enable the second one?) or is my model too big ? Thank You",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have installed Anaconda, theano , GPU Toolkit ver 8. I am getting this error. ERROR: refusing to load cuda driver library because the version is blacklisted. Versions 373.06 and below are known to be ok. If you want to bypass this check and force the driver load define GPUARRAY_FORCE_CUDA_DRIVER_LOAD in your environement. ERROR (theano.gpuarray): Could not initialize pygpu, support disabled",
        "answers": [
            [
                "See discussion here. I reinstalled libgpuarray and it worked for me."
            ],
            [
                "Your cuda driver is faulty. Install another one, preferably 373.06. Using your current driver will result in wrong computations. DO NOT force the driver load"
            ]
        ],
        "votes": [
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "Hi I am trying to run theano on gpu. My configuration is Windows 7 CUDA toolkit 8.0 Anaconda python 3.5 Visual studio 14.0 =============================== 'C:\\Program' is not recognized as an internal or external command, operable program or batch file. ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -LC:\\\\Anaconda\\\\libs --compiler-bindir C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\VC\\\\bin -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda -IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\include -IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\theano\\\\gof -o C:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-3.5.2-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\libs -LC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3 -lcublas -lpython35 -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). mod.cu ['nvcc', '-shared', '-O3', '-LC:\\\\Anaconda\\\\libs', '--compiler-bindir', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 14.0\\\\VC\\\\bin', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda', '-IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include', '-IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\include', '-IC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\theano\\\\gof', '-o', 'C:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-3.5.2-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-LC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\libs', '-LC:\\\\Users\\\\aniketb\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3', '-lcublas', '-lpython35', '-lcudart'] runfile('C:/Python27/test.py', wdir='C:/Python27') [Elemwise{exp,no_inplace}(&lt;TensorType(float32, vector)&gt;)] Looping 1000 times took 12.502791 seconds Result is [ 1.23178029 1.61879337 1.52278066 ..., 2.20771813 2.29967761 1.62323284] Used the cpu Any idea ?",
        "answers": [],
        "votes": []
    },
    {
        "question": "My OS is Win10_64, i've installed cuda8.0, and i already have the graphics driver updated but.. when i type in 'import theano', it says: DEBUG: nvcc STDOUT mod.cu building library: C:/Users/asus/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0- Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.6.0-64/tmp81safx1e/m91973e5c136ea49268a916ff971b7377.lib and subject C:/Users/asus/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.6.0-64/tmp81safx1e/ m91973e5c136ea49268a916ff971b7377.exp Using gpu device 0: GeForce GTX 960M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5005) Traceback (most recent call last): File \"mlp.py\", line 10, in &lt;module&gt; import theano File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\theano\\__init__.py\", line 111, in &lt;module&gt; theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\theano\\sandbox \\cuda\\tests\\test_driver.py\", line 39, in test_nvidia_driver1 raise Exception(\"The nvidia driver version installed with this OS \" Exception: The nvidia driver version installed with this OS does not give good results for reduction.Installing the nvidia driver available on the same download page as the cuda package will fix the problem: http://developer.nvidia.com/cuda-downloads and My python version is 3.6 I don't know if it's about the version of cuda or something else? When i type in nvcc -V, it shows: nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2016 NVIDIA Corporation Built on Mon_Jan__9_17:32:33_CST_2017 Cuda compilation tools, release 8.0, V8.0.60 So i guess cuda is ok. don't know how to solve it... I'll appreciate if you know how to solve it. Thank you!",
        "answers": [],
        "votes": []
    },
    {
        "question": "While trying to run my Keras code on GPU (CUDA installed), I am not able to execute the following statement, as has been suggested on many online references. set THEANO_FLAGS=\"mode=FAST_RUN,device=gpu,floatX=float32\" &amp; python theanogpu_example.py I am getting the following error. ValueError: Invalid value (\"FAST_RUN,device=gpu,floatX=float32\") for configurati on variable \"mode\". Valid options are ('Mode', 'DebugMode', 'FAST_RUN', 'NanGuar dMode', 'FAST_COMPILE', 'DEBUG_MODE') I have tried the other mode suggested as well from inside the code. import theano theano.config.device = 'gpu' theano.config.floatX = 'float32' I get the following error. Exception: Can't change the value of this config parameter after initialization! Apart from knowing how to make it run, I would also take this opportunity to ask a simpler question. How to know in Windows what is my device i.e. whether 'gpu' or 'gpu1' or 'gpu0'? I have tried all 3 for my case but it hasn't yielded result. Any suggestions will be appreciated.",
        "answers": [
            [
                "The best way is using THEANO_FLAGS before run code, because the config variables cannot be changed after importing Theano, try this: import os os.environ['THEANO_FLAGS'] = \"device=cuda,force_device=True,floatX=float32\" import theano"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'm trying to use Theano with my GPU for several days in my Python environment. While importing theano, I obtain this error: d:\\anaconda2\\include\\pyconfig.h(239) : fatal error C1083: Cannot open include file: 'basetsd.h': No such file or directory I tried to include \"D:\\Anaconda2\\MinGW\\x86_64-w64-mingw32\\include\" (this folder contains \"pyconfig.h\") in PYTHONPATH, in PATH and in .theanorc.txt, with the same error message. Do you have any ideas to connect anaconda/cuda/nvcc to the compiler in Theano? Here is my configuration: OS: Windows 7 GPU: GeForce GTX 950 cl.exe : D:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC\\bin nvcc.exe : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin Python IDE: Spyder from Anaconda 2, in Python 2. Theano 0.8.2 I can \"import theano\" with the CPU, but I want to use GPU for computations. After typing \"import theano\" (with device=gpu), I can see a console window launching \"nvcc.exe\" before showing the error. I tested CUDA with Visual Studio 2012 and it's working, for example \"bilateralFilter\" works in Visual Studio without error: Found 1 CUDA Capable device(s) supporting CUDA Device 0: \"GeForce GTX 950\" CUDA Runtime Version: 8.0 CUDA Compute Capability: 5.2 ... Running Standard Demonstration with GLUT loop... Here is my theanorc.txt file (the same error occurs with or without [nvcc] and [cuda]) [global] device = gpu floatX = float32 [cuda] root = -LC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0 [nvcc] flags = -LD:\\Anaconda\\libs fastmath = True compiler-bindir = -LD:\\Anaconda2\\MinGW\\x86_64-w64-mingw32\\include Here is my PATH D:\\Anaconda2\\MinGW\\x86_64-w64-mingw32\\include C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\libnvvp C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC\\bin D:\\Anaconda2 D:\\Anaconda2\\Scripts D:\\Anaconda2\\Library\\bin C:\\Program Files (x86)\\Windows Kits\\8.0\\Windows Performance Toolkit\\ C:\\Program Files\\Microsoft SQL Server\\110\\Tools\\Binn\\ Here is my PYTHONPATH D:\\Anaconda2\\MinGW\\x86_64-w64-mingw32\\include C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC\\bin\\amd64 C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC\\bin C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin Here is the complete error message after typing \"import theano\" in Spyder (with device=gpu in theanorc.txt): 1 #define _CUDA_NDARRAY_C 2 3 #include &lt;Python.h&gt; 4 #include &lt;structmember.h&gt; 5 #include \"theano_mod_helper.h\" 6 7 #include &lt;numpy/arrayobject.h&gt; 8 #include &lt;iostream&gt; ... 5358 /* 5359 Local Variables: 5360 mode:c++ 5361 c-basic-offset:4 5362 c-file-style:\"stroustrup\" 5363 indent-tabs-mode:nil 5364 fill-column:79 5365 End: 5366 */ 5367 // vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:textwidth=79 : 5368 =============================== c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(849) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(1787) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(2637) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(3492) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(4431) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(5345) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(6252) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(7142) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(7956) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_functions.h : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_functions.h(774) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_functions.h(1618) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_double_functions.h : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\sm_20_intrinsics.h : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\sm_20_intrinsics.h(943) : warning C4819: The file contains a character that cannot be represented in the current code page (936). Save the file in Unicode format to prevent data loss d:\\anaconda2\\include\\pyconfig.h(239) : fatal error C1083: Cannot open include file: 'basetsd.h': No such file or directory ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -LD:\\\\Anaconda\\\\libs -use_fast_math -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda -ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -ID:\\\\Anaconda2\\\\include -ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\gof -o C:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.13-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LD:\\\\Anaconda2\\\\libs -LD:\\\\Anaconda2 -lcublas -lpython27 -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). mod.cu ['nvcc', '-shared', '-O3', '-LD:\\\\Anaconda\\\\libs', '-use_fast_math', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda', '-ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include', '-ID:\\\\Anaconda2\\\\include', '-ID:\\\\Anaconda2\\\\lib\\\\site-packages\\\\theano\\\\gof', '-o', 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.13-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-LD:\\\\Anaconda2\\\\libs', '-LD:\\\\Anaconda2', '-lcublas', '-lpython27', '-lcudart']",
        "answers": [
            [
                "I found a solution for my problem. Short answer Add C:\\Windows\\System32 to PATH Launch C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC\\bin\\amd64\\vcvars64.bat End. For information, here is my new current PATH: C:\\Windows\\System32 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin C:\\Program Files (x86)\\Microsoft Visual Studio 11.0\\VC\\bin\\amd64 D:\\Anaconda2 D:\\Anaconda2\\Scripts D:\\Anaconda2\\Library\\bin Here is my PYTHONPATH: nothing Here is my .theanorc.txt: [global] device=gpu floatx = float32 Some details In addition with PATH, one needs to configure Windows registry, as explained in this post: compilation error in visual studio linked with python26 . It is done by launching vcvars64.bat I did this before, but I forgot to notice that a message appeared: ERROR: Cannot determine the location of the VS Common Tools folder. According to https://social.msdn.microsoft.com/Forums/en-US/78703f6b-f610-456c-b770-76a12be3e1ae/error-cannot-determine-the-location-of-the-vs-common-tools-folder?forum=vssetup , the solution is to add C:\\Windows\\System32 to PATH."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have working installtion of CUDA8 and have installed theano, while importing the theano it searches for CUDA7.5 instead of CUDA8, How can tell theano to use CUDA8 instead of CUDA7.5? My sytem only have CUDA8, and it doesn't contain mixed environment cuda(i.e. having both CUDA7.5 and CUDA8). Here is a output of nvidia-smi $ nvidia-smi Sat Feb 4 11:32:30 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 375.26 Driver Version: 375.26 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 970M Off | 0000:01:00.0 Off | N/A | | N/A 54C P0 22W / N/A | 0MiB / 3016MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | Here is a output of nvcc -V $ nvcc -V nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2016 NVIDIA Corporation Built on Sun_Sep__4_22:14:01_CDT_2016 Cuda compilation tools, release 8.0, V8.0.44 While importing theano in ipython it fails to run in gpu mode with error that, it can't find the libcudart.so.7.5 Python 3.6.0 (default, Jan 16 2017, 12:12:55) Type \"copyright\", \"credits\" or \"license\" for more information. IPython 5.1.0 -- An enhanced Interactive Python. ? -&gt; Introduction and overview of IPython's features. %quickref -&gt; Quick reference. help -&gt; Python's own help system. object? -&gt; Details about 'object', use 'object??' for extra details. In [1]: import theano ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcudart.so.7.5: cannot open shared object file: No such file or directory WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available (error: cuda unavailable) Here is a content of my .theanorc [global] floatX = float32 device = gpu0 cuda.root = /opt/cuda I tried to build theano from source, after uninstalling the previous installtion of it, that too is not working. I did cleared the theano-cache with theano-cache clean/theano-cache purge and my manually deleting the content under .theano directory, which too couldn't helped. With more debugging I get error here https://github.com/Theano/Theano/blob/8b9f73365e4932f1c005a0a37b907d28985fbc5f/theano/gof/cmodule.py#L302 when nvcc_compiler tries to load the cuda_ndarray.so from cuda_ndarray in theano cache comiplation phase for mod.cu runs without error. In this case linker is pointing to wrong libcudart readelf -a cuda_ndarray.so | grep NEEDED 0x0000000000000001 (NEEDED) Shared library: [libcublas.so.8.0] 0x0000000000000001 (NEEDED) Shared library: [libpython3.6m.so.1.0] 0x0000000000000001 (NEEDED) Shared library: [libcudart.so.7.5] 0x0000000000000001 (NEEDED) Shared library: [librt.so.1] 0x0000000000000001 (NEEDED) Shared library: [libpthread.so.0] 0x0000000000000001 (NEEDED) Shared library: [libdl.so.2] 0x0000000000000001 (NEEDED) Shared library: [libstdc++.so.6] 0x0000000000000001 (NEEDED) Shared library: [libm.so.6] 0x0000000000000001 (NEEDED) Shared library: [libgcc_s.so.1] 0x0000000000000001 (NEEDED) Shared library: [libc.so.6] I assume ldconfig is properly caching the cuda libraries $ sudo ldconfig -v | grep -e 'cuda\\|blas' /opt/cuda/lib64: libcublas.so.8.0 -&gt; libcublas.so.8.0.45 libcudart.so.8.0 -&gt; libcudart.so.8.0.44 libnvblas.so.8.0 -&gt; libnvblas.so.8.0.44 /opt/cuda/nvvm/lib64: libcuda.so.1 -&gt; libcuda.so.375.26 libblas.so.3 -&gt; libblas.so.3.7.0 libicudata.so.58 -&gt; libicudata.so.58.2 libopenblas.so.0 -&gt; libopenblas.so libicudata.so.58 -&gt; libicudata.so.58.1",
        "answers": [
            [
                "After more digging about the my issue, I refactored my original question and posted here nvcc is picking wrong libcudart library which resolved my problem."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "To configure theano we create a .theanorc file in your home folder and add the following to set up theano to run on GPU. [global] device = gpu floatx = float32 but sometime i save in configure that smbd put device = cuda, what's the difference? As i understans, if you use cuda, it should work faster because cuda drivers will manage gpu more better,not getting other jobs for gpu at calculation time",
        "answers": [
            [
                "Setting device=gpu in your .theanorc file instructs Theano to use the cuda backend. On the other hand, setting device=cuda instructs theano to use the libgpuarray backend. Both lead to the use of the GPU (in contrast to setting device=cpu in your .theanorc file which would lead to the use of the CPU), and the difference is the low-level API they use to communicate with it. The libgpuarray backend is the newer one of the two that is a wrapper that allows Theano to communicate with both cuda (for NVIDIA GPUs) and opencl (for non-NVIDIA GPUs). Note that the cuda backend will be deprecated in the next release of Theano and it is recommended that you always use the libgpuarray backend henceforth."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "This is an error message I get when I execute import theano: ImportError: dynamic module does not define module export function (PyInit_m3d1cf20adb1014f04986e6a344a55bde) I'm using Python 3.5.2 on Windows 10. I have also asked this of the authors of Theano on GitHub. I'm asking here hoping somebody will be able to help me even if he/she doesn't know Theano's internals. I suspect this has more to do with Python 2 versus 3. Here's the full error: ERROR (theano.gpuarray): Could not initialize pygpu, support disabled Traceback (most recent call last): File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gpuarray\\__init__.py\", line 164, in &lt;module&gt; use(config.device) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gpuarray\\__init__.py\", line 151, in use init_dev(device) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gpuarray\\__init__.py\", line 66, in init_dev avail = dnn.dnn_available(name) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gpuarray\\dnn.py\", line 174, in dnn_available if not dnn_present(): File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gpuarray\\dnn.py\", line 157, in dnn_present dnn_present.avail, dnn_present.msg = _dnn_check_version() File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gpuarray\\dnn.py\", line 130, in _dnn_check_version v = version() File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gpuarray\\dnn.py\", line 316, in version profile=False) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\compile\\function.py\", line 326, in function output_keys=output_keys) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\compile\\pfunc.py\", line 486, in pfunc output_keys=output_keys) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\compile\\function_module.py\", line 1795, in orig_function defaults) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\compile\\function_module.py\", line 1661, in create input_storage=input_storage_lists, storage_map=storage_map) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\link.py\", line 699, in make_thunk storage_map=storage_map)[:3] File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\vm.py\", line 1063, in make_all impl=impl)) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\op.py\", line 924, in make_thunk no_recycling) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\op.py\", line 828, in make_c_thunk output_storage=node_output_storage) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\cc.py\", line 1190, in make_thunk keep_lock=keep_lock) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\cc.py\", line 1131, in __compile__ keep_lock=keep_lock) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\cc.py\", line 1589, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\cmodule.py\", line 1155, in module_from_key module = lnk.compile_cmodule(location) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\cc.py\", line 1492, in compile_cmodule preargs=preargs) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\cmodule.py\", line 2318, in compile_str return dlimport(lib_filename) File \"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\\cmodule.py\", line 302, in dlimport rval = __import__(module_name, {}, {}, [module_name]) ImportError: dynamic module does not define module export function (PyInit_m3d1cf20adb1014f04986e6a344a55bde) As far as I can tell, Theano compiles a cpp file. Here are the files after the compilation: Directory of [..]\\tmp04_uyjkc 04/02/2017 16:41 &lt;DIR&gt; . 04/02/2017 16:41 &lt;DIR&gt; .. 04/02/2017 16:08 0 delete.me 04/02/2017 16:08 108.834 m3d1cf20adb1014f04986e6a344a55bde.pyd 04/02/2017 16:08 5.502 mod.cpp 04/02/2017 16:41 0 ok.txt 04/02/2017 16:08 0 __init__.py 04/02/2017 16:08 &lt;DIR&gt; __pycache__ 5 File(s) 114.336 bytes Directory of [..]\\tmp04_uyjkc\\__pycache__ 04/02/2017 16:08 &lt;DIR&gt; . 04/02/2017 16:08 &lt;DIR&gt; .. 04/02/2017 16:08 239 __init__.cpython-35.pyc 1 File(s) 239 bytes Here's the content of mod.cpp: #include &lt;Python.h&gt; #include &lt;iostream&gt; #include \"theano_mod_helper.h\" #include \"cudnn.h\" ////////////////////// //// Support Code ////////////////////// #if PY_MAJOR_VERSION &gt;= 3 #define PyInt_FromLong PyLong_FromLong #endif namespace { struct __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde { PyObject* __ERROR; PyObject* storage_V1; __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde() { // This is only somewhat safe because we: // 1) Are not a virtual class // 2) Do not use any virtual classes in the members // 3) Deal with mostly POD and pointers // If this changes, we would have to revise this, but for // now I am tired of chasing segfaults because // initialization code had an error and some pointer has // a junk value. memset(this, 0, sizeof(*this)); } ~__struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde(void) { cleanup(); } int init(PyObject* __ERROR, PyObject* storage_V1) { Py_XINCREF(storage_V1); this-&gt;storage_V1 = storage_V1; this-&gt;__ERROR = __ERROR; return 0; } void cleanup(void) { __label_1: double __DUMMY_1; __label_4: double __DUMMY_4; Py_XDECREF(this-&gt;storage_V1); } int run(void) { int __failure = 0; PyObject* py_V1; PyObject* V1; { py_V1 = Py_None; {Py_XINCREF(py_V1);} V1 = NULL; { // Op class DnnVersion V1 = PyTuple_Pack(2, PyInt_FromLong(CUDNN_VERSION), PyInt_FromLong(cudnnGetVersion())); __label_3: double __DUMMY_3; } __label_2: if (!__failure) { assert(py_V1-&gt;ob_refcnt &gt; 1); Py_DECREF(py_V1); py_V1 = V1 ? V1 : Py_None; Py_INCREF(py_V1); PyObject* old = PyList_GET_ITEM(storage_V1, 0); {Py_XINCREF(py_V1);} PyList_SET_ITEM(storage_V1, 0, py_V1); {Py_XDECREF(old);} } Py_XDECREF(V1); {Py_XDECREF(py_V1);} double __DUMMY_2; } if (__failure) { // When there is a failure, this code puts the exception // in __ERROR. PyObject* err_type = NULL; PyObject* err_msg = NULL; PyObject* err_traceback = NULL; PyErr_Fetch(&amp;err_type, &amp;err_msg, &amp;err_traceback); if (!err_type) {err_type = Py_None;Py_INCREF(Py_None);} if (!err_msg) {err_msg = Py_None; Py_INCREF(Py_None);} if (!err_traceback) {err_traceback = Py_None; Py_INCREF(Py_None);} PyObject* old_err_type = PyList_GET_ITEM(__ERROR, 0); PyObject* old_err_msg = PyList_GET_ITEM(__ERROR, 1); PyObject* old_err_traceback = PyList_GET_ITEM(__ERROR, 2); PyList_SET_ITEM(__ERROR, 0, err_type); PyList_SET_ITEM(__ERROR, 1, err_msg); PyList_SET_ITEM(__ERROR, 2, err_traceback); {Py_XDECREF(old_err_type);} {Py_XDECREF(old_err_msg);} {Py_XDECREF(old_err_traceback);} } // The failure code is returned to index what code block failed. return __failure; } }; } static int __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde_executor(__struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde *self) { return self-&gt;run(); } static void __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde_destructor(PyObject *capsule) { __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde *self = (__struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde *)PyCapsule_GetContext(capsule); delete self; } ////////////////////// //// Functions ////////////////////// static PyObject * instantiate(PyObject * self, PyObject *argtuple) { assert(PyTuple_Check(argtuple)); if (2 != PyTuple_Size(argtuple)){ PyErr_Format(PyExc_TypeError, \"Wrong number of arguments, expected 2, got %i\", (int)PyTuple_Size(argtuple)); return NULL; } __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde* struct_ptr = new __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde(); if (struct_ptr-&gt;init( PyTuple_GET_ITEM(argtuple, 0),PyTuple_GET_ITEM(argtuple, 1) ) != 0) { delete struct_ptr; return NULL; } PyObject* thunk = PyCapsule_New((void*)(&amp;__struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde_executor), NULL, __struct_compiled_op_m3d1cf20adb1014f04986e6a344a55bde_destructor); if (thunk != NULL &amp;&amp; PyCapsule_SetContext(thunk, struct_ptr) != 0) { PyErr_Clear(); Py_DECREF(thunk); thunk = NULL; } return thunk; } ////////////////////// //// Module init ////////////////////// static PyMethodDef MyMethods[] = { {\"instantiate\", instantiate, METH_VARARGS, \"undocumented\"} , {NULL, NULL, 0, NULL} }; static struct PyModuleDef moduledef = { PyModuleDef_HEAD_INIT, \"m3d1cf20adb1014f04986e6a344a55bde\", NULL, -1, MyMethods, }; PyMODINIT_FUNC PyInit_m3d1cf20adb1014f04986e6a344a55bde(void) { PyObject *m = PyModule_Create(&amp;moduledef); return m; } Function PyInit_m3d1cf20adb1014f04986e6a344a55bde seems to be present, so what's the problem? edit 1 I copied the files to d:\\test and managed to recompile the .pyd file using the same exact command used by Theano (thanks to procmon): import os add_dir = r'C:\\Users\\Kiuhnm\\Anaconda3\\Library\\mingw-w64\\bin' os.environ['PATH'] += os.pathsep + add_dir cmd = r'\"\"C:\\Users\\Kiuhnm\\Anaconda3\\Library\\mingw-w64\\bin\\g++.exe\" -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -Wl,-rpath, -march=haswell -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf -mmovbe -maes -mno-sha -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4 -mno-xop -mbmi -mbmi2 -mno-tbm -mavx -mavx2 -msse4.2 -msse4.1 -mlzcnt -mno-rtm -mno-hle -mrdrnd -mf16c -mfsgsbase -mno-rdseed -mno-prfchw -mno-adx -mfxsr -mxsave -mxsaveopt -mno-avx512f -mno-avx512er -mno-avx512cd -mno-avx512pf -mno-prefetchwt1 -mno-clflushopt -mno-xsavec -mno-xsaves -mno-avx512dq -mno-avx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mno-clwb -mno-pcommit -mno-mwaitx --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=8192 -mtune=haswell -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -DMS_WIN64 -I\"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\numpy\\core\\include\" -I\"C:\\Users\\Kiuhnm\\Anaconda3\\include\" -I\"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\" -L\"C:\\Users\\Kiuhnm\\Anaconda3\\libs\" -L\"C:\\Users\\Kiuhnm\\Anaconda3\" -o d:\\test\\m3d1cf20adb1014f04986e6a344a55bde.pyd d:\\test\\mod.cpp -lcudnn -lpython35\"' os.system(cmd) I read that pyd files are just DLLs (at least on Windows). The odd thing is that the compiled pyd file doesn't seem to export any function. Maybe I don't understand how Python finds exported functions: D:\\test&gt;dumpbin /EXPORTS m3d1cf20adb1014f04986e6a344a55bde.pyd Microsoft (R) COFF/PE Dumper Version 12.00.40629.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file m3d1cf20adb1014f04986e6a344a55bde.pyd File Type: DLL Section contains the following exports for m3d1cf20adb1014f04986e6a344a55bde.pyd 00000000 characteristics 5896198F time date stamp Sat Feb 04 19:12:31 2017 0.00 version 1 ordinal base 0 number of functions 0 number of names ordinal hint RVA name Summary 1000 .CRT 1000 .bss 1000 .data 2000 .debug_abbrev 1000 .debug_aranges 1000 .debug_frame 9000 .debug_info 2000 .debug_line 3000 .debug_loc 1000 .debug_ranges 1000 .debug_str 1000 .edata 1000 .idata 1000 .pdata 1000 .rdata 1000 .reloc 2000 .text 1000 .tls 1000 .xdata",
        "answers": [
            [
                "I've finally solved this puzzle! Let's have a look at the g++ command again: \"C:\\Users\\Kiuhnm\\Anaconda3\\Library\\mingw-w64\\bin\\g++.exe\" -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -Wl,-rpath, -march=haswell -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf -mmovbe -maes -mno-sha -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4 -mno-xop -mbmi -mbmi2 -mno-tbm -mavx -mavx2 -msse4.2 -msse4.1 -mlzcnt -mno-rtm -mno-hle -mrdrnd -mf16c -mfsgsbase -mno-rdseed -mno-prfchw -mno-adx -mfxsr -mxsave -mxsaveopt -mno-avx512f -mno-avx512er -mno-avx512cd -mno-avx512pf -mno-prefetchwt1 -mno-clflushopt -mno-xsavec -mno-xsaves -mno-avx512dq -mno-avx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mno-clwb -mno-pcommit -mno-mwaitx --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=8192 -mtune=haswell -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -DMS_WIN64 -I\"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\numpy\\core\\include\" -I\"C:\\Users\\Kiuhnm\\Anaconda3\\include\" -I\"C:\\Users\\Kiuhnm\\Anaconda3\\lib\\site-packages\\theano\\theano\\gof\" -L\"C:\\Users\\Kiuhnm\\Anaconda3\\libs\" -L\"C:\\Users\\Kiuhnm\\Anaconda3\" -o d:\\test\\m3d1cf20adb1014f04986e6a344a55bde.pyd d:\\test\\mod.cpp -lcudnn -lpython35 Do you see that -Wl,-rpath, on the second row? Well, it turns out that, at least in Windows, that swallows up everything which follows it! -Wl,a,b,c,d is used to pass \"a b c d\" to the linker, but that trailing comma followed by a space is problematic in Windows. Maybe it has to do with the fact that Windows allow spaces in filenames. After removing the offending part, the output file becomes 40 KB bigger suggesting that it now includes the object code for mod.cpp. Importing the module succeeds, finally, but now I'll have to delve into Theano code to see what's wrong, since the command is dynamically generated. EDIT: It wasn't difficult. All one has to do is add [dnn] library_path=d:\\whatever to .theanorc. I use a dummy directory because cuDNN's files are already reachable on my system (I must have updated PATH). If you don't have cuDNN installed, then you should never experience this issue. Now -Wl,-rpath, should be -Wl,-rpath,d:\\whatever, but I didn't check. Just for completeness, the relevant code is in [...]Lib\\site-packages\\Theano\\theano\\gpuarray\\dnn.py at line 267: def c_compile_args(self): return ['-Wl,-rpath,' + config.dnn.library_path] config.dnn.library_path is now \"d:\\whatever\" and all is good."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "1.Problem: I designed a simple model using Keras ( backend: Theano) to train on stock data set. When configure Theano to use cpu, no problem appears. However, when using gpu, there will appear the problem as shown below. In file included from /home/haichao3/anaconda2/include/python2.7/Python.h:8:0, from mod.cu:1: /home/haichao3/anaconda2/include/python2.7/pyconfig.h:1193:0: warning: \"_POSIX_C_SOURCE\" redefined [enabled by default] In file included from /usr/local/cuda/bin/..//include/host_config.h:178:0, from /usr/local/cuda/bin/..//include/cuda_runtime.h:78, from &lt;command-line&gt;:0: /usr/include/features.h:230:0: note: this is the location of the previous definition In file included from /home/haichao3/anaconda2/include/python2.7/Python.h:8:0, from mod.cu:1: /home/haichao3/anaconda2/include/python2.7/pyconfig.h:1215:0: warning: \"_XOPEN_SOURCE\" redefined [enabled by default] In file included from /usr/local/cuda/bin/..//include/host_config.h:178:0, from /usr/local/cuda/bin/..//include/cuda_runtime.h:78, from &lt;command-line&gt;:0: /usr/include/features.h:162:0: note: this is the location of the previous definition mod.cu(298): error: identifier \"callkernel_node_a6d034c0a2ad758dff9965b4853b6097_0\" is undefined 1 error detected in the compilation of \"/tmp/tmpxft_000002ab_00000000-9_mod.cpp1.ii\". (None, 82, 32) (None, 78, 16) (None, 1248) (None, 256) (None, 32) (None, 1) ['nvcc', '-shared', '-O3', '--maxrregcount=32', '-arch=sm_61', '-m64', '-Xcompiler', '-fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden', '-Xlinker', '-rpath,/home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/cuda_ndarray', '-I/home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/cuda_ndarray', '-I/usr/local/cuda/root/include', '-I/home/haichao3/anaconda2/lib/python2.7/site-packages/numpy/core/include', '-I/home/haichao3/anaconda2/include/python2.7', '-I/home/haichao3/Theano/theano/gof', '-I/home/haichao3/Theano/theano/sandbox/cuda', '-L/home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/cuda_ndarray', '-L/home/haichao3/anaconda2/lib', '-o', '/home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/tmppSrSeT/a6d034c0a2ad758dff9965b4853b6097.so', 'mod.cu', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lpython2.7'] Traceback (most recent call last): File \"model_conv_trend.py\", line 44, in &lt;module&gt; history = model.fit(tr_input, tr_output, nb_epoch=epoch, batch_size=train_batch_size, verbose=1,validation_data=(ts_input,ts_output)) File \"/home/haichao3/anaconda2/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/models.py\", line 672, in fit initial_epoch=initial_epoch) File \"/home/haichao3/anaconda2/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/engine/training.py\", line 1133, in fit self._make_test_function() File \"/home/haichao3/anaconda2/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/engine/training.py\", line 783, in _make_test_function **self._function_kwargs) File \"/home/haichao3/anaconda2/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/backend/theano_backend.py\", line 969, in function return Function(inputs, outputs, updates=updates, **kwargs) File \"/home/haichao3/anaconda2/lib/python2.7/site-packages/Keras-1.2.1-py2.7.egg/keras/backend/theano_backend.py\", line 955, in __init__ **kwargs) File \"/home/haichao3/Theano/theano/compile/function.py\", line 326, in function output_keys=output_keys) File \"/home/haichao3/Theano/theano/compile/pfunc.py\", line 486, in pfunc output_keys=output_keys) File \"/home/haichao3/Theano/theano/compile/function_module.py\", line 1784, in orig_function defaults) File \"/home/haichao3/Theano/theano/compile/function_module.py\", line 1651, in create input_storage=input_storage_lists, storage_map=storage_map) File \"/home/haichao3/Theano/theano/gof/link.py\", line 699, in make_thunk storage_map=storage_map)[:3] File \"/home/haichao3/Theano/theano/gof/vm.py\", line 1063, in make_all impl=impl)) File \"/home/haichao3/Theano/theano/gof/op.py\", line 924, in make_thunk no_recycling) File \"/home/haichao3/Theano/theano/gof/op.py\", line 828, in make_c_thunk output_storage=node_output_storage) File \"/home/haichao3/Theano/theano/gof/cc.py\", line 1190, in make_thunk keep_lock=keep_lock) File \"/home/haichao3/Theano/theano/gof/cc.py\", line 1131, in __compile__ keep_lock=keep_lock) File \"/home/haichao3/Theano/theano/gof/cc.py\", line 1589, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File \"/home/haichao3/Theano/theano/gof/cmodule.py\", line 1155, in module_from_key module = lnk.compile_cmodule(location) File \"/home/haichao3/Theano/theano/gof/cc.py\", line 1492, in compile_cmodule preargs=preargs) File \"/home/haichao3/Theano/theano/sandbox/cuda/nvcc_compiler.py\", line 390, in compile_str 'for cmd', ' '.join(cmd)) Exception: ('The following error happened while compiling the node', GpuElemwise{RoundHalfToEven}[(0, 0)](GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0), '\\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 --maxrregcount=32 -arch=sm_61 -m64 -Xcompiler -fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/cuda_ndarray -I/home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/cuda_ndarray -I/usr/local/cuda/root/include -I/home/haichao3/anaconda2/lib/python2.7/site-packages/numpy/core/include -I/home/haichao3/anaconda2/include/python2.7 -I/home/haichao3/Theano/theano/gof -I/home/haichao3/Theano/theano/sandbox/cuda -L/home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/cuda_ndarray -L/home/haichao3/anaconda2/lib -o /home/haichao3/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/tmppSrSeT/a6d034c0a2ad758dff9965b4853b6097.so mod.cu -lcudart -lcublas -lcuda_ndarray -lpython2.7', '[GpuElemwise{RoundHalfToEven}[(0, 0)](&lt;CudaNdarrayType(float32, matrix)&gt;)]') 2.Hardware: Titan X Maxwell, Driver Version 367.48, cuda V8.0.44. cuDNN 5. I noticed that I was warned my cuDNN version is too recent than Theano when installing it. 3.This is the source code: #!/home/xxx/anaconda2/bin/python import numpy as np import scipy.io as sio from keras.models import Sequential from keras.layers import Dense, Activation, Convolution1D, Flatten from keras.optimizers import SGD from data_provider import DataProvider import matplotlib matplotlib.use('Agg') import matplotlib.pyplot as plt from time import sleep past_len = 90 predict_len = 5 train_batch_size = 128 test_batch_size = 64 epoch = 10 lr = 1e-3 #important decay = 1e-5 init = 'he_normal' folders = ['./data/table1', './data/table2', './data/table3'] provider = DataProvider(folders, kind='trend', load=True, data_path = './data/data_conv_trend.h5') tr_input, tr_output, ts_input, ts_output = provider.prepare(20091231, past_len, predict_len) tr_output = tr_output.reshape(tr_output.shape[0], 1) ts_output = ts_output.reshape(ts_output.shape[0], 1) model = Sequential() model.add(Convolution1D(64, 5, activation = 'relu', init=init, border_mode='valid', input_shape=(past_len, 5))) model.add(Convolution1D(32, 5, activation = 'relu', init=init, border_mode='valid')) model.add(Convolution1D(16, 5, activation = 'relu', init=init, border_mode='valid')) model.add(Flatten()) model.add(Dense(256, activation = 'sigmoid', init=init)) model.add(Dense(32, activation = 'sigmoid', init=init)) model.add(Dense(1, activation='sigmoid', init=init)) for i in range(-6, 0): print(model.layers[i].output_shape) #model.load_weights('./mdl/weights.h5'); model.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr,decay=decay,momentum=0.9,nesterov=False), metrics=['accuracy']) history = model.fit(tr_input, tr_output, nb_epoch=epoch, batch_size=train_batch_size, verbose=1,validation_data=(ts_input,ts_output)) model.save('./mdl/model_' + str(lr) + '_' + str(decay) + '_' + init + '_' + '.h5')",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am using fixed point numbers within my network based on keras framework. My concern is when there are multiplication operations in the network on theano variables, the result is float32 ( even if the numbers supplied are in fixed point). Is there any intrinsic way to get the result in fixed point format, or even int. If not, what can be alternative approaches?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have a Python-based machine learning code that runs three algorithms on my data: Random Forest (implementation in scikit-learn), Gradient Boosting (implementation in XGBoost), and Recurrent Neural Network (implementation in Theano/Keras). The first two are running on the CPU and are parallelized using joblib.Parallel() and the latter runs on the GPU using CUDA. I pass the name of the algorithm I want to use (RF, XGB, NN) in the variable method to a function, and it will proceed with running a parallel implementation of each algorithm. from joblib import Parallel, delayed if method in ['RF', 'XGB']: with Parallel(n_jobs = 8) as parallel_param: ... model_scores = parallel_param(delayed(model_selection_loop)(p_idx, ..., method, ...) for p_idx in range(num_parameter_samples)) ... elif method == 'NN': ... model_scores = [] for p_idx in range(num_parameter_samples): model_scores.append(model_selection_loop(p_idx, ..., method, ...)) ... else: raise ValueError(\"Unknown algorithm!\") model_selection_loop() is a function that performs nested cross-validation to select the best performing hyper-parameters and to estimate the performance of the selected model on new data, and num_parameter_samples is the number of different hyper-parameter configurations to be sampled from a grid (I use, say, 30 different configurations). If the run order is (1) RF, (2) XGB, (3) NN, everything runs fine; the first two are parallelized on a 4-core CPU and the latter runs on a Tesla K80 GPU; at the end, I get three predictions which I can later merge. However, after running the Theano-based, CUDA-parallelized neural network, if I rerun either RF or XGB, I will get the following error: --&gt; 965 model_scores = parallel_param(delayed(model_selection_loop)(p_idx, ..., method, ...) for p_idx in range(num_parameter_samples)) /home/s/anaconda2/lib/python2.7/site-packages/joblib/parallel.pyc in __call__(self, iterable) 808 # consumption. 809 self._iterating = False --&gt; 810 self.retrieve() 811 # Make sure that we get a last message telling us we are done 812 elapsed_time = time.time() - self._start_time /home/s/anaconda2/lib/python2.7/site-packages/joblib/parallel.pyc in retrieve(self) 725 job = self._jobs.pop(0) 726 try: --&gt; 727 self._output.extend(job.get()) 728 except tuple(self.exceptions) as exception: 729 # Stop dispatching any new job in the async callback thread /home/s/anaconda2/lib/python2.7/multiprocessing/pool.pyc in get(self, timeout) 565 return self._value 566 else: --&gt; 567 raise self._value 568 569 def _set(self, i, obj): GpuArrayException: invalid argument It seems to me that once the CUDA-based code (recurrent neural network) is executed, any call to Parallel() will get rerouted to the GPU instead of the CPU, since the error I get is GpuArrayException even though I had called a scikit-learn Random Forest classifier which should run on the CPU. In fact, if my first run is ordered like (1) NN, (2) RF, (3) XGB, I get the same error after finishing the first pass. I should mention that I am running these in an IPython session, so I am typing the commands by hand in the terminal (although I am not sure if that matters or not). Any ideas on why this happens and how I can route any execution of RF or XGB to the CPU regardless of whether a NN method was previously executed on the GPU or not? I'd appreciate your help.",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm trying to make a predictive model for Diabetic Retinopathy Detection. The competition's trainig dataset includes hy-res images are unsymmetricaly divided in 5 classes: Normal-25807 images-73.48%; Mild-2442 images-6.96%; Moderate-5291 images-15.07%; Severe-873 images-2.48% and Proliferative-708 images - 2.01%. For this purpose I use Keras framework with Theano backend (for CUDA comutations). For image augmentation I used the ImageDataGenerator (the code is below). I've resized images to 299x299 and divided them into 5 folders accordingly their classes: train_datagen=ImageDataGenerator(rescale=1./255, rotation_range=40, zoom_range=0.2, horizontal_flip=True, fill_mode=\"constant\", zca_whitening=True) train_generator=train_datagen.flow_from_directory('data/~huge_data/preprocessed_imgs/', target_size=(299, 299), batch_size=32, class_mode='categorical') At first, just for testing, I desided to use a simple convolutional model: model=Sequential() model.add(Convolution2D(32,3,3, input_shape=(3, 299, 299), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Convolution2D(32, 3, 3, activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Convolution2D(64, 3, 3, activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Flatten()) model.add(Dense(64, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(5, activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) In fitting Image generator, I pointed the class_weights in order to fix the asymmetry of data: class_weight ={0: 25807., 1:2442., 2:5291., 3:873., 4:708.}; model.fit_generator(train_generator, samples_per_epoch=2000, nb_epoch=50, verbose=2, callbacks=callbacks_list, class_weight ={0: 25807., 1:2442., 2:5291., 3:873., 4:708.}) My folders with images Problems: The model outputs with high loss and high accuracy. Why? Epoch 1/50 110s - loss: 5147.2669 - acc: 0.7366 Epoch 2/50 105s - loss: 5052.3844 - acc: 0.7302 Epoch 3/50 105s - loss: 5042.0261 - acc: 0.7421 Epoch 4/50 105s - loss: 4986.3544 - acc: 0.7361 Epoch 5/50 105s - loss: 4999.4177 - acc: 0.7361 Every image model predict as '0' class: datagen_2=ImageDataGenerator(rescale=1./255) val_generator=datagen_2.flow_from_directory('data/color_validation_images/', target_size=(299,299), batch_size=100, class_mode='categorical') y_predict=model.predict_generator(val_generator, val_samples=82) [np.argmax(i) for i in y_predict] the output of it is: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 without argmax(partly) array([ 9.47651565e-01, 7.30426749e-03, 4.40788604e-02, 6.25302084e-04, 3.39932943e-04], dtype=float32), array([ 9.51994598e-01, 6.50278665e-03, 4.07058187e-02, 5.17037639e-04, 2.79774162e-04], dtype=float32), array([ 9.49448049e-01, 6.50656316e-03, 4.32702228e-02, 5.20388770e-04, 2.54814397e-04], dtype=float32), array([ 9.47873473e-01, 7.13181263e-03, 4.40776311e-02, 6.00705389e-04, 3.16353660e-04], dtype=float32), array([ 9.53514516e-01, 6.13699574e-03, 3.96034382e-02, 4.82603034e-04, 2.62484333e-04], dtype=float32), .... If I've tried to use class_weight ='auto'. In this case, model showed 'predictable' output: Epoch 1/50 107s - loss: 0.9036 - acc: 0.7381 Epoch 2/50 104s - loss: 0.9333 - acc: 0.7321 Epoch 3/50 105s - loss: 0.8865 - acc: 0.7351 Epoch 4/50 106s - loss: 0.8978 - acc: 0.7351 Epoch 5/50 105s - loss: 0.9158 - acc: 0.7302 But, it still doesn't work: severe_DR=plt.imread('data/~huge_data/preprocessed_imgs/3_Severe/99_left.jpeg') mild_DR=plt.imread('data/~huge_data/preprocessed_imgs/1_Mild/15_left.jpeg') moderate_DR=plt.imread('data/~huge_data/preprocessed_imgs/2_Moderate/78_right.jpeg') model.predict(mild_DR.reshape((1,)+x[1].shape)) array([[ 1., 0., 0., 0., 0.]], dtype=float32) model.predict(severe_DR.reshape((1,)+x[1].shape)) array([[ 1., 0., 0., 0., 0.]], dtype=float32) model.predict(moderate_DR.reshape((1,)+x[1].shape)) array([[ 1., 0., 0., 0., 0.]], dtype=float32) What I've done wrong? After answer of Sergii Gryshkevych, I fixed my model: I've changed class_weight to {0:1, 1:10.57, 2:4.88, 3:29, 4:35} (I divided images in each classes to maximum images (in first class)). Next, I changed metrics to categorical_accuracy. And I inctreased the number of layers in model (like here). So, the output after 5 epochs is: Epoch 1/5 500/500 [==============================] - 52s - loss: 5.6944 - categorical_accuracy: 0.1840 Epoch 2/5 500/500 [==============================] - 52s - loss: 6.7357 - categorical_accuracy: 0.2040 Epoch 3/5 500/500 [==============================] - 52s - loss: 6.7373 - categorical_accuracy: 0.0800 Epoch 4/5 500/500 [==============================] - 52s - loss: 6.0311 - categorical_accuracy: 0.0180 Epoch 5/5 500/500 [==============================] - 51s - loss: 4.9924 - categorical_accuracy: 0.0560 Is it correct? Is there any way to make assign a quadratic weighted kappa as metrics in keras?",
        "answers": [
            [
                "\"High\" accuracy around 73-74% comes from the fact that all images are classified as 0 class. Your data set is imbalanced, since the majority class accounts for 73% of samples. So accuracy does not say much in this case, you need to use other metrics derived from confusion matrix like precision, recall, F1 score, etc. Multiclass log loss function punishes wrong predictions extremely. Your predictions are almost zero for all classes except the 0, so there is nothing surprising in such high loss values. To sum up, you are facing classic Class Imbalance Problem. Two most common ways to mitigate it are Adjust class weights. Make minority classes \"more important\", so learning algorithm does not ignore them. You can provide your custom class weights as an argument to the fit method: class_weight: dictionary mapping classes to a weight value, used for scaling the loss function (during training only). Oversampling/Undersampling. Simply oversample examples of minority classes to make your data set balanced, or combine it with undersampling, when some randomly selected examples of the majority class are dropped at the beginning of each learning epoch. The Class Imbalance problem is nothing new, so there is plenty of reading on this topic like this and this introductory posts."
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I am trying to use theano gpu on my ubuntu, but each time after it running one time successfully, it will give me the error like this when I try to run next time. No idea why, could anyone help me ? import theano Traceback (most recent call last): File \"\", line 1, in File \"/home/sirius/anaconda3/lib/python3.5/site-packages/theano/init.py\", line 95, in if hasattr(theano.tests, \"TheanoNoseTester\"): AttributeError: module 'theano' has no attribute 'tests'",
        "answers": [
            [
                "I met the same problem.I just fix it with conda install nose"
            ],
            [
                "For latest version of Theano (1.04) import theano generates an error without the nose package installed install via conda or pip pip install nose / conda install nose"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "Let's say I used CUDA to train an object tracking program. Could I then put that program on another computer that didn't have a powerful gpu and run the object tracking program? Or is gpu support required to run the outputted algorithm as well as train it?",
        "answers": [
            [
                "No, it does not matter how you trained your model. You can execute it in completely different scenario, using CPU, GPU, cloud or whatever you want. Since execution is usually much cheaper than training - you will usually need much less powerful hardware."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "At the moment I am trying to install theano on my ubuntu 16.04 system with cuda support. The installation process itself went well until I tried to test the installation: python -c \"import theano; theano.test()\" The last few lines of the output were: ====================================================================== ERROR: Failure: ImportError (No module named nose_parameterized) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/home/myUser/anaconda2/lib/python2.7/site-packages/nose/loader.py\", line 418, in loadTestsFromName addr.filename, addr.module) File \"/home/myUser/anaconda2/lib/python2.7/site-packages/nose/importer.py\", line 47, in importFromPath return self.importFromDir(dir_path, fqname) File \"/home/myUser/anaconda2/lib/python2.7/site-packages/nose/importer.py\", line 94, in importFromDir mod = load_module(part_fqname, fh, filename, desc) File \"/home/myUser/anaconda2/lib/python2.7/site-packages/theano/tests/test_rop.py\", line 16, in &lt;module&gt; from theano.tests import unittest_tools as utt File \"/home/myUser/anaconda2/lib/python2.7/site-packages/theano/tests/unittest_tools.py\", line 7, in &lt;module&gt; from nose_parameterized import parameterized ImportError: No module named nose_parameterized ---------------------------------------------------------------------- Ran 408 tests in 13.085s FAILED (SKIP=26, errors=80) These were preceded by approximately 20 blocks with what appears to be different tests failing on exactly the same top 3 lines in the stacktrace. The code where the final occurs looks like this (with added line numbers): 411. # FIXME: to support module.name names, 412. # do what resolve-name does and keep trying to 413. # import, popping tail of module into addr.call, 414. # until we either get an import or run out of 415. # module parts 416. try: 417. module = self.importer.importFromPath( 418. addr.filename, addr.module) 419. finally: 420. self.config.plugins.afterImport( 421. addr.filename, addr.module) While searching for a solution I came across: Error running nosetests I tried the solution proposed there: sudo pip install nose-parameterized However this had no effect. Does anyone know what else could be causing this error? edit: so I reinstalled theano to make the problem more reproducible. I installed theano using the instructions found here, so I used: sudo apt-get install python-numpy python-scipy python-dev python-pip python-nose g++ libopenblas-dev git sudo pip install Theano Then I used: nosetests theano The last few lines of the output of this are almost the same as earlier: ====================================================================== ERROR: Failure: ImportError (No module named nose_parameterized) ---------------------------------------------------------------------- Traceback (most recent call last): File \"/home/myUser/anaconda2/lib/python2.7/site-packages/nose/loader.py\", line 418, in loadTestsFromName addr.filename, addr.module) File \"/home/myUser/anaconda2/lib/python2.7/site-packages/nose/importer.py\", line 47, in importFromPath return self.importFromDir(dir_path, fqname) File \"/home/myUser/anaconda2/lib/python2.7/site-packages/nose/importer.py\", line 94, in importFromDir mod = load_module(part_fqname, fh, filename, desc) File \"/home/myUser/.local/lib/python2.7/site-packages/theano/tests/test_rop.py\", line 16, in &lt;module&gt; from theano.tests import unittest_tools as utt File \"/home/myUser/.local/lib/python2.7/site-packages/theano/tests/unittest_tools.py\", line 7, in &lt;module&gt; from nose_parameterized import parameterized ImportError: No module named nose_parameterized ---------------------------------------------------------------------- Ran 457 tests in 160.608s FAILED (SKIP=24, errors=95) edit 2: I thought it might be a python-version issue. When I try: python -V I get: Python 2.7.12 :: Anaconda 4.2.0 (64-bit) And the following folders exist: /usr/local/lib/python2.7/dist-packages/nose_parameterized So, that shouldn't be a problem as far as I can see. However when I try: python2.7 -c \"import nose_parameterized\" I get: Traceback (most recent call last): File \"&lt;string&gt;\", line 1, in &lt;module&gt; ImportError: No module named nose_parameterized",
        "answers": [
            [
                "Found the problem, anaconda was looking in its own folder. So to solve, I did: conda install nose-parameterized"
            ],
            [
                "The following works for me: pip install nose-parameterized"
            ]
        ],
        "votes": [
            4.0000001,
            1.0000001
        ]
    },
    {
        "question": "I am performing nested cross-validation for model selection and performance estimation for a set of recurrent neural networks with different architectures and parameters using Keras and Theano, which are set up to run on a AWS P2 instance which has a Tesla K80 GPU with CUDA and cuDNN installed/enabled. To perform model selection, I compare 30 models sampled from the parameter space using param_grid = { 'nb_hidden_layers': [1, 2, 3], 'dropout_frac': [0.15, 0.20], 'output_activation': ['sigmoid', 'softmax'], 'optimization': ['Adedelta', 'RMSprop', 'Adam'], 'learning_rate': [0.001, 0.005, 0.010], 'batch_size': [64, 100, 150, 200], 'nb_epoch': [10, 15, 20], 'perform_batchnormalization': [True, False] } params_list = list(ParameterSampler(param_grid, n_iter = 30)) I then construct a RNN model using the function NeuralNetworkClassifier() defined below def NeuralNetworkClassifier(params, units_in_hidden_layer = [50, 75, 100, 125, 150]): nb_units_in_hidden_layers = np.random.choice(units_in_hidden_layer, size = params['nb_hidden_layers'], replace = False) layers = [8] # number of features in every week layers.extend(nb_units_in_hidden_layers) layers.extend([1]) # node identifying quit/stay model = Sequential() # constructing all layers up to, but not including, the penultimate one layer_idx = -1 # this ensures proper generalization nb_hidden_layers = 1 (for which the loop below will never run) for layer_idx in range(len(layers) - 3): model.add(LSTM(input_dim = layers[layer_idx], output_dim = layers[layer_idx + 1], init = 'he_uniform', return_sequences = True)) # all LSTM layers, up to and including the penultimate one, need return_sequences = True if params['perform_batchnormalization'] == True: model.add(BatchNormalization()) model.add(Activation('relu')) model.add(Dropout(params['dropout_frac'])) # constructing the penultimate layer model.add(LSTM(input_dim = layers[layer_idx + 1], output_dim = layers[(layer_idx + 1) + 1], init = 'he_uniform', return_sequences = False)) # the last LSTM layer needs return_sequences = False if params['perform_batchnormalization'] == True: model.add(BatchNormalization()) model.add(Activation('relu')) model.add(Dropout(params['dropout_frac'])) # constructing the final layer model.add(Dense(output_dim = layers[-1], init = 'he_normal')) model.add(Activation(params['output_activation'])) if params['optimization'] == 'SGD': optim = SGD() optim.lr.set_value(params['learning_rate']) elif params['optimization'] == 'RMSprop': optim = RMSprop() optim.lr.set_value(params['learning_rate']) elif params['optimization'] == 'Adam': optim = Adam() elif params['optimization'] == 'Adedelta': optim = Adadelta() model.compile(loss = 'binary_crossentropy', optimizer = optim, metrics = ['precision']) return model which construct a RNN whose number of hidden layers is given by the parameter 'nb_hidden_layers' in param_grid and the number of hidden units in each layer is randomly sampled from the list [50, 75, 100, 125, 150]. At the end, this function compiles the model and returns it. During the nested cross-validation (CV), the inner loop (which runs IN times) compares the performance of the 30 randomly selected model. After this step, I pick the best-performing model in the outer loop and estimate its performance on a hold-out dataset; this scheme is repeated OUT times. Therefore, I am compileing a RNN model OUTxINx30 times, and this takes an extremely long time; for example, when OUT=4 and IN=3, my method takes between 6 to 7 hours to finish. I see that the GPU is being used sporadically (but the GPU usage never goes above 40%); however, most of the time, it is the CPU that is being used. My (uneducated) guess is that compile is being done on the CPU many many times and takes the bulk of the computing time, whereas model fitting and predicting are done on the GPU and takes a short time. My questions: Is there a way to remedy this situation? Is compile actually done on the CPU? How do people do nested CV to select the best RNN architecture? Is it reasonable for me to perform this scheme on the production server? Do you suggest I do one big nested CV, that might take 24 hours, to select the best performing model and just use that one model afterwards on the production server? Thank you all.",
        "answers": [
            [
                "I can't answer all your questions, still hope it helps. Compilation is done in CPU because it's mainly composed of symbolic graph operations and code generation. To make things worse, theano graph optimization uses pure python code, which can be an overhead compared to a C/C++ implementation. To improve theano compilation time (at the cost of runtime performance): Use less aggressive optimization In /home/ec2-user/.theanorc add line: optimizer = fast_compile Or totally disable optimization with: optimizer = None Precompile some blocks If there are common blocks shared amoung your models, you can precompile them with theano.OpFromGraph You can't do this in Keras alone, though. Switch framework Keras does support tensorflow backend. Compared to theano, tensorflow work more like a VM than a compiler. Typically TF runs slower than theano but compiles much faster."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I am trying to test my GPU sanity by running this code from theano import function, config, shared, sandbox import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') I got this error: mod.cu(941): warning: pointless comparison of unsigned integer with zero mod.cu(3001): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3004): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3006): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3009): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3011): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3014): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3017): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3020): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3022): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3025): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3027): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3030): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3032): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3035): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3038): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3041): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3043): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3046): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3048): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3051): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(941): warning: pointless comparison of unsigned integer with zero mod.cu(3001): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3004): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3006): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3009): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3011): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3014): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3017): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3020): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3022): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3025): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3027): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3030): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3032): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3035): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3038): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3041): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3043): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3046): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3048): warning: conversion from a string literal to \"char *\" is deprecated mod.cu(3051): warning: conversion from a string literal to \"char \" is deprecated /usr/include/string.h: In function \u2018void __mempcpy_inline(void*, const void*, size_t)\u2019: /usr/include/string.h:652:42: error: \u2018memcpy\u2019 was not declared in this scope return (char ) memcpy (__dest, __src, __n) + __n; ^ mod.cu: In function \u2018PyObject CudaNdarray_Reshape(CudaNdarray*, PyObject*)\u2019: mod.cu:955:122: warning: format \u2018%lld\u2019 expects argument of type \u2018long long int\u2019, but argument 3 has type \u2018size_t {aka long unsigned int}\u2019 [-Wformat=] PyErr_Format(PyExc_ValueError, \"size must remain unchanged, changed from %lld to %lld\", CudaNdarray_SIZE(self), rval_size); ^ ['nvcc', '-shared', '-O3', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden', '-Xlinker', '-rpath,/home/rkenaya/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.12-64/cuda_ndarray', '-I/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda', '-I/usr/local/lib/python2.7/dist-packages/numpy/core/include', '-I/usr/include/python2.7', '-I/usr/local/lib/python2.7/dist-packages/theano/gof', '-o', '/home/rkenaya/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.12-64/cuda_ndarray/cuda_ndarray.so', 'mod.cu', '-L/usr/lib', '-lcublas', '-lpython2.7', '-lcudart'] mod.cu:955:122: warning: format \u2018%lld\u2019 expects argument of type \u2018long long int\u2019, but argument 4 has type \u2018size_t {aka long unsigned int}\u2019 [-Wformat=] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/rkenaya/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.12-64/cuda_ndarray -I/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -I/usr/local/lib/python2.7/dist-packages/theano/gof -o /home/rkenaya/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.12-64/cuda_ndarray/cuda_ndarray.so mod.cu -L/usr/lib -lcublas -lpython2.7 -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) [Elemwise{exp,no_inplace}()] Looping 1000 times took 4.233657 seconds Result is [ 1.23178029 1.61879337 1.52278066 ..., 2.20771813 2.29967761 1.62323284] Used the cpu",
        "answers": [],
        "votes": []
    },
    {
        "question": "Today I tried to install Theano on W7 x64. I guess I installed it but I also made a mistake in somewhere and I don't know where. I actually want to use it with CUDA. Here is the programs I installed: Anaconda 4.2.0 x64 (Python 2.7.12), TDM GCC, CUDA 8.0 Visual Studio 13 Theano via Git Here is the theanorc file: [global] floatX = float32 device = gpu [nvcc] compiler_bindir=C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin [cuda] root = C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0 Like I said I've no idea where I made a mistake. Here is the output when I write \"import theano\" Thanks in advance guys! In [2]: import theano --------------------------------------------------------------------------- ImportError Traceback (most recent call last) &lt;ipython-input-2-3397704bd624&gt; in &lt;module&gt;() ----&gt; 1 import theano C:\\Users\\silverstone\\Theano\\theano\\__init__.py in &lt;module&gt;() 64 object2, utils) 65 ---&gt; 66 from theano.compile import ( 67 SymbolicInput, In, 68 SymbolicOutput, Out, C:\\Users\\silverstone\\Theano\\theano\\compile\\__init__.py in &lt;module&gt;() 8 SpecifyShape, specify_shape, register_specify_shape_c_code) 9 ---&gt; 10 from theano.compile.function_module import * 11 12 from theano.compile.mode import * C:\\Users\\silverstone\\Theano\\theano\\compile\\function_module.py in &lt;module&gt;() 16 17 import theano ---&gt; 18 from theano import config, gof 19 from theano.compat import izip 20 from theano.gof import graph ImportError: cannot import name gof ps: one more error -&gt; http://pastebin.com/V59Pm9Qa",
        "answers": [
            [
                "Have you added system variables? If no, try this: Right click Computer -&gt; properties -&gt; advanced system settings -&gt; environment variables Add a new system variable Name = THEANO_FLAGS Value = floatX=float32,device=gpu,nvcc.fastmath=True Also add Visual Studio's c++ compiler to the path Add ;pathToYourVSInstallation\\VC\\bin\\ If this wont work, please go there and do it again, from the top: https://stackoverflow.com/a/41401271/7349628"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I tried to create an autoencoder using keras. (ref: https://blog.keras.io/building-autoencoders-in-keras.html) the following test code works just fine on my mac: import numpy as np from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D, ZeroPadding2D from keras.models import Model input_img = Input(shape=(1, 30, 32)) testx = np.random.rand(10,1,30,32) x = ZeroPadding2D((1, 0))(input_img) x = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(x) x = MaxPooling2D((2, 2), border_mode='same')(x) x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x) x = MaxPooling2D((2, 2), border_mode='same')(x) x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x) encoded = MaxPooling2D((2, 2), border_mode='same')(x) x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(encoded) x = UpSampling2D((2, 2))(x) x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x) x = UpSampling2D((2, 2))(x) x = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(x) x = UpSampling2D((2, 2))(x) x = Cropping2D(cropping=((1,1),(0,0)))(x) decoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x) autoencoder = Model(input_img, decoded) autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy') autoencoder.fit(testx, testx, nb_epoch = 5, batch_size =1) However, when I test this piece of code on AWS EC2 g2.2xlarge (my configuration info is on the end of this post), I run into the following Error: Using Theano backend. Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005) ____________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ==================================================================================================== input_1 (InputLayer) (None, 1, 30, 32) 0 ____________________________________________________________________________________________________ zeropadding2d_1 (ZeroPadding2D) (None, 1, 32, 32) 0 input_1[0][0] ____________________________________________________________________________________________________ convolution2d_1 (Convolution2D) (None, 16, 32, 32) 160 zeropadding2d_1[0][0] ____________________________________________________________________________________________________ maxpooling2d_1 (MaxPooling2D) (None, 16, 16, 16) 0 convolution2d_1[0][0] ____________________________________________________________________________________________________ convolution2d_2 (Convolution2D) (None, 8, 16, 16) 1160 maxpooling2d_1[0][0] ____________________________________________________________________________________________________ maxpooling2d_2 (MaxPooling2D) (None, 8, 8, 8) 0 convolution2d_2[0][0] ____________________________________________________________________________________________________ convolution2d_3 (Convolution2D) (None, 8, 8, 8) 584 maxpooling2d_2[0][0] ____________________________________________________________________________________________________ maxpooling2d_3 (MaxPooling2D) (None, 8, 4, 4) 0 convolution2d_3[0][0] ____________________________________________________________________________________________________ convolution2d_4 (Convolution2D) (None, 8, 4, 4) 584 maxpooling2d_3[0][0] ____________________________________________________________________________________________________ upsampling2d_1 (UpSampling2D) (None, 8, 8, 8) 0 convolution2d_4[0][0] ____________________________________________________________________________________________________ convolution2d_5 (Convolution2D) (None, 8, 8, 8) 584 upsampling2d_1[0][0] ____________________________________________________________________________________________________ upsampling2d_2 (UpSampling2D) (None, 8, 16, 16) 0 convolution2d_5[0][0] ____________________________________________________________________________________________________ convolution2d_6 (Convolution2D) (None, 16, 16, 16) 1168 upsampling2d_2[0][0] ____________________________________________________________________________________________________ upsampling2d_3 (UpSampling2D) (None, 16, 32, 32) 0 convolution2d_6[0][0] ____________________________________________________________________________________________________ cropping2d_1 (Cropping2D) (None, 16, 30, 32) 0 upsampling2d_3[0][0] ____________________________________________________________________________________________________ convolution2d_7 (Convolution2D) (None, 1, 30, 32) 145 cropping2d_1[0][0] ==================================================================================================== Total params: 4,385 Trainable params: 4,385 Non-trainable params: 0 ____________________________________________________________________________________________________ Epoch 1/5 Traceback (most recent call last): File \"testtest.py\", line 32, in &lt;module&gt; autoencoder.fit(testx, testx, nb_epoch = 5, batch_size =1) File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 1144, in fit initial_epoch=initial_epoch) File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 844, in _fit_loop outs = f(ins_batch) File \"/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py\", line 953, in __call__ return self.function(*inputs) File \"/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py\", line 886, in __call__ storage_map=getattr(self.fn, 'storage_map', None)) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/link.py\", line 325, in raise_with_op reraise(exc_type, exc_value, exc_trace) File \"/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py\", line 873, in __call__ self.fn() if output_subset is None else\\ ValueError: Input dimension mis-match. (input[0].shape[3] = 32, input[1].shape[3] = 0) Apply node that caused the error: Elemwise{mul,no_inplace}(convolution2d_7_target, Elemwise{log,no_inplace}.0) Toposort index: 703 Inputs types: [TensorType(float32, 4D), TensorType(float32, 4D)] Inputs shapes: [(1, 1, 30, 32), (1, 1, 30, 0)] Inputs strides: [(3840, 3840, 128, 4), (120, 120, 4, 4)] Inputs values: ['not shown', array([], shape=(1, 1, 30, 0), dtype=float32)] Outputs clients: [[Elemwise{add,no_inplace}(Elemwise{mul,no_inplace}.0, Elemwise{mul,no_inplace}.0)]] Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer): File \"testtest.py\", line 30, in &lt;module&gt; autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy') File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 619, in compile sample_weight, mask) File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 307, in weighted score_array = fn(y_true, y_pred) File \"/usr/local/lib/python2.7/dist-packages/keras/objectives.py\", line 49, in binary_crossentropy return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1) File \"/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py\", line 1235, in binary_crossentropy return T.nnet.binary_crossentropy(output, target) I can run the code on GPU if the Cropping2D function was removed: import numpy as np from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D, ZeroPadding2D from keras.models import Model input_img = Input(shape=(1, 30, 32)) testx = np.random.rand(10,1,30,32) testy = np.random.rand(10,1,32,32) x = ZeroPadding2D((1, 0))(input_img) x = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(x) x = MaxPooling2D((2, 2), border_mode='same')(x) x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x) x = MaxPooling2D((2, 2), border_mode='same')(x) x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x) encoded = MaxPooling2D((2, 2), border_mode='same')(x) # at this point the representation is (8, 4, 4) i.e. 128-dimensional x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(encoded) x = UpSampling2D((2, 2))(x) x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x) x = UpSampling2D((2, 2))(x) x = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(x) x = UpSampling2D((2, 2))(x) # x = Cropping2D(cropping=((1,1),(0,0)))(x) decoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x) autoencoder = Model(input_img, decoded) autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy') autoencoder.summary() autoencoder.fit(testx, testy, nb_epoch = 5, batch_size =1) In a similar scenario, Cropping3D also raise the similar error... :-( My question is: How can I solve this and run Cropping2D/Cropping3D on GPU? ps. My AWS EC2 g2.2xlarge configuration is as followed: Ubuntu 14.04 Cuda 7.5 Cudnn v5 Keras (1.2.0) Theano (0.9.0dev4) Thank you!",
        "answers": [
            [
                "There appears to be a bug in Keras. It has been taking care of. Case closed!"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am having trouble running Theano testing code on GPU. I have followed the official Theano installation guides, and after that didn't work i followed this guide:https://github.com/philferriere/dlwin . However i am still not able to run the code on GPU plus some strange behaviors are exhibited. Test example i want to run: from theano import function, config, shared, sandbox import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') When running in Pycharm i get the following error: E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(17): warning C4005: 'PyString_Check': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(63): note: see previous definition of 'PyString_Check' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(18): warning C4005: 'PyString_FromString': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(65): note: see previous definition of 'PyString_FromString' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(19): warning C4005: 'PyString_AsString': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(72): note: see previous definition of 'PyString_AsString' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(20): warning C4005: 'PyString_FromStringAndSize': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(66): note: see previous definition of 'PyString_FromStringAndSize' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(21): warning C4005: 'PyString_Size': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(74): note: see previous definition of 'PyString_Size' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(888): warning: variable \"prev\" was set but never used E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(912): warning: variable \"result\" was set but never used mod.cu(803): warning: conversion from pointer to smaller integer mod.cu(941): warning: pointless comparison of unsigned integer with zero mod.cu(3075): warning: statement is unreachable E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(17): warning C4005: 'PyString_Check': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(63): note: see previous definition of 'PyString_Check' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(18): warning C4005: 'PyString_FromString': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(65): note: see previous definition of 'PyString_FromString' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(19): warning C4005: 'PyString_AsString': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(72): note: see previous definition of 'PyString_AsString' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(20): warning C4005: 'PyString_FromStringAndSize': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(66): note: see previous definition of 'PyString_FromStringAndSize' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(21): warning C4005: 'PyString_Size': macro redefinition E:\\Programs\\Anaconda\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(74): note: see previous definition of 'PyString_Size' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(888): warning: variable \"prev\" was set but never used E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(912): warning: variable \"result\" was set but never used mod.cu(803): warning: conversion from pointer to smaller integer mod.cu(941): warning: pointless comparison of unsigned integer with zero mod.cu(3075): warning: statement is unreachable nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). mod.cu E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(668): warning C4477: 'fprintf' : format string '%lu' requires an argument of type 'unsigned long', but variadic argument 2 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(668): note: consider using '%zu' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): warning C4477: 'fprintf' : format string '%016lx' requires an argument of type 'unsigned long', but variadic argument 1 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): note: consider using '%zx' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): warning C4477: 'fprintf' : format string '%016lx' requires an argument of type 'unsigned long', but variadic argument 2 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): note: consider using '%zx' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): warning C4477: 'fprintf' : format string '%lu' requires an argument of type 'unsigned long', but variadic argument 3 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): note: consider using '%zu' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): warning C4477: 'fprintf' : format string '%016lx' requires an argument of type 'unsigned long', but variadic argument 4 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): note: consider using '%zx' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): warning C4477: 'fprintf' : format string '%2lu' requires an argument of type 'unsigned long', but variadic argument 5 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(670): note: consider using '%zu' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(690): warning C4477: 'fprintf' : format string '%016lx' requires an argument of type 'unsigned long', but variadic argument 3 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(690): note: consider using '%zx' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(690): warning C4477: 'fprintf' : format string '%lu' requires an argument of type 'unsigned long', but variadic argument 4 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(690): note: consider using '%zu' in the format string E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(690): warning C4477: 'fprintf' : format string '%lu' requires an argument of type 'unsigned long', but variadic argument 5 has type 'std::size_t' E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cnmem.cpp(690): note: consider using '%zu' in the format string mod.cu(803): warning C4311: 'type cast': pointer truncation from 'CudaNdarray *' to 'long' mod.cu(3374): warning C4312: 'type cast': conversion from 'long' to 'float *' of greater size LINK : fatal error LNK1104: cannot open file 'uuid.lib' ['nvcc', '-shared', '-O3', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=m18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IE:\\\\Programs\\\\Anaconda\\\\lib\\\\site-packages\\\\theano-0.8.2-py3.5.egg\\\\theano\\\\sandbox\\\\cuda', '-IE:\\\\Programs\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include', '-IE:\\\\Programs\\\\Anaconda\\\\include', '-IE:\\\\Programs\\\\Anaconda\\\\lib\\\\site-packages\\\\theano-0.8.2-py3.5.egg\\\\theano\\\\gof', '-o', 'C:\\\\Users\\\\erikj\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-3.5.2-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-LE:\\\\Programs\\\\Anaconda\\\\libs', '-LE:\\\\Programs\\\\Anaconda', '-lcublas', '-lpython35', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=m18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IE:\\\\Programs\\\\Anaconda\\\\lib\\\\site-packages\\\\theano-0.8.2-py3.5.egg\\\\theano\\\\sandbox\\\\cuda -IE:\\\\Programs\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -IE:\\\\Programs\\\\Anaconda\\\\include -IE:\\\\Programs\\\\Anaconda\\\\lib\\\\site-packages\\\\theano-0.8.2-py3.5.egg\\\\theano\\\\gof -o C:\\\\Users\\\\erikj\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-3.5.2-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LE:\\\\Programs\\\\Anaconda\\\\libs -LE:\\\\Programs\\\\Anaconda -lcublas -lpython35 -lcudart') [Elemwise{exp,no_inplace}(&lt;TensorType(float64, vector)&gt;)] Looping 1000 times took 11.687520 seconds Result is [ 1.23178032 1.61879341 1.52278065 ..., 2.20771815 2.29967753 1.62323285] Used the cpu Process finished with exit code 0 But when i just try to import theano from the console i get the following error: erikj@DESKTOP-76UUOFA MINGW64 /c/Users/erikj/Desktop $ python -i Python 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul 5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. &gt;&gt;&gt; import theano Traceback (most recent call last): File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\gof\\cutils.py\", line 305, in &lt;module&gt; from cutils_ext.cutils_ext import * # noqa ImportError: DLL load failed: The specified procedure could not be found. During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\gof\\cutils.py\", line 316, in &lt;module&gt; from cutils_ext.cutils_ext import * # noqa ImportError: DLL load failed: The specified procedure could not be found. During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\__init__.py\", line 76, in &lt;module&gt; from theano.scan_module import scan, map, reduce, foldl, foldr, clone File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\scan_module\\__init__.py\", line 40, in &lt;module&gt; from theano.scan_module import scan_opt File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\scan_module\\scan_opt.py\", line 59, in &lt;module&gt; from theano import tensor, scalar File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\tensor\\__init__.py\", line 7, in &lt;module&gt; from theano.tensor.subtensor import * File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\tensor\\subtensor.py\", line 27, in &lt;module&gt; import theano.gof.cutils # needed to import cutils_ext File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\gof\\cutils.py\", line 319, in &lt;module&gt; compile_cutils() File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\gof\\cutils.py\", line 284, in compile_cutils preargs=args) File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\gof\\cmodule.py\", line 2213, in compile_str return dlimport(lib_filename) File \"E:\\Programs\\Anaconda\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\gof\\cmodule.py\", line 299, in dlimport rval = __import__(module_name, {}, {}, [module_name]) ImportError: DLL load failed: The specified procedure could not be found. &gt;&gt;&gt; I installed latest 64 bit version of cuda (cuda-8.0.44), I have a 64 bit python 3.5.2, theano realease 0.8.2, NVIDIA GTX 680, Microsoft visual studio 2015. I have been bothering for 24 hours with this and i am running out of ideas. Thank you in advance for the help ! edit: Import of theano in PyCharm works fine and i am using the same python in both cases",
        "answers": [],
        "votes": []
    },
    {
        "question": "I use theano for some deep learning experiments. I have killed a 3 weeks running process by ctrl+c, to start a new process. As I see, although I have killed the process, the gpu memory is not released. According to nvidia-smi, the memory is free, except 23MB small usage. I use Tesla k40. +-----------------------------------------------------------------------------+ | NVIDIA-SMI 367.57 Driver Version: 367.57 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Tesla K40m Off | 0000:85:00.0 Off | 0 | | N/A 24C P8 21W / 235W | 23MiB / 11439MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 2873 G /usr/lib/xorg/Xorg 23MiB | +-----------------------------------------------------------------------------+ But in reality, when I try to run even very small datasets, I get memory error. If it would be only 23 MB usage, it shouldn't be a problem at all. I don't have sudo privileges on the machine I am using. How can I fix this problem?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have custom layer model using graph structure in keras. I want to add an intermediate layer between each pair of existing layer. The function of this layer will be to add some noise similar to GaussianNoise layer provided by keras. I want to manipulate the weights from the previous layer and then feed it to the next layer. My problem is I cant understand how to fetch these weights from the previous layer. I looked GaussianNoise layer as an example. The call method is defined as : def call(self, x, mask=None): noise_x = x + K.random_normal(shape=K.shape(x), mean=0., std=self.sigma) return K.in_train_phase(noise_x, x) The 'x' is a TensorVariable and it has no information about the weights. How can I get weight's within this intermediate layer? Thanks",
        "answers": [],
        "votes": []
    },
    {
        "question": "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) I get this error when trying to run any sample Theano program. I have tried all the suggested fixes provided in this thread. nvcc --version output: nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2015 NVIDIA Corporation Built on Tue_Aug_11_14:27:32_CDT_2015 Cuda compilation tools, release 7.5, V7.5.17 nvidia-smi output: Sat Dec 10 00:46:14 2016 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 367.57 Driver Version: 367.57 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 1070 Off | 0000:01:00.0 Off | N/A | | 0% 37C P0 33W / 151W | 0MiB / 8112MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ gcc version: (venv) rgalbo@blueberry:~$ gcc --version gcc (Ubuntu 4.9.3-13ubuntu2) 4.9.3 I have been trying to get this to work for a while now, would like someone to point me in the right direction.",
        "answers": [
            [
                "So I was finally able to get Theano to find the gpu, I went through the steps provided here in order to clean up any corrupt installation that may have occured from my initial installation of CUDA. After this I ran sudo apt-get install cuda which installed the right driver packages for my nvidia graphics card. I then proceeded to install CUDA 8.0 from the deb and this was able to over-write the 7.5 version that was giving me issues. This is the output I am now able to get from theano_test.py: (venv) rgalbo@blueberry:~$ python theano_test.py Using gpu device 0: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5103) [GpuElemwise{exp,no_inplace}(&lt;CudaNdarrayType(float32, vector)&gt;), HostFromGpu(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.185949 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the gpu and here is my ~/.theanorc file: (venv) rgalbo@blueberry:~$ cat ~/.theanorc [global] floatX = float32 device = gpu [nvcc] flags=-D_FORCE_INLINE [cuda] root = /usr/local/cuda-8.0 After each separate install I updated and rebooted the server just for good luch, which I found to be helpful."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I've been banging my head against this issue all day! Initially I was having issues with the compiler not being able to find the corecrt.h file. I seem to have fixed it by copying all include files from C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.10240.0\\ucrt to C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\include. But now, I'm getting hundreds of compilation errors. I'm not that familiar with C/C++, does this appear to be a simple obvious issue? cl : Command line warning D9002 : ignoring unknown option '-m64' mod.cu C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\include\\cuda_runtime.h: warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\cuda_runtime_api.h(1946): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\cuda_runtime_api.h(1946): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h: warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(849): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(1787): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(2637): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(3492): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(4431): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(5345): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(6252): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(7142): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\math_functions.h(7956): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_functions.h: warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_functions.h(774): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_functions.h(1618): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\device_double_functions.h: warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\sm_20_intrinsics.h: warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss c:\\program files\\nvidia gpu computing toolkit\\cuda\\v8.0\\include\\sm_20_intrinsics.h(943): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss C:\\toolkits\\Anaconda3\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(17): warning C4005: 'PyString_Check': macro redefinition C:\\toolkits\\Anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(63): note: see previous definition of 'PyString_Check' C:\\toolkits\\Anaconda3\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(18): warning C4005: 'PyString_FromString': macro redefinition C:\\toolkits\\Anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(65): note: see previous definition of 'PyString_FromString' C:\\toolkits\\Anaconda3\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(19): warning C4005: 'PyString_AsString': macro redefinition C:\\toolkits\\Anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(72): note: see previous definition of 'PyString_AsString' C:\\toolkits\\Anaconda3\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(20): warning C4005: 'PyString_FromStringAndSize': macro redefinition C:\\toolkits\\Anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(66): note: see previous definition of 'PyString_FromStringAndSize' C:\\toolkits\\Anaconda3\\lib\\site-packages\\theano-0.8.2-py3.5.egg\\theano\\sandbox\\cuda\\cuda_ndarray.cuh(21): warning C4005: 'PyString_Size': macro redefinition C:\\toolkits\\Anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy/npy_3kcompat.h(74): note: see previous definition of 'PyString_Size' C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\include\\cuda_runtime_api.h(1946): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\include\\cuda_runtime_api.h(1946): warning C4819: The file contains a character that cannot be represented in the current code page (932). Save the file in Unicode format to prevent data loss C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vadefs.h(127): error: bool type is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vadefs.h(133): error: bool type is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vadefs.h(139): error: bool type is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\yvals.h(646): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\yvals.h(658): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\yvals.h(659): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\yvals.h(781): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\initializer_list(27): error: identifier \"constexpr\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\initializer_list(27): error: member function with the same name as its class must be a constructor C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\initializer_list(27): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\initializer_list(60): error: \"constexpr\" is not a function or static data member C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\initializer_list(71): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(24): error: identifier \"constexpr\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(24): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(26): error: member \"std::integral_constant&lt;_Ty, _Val&gt;::_Ty\" is not a type name C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(27): error: member \"std::integral_constant&lt;_Ty, _Val&gt;::_Ty\" is not a type name C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(29): error: identifier \"constexpr\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(29): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(45): error: expected a declaration C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(45): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(100): error: \"constexpr\" is not a function or static data member C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(213): error: identifier \"char16_t\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(219): error: identifier \"char32_t\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(219): error: class \"std::_Is_integral&lt;&lt;error-type&gt;&gt;\" has already been defined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(245): error: this declaration has no storage class or type specifier C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(245): error: \"constexpr\" is not a function or static data member C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(282): error: this declaration has no storage class or type specifier C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(282): error: \"constexpr\" is not a function or static data member C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(295): error: this declaration has no storage class or type specifier C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xtr1common(295): error: \"constexpr\" is not a function or static data member C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(146): error: explicit type is missing (\"int\" assumed) C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(146): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(181): error: identifier \"constexpr\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(181): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(195): error: identifier \"constexpr\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(195): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(209): error: identifier \"constexpr\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(209): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(223): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(237): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(251): error: member \"std::plus&lt;void&gt;::constexpr\" is not a valid class member template C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(251): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(268): error: member \"std::minus&lt;void&gt;::constexpr\" is not a valid class member template C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(268): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(285): error: member \"std::multiplies&lt;void&gt;::constexpr\" is not a valid class member template C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(285): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(302): error: member \"std::equal_to&lt;void&gt;::constexpr\" is not a valid class member template C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(302): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(319): error: member \"std::less&lt;void&gt;::constexpr\" is not a valid class member template C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(319): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(375): error: invalid combination of type specifiers C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(404): error: identifier \"char16_t\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(405): error: identifier \"char16_t\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(410): error: identifier \"char32_t\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(410): error: class \"std::hash&lt;&lt;error-type&gt;&gt;\" has already been defined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(411): error: identifier \"char32_t\" is undefined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(635): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(635): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(641): error: type name is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(640): error: template parameter \"_Ty1\" is not used in or cannot be deduced from the template argument list of class template \"std::_Arg_types&lt;&lt;error-constant&gt;&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(648): error: type name is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(648): error: too many arguments for class template \"std::_Arg_types\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(659): error: explicit type is missing (\"int\" assumed) C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(659): error: expected a \";\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: constant \"&lt;unnamed&gt;\" is not used in or cannot be deduced from the template argument list of class template \"std::_Is_function&lt;_Ret (std::_Types, ...)&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: class template \"std::_Is_function\" has already been defined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: constant \"&lt;unnamed&gt;\" is not used in or cannot be deduced from the template argument list of class template \"std::_Is_function&lt;_Ret (std::_Types, ...)&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: class template \"std::_Is_function\" has already been defined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: constant \"&lt;unnamed&gt;\" is not used in or cannot be deduced from the template argument list of class template \"std::_Is_function&lt;_Ret (std::_Types, ...)&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: class template \"std::_Is_function\" has already been defined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: constant \"&lt;unnamed&gt;\" is not used in or cannot be deduced from the template argument list of class template \"std::_Is_function&lt;_Ret (std::_Types, ...)&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: class template \"std::_Is_function\" has already been defined C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: expected a \"&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: expected a \"&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: expected a \"&gt;\" C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: \"...\" is not allowed C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: a nontype template parameter may not have class type C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef(673): error: expected a \"&gt;\" Error limit reached. 100 errors detected in the compilation of \"C:/Users/Takkeezi/AppData/Local/Temp/tmpxft_0000c094_00000000-10_mod.cpp1.ii\".",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm trying to get theano up and running on a Windows 10 (x64) machine. I've installed Python from the WinPython distribution, which comes with theano already running. But after installing CUDA 8.0.44 and MingW, I constantly get the following errors when running the simple script import theano theano.test() Note that I had several warnings before, that I already solved (e.g. by installing missing packages from here. But this error gives me no usable information. The really weird thing is, that the module-name is not given anywhere that theano is missing. theano.gof.opt: ERROR: Optimization failure due to: constant_folding theano.gof.opt: ERROR: node: DimShuffle{x,x}(TensorConstant{1.0}) theano.gof.opt: ERROR: TRACEBACK: theano.gof.opt: ERROR: Traceback (most recent call last): File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\opt.py\", line 1772, in process_node replacements = lopt.transform(node) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\tensor\\opt.py\", line 5825, in constant_folding no_recycling=[]) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\op.py\", line 970, in make_thunk no_recycling) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\op.py\", line 879, in make_c_thunk output_storage=node_output_storage) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\cc.py\", line 1200, in make_thunk keep_lock=keep_lock) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\cc.py\", line 1143, in __compile__ keep_lock=keep_lock) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\cc.py\", line 1595, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\cmodule.py\", line 1142, in module_from_key module = lnk.compile_cmodule(location) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\cc.py\", line 1506, in compile_cmodule preargs=preargs) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\cmodule.py\", line 2213, in compile_str return dlimport(lib_filename) File \"C:\\Programmieren\\WinPython-64bit-3.5.2.2\\python-3.5.2.amd64\\lib\\site-packages\\theano\\gof\\cmodule.py\", line 299, in dlimport rval = __import__(module_name, {}, {}, [module_name]) ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed. Potentially related posts are Test Optimization failure and Installing theano on windows. Any ideas how to resolve this or find out what dll is missing?",
        "answers": [
            [
                "Solved this issue, by following this excellent tutorial (the only one that actually works and is up to date) for installing Deep Learning Libraries natively on a Windows machine."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I have Anaconda Python 2.7.12 installed with numpy 1.11.2 and scipy 0.18.1 versions. I have installed Theano 0.8.2 through conda install. I have added these lines in the .theanorc.txt file: [global] floatX = float32 device = gpu0 [nvcc] compiler_bindir=C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin` I have the CUDA Path set in the environment variables. I have also added CUDNN v4.0 to the cuda installation. However when I do a simple import theano in the python interpreter it gives me the following error and falls back to cpu. `DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning). mod.cu Creating library C:/Users/&lt;USER_NAME&gt;/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/cuda_ndarray/cuda_ndarray.lib and object C:/Users/&lt;USER_NAME&gt;/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/cuda_ndarray/cuda_ndarray.exp ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: DLL load failed: The specified module could not be found. WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available (error: cuda unavailable)` The error does not specify which DLL is missing either. I am not sure if this is a bug or a theano installation/config issue or a CUDA installation/config issue. Thanks",
        "answers": [
            [
                "Worked after re-installation of CUDAv8.0, weird because the CUDA samples specific to GPU like devicequery were working correctly.."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am using Theano with keras. I have a trained DNN and I have dumped the weight's in a file. I am performing some operations on these weights and again dumping the new converted weights into another file. Now, I am loading my DNN model with these converted weights and want to compare the results between the two. I used the keras.evaluate method but I find the accuracy to be exactly same even though the weights are different. Is there another approach with which I can compare the accuracy? Thanks.",
        "answers": [
            [
                "Keras performs some under the hood operations for your batch_size including normalization. So if you only scaled and translated your image the result will stay the same. Anyways you can do model.predict(sample, 1) and write your own evaluation metric to circumvent this issue."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have a aws machine with 4 GPUs: 00:03.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K520] (rev a1) 00:04.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K520] (rev a1) 00:05.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K520] (rev a1) 00:06.0 VGA compatible controller: NVIDIA Corporation GK104GL [GRID K520] (rev a1) and my theanorc file looks like this: [global] floatX = float32 device = gpu0 [lib] cnmem = 1 When I open one jupyter notebook and import theano I get the following (which I assume is only using one GPU): Using Theano backend. Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105) /home/sabeywardana/anaconda3/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5. However, if I open a second jupyter notebook on the same machine at the same time. Then I get the error: ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device 0 failed: initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1 ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device gpu failed: initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1 If I manually change my .theanorc to use gpu1 then the second jupyter notebook works fine. So the question is: Is there a way to configure .theanorc to just get the available GPU?",
        "answers": [
            [
                "You can use device=gpu, which will select the first available GPU. However, in your case, GPU 0 will still be considered \"available\" (it does not have much memory left, but execution is still possible). You can use nvidia-smi to set the compute mode of your GPUs to \"Exclusive Thread\", so that the first notebook \"blocks\" the first GPU for its exclusive use, and the second notebook will use another one. Another option is to change the THEANO_FLAGS environment variable from inside the notebook, before importing theano. Something like: import os os.environ['THEANO_FLAGS'] = os.environ.get('THEANO_FLAGS', '') + ',' + 'device=gpu1' import theano"
            ],
            [
                "It is not possible to change the gpu device after importing theano. May be you can try this- import os os.system(\"THEANO_FLAGS='device=gpu0' python script_1.py\") os.system(\"THEANO_FLAGS='device=gpu1' python script_2.py\") os.system(\"THEANO_FLAGS='device=gpu1' python script_3.py\") os.system(\"THEANO_FLAGS='device=gpu1' python script_4.py\") If you want to do it from inside the notebook (more programmatical) you may use following snippet :- import theano.sandbox.cuda theano.sandbox.cuda.use(\"gpu0\") Paste this to every notebook and change the gpu id. It will work."
            ]
        ],
        "votes": [
            2.0000001,
            1.0000001
        ]
    },
    {
        "question": "I use a server which has CUDA 7.5. But the server does not involve CUDNN. Is it possible to install CUDNN, and set all the linkings with CUDA, without root access, for the usage of all applications on ubuntu 14.04? I have implemented the solution on this page Installing cuDNN for Theano without root access, but it did not work for me. I have verified by building caffe; http://caffe.berkeleyvision.org/, and I have checked that using cmake. I have created a directory caffe/build and run cmake .. from there. If the configuration was correct I would see these lines: -- Found cuDNN (include: /usr/local/cuda-7.0/include, library: /usr/local/cuda-7.0/lib64/libcudnn.so) -- NVIDIA CUDA: -- Target GPU(s) : Auto -- GPU arch(s) : sm_30 -- cuDNN : Yes But I saw -- cuDNN : Not found P.S. I also need to run: https://github.com/rsennrich/nematus What is the best way to install CUDNN locally, and link with global CUDA in the server?",
        "answers": [
            [
                "it is possible to use CuDNN with a CUDA installed in a server, here is what I did to make it work. First, you just need to simply make a file in your local space: Home/local and make it contain include and lib folders(I guess most of you have had these local folders). HOME/local/include HOME/local/lib Then download CuDNN and move the content from include and lib64 in the CuDNN folder into your local include and lib folders separately(which you just made) At last, add these two environment paths to your .bashrc file export CPATH=$CPATH:$HOME/local/include export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/local/lib It will work then. BTW, if you meet a problem of 'out of memory' after successfully installing the CuDNN, enter this line in the terminal before running your code: export CUDA_VISIBLE_DEVICES=0 to change the GPU device."
            ],
            [
                "I created a separate directory in my home for using the shared object and .h files for CuDNN. Then I added the path of this separate directory in the PATH and LD_LIBRARY_PATH variables in the bashrc. It works for me."
            ]
        ],
        "votes": [
            8.0000001,
            3.0000001
        ]
    },
    {
        "question": "I have a CPU with integrated GPU. I also have an external GPU that i have been using for ML. What i want is to use the integrated GPU only for display and dedicate the external GPU to NN training (in order to free some memory). I have set at the BIOS the external GPU to be the primary GPU, but also to both be active. So they are both working. After i boot the system i can plug the monitor to any one of them and they both work. The problem is that when i plug the monitor to the motherboard (integrated GPU) theano stops using the external GPU: ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device gpu failed: Is there a way to explicitly point theano to the external GPU? here is my the relevant part of my .theanorc: [global] floatX = float32 device = gpu",
        "answers": [
            [
                "I have a similar system to yours. For linux, installing bumblebee worked. sudo apt-get install bumblebee-nvidia (adapt to your distro's package manager) Then launch python via: optirun python"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I ran a python program with Theano, but it errors with: ImportError: cuDNN not available: Version is too old. Update to v5, was 3007. So, is it possible to use Theano with CUDA 6.5 and CuDNN 3.0? Currently, I don't have the root privilege to install a newer version of CUDA (because the newer CUDA needs newer driver).",
        "answers": [
            [
                "git clone theano from git repo, use git checkout to grab an older version, then install locally."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am doing a project on image captioning. I want to set a batch of image features with shape=(batch_size, 512) as the initial hidden state of a LSTMLayer in Lasagne (theano). The sequence input to the LSTMLayer is a batch of text sequence with shape=(batch_size, max_sequence_length, 512). I notice that LSTMLayer in lasagne has a hid_init parameter. Does anyone know how to use it for LSTMLayer in Lasagne? Do I need to implement a custom LSTMLayer by myself?",
        "answers": [
            [
                "You dont need to set h_0 parameter, because h_0 uses c0 (see this enter link description here and write down connections from h0 to c0), so, you have to set only c0 parameter: decoder = LSTMLayer(l_word_embeddings, num_units=LSTM_UNITS, cell_init=your_image_features_layer_512_shape, #this is c0 mask_input=l_mask) You can set c0 as Layer or as other arrays (see lasagne LSTM doc enter link description here). Ready to discuss further."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'm trying to set up Theano to use GPU, but I keep getting the same error when importing theano in python environment: nvcc fatal : Could not set up the environment for Microsoft Visual Studio using 'd:/Microsoft Visual Studio 12.0/VC/bin//../../VC/bin/amd64/vcvars64.bat' I have a .theanorc file in my C:\\Users\\Denis\\ folder: [global] floatX = float32 device = gpu [nvcc] fastmath = True compiler_bindir=D:\\Microsoft Visual Studio 12.0\\VC\\bin\\amd64\\cl.exe I also have a Vistual Studio 2012 installed on the D:\\ disk. CUDA 8 is installed in the default location. In my PATH environment variable, apart from CUDA and other env vars, I have the following: d:\\Anaconda3\\MinGW\\x86_64-w64-mingw32\\bin\\;d:\\Microsoft Visual Studio 12.0\\VC\\bin\\amd64;d:\\Microsoft Visual Studio 12.0\\VC\\bin\\amd64\\cl.exe; I use Anaconda and Python 3.4. My Anaconda folder is located in D:\\Anaconda3\\. I've also set up this environment variables: VCINSTALLDIR = d:\\Microsoft Visual Studio 12.0\\VC VSINSTALLDIR = d:\\Microsoft Visual Studio 12.0\\ I keep getting the same error when importing theano. Could you please help me to find out what I'm doing wrong?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am implementing some deep learning algorithms using theano. After I stop some programs running theano, occasionally the following error appears if I want to import theano again. &gt;&gt;&gt; import theano ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device gpu failed: initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1 Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"/home/jjhu/.local/lib/python2.7/site-packages/theano/__init__.py\", line 118, in &lt;module&gt; theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File \"/home/jjhu/.local/lib/python2.7/site-packages/theano/sandbox/cuda/tests/test_driver.py\", line 40, in test_nvidia_driver1 if not numpy.allclose(f(), a.sum()): File \"/home/jjhu/.local/lib/python2.7/site-packages/theano/compile/function_module.py\", line 875, in __call__ storage_map=getattr(self.fn, 'storage_map', None)) File \"/home/jjhu/.local/lib/python2.7/site-packages/theano/gof/link.py\", line 317, in raise_with_op reraise(exc_type, exc_value, exc_trace) File \"/home/jjhu/.local/lib/python2.7/site-packages/theano/compile/function_module.py\", line 862, in __call__ self.fn() if output_subset is None else\\ RuntimeError: Cuda error: kernel_reduce_ccontig_node_4894639462a290346189bb38dab7bb7e_0: out of memory. (grid: 1 x 1; block: 256 x 1 x 1) Apply node that caused the error: GpuCAReduce{add}{1}(&lt;CudaNdarrayType(float32, vector)&gt;) Toposort index: 0 Inputs types: [CudaNdarrayType(float32, vector)] Inputs shapes: [(10000,)] Inputs strides: [(1,)] Inputs values: ['not shown'] Outputs clients: [[HostFromGpu(GpuCAReduce{add}{1}.0)]] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node. I search for several solutions. Someone suggests to remove the compilation folder by rm -rf ./theano . I also check that the owner of ./theano is not root user. I also try setting my ./theanorc as following. But both do not work for me. [global] floatX = float32 device = cpu optimizer=fast_run [lib] cnmem = 0.1 [cuda] root = /usr/local/cuda The only working solution is to reboot or log out the machine. It is very awkward. I don't know what causes this problem. Can anyone suggest some solutions?",
        "answers": [],
        "votes": []
    },
    {
        "question": "Several places mention that using shared variables improve performance when using a GPU (like here, or here). But I haven't been able to find any numbers quantifying the difference. Today I was told by a Professor at my school that I am basically wasting my time setting up shared variables, because the speed up in negligible. Are there any formal tests that you know of, or failing that what are your personal experiences/heuristics?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am starting to get into deep learning and I am trying out the example from Chapter 6 on neuralnetworksanddeeplearning.com. Theano is telling me, that it is using my GPU (a GTX 780). However, the GPU usage hovers only at around 40~50% and the clockspeed is only at ~800 MHz (normal Boost clock in games is ~1100 MHz). Is this normal? Or is something wrong here?",
        "answers": [
            [
                "It is normal. Actually, 40~50% should be considered high usage. Some operations like vector concatenation are performed on CPU. The GPU has to wait these operations to be completed before using the results as input. Besides, the overhead can be caused by loading data from memory. So people commonly run 2~3 programs on the same GPU to take full advantage of it."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "Theano fails to be imported with theano configuration cnmem = 1 Any idea how to make sure the GPU is totally allocated to the theano python script? Note: Display is not used to avoid its GPU usage File: .theanorc cnmem = 1 File: test.py print 'Importing Theano Library ...' import theano print 'Imported' Output: $ python test.py Importing Theano Library ... Killed $ It only works with cnmem = 0.75 File: .theanorc cnmem = 0.75 Output: $ python test.py Importing Theano Library ... Imported $",
        "answers": [
            [
                "https://github.com/Theano/Theano/issues/4302#issuecomment-202067917 Could you try with 1.0 instead of 1? according to the docs, it needs to be a float. Also, it is limited to 0.95 to allow space for device drivers. So, you can't use the entire GPU memory just like you can't use all of RAM."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "(Very long error messages in the question below. TL;DR, here is the specific question: Why does this test code not execute on the TX1's GPU, and what do I need to do to make it do so?) I have just flashed and installed a brand new Nvidia Jetson TX1, with JetPack 2.3. I am trying to get Theano installed on the TX1 in such a way as to enable the use of the on-board GPU, for further machine learning and neural network applications. However, I cannot seem to get the GPU itself to work. The install of Theano was taken from here: sudo apt-get install python-numpy python-scipy python-dev python-pip python-nose g++ libblas-dev git pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git --user # Need Theano 0.8(not yet released) or more recent Theano version installed was 0.9.0.dev2, python is version 2.7.12. I used the test script from here : from theano import function, config, shared, tensor import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], tensor.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, tensor.Elemwise) and ('Gpu' not in type(x.op).__name__) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') When running as recommended: THEANO_FLAGS=device=cuda0 python gpu_tutorial1.py I get the following response, full of errors, warnings, and an execution on the CPU rather than the GPU: ERROR (theano.gpuarray): pygpu was configured but could not be imported Traceback (most recent call last): File \"/home/ubuntu/.local/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 21, in &lt;module&gt; import pygpu ImportError: No module named pygpu WARNING (theano.gof.cmodule): OPTIMIZATION WARNING: Theano was not able to find the default g++ parameters. This is needed to tune the compilation to your specific CPU. This can slow down the execution of Theano functions. Please submit the following lines to Theano's mailing list so that we can fix this problem: ['# 1 \"&lt;stdin&gt;\"\\n', '# 1 \"&lt;built-in&gt;\"\\n', '# 1 \"&lt;command-line&gt;\"\\n', '# 1 \"/usr/include/stdc-predef.h\" 1 3 4\\n', '# 1 \"&lt;command-line&gt;\" 2\\n', '# 1 \"&lt;stdin&gt;\"\\n', 'Using built-in specs.\\n', 'COLLECT_GCC=/usr/bin/g++\\n', 'Target: aarch64-linux-gnu\\n', \"Configured with: ../src/configure -v --with-pkgversion='Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.2' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-libquadmath --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-arm64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-arm64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-arm64 --with-arch-directory=aarch64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-multiarch --enable-fix-cortex-a53-843419 --disable-werror --enable-checking=release --build=aarch64-linux-gnu --host=aarch64-linux-gnu --target=aarch64-linux-gnu\\n\", 'Thread model: posix\\n', 'gcc version 5.4.0 20160609 (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.2) \\n', \"COLLECT_GCC_OPTIONS='-E' '-v' '-shared-libgcc' '-mlittle-endian' '-mabi=lp64'\\n\", ' /usr/lib/gcc/aarch64-linux-gnu/5/cc1 -E -quiet -v -imultiarch aarch64-linux-gnu - -mlittle-endian -mabi=lp64 -fstack-protector-strong -Wformat -Wformat-security\\n', 'ignoring nonexistent directory \"/usr/local/include/aarch64-linux-gnu\"\\n', 'ignoring nonexistent directory \"/usr/lib/gcc/aarch64-linux-gnu/5/../../../../aarch64-linux-gnu/include\"\\n', '#include \"...\" search starts here:\\n', '#include &lt;...&gt; search starts here:\\n', ' /usr/lib/gcc/aarch64-linux-gnu/5/include\\n', ' /usr/local/include\\n', ' /usr/lib/gcc/aarch64-linux-gnu/5/include-fixed\\n', ' /usr/include/aarch64-linux-gnu\\n', ' /usr/include\\n', 'End of search list.\\n', 'COMPILER_PATH=/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/:/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/\\n', 'LIBRARY_PATH=/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/5/../../../aarch64-linux-gnu/:/usr/lib/gcc/aarch64-linux-gnu/5/../../../../lib/:/lib/aarch64-linux-gnu/:/lib/../lib/:/usr/lib/aarch64-linux-gnu/:/usr/lib/../lib/:/usr/lib/gcc/aarch64-linux-gnu/5/../../../:/lib/:/usr/lib/\\n', \"COLLECT_GCC_OPTIONS='-E' '-v' '-shared-libgcc' '-mlittle-endian' '-mabi=lp64'\\n\"] [Elemwise{exp,no_inplace}(&lt;TensorType(float64, vector)&gt;)] Looping 1000 times took 12.736936 seconds Result is [ 1.23178032 1.61879341 1.52278065 ..., 2.20771815 2.29967753 1.62323285] Used the cpu When I change the device flag to 'gpu': THEANO_FLAGS=device=gpu python gpu_tutorial1.py things improve somewhat, in that the NVIDIA Tegra X1 is at least found, although it is ultimately not used: Using gpu device 0: NVIDIA Tegra X1 (CNMeM is disabled, cuDNN 5105) WARNING (theano.gof.cmodule): OPTIMIZATION WARNING: Theano was not able to find the default g++ parameters. This is needed to tune the compilation to your specific CPU. This can slow down the execution of Theano functions. Please submit the following lines to Theano's mailing list so that we can fix this problem: ['# 1 \"&lt;stdin&gt;\"\\n', '# 1 \"&lt;built-in&gt;\"\\n', '# 1 \"&lt;command-line&gt;\"\\n', '# 1 \"/usr/include/stdc-predef.h\" 1 3 4\\n', '# 1 \"&lt;command-line&gt;\" 2\\n', '# 1 \"&lt;stdin&gt;\"\\n', 'Using built-in specs.\\n', 'COLLECT_GCC=/usr/bin/g++\\n', 'Target: aarch64-linux-gnu\\n', \"Configured with: ../src/configure -v --with-pkgversion='Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.2' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-libquadmath --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-arm64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-arm64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-arm64 --with-arch-directory=aarch64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-multiarch --enable-fix-cortex-a53-843419 --disable-werror --enable-checking=release --build=aarch64-linux-gnu --host=aarch64-linux-gnu --target=aarch64-linux-gnu\\n\", 'Thread model: posix\\n', 'gcc version 5.4.0 20160609 (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.2) \\n', \"COLLECT_GCC_OPTIONS='-E' '-v' '-shared-libgcc' '-mlittle-endian' '-mabi=lp64'\\n\", ' /usr/lib/gcc/aarch64-linux-gnu/5/cc1 -E -quiet -v -imultiarch aarch64-linux-gnu - -mlittle-endian -mabi=lp64 -fstack-protector-strong -Wformat -Wformat-security\\n', 'ignoring nonexistent directory \"/usr/local/include/aarch64-linux-gnu\"\\n', 'ignoring nonexistent directory \"/usr/lib/gcc/aarch64-linux-gnu/5/../../../../aarch64-linux-gnu/include\"\\n', '#include \"...\" search starts here:\\n', '#include &lt;...&gt; search starts here:\\n', ' /usr/lib/gcc/aarch64-linux-gnu/5/include\\n', ' /usr/local/include\\n', ' /usr/lib/gcc/aarch64-linux-gnu/5/include-fixed\\n', ' /usr/include/aarch64-linux-gnu\\n', ' /usr/include\\n', 'End of search list.\\n', 'COMPILER_PATH=/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/:/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/\\n', 'LIBRARY_PATH=/usr/lib/gcc/aarch64-linux-gnu/5/:/usr/lib/gcc/aarch64-linux-gnu/5/../../../aarch64-linux-gnu/:/usr/lib/gcc/aarch64-linux-gnu/5/../../../../lib/:/lib/aarch64-linux-gnu/:/lib/../lib/:/usr/lib/aarch64-linux-gnu/:/usr/lib/../lib/:/usr/lib/gcc/aarch64-linux-gnu/5/../../../:/lib/:/usr/lib/\\n', \"COLLECT_GCC_OPTIONS='-E' '-v' '-shared-libgcc' '-mlittle-endian' '-mabi=lp64'\\n\"] [Elemwise{exp,no_inplace}(&lt;TensorType(float64, vector)&gt;)] Looping 1000 times took 12.820628 seconds Result is [ 1.23178032 1.61879341 1.52278065 ..., 2.20771815 2.29967753 1.62323285] Used the cpu I do plan to send the warning lines to the Theano mailing list, but that warning seems unrelated to what is currently my main issue: Why does this test code not execute on the TX1's GPU, and what do I need to do to make it do so?",
        "answers": [
            [
                "It turns out that the recommended CLI invocation on that site is not correct. The correct invocation is: THEANO_FLAGS='device=gpu,floatX=float32' python gpu_tutorial1.py This is sufficient to execute on the GPU with a satisfactory speedup (noticeable and reported in the output) and to get rid of that gob-smackingly long error warning. Putting both those flags in a .theanorc file is also sufficient, and simplifies the invocation."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "Can I install cuDNN locally without root access ? I don't have root access to a linux machine I am using (the distro is openSuse), but I have CUDA 7.5 already installed. I am using Theano and I need cuDNN to improve the speed of the operations on the GPU. I downloaded cudnn-7.5-linux-x64-v5.1 from Nvidia and as per the instructions I need to copy the CuDNN archive content to CUDA installation folder, i.e. (cuda/lib64/ and cuda/include/). But that would require me to have root access. Is it possible that I extract the cudnn archive locally and provide theano with the path to the cudnn library ?",
        "answers": [
            [
                "You could copy the entire CUDA SDK to your home and tell Theano and others that they should use your local copy of CUDA by adding/modifying these environment variables in your ~/.bashrc export CUDA_ROOT=~/program/cuda-7.5 export CUDA_HOME=~/program/cuda-7.5 export PATH=${CUDA_HOME}/bin:$PATH export LD_LIBRARY_PATH=/usr/lib64/nvidia:${CUDA_HOME}/lib64:$LD_LIBRARY_PATH Then you could simply extract cuDNN to your local CUDA SDK dir ~/program/cuda-7.5/"
            ]
        ],
        "votes": [
            6.0000001
        ]
    },
    {
        "question": "I am a non-root user on a cluster computer running Scientific Linux release 6.6 (Carbon). I am experiencing some theano crashes when running code on a GPU with CUDA 7.5 and cuDNN 5. I am using Python 2.7, Theano 0.9, Keras 1.0.7 and Lasange 0.1. The following crash occurs ONLY when I run the program on a GPU node with cuDNN enabled. The code completes without issue on a CPU and a GPU with cuDNN disabled. Traceback (most recent call last): File \"runner.py\", line 306, in &lt;module&gt; main() File \"runner.py\", line 241, in main queries_exp = __import__(args.exp_model).queries_exp File \"/mnt/nfs2/inf/tjb32/workspace/CNN_EL/nlp-entity-convnet/exp_multi_conv_cosim.py\", line 923, in &lt;module&gt; queries_exp = EntityVectorLinkExp() File \"/mnt/nfs2/inf/tjb32/workspace/CNN_EL/nlp-entity-convnet/exp_multi_conv_cosim.py\", line 51, in __init__ self._setup() File \"/mnt/nfs2/inf/tjb32/workspace/CNN_EL/nlp-entity-convnet/exp_multi_conv_cosim.py\", line 543, in _setup on_unused_input='ignore', File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/compile/function.py\", line 326, in function output_keys=output_keys) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/compile/pfunc.py\", line 484, in pfunc output_keys=output_keys) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/compile/function_module.py\", line 1788, in orig_function output_keys=output_keys).create( File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/compile/function_module.py\", line 1467, in __init__ optimizer_profile = optimizer(fgraph) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 102, in __call__ return self.optimize(fgraph) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 90, in optimize ret = self.apply(fgraph, *args, **kwargs) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 235, in apply sub_prof = optimizer.optimize(fgraph) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 90, in optimize ret = self.apply(fgraph, *args, **kwargs) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 235, in apply sub_prof = optimizer.optimize(fgraph) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 90, in optimize ret = self.apply(fgraph, *args, **kwargs) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 2262, in apply lopt_change = self.process_node(fgraph, node, lopt) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 1825, in process_node lopt, node) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 1719, in warn_inplace return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node) File \"/home/t/tj/tjb32/.local/lib/python2.7/site-packages/theano/gof/opt.py\", line 1705, in warn raise exc AssertionError My .theanorc looks like this: [global] floatX = float32 device = gpu [lib] cnmem = 1 [nvcc] fastmath = True And my profile has the following: export LD_LIBRARY_PATH=/home/t/tj/tjb32/cuda/lib64:$LD_LIBRARY_PATH export CPATH=/home/t/tj/tjb32/cuda/include:$CPATH export LIBRARY_PATH=/home/t/tj/tjb32/cuda/lib64:$LD_LIBRARY_PATH export PATH=/home/t/tj/tjb32/cuda/bin:$PATH When I query theano, the following is returned, which suggests to me that theano is interacting with CUDA and cuDNN. Using gpu device 0: Tesla K20m (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005) I'm fairly sure that I have installed CUDA and cuDNN correctly, if anyone could suggest any additional configuration steps that I may have missed that is causing cuDNN to crash the program, that would be greatly appreciated.",
        "answers": [
            [
                "Not sure if this can be the issues but: export LIBRARY_PATH=/home/t/tj/tjb32/cuda/lib64:$LD_LIBRARY_PATH should be? export LIBRARY_PATH=/home/t/tj/tjb32/cuda/lib64:$LIBRARY_PATH"
            ],
            [
                "I also use CUDA-7.5 and CuDNN 5 for running DNN in Keras. I created a separate directory (cuDNN/copy) in my home and put all CuDNN (obtained from nvidia website) files (.so and .h files) in this directory. Then I made appropriate changes to PATH and LD_LIBRARY variables in bashrc. I also made changes in .theanorc file. So the DNN works for me. This is how my bashrc looks - ########################## # CUSTOMIZATIONS GO HERE # ########################## export PATH=\"/users/start2015/r0605639/miniconda2/envs/kerPy3.4/bin:$PATH\" export PATH=\"/usr/local/cuda/bin:$PATH\" export LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:$PATH\" #http://www.chioka.in/why-is-keras-running-so-slow/ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-7.5/lib64:/users/start2015/r0605639/cuDNN/copy: export LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-7.5/lib64:/users/start2015/r0605639/cuDNN/copy: export CPATH=$CPATH:/users/start2015/r0605639/cuDNN/copy: export PATH=$PATH:/usr/local/cuda-7.5/bin This is how my .theanorc looks like : [global] device = gpu floatX = float32 optimizer = fast_run [blas] ldflags = -L/users/start2015/r0605639/kerasLibs/lib -lopenblas [lib] cnmem = 0.8 [cuda] root = /usr/local/cuda-7.5 [nvcc] fastmath = True optimizer_including=cudnn flags=-D_FORCE_INLINES -I/usr/local/cuda-7.5/include -I/usr/local/cuda-7.5/bin [dnn] enabled = True"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I am training a model in Theano 0.9 and Lasagne 0.1 and want to run it on GPU. I've set THEANO_FLAGS as follows: THEANO_FLAGS=device=gpu0,force_device=True,floatX=float64 Theano prints it is using GPU Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 4007) However, I noticed it's not, profiling shows that it's using CorrMM operation which is according to the docs CorrMM This is a CPU-only 2d correlation implementation taken from caffe\u2019s cpp implementation and also used by Torch. I have CUDA Toolkit 7.5 installed, Tensorflow works perfectly on GPU. For some reason Theano is falling back to CPU, it is supposed to cause an error due to force_device flag but it's not. I am not sure where the problem is as I'm new to Theano, I appreciate your help.",
        "answers": [
            [
                "Issue is floatX=float64. Use floatX=float32. GPU supports 32 bit only yet."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I just installed Anaconda and PyCharm on Windows 8.1 (64 bit). For an existing project, i created a conda environment which includes Theano and some other librarires. Theano is able to use the GPU (with CUDA) or the CPU for its calculations. I prefer to use the GPU, because it is much faster. If i start a test script of the project in the command line, i get the following output: Using gpu device 0: GeForce GT 650M (CNMeM is enabled with initial size: 85.0% of memory, cuDNN not available) ... This is what i like to have as output. I also tried to do this with PyCharm. I installed it and i used the correct conda environment, but i always get this output: WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string. WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) ... Theano then uses the CPU (which is incredibly slow...). In the command line i checked where \"g++\" is located: (venv) E:\\XXX\\panoptes_dl&gt;where g++ C:\\Users\\XXX\\Anaconda2\\envs\\venv\\Scripts\\g++.bat This means the used g++ is inside the Script-directory of the created environment. Sure, i could add the path C:\\Users\\XXX\\Anaconda2\\envs\\venv\\Scripts to the system's path variable, but this is very ugly, because i also have to use different environments. Does someone has an idea how this can be done with PyCharm? Thank you very much Regards Kevin",
        "answers": [
            [
                "I had the same issue on windows with Anaconda env in Pycharm. Go to: File -&gt; Settings -&gt; Project Interpreter Click on the gear beside the listed project interpreter at the top and select more. All the interpreters that PyCharm knows about will be listed. Select the environment that you are using and click the bottom button to the right under the filter symbol. This allows you to add a path to the interpreter paths. If you add your Scripts folder to this list of paths then it will be picked up when running in PyCharm."
            ]
        ],
        "votes": [
            -0.9999999
        ]
    },
    {
        "question": "I am new in Theano and Deep Learning, I am running my experiments in Theano but I would like to reduce the time I spend per epoch by doing data augmentation directly using the GPU. Unfortunately I can not use PyCuda, so I would like to know if is possible to do basic Data Augmentation using Theano. For example Translation or Rotation in images, meanwhile I am using scipy functions in CPU using Numpy but it is quite slow.",
        "answers": [
            [
                "If the data augmentation is part of your computation graph, and can be executed on GPU, it will naturally be executed on the GPU. So the question narrows down to \"is it possible to do common data augmentation tasks using Theano tensor operations on the GPU\". If the transformations you want to apply are just translations, you can just use theano.tensor.roll followed by some masking. If you want the rotations as well, take a look at this implementation of spatial transformer network. In particular take a look at the _transform function, it takes as an input a matrix theta that has a 2x3 transformation (left 2x2 is rotation, and right 1x2 is translation) one per sample and the actual samples, and applies the rotation and translation to those samples. I didn't confirm that what it does is optimized for the GPU (i.e. it could be that the bottleneck of that function is executed on the CPU, which will make it not appropriate for your use case), but it's a good starting point."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "in Ubuntu MATE 16.04 I'm trying to run the deep-learning python examples here using the GPU: testing Theano with GPU I did run the example code, THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python check1.py but it seems that it is used the CPU and not the GPU. Here is the last part of terminal output: WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available (error: cuda unavailable) ... Used the cpu I tried to run this code too: THEANO_FLAGS=device=cuda0 python check1.py but the output is: ERROR (theano.sandbox.gpuarray): pygpu was configured but could not be imported Traceback (most recent call last): File \"/usr/local/lib/python2.7/dist-packages/theano/sandbox/gpuarray/__init__.py\", line 20, in &lt;module&gt; import pygpu ImportError: No module named pygpu ... used cpu I installed the cuda toolkit from apt. Here there are (hopefully) useful data: python --version Python 2.7.12 g++ -v gcc version 5.4.0 nvcc --version Cuda compilation tools, release 7.5, V7.5.17 lspci NVIDIA Corporation GM107 [GeForce GTX 750 Ti] (rev a2) nvidia-smi +------------------------------------------------------+ | NVIDIA-SMI 361.42 Driver Version: 361.42 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 750 Ti Off | 0000:01:00.0 On | N/A | | 29% 35C P8 1W / 38W | 100MiB / 2044MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 2861 G /usr/lib/xorg/Xorg 90MiB | +-----------------------------------------------------------------------------+",
        "answers": [
            [
                "Finally I solved! This post Ubuntu 16.04, Theano and Cuda suggests to add flag nvcc.flags=-D_FORCE_INLINES to command line, so the command line becomes: THEANO_FLAGS=floatX=float32,device=gpu,nvcc.flags=-D_FORCE_INLINES python check1.py It seems to fix a bug in using glibc 2.23 fix for glibc 2.23 Now the program uses correctly the GPU, this is the correct output: THEANO_FLAGS=floatX=float32,device=gpu,nvcc.flags=-D_FORCE_INLINES python check1.py Using gpu device 0: GeForce GTX 750 Ti (CNMeM is disabled, cuDNN not available) [GpuElemwise{exp,no_inplace}(&lt;CudaNdarrayType(float32, vector)&gt;), HostFromGpu(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.317012 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the gpu Note that before trying this solution, I removed nvidia-cuda-toolkit and installed CUDA from Nvidia website, following part of instructions found here: CUDA with Ubuntu 16.04 This is what exactly I did: 1) I downloaded CUDA from here CUDA 7.5 download selecting LINUX, x86_64, Ubuntu 15.04, deb local 2) I installed the deb file dpkg -i cuda_repo-ubuntu1504-7-5-local_7.5-18_amd64.deb 3) Then run apt-get update This gives some errors! I fixed it overwriting the file Release in \\var\\cuda-repo-7.5-local with the following lines: Origin: NVIDIA Label: NVIDIA CUDA Architecture: repogenstagetemp MD5Sum: 51483bc34577facd49f0fbc8c396aea0 75379 Packages 4ef963dfa4276be01db8e7bf7d8a4f12 21448 Packages.gz SHA256: 532b1bb3b392b9083de4445dab2639b36865d7df1f610aeef8961a3c6f304d8a 75379 Packages 2e48cc13b6cc5856c9c6f628c6fe8088ef62ed664e9e0046fc72819269f7432c 21448 Packages.gz (sorry, I do not remember where I read this solution). 4) I succesfully run apt-get-update apt-get install cuda 5) Everything was insatlled in \\usr\\local\\cuda-7.5 6) I commented the line n 115 in file \\usr\\local\\cuda-7.5\\include\\host-config.h #if __GNUC__ &gt; 4 || (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &gt; 9) //#error -- unsupported GNU version! gcc versions later than 4.9 are not supported! #endif /* __GNUC__ &gt; 4 || (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &gt; 9) */ which seems to prevent CUDA from using gcc 5.4 After all these operations, I updated the .theanorc file, adding the cuda root [cuda] root = /usr/local/cuda-7.5 That's all :) PS: I do not know if it would work even with nvidia-cuda-toolkit!"
            ],
            [
                "In my system, this issue got resolved just by rebooting the system. Maybe you can give it a try."
            ],
            [
                "I fixed this problem, by adding the cuda path to the ~/.bashrc, as following, export LD_LIBRARY_PATH=/usr/lib64:$LD_LIBRARY_PATH export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH"
            ]
        ],
        "votes": [
            8.0000001,
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I'm following the autoencoder example @ https://blog.keras.io/building-autoencoders-in-keras.html but utilizing my own data. I get very low GPU utilization and almost no GPU memory utilization. I'm wondering if it's just having trouble fitting batches onto the GPU. My input data is 5k dimensions, and I'm encoding it to a hidden representation of 250 dimensions. When I vary the batch size on my autoencoder down to one, I get higher GPU usage but it's obviously quite slow (lots of shuffling of data). But when I go higher, I get almost no GPU usage and it's still pretty slow (and slower than CPU accelerated; lowest I've seen on GPU is 3.5k seconds versus 1.8k seconds on CPU). My GPU is a GTX 970, and everything appears to be working just fine with it. #input and hidden dimension parameters input_dimensions = Input(shape=(5000,)) encoded_dimensions = 250 #build autoencoder model encoded = Dense(encoded_dimensions, activation='relu')(input_dimensions) decoded = Dense(5000, activation='sigmoid')(encoded) autoencoder = Model(input=input_dimensions, output=decoded) #build encoder model encoder = Model(input=input_dimensions, output=encoded) #build decoder model encoded_input = Input(shape=(encoded_dimensions,)) decoder_layer = autoencoder.layers[-1] decoder = Model(input=encoded_input, output=decoder_layer(encoded_input)) autoencoder.compile(optimizer='adadelta', loss = 'mae') autoencoder.fit(data, data, nb_epoch = 10, batch_size=512, shuffle=True, validation_split=0.1) Is there a problem with my code that's causing it to run slow, or perhaps some strange configuration issue (my .theanorc, for what it's worth, is configured for GPU and theano reports utilizing the GPU), or is it a function of my data?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm installing Theano into an Ananconda environment and seem to have run into an install issue I don't understand. After I create the environment I run theano.test() and get the following error: ERROR:theano.sandbox.cuda:Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -m64 -Xcompiler -DCUDA_NDARRAY_CUH=m11b90075e2397c684f9dc0f7276eab8f,-D NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC -Xlinker -rpath,/home/brad/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.2-64/cuda_ndarray -I/home/brad/anaconda3/envs/theano1/lib/python3.5/site-packages/theano/sandbox/cuda -I/home/brad/anaconda3/envs/theano1/lib/python3.5/site-packages/numpy/core/include -I/home/brad/anaconda3/envs/theano1/include/python3.5m -o /home/brad/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.2-64/cuda_ndarray/cuda_ndarray.so mod.cu -L/home/brad/anaconda3/envs/theano1/lib -lpython3.5m -lcublas -lcudart') If I run the quoted nvcc command from the command line, I get: nvcc fatal : Don't know what to do with 'NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC' The CUDA install seems to be working. I can compile and run all the CUDA examples, run deviceQuery and do a bandwidth test successfully. I get the same error inside or outside of my Anaconda environment and with python 2.7 or 3.5. Theano.test(0) seems to be running fine except for the nvcc error.(still running) The error is triggered with just theano.test(), but it is also triggered if I also import Keras and run 'from keras.models import Sequential' I noticed there are a lot of unanswered Theano install questions, but hopefully this issue is not unique to me. I haven't had much luck googling a solution. Ubuntu 16.04, Anaconda Python 3.5.2 (or 2.7), CUDA 7.5.17, decorator 4.0.10 py35_0 ipykernel 4.3.1 py35_0 ipython 5.0.0 py35_0 ipython_genutils 0.1.0 py35_0 jupyter_client 4.3.0 py35_0 jupyter_core 4.1.0 py35_0 libgfortran 3.0.0 1 libsodium 1.0.10 0 mkl 11.3.3 0 nose 1.3.7 py35_1 numpy 1.10.4 py35_2 openssl 1.0.2h 1 path.py 8.2.1 py35_0 pexpect 4.0.1 py35_0 pickleshare 0.7.3 py35_0 pip 8.1.2 py35_0 prompt_toolkit 1.0.3 py35_0 ptyprocess 0.5.1 py35_0 pygments 2.1.3 py35_0 python 3.5.2 0 pyzmq 15.3.0 py35_0 readline 6.2 2 scipy 0.17.1 np110py35_1 setuptools 25.1.6 py35_0 simplegeneric 0.8.1 py35_1 six 1.10.0 py35_0 sqlite 3.13.0 0 theano 0.7.0 np110py35_0 tk 8.5.18 0 tornado 4.4.1 py35_0 traitlets 4.2.2 py35_0 wcwidth 0.1.7 py35_0 wheel 0.29.0 py35_0 xz 5.2.2 0 zeromq 4.1.4 0 zlib 1.2.8 3",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am using ubuntu 14.04 with theano 0.8.2 installed. When I ran import theano in my gpu_tesy.py, there came ~5300 lines of codes and: 5367 // vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:textwidth=79 : 5368 =============================== In file included from :0:0: /usr/include/stdc-predef.h:59:1: fatal error: cuda_runtime.h: No such file or directory #endif ^ compilation terminated. ['nvcc', '-shared', '-O3', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden', '-Xlinker', '-rpath,/home/theory/.theano/compiledir_Linux-3.13--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/cuda_ndarray', '-I/home/theory/test_theono/local/lib/python2.7/site-packages/theano/sandbox/cuda', '-I/home/theory/test_theono/local/lib/python2.7/site-packages/numpy/core/include', '-I/usr/include/python2.7', '-I/home/theory/test_theono/local/lib/python2.7/site-packages/theano/gof', '-o', '/home/theory/.theano/compiledir_Linux-3.13--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/cuda_ndarray/cuda_ndarray.so', 'mod.cu', '-L/usr/lib', '-lcublas', '-lpython2.7', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/theory/.theano/compiledir_Linux-3.13--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/cuda_ndarray -I/home/theory/test_theono/local/lib/python2.7/site-packages/theano/sandbox/cuda -I/home/theory/test_theono/local/lib/python2.7/site-packages/numpy/core/include -I/usr/include/python2.7 -I/home/theory/test_theono/local/lib/python2.7/site-packages/theano/gof -o /home/theory/.theano/compiledir_Linux-3.13--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/cuda_ndarray/cuda_ndarray.so mod.cu -L/usr/lib -lcublas -lpython2.7 -lcudart') which nvcc: /usr/local/cuda-7.0/bin/nvcc CUDA_HOME=/usr/local/cuda-7.0 LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/lib/lib:/opt/intel/mkl/lib/intel64::/usr/local/cuda-7.0/lib64 DYLD_LIBRARY_PATH=:/usr/local/cuda-7.0/lib Several versions of cuDNN and CUDA are installed in the same machine. I am not sure how I should them into the correct path though. Appreciate any help!",
        "answers": [
            [
                "I was stuck on this problem for a few days. Basically, I had multiple versions of python and I think multiple versions of nvcc installed. I could import Theano successfully using python 2, but when I tried to do the same with python 3, I would get the error you have posted. Eventually I solved it thanks to the first comment on this post: theano.test() fails with nvcc error - nvcc fatal : Don't know what to do with 'NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC'. You should add this to your .theanorc file: [nvcc] flags=-D_FORCE_INLINES You can do this in one line from the terminal in Ubuntu: echo -e \"\\n[nvcc]\\nflags=-D_FORCE_INLINES\\n\" &gt;&gt; ~/.theanorc After doing this I was getting other errors when trying to import Theano with python 3, which I fixed by upgrading to the latest version of Theano. Again from the ubuntu terminal: pip install --upgrade https://github.com/Theano/Theano/archive/master.zip"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I have a CNN model. The requests of using this model, for example to classify a picture, come 1 time a second. I would like to collect the requests as new unsuperised data, and keep training my model. My question is: How can I handle the training task and classify task effictively? I will explain why it becomes a problem: Every training step takes a long time, at least severy seconds, using GPU and not interruptable. So, if my classify tasks use GPU too, I cannot response the requests in time. I would like to make classify tasks using CPU, but looks like theano not support two diffrent config.device in one process. Multi-process is not acceptable, because my memory is limited and theano costs too much. Any help or advice would be apreciated.",
        "answers": [
            [
                "You could build two separate copies of the same CNN, one on the CPU and one on the GPU. I think this could be done under either the old GPU backend or the new one, but in different ways....some ideas: Under the old backend: Load Theano with device=cpu. Build your inference function and compile it. Then call theano.sandbox.cuda.use('gpu'), and build a new copy of your inference function and take gradients of that one to make any training functions. Now the inference function should execute on the CPU, and the training should happen on the GPU. (I've never done this on purpose but I had it happen to me on accident!) Under the new backend: As far as I know, you have to tell Theano about any GPUs right when importing, not later. In this case, you could use THEANO_FLAGS=\"contexts=dev0-&gt;cuda0\", which doesn't force using one device over another. Then build the inference version of your function like normal, and for the training version, again put all the shared variables on the GPU, and the input variables to any of your training functions should also be GPU variables (e.g. input_var_1.transfer('dev0')). When all your functions are compiled, look at the programs using theano.printing.debugprint(function) to see what's on GPU vs CPU. (When compiling the CPU functions, it might give a warning that it cannot infer the context, and as far as I've seen, that lands it on the CPU...not sure if this behavior is safe to depend on.) In either case, this will depend on your GPU-based functions do NOT RETURN ANYTHING TO THE CPU (make sure the output variables are GPU ones). This should allow the training function to run concurrently to your inference function, and later you grab what you need to the CPU. For example when you take a training step, just copy the new values over to your inference network parameters, of course. Let us hear what you come up with!"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am trying to train a model in Keras with the Theano backend and use my GPU. If I run with 100 images or 20K I get an error from Theano(look below) saying I do not have enough memory but I have 6GB on my GPU. I have used the THEANO_FLAG from Keras docs \"THEANO_FLAGS=device=gpu,floatX=float32 python my_keras_script.py\" the problem I used the this one from stackoverflow (echo -e \"\\n[global]\\nfloatX=float32\\ndevice=gpu0\\n[lib]\\ncnmem=0\\n\" &gt;&gt; ~/.theanorc ) to set the cnmem variable so if you use the flags from Keras it will use what cnmem you set with the stack overflow one. I have set cnmem to 0.83 (the highest it goes without erroring out right away) and to 0 and nothing has the 822 MB's that it requires but I have 6GB of video memory. I am sure I am doing something simple wrong but there isn't any information I can find on it. I am on Ubuntu 14.04 and I have CUDA installed. And I just did the Keras MNIST example using \"THEANO_FLAGS=device=gpu,floatX=float32 python mnist_transfer_cnn.py \" MemoryError: Error allocating 822083584 bytes of device memory (out of memory). Apply node that caused the error: GpuElemwise{add,no_inplace} (GpuDnnConv{algo='small', inplace=True}.0, GpuReshape{4}.0) Toposort index: 375 Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (True, False, True, True))] Inputs shapes: [(64, 64, 224, 224), (1, 64, 1, 1)] Inputs strides: [(3211264, 50176, 224, 1), (0, 1, 0, 0)] Inputs values: ['not shown', 'not shown'] Outputs clients: [[GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}(CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuElemwise{add,no_inplace}.0), GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))}}[(0, 1)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuDnnPoolGrad{mode='max'}.0, GpuElemwise{add,no_inplace}.0)]] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
        "answers": [],
        "votes": []
    },
    {
        "question": "In python, after importing theano, I get the following: In [1]: import theano WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: Unable to get the number of gpus available: unknown error) I'm running this on ubuntu 14.04 and I have an old gpu: GeForce GTX280 And my nvidia driver: $ nvidia-smi Wed Jul 13 21:25:58 2016 +------------------------------------------------------+ | NVIDIA-SMI 340.96 Driver Version: 340.96 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 280 Off | 0000:02:00.0 N/A | N/A | | 40% 65C P0 N/A / N/A | 638MiB / 1023MiB | N/A Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Compute processes: GPU Memory | | GPU PID Process name Usage | |=============================================================================| | 0 Not Supported | +-----------------------------------------------------------------------------+ I'm not sure why it's saying it's 'Not Supported' but it seems as though that might not be an issue as said here Also, the CUDA version: $ nvcc -V nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2014 NVIDIA Corporation Built on Thu_Jul_17_21:41:27_CDT_2014 Cuda compilation tools, release 6.5, V6.5.12 Any help I can get would be awesome. I've been at this all day...",
        "answers": [
            [
                "I feel your pain. I spent a few days ploughing through all the CUDA related errors. Firstly, update to a more recent driver. eg, 361. (CLEAN INSTALL IT!) Then completely wipe cuda and cudnn from your harddrive with sudo rm -rf /usr/local/cuda or wherever else you installed it, then install cuda 7.5 (seriously, this specific version) and cuDNN v4 (again, this specific version) You can run the following commands to settle CUDA. wget http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.18_linux.run bash cuda_7.5.18_linux.run --override Follow the instructions, say NO when they ask you to install the 350 driver. And you should be set. For cudnn, there's no direct link to wget, so you have to get the installer from https://developer.nvidia.com/cudnn and run the following commands: tar xvzf cudnn-7.0-linux-x64-v4.0-prod.tgz sudo cp cuda/include/cudnn.h /usr/local/cuda-7.5/include sudo cp -r cuda/lib64/. /usr/local/cuda-7.5/lib64 echo -e 'export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda-7.5/lib64\"\\nexport CUDA_HOME=/usr/local/cuda-7.5' &gt;&gt; ~/.bash_profile source ~/.bash_profile Now to handle Theano on GPU: nano ~/.theanorc add these lines: [global] floatX = float32 device = gpu0 If you get an nvcc error, make it so instead: [global] floatX = float32 device = gpu0 [nvcc] flags=-D_FORCE_INLINES"
            ],
            [
                "I had the same issue and was able to solve my issue by doing two things: Install gcc-5 and linking/usr/bin/gcc to /usr/bin/gcc-5 as well as /usr/bin/g++ to/usr/bin/g++-5 (PS: I am using cuda 8) Adding this flag flags=-D_FORCE_INLINES to the file ~/.theanorc under nvcc since apparently a bug in glibc 2.23 causes this issue"
            ]
        ],
        "votes": [
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "I had Theano (with Keras and nolearn) properly installed and running on my GPU Windows 10 system. After adding some additional installations (Kaldi/ PDNN), I keep getting these two warnings when importing theano and, as mentioned below, I am having severe degradation in performance. **WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string. WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable)** I have read some post about g++ installation but I am pretty sure that it is some overridden configuration issue. Has anyone ran into this problem? If so, how can I fix it?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have an Intel Graphics Card (Intel(R) HD Graphics 520, also am on Windows 10) and as far as I know I can't use CUDA unless I have a NVIDIA GPU. The purpose is to use Theano's GPU capabilities (for deep learning which is why I need GPU power). Is there a workaround that somehow allows me to use CUDA with my current GPU? If not is there another API that I can use with my current GPU for Theano (in Python 2.7)? Or as a last option, using another language entirely, such as Java that has an API that allows for GPU use that I can use? Figuring this out would be very helpful, because even though I just started with deep learning, I will probably get to the point where I need GPU parallel processing power to get results without waiting days at a minimum.",
        "answers": [
            [
                "In order: No. You must have a supported NVIDIA GPU to use CUDA. As pointed out in comments, there is an alternative backend for Theano which uses OpenCL and which might work on your GPU Intel support OpenCL on your GPU, so any language bindings for the OpenCL APIs, or libraries with in-built OpenCL would be a possible solution in this case [This answer has been assembled from comments and added as a community wiki entry in order to get it off the unanswered queue for the CUDA tag]."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am working on a reinforcement learning task and decided to use keras NN model for Q value approximation. The approach is common: after each action the reward is stored in a memory replay array, then I take random sample from it and fit the model with new data state-action =&gt; reward+predicted_Q(more details here). In order to do the training the Q value has to be predicted for each item in the training set. The script is running very slow so I started investigating. Profiling shows that 56,87% of cumulative time is taken by _predict_loop method: And it looks strange, cause prediction is just a one-way propagation. Just a one-time multiplication of set of numbers. The model I am using is very simple: 8 inputs, 5 nodes on hidden layer, 1 output. I have installed and configured CUDA, run few example tests and it shows that GPU is used, also I can see huge load of GPU. When I run my code - there is a message: \"Using gpu device 0: GeForce GT 730\" but I can see that GPU load is really low(about 10%). Is it normal for predict function to take so much time? Is there a way to use GPU for this computation?",
        "answers": [
            [
                "It seems the size of your NN is much too small to fully utilize the GPU. Typically GPU is faster than multi-core CPU only when the input/hidden/output layer size is larger than 200~500 (depending on the implementation code). However the size of your NN is only 8/5/1, which means most of the time is spent on GPU overhead such CUDA kernel launching, PCIe data transfer, etc. In this case, the number of calls is the main factor that determines the training time. To speed up, you probably need to train your model on CPU, and with a programming language such as C/C++ that has much lower overhead."
            ],
            [
                "It's well know issue. That's why we have CNMeM. This is a library, developed by NVIDIA, which helps deep learning frameworks managing CUDA memory. CNMeM is already integrated in Theano so you don\u2019t have to install anything. To enable CNMeM in Theano, you have to add to .theanorc the lines: [lib] cnmem = 0.8 The cnmem value specifies the amount of GPU memory allocated for Theano. To quote the documentation: 0: not enabled. 0 &lt; N &lt;= 1: use this fraction of the total GPU memory (clipped to .95 for driver memory). [Note: This should be a float value, for instance 0.25 or 1.0] . &gt;1: use this number in megabytes (MB) of memory. For more information, instrucion about .theanorc and CuDNN (another usefull lib) please visit: http://ankivil.com/making-theano-faster-with-cudnn-and-cnmem-on-windows-10/"
            ],
            [
                "Your model is really small so you could also run the inference on the CPU and try OpenVINO for better performance. OpenVINO is optimized for Intel hardware but it should work with any processor. It optimizes your model by converting to Intermediate Representation (IR), performing graph pruning and fusing some operations into others while preserving accuracy. Here are for various models and CPUs. It's rather straightforward to convert your Keras model to OpenVINO. The full tutorial on how to do it can be found here. Some snippets below. Install OpenVINO The easiest way to do it is using PIP. Alternatively, you can use this tool to find the best way in your case. pip install openvino-dev[tensorflow2] Save your model as SavedModel OpenVINO is not able to convert HDF5 model, so you have to save it as SavedModel first. import tensorflow as tf from custom_layer import CustomLayer model = tf.keras.models.load_model('model.h5', custom_objects={'CustomLayer': CustomLayer}) tf.saved_model.save(model, 'model') Use Model Optimizer to convert SavedModel model The Model Optimizer is a command-line tool that comes from OpenVINO Development Package. It converts the Tensorflow model to IR, which is a default format for OpenVINO. You can also try the precision of FP16, which should give you better performance without a significant accuracy drop (just change data_type). Run in the command line: mo --saved_model_dir \"model\" --input_shape \"[1, 3, 224, 224]\" --data_type FP32 --output_dir \"model_ir\" Run the inference The converted model can be loaded by the runtime and compiled for a specific device e.g. CPU or GPU (integrated into your CPU like Intel HD Graphics). If you don't know what is the best choice for you, just use AUTO. # Load the network ie = Core() model_ir = ie.read_model(model=\"model_ir/model.xml\") compiled_model_ir = ie.compile_model(model=model_ir, device_name=\"CPU\") # Get output layer output_layer_ir = compiled_model_ir.output(0) # Run inference on the input image result = compiled_model_ir([input_image])[output_layer_ir] Disclaimer: I work on OpenVINO."
            ]
        ],
        "votes": [
            9.0000001,
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "I have Theano working fine on Windows 10 without GPU support. I have a new GTX 1080 and want to get Theano running on it. This requires the latest CUDA 8.0 Toolkit from NVIDIA. I have installed everything according to http://deeplearning.net/software/theano/install_windows.html allowing for some minor software version differences. Whenever I try to simply 'import theano' with GPU support enabled via .theanorc.txt I get compilation errors. Cuda 8.0 can work fine with Theano-master according to this thread: https://github.com/Theano/Theano/issues/4558 Running WinPython 64bit 2.7.10.3, scipy 0.161, numpy 1.9.3, Microsoft Visual Studio 12.0 and theano-master from June 16. Latest attempt results in this list of errors: =============================== C:/Users/CHARLE~1/AppData/Local/Temp/tmpxft_00001148_00000000-10_mod.cpp1.ii(1): error: this declaration has no storage class or type specifier C:/Users/CHARLE~1/AppData/Local/Temp/tmpxft_00001148_00000000-10_mod.cpp1.ii(1): error: identifier \"R\" is undefined C:/Users/CHARLE~1/AppData/Local/Temp/tmpxft_00001148_00000000-10_mod.cpp1.ii(1): error: expected a \";\" At end of source: warning: parsing restarts here after previous syntax error 3 errors detected in the compilation of \"C:/Users/CHARLE~1/AppData/Local/Temp/tmpxft_00001148_00000000-10_mod.cpp1.ii\". mod.cu ['nvcc', '-shared', '-O3', '-arch=sm_61', '--compiler-bindir', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 12.0\\\\VC\\\\bin\\\\lc.exe', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IC:\\\\Users\\\\Charles Gillespie\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.10-64\\\\cuda_ndarray', '-IC:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v8.0\\\\include', '-IC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include', '-IC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\include', '-Ic:\\\\scisoft\\\\winpython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\theano\\\\theano\\\\gof', '-Ic:\\\\scisoft\\\\winpython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\theano\\\\theano\\\\sandbox\\\\cuda', '-o', 'C:\\\\Users\\\\Charles Gillespie\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.10-64\\\\tmp6qa5py\\\\4894639462a290346189bb38dab7bb7e.pyd', 'mod.cu', '-LC:\\\\Users\\\\Charles Gillespie\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.10-64\\\\cuda_ndarray', '-LC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\libs', '-LC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lpython27'] Traceback (most recent call last): File \"test-theano.py\", line 3, in &lt;module&gt; import theano File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\__init__.py\", line 118, in &lt;module&gt; theano.sandbox.cuda.tests.test_driver.test_nvidia_driver1() File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\sandbox\\cuda\\tests\\test_driver.py\", line 32, in test_nvidia_driver1 profile=False) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\compile\\function.py\", line 322, in function output_keys=output_keys) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\compile\\pfunc.py\", line 480, in pfunc output_keys=output_keys) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\compile\\function_module.py\", line 1784, in orig_function defaults) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\compile\\function_module.py\", line 1648, in create input_storage=input_storage_lists, storage_map=storage_map) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\link.py\", line 693, in make_thunk storage_map=storage_map)[:3] File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\vm.py\", line 1034, in make_all no_recycling)) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\sandbox\\cuda\\__init__.py\", line 256, in make_thunk compute_map, no_recycling) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\op.py\", line 969, in make_thunk no_recycling) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\op.py\", line 872, in make_c_thunk output_storage=node_output_storage) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\cc.py\", line 1200, in make_thunk keep_lock=keep_lock) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\cc.py\", line 1143, in __compile__ keep_lock=keep_lock) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\cc.py\", line 1591, in cthunk_factory key=key, lnk=self, keep_lock=keep_lock) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\cmodule.py\", line 1145, in module_from_key module = lnk.compile_cmodule(location) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\gof\\cc.py\", line 1502, in compile_cmodule preargs=preargs) File \"c:\\scisoft\\winpython-64bit-2.7.10.3\\python-2.7.10.amd64\\theano\\theano\\sandbox\\cuda\\nvcc_compiler.py\", line 403, in compile_str 'for cmd', ' '.join(cmd)) Exception: ('The following error happened while compiling the node', GpuCAReduce{add}{1}(&lt;CudaNdarrayType(float32, vector)&gt;), '\\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -arch=sm_61 --compiler-bindir C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 12.0\\\\VC\\\\bin\\\\lc.exe -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\\\Users\\\\Charles Gillespie\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.10-64\\\\cuda_ndarray -IC:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v8.0\\\\include -IC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -IC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\include -Ic:\\\\scisoft\\\\winpython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\theano\\\\theano\\\\gof -Ic:\\\\scisoft\\\\winpython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\theano\\\\theano\\\\sandbox\\\\cuda -o C:\\\\Users\\\\Charles Gillespie\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.10-64\\\\tmp6qa5py\\\\4894639462a290346189bb38dab7bb7e.pyd mod.cu -LC:\\\\Users\\\\Charles Gillespie\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.10-64\\\\cuda_ndarray -LC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\libs -LC:\\\\scisoft\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64 -lcudart -lcublas -lcuda_ndarray -lpython27', '[GpuCAReduce{add}{1}(&lt;CudaNdarrayType(float32, vector)&gt;)]') Please help!",
        "answers": [
            [
                "CUDA 8 RC and Visual Studio 2015 Update 2 (VC12) and greater do not blend. You'll have to wait until NVidia gets it together and releases an update OR uninstall VC12 and install VC11. You should be good to go."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "my question is the next one: I use theano on ubuntu 14 and configure theano flags by editing .theanorc. To use cuda, I only have to add: [cuda] root=/usr/local/cudaVersion/ And everything goes, theano is capable of finding nvcc, the libs and everything, I do not have to add cudaRoot to the $PATH or the library directory to $LD_LIBRARY_PATH. In ubuntu 12 this does not happens. If I create the .theanorc in the same way, theano is only capable of finding nvcc but not the library, and I have to add /usr/local/cudaVersion/lib64 to the LD_LIBRARY_PATH enviroment variable. The problem is that I do not like to use this enviroment variable. Does anyone knows why in ubuntu 14 only editing .theanorc is enough and in ubuntu 12 is not?",
        "answers": [
            [
                "I will try to help you the best i can. I use Theano and CUDA on Linux. First, are you sudo in both OS's ? Did you install theano and python environment and cuda as sudo? Because, i suppose that, if the setup of CUDA wasnt done on global library path, then it wont be automatically detected. Also, according to the official website of theano: http://deeplearning.net/software/theano/install_ubuntu.html#install-ubuntu Quoting : For Ubuntu 11.10 through 14.04: sudo apt-get install python-numpy python-scipy python-dev python-pip python-nose g++ libopenblas-dev git sudo pip install Theano On 14.04, this will install Python 2 by default. If you want to use Python 3: sudo apt-get install python3-numpy python3-scipy python3-dev python3-pip python3-nose g++ libopenblas-dev git sudo pip install Theano For Ubuntu 11.04: sudo apt-get install python-numpy python-scipy python-dev python-pip python-nose g++ git libatlas3gf-base libatlas-dev sudo pip install Theano So did you follow these instructions? They might be the cause. Also, There is additional instructions to setting up cuda for theano, on the same page: Ubuntu 11.10/12.04 (probably work on 11.04 too): sudo apt-add-repository ppa:ubuntu-x-swat/x-updates sudo apt-get update sudo apt-get install nvidia-current Ubuntu 14.04: sudo apt-get install nvidia-current sudo apt-get install nvidia-cuda-toolkit The questions below might also help if the above didnt solve it. As described on the references, did you edit .bashrc properly? How did you install CUDA on both OS's? Did you try to uninstall CUDA,Theano and python environments and install them again? Its probably worth to edit the question with more info if these didnt help! Extra references: https://groups.google.com/forum/#!topic/theano-users/RRqYTf42YIo http://dhaneshr.net/2015/09/10/setting-up-cudnn-and-theano-on-ubuntu-14-04-and-15-10/"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "In my .theanorc file I have set the parameter... [global] floatX = float32 However when I run keras with the theano backend and make calls to model.predict the numpy datatype of the returned array is always of type FP64 not FP32. I am not sure if this is a problem or if keras / theano makes a conversion to FP32 before executing on the GPU. Is there a way to check. I would like it if theano could post and error or warning if I try to use FP64 on the GPU.",
        "answers": [
            [
                "To check the type of floatX you can simply run import theano print theano.config.floatX If that code prints 'float32' then theano will print out a warning when you try to use float64 as input for gpu computations. This can be suppressed though if you add the keyword argument allow_downcast, so make sure that you don't have this keyword in theano.function when you are compiling the graph."
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I reinstall new ubuntu 14:04 on my machine then I started to receive this error while in old installation the program works perfect without any annoying errors. Any help please. BTW I found question here cant load mnist dataset in keras but it looks different error and mine was working without any problem. Using Theano backend. Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005) Downloading data from https://s3.amazonaws.com/img-datasets/mnist.pkl.gz Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"mnist_cnnFORTESTING.py\", line 9, in &lt;module&gt; execfile(\"file.py\") File \"file.py\", line 28, in &lt;module&gt; (X_train, y_train), (X_test, y_test) = mnist.load_data() File \"/home/sal/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/keras/datasets/mnist.py\", line 9, in load_data path = get_file(path, origin=\"https://s3.amazonaws.com/img-datasets/mnist.pkl.gz\") File \"/home/sal/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/keras/utils/data_utils.py\", line 70, in get_file raise Exception(error_msg.format(origin, e.errno, e.reason)) Exception: URL fetch failure on https://s3.amazonaws.com/img-datasets/mnist.pkl.gz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)",
        "answers": [
            [
                "WOW I found the answer, just use sudo mkdir -p /etc/pki/tls sudo ln -s /etc/ssl/certs /etc/pki/tls/certs I found the answer in the following link by the clue of @ Dilettant thanks https://support.enthought.com/hc/en-us/articles/204646264-Linux-non-RHEL-Python-code-fails-to-connect-to-https-with-certificate-errors"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I use ubuntu 14.04 and cuda 7.5. I get cuda version information using $ nvcc --version : nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2015 NVIDIA Corporation Built on Tue_Aug_11_14:27:32_CDT_2015 Cuda compilation tools, release 7.5, V7.5.17 $PATH and $LD_LIBRARY_PATH are below : $ echo $PATH /usr/local/cuda-7.5/bin:/usr/local/cuda-7.5/bin/:/opt/ros/indigo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games $ echo $LD_LIBRARY_PATH /usr/local/cuda-7.5/lib64 I install theano. I use it with cpu but not gpu. This guide says that Testing Theano with GPU\u00b6 To see if your GPU is being used, cut and paste the following program into a file and run it. from theano import function, config, shared, sandbox import &gt; theano.tensor as T import numpy import time &gt; &gt; vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 &gt; &gt; rng = numpy.random.RandomState(22) x = &gt; shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], &gt; T.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in &gt; range(iters): &gt; r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if &gt; numpy.any([isinstance(x.op, T.Elemwise) for x in &gt; f.maker.fgraph.toposort()]): &gt; print('Used the cpu') else: &gt; print('Used the gpu') The program just computes the exp() of a bunch of random numbers. Note that we use the shared function to make &gt; sure that the input x is stored on the graphics device. If I run this program (in check1.py) with device=cpu, my computer takes a little over 3 seconds, whereas on the GPU it takes just over 0.64 seconds. The GPU will not always produce the exact same floating-point numbers as the CPU. As a benchmark, a loop that calls numpy.exp(x.get_value()) takes about 46 seconds. $ THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python check1.py [Elemwise{exp,no_inplace}()] Looping 1000 times took 3.06635117531 seconds Result is [ 1.23178029 1.61879337 1.52278066 ..., 2.20771813 2.29967761 1.62323284] Used the cpu $ THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python check1.py Using gpu device 0: GeForce GTX 580 [GpuElemwise{exp,no_inplace}(), HostFromGpu(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.638810873032 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the gpu Note that GPU operations in Theano require for now floatX to be float32 (see also below). I run gpu version command without sudo, it throws permission denied error : /theano/gof/cmodule.py\", line 741, in refresh files = os.listdir(root) OSError: [Errno 13] Permission denied: '/home/user/.theano/compiledir_Linux-3.16--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/tmp077r7U' If I use it with sudo, the compiler cannot find nvcc path. ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again. How can I fix this error?",
        "answers": [
            [
                "Try running chown -R user /home/user/.theano chmod -R 775 /home/user/.theano this will change the permissions of the folder that your python script can't access. The first one will make the folder belong to your user and the second one will change the permissions to be readable, writable and executable by the user."
            ],
            [
                "Regarding this error only: You can check where your NVCC is installed , default path is '/usr/local/cuda/bin', if you could see it there then do as below: $ export PATH=\"/usr/local/cuda/bin:$PATH\" $ source .bashrc This worked for me and now I can use NVCC and it is no longer missing."
            ]
        ],
        "votes": [
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "I use the following script to test if GPU is working: #!/usr/bin/env python from theano import function, config, shared, sandbox import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print f.maker.fgraph.toposort() t0 = time.time() for i in xrange(iters): r = f() t1 = time.time() print 'Looping %d times took' % iters, t1 - t0, 'seconds' print 'Result is', r if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') When I run it, I get: http://pastebin.com/wM9jaGMF The interesting part is at the end: ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/moose/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.11+-64/cuda_ndarray -I/home/moose/.local/lib/python2.7/site-packages/theano/sandbox/cuda -I/usr/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -I/home/moose/.local/lib/python2.7/site-packages/theano/gof -o /home/moose/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.11+-64/cuda_ndarray/cuda_ndarray.so mod.cu -L/usr/lib -lcublas -lpython2.7 -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) My system I use Ubuntu 16.04. I've installed CUDA through the standard repos (V7.5.17). nvcc --version works. I've installed Theano via pip I have CuDNN 4 (works with TensorFlow) I set CUDA_ROOT=/usr/bin/ and LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/ (I'm not sure if that is correct) My ~/.theanorc is [global] exception_verbosity=high device=gpu floatX=float32 [cuda] root=/usr/bin/ Paths I think the installation from the standard repos might make things different from a manual installation. Here are some paths which might uncover some problems: /usr/bin/nvcc /usr/lib/x86_64-linux-gnu/libcuda.so /usr/lib/x86_64-linux-gnu/libcudart.so /usr/lib/nvidia-cuda-toolkit /usr/include/cudnn.h Question How can I make it work?",
        "answers": [
            [
                "I'm not exactly sure what solved the issue, but one or both of the following (source) sudo apt-get install python-numpy python-scipy python-dev python-pip python-nose g++ libopenblas-dev libblas-dev git echo -e \"\\n[nvcc]\\nflags=-D_FORCE_INLINES\\n\" &gt;&gt; ~/.theanorc"
            ],
            [
                "I am writing a more general answer here in case others find themselves in a similar situation. First, see that theano dependencies are installed, as explained here. you should install nvidia driver as described here, use sudo ubuntu-drivers devices to determine which driver is recommended and install it with sudo apt-get install nvidia-xxx (xxx = 375 at this time). Then see that the nvidia driver is being used by opening \"additional drivers\" window (from terminal software-properties-gtk --open-tab=4). Setup a ~/.theanorc text file as follows: [global] exception_verbosity=high device=gpu floatX=float32 [cuda] root=/usr/bin/ [nvcc] flags=-D_FORCE_INLINES [lib] cnmem = 1 [lib] section is not necessary but on my laptop performance was about 2 times faster when adding it to .theanorc."
            ]
        ],
        "votes": [
            4.0000001,
            1e-07
        ]
    },
    {
        "question": "I have installed CUDA Toolkit V 7.0 and its graphics driver version is 347.62. In my theano code import os os.environ['THEANO FLAGS']= 'mode=FAST RUN,device= gpu, lib.cnmem = 1,floatX=float32' I used this. Its showing the following error.\\n You forced the use of gpu device gpu, but CUDA initialization failed with error: Unable to get the number of gpus available: CUDA driver version is insufficient for CUDA runtime version' What should I do?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have the following code based on Theano example: from theano import function, config, shared, sandbox import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') Now when I test the code with two modes: GPU mode, I get this: $ THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python gpu.py Using gpu device 0: Tesla C2075 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN not available) [GpuElemwise{exp,no_inplace}(&lt;CudaNdarrayType(float32, vector)&gt;), HostFromGpu(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.475526 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the gpu CPU mode, I get this: $ THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python gpu.py [Elemwise{exp,no_inplace}(&lt;TensorType(float32, vector)&gt;)] Looping 1000 times took 5.221368 seconds Result is [ 1.23178029 1.61879337 1.52278066 ..., 2.20771813 2.29967761 1.62323284] Used the cpu Notice two things, GPU is indeed faster than CPU (0.47sec vs 5 sec). But at the same time at GPU I get the cuDNN not available message. My question is this. What's the effect of the absence of cuDNN? Is it harmful?",
        "answers": [
            [
                "If you didn't use cuDNN , you code not use all power of GPU. The benefit of GPU before CPU ,is that GPU have a lot of real cores(from 700 till 4000), ordinary CPU from 1 to 8. But GPU cores can make only primitive calculation. if you are not use cuDNN ,other standard libraries makes calculation, or probably (i don't know exactly only use GPU memory and use simple CPU for calculation). CuDNN is a GPU-accelerated library of primitives. It's means if you start to make Deep Neural Network application it will be not so fast ,as it can be. Please read CuDNN Note: because i wrote GPU cores can make only primitive calculation, if you choose to use GPU, but use function which is not supported of GPU, theano will switch application temporary for such function for CPU.(it's take time to make it)"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "Setup: Using a Amazon Linux system with a Nvidia GPU I'm using Keras 1.0.1 Running Theano v0.8.2 backend Using CUDA and CuDNN THEANO_FLAGS=\"device=gpu,floatX=float32,lib.cnmem=1\" Everything works fine, but I run out of video memory on large models when I increase the batch size to speed up training. I figure moving to a 4 GPU system would in theory either improve total memory available or allow smaller batches to build faster, but observing the the nvidia stats, I can see only one GPU is used by default: +------------------------------------------------------+ | NVIDIA-SMI 361.42 Driver Version: 361.42 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GRID K520 Off | 0000:00:03.0 Off | N/A | | N/A 44C P0 45W / 125W | 3954MiB / 4095MiB | 94% Default | +-------------------------------+----------------------+----------------------+ | 1 GRID K520 Off | 0000:00:04.0 Off | N/A | | N/A 28C P8 17W / 125W | 11MiB / 4095MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 GRID K520 Off | 0000:00:05.0 Off | N/A | | N/A 32C P8 17W / 125W | 11MiB / 4095MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 GRID K520 Off | 0000:00:06.0 Off | N/A | | N/A 29C P8 17W / 125W | 11MiB / 4095MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 9862 C python34 3941MiB | I know with raw Theano you can use manually multiple GPU's explicitly. Does Keras support use of multiple GPU's? If so, does it abstract it or do you need to map the GPU's to devices as in Theano and explicitly marshall computations to specific GPU's?",
        "answers": [
            [
                "Multi-GPU training is experimental (\"The code is rather new and is still considered experimental at this point. It has been tested and seems to perform correctly in all cases observed, but make sure to double-check your results before publishing a paper or anything of the sort.\") and hasn't been integrated into Keras yet. However, you can use multiple GPUs with Keras with the Tensorflow backend: https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html#multi-gpu-and-distributed-training."
            ]
        ],
        "votes": [
            4.0000001
        ]
    },
    {
        "question": "OS: OSX 10.11.4 GPU: GeForce GT 750M, CUDA7.5 Language: Python Anaconda 2.7 I have followed theano's instructions to setup CUDA on my Mac: set PATH: export PATH=/Developer/NVIDIA/CUDA-7.5/bin:$PATH set LD_LIBRARY_PATH: export LD_LIBRARY_PATH=/Developer/NVIDIA/CUDA-7.5/lib:$LD_LIBRARY_PATH created a .theanorc file and add CUDA_ROOT=/Developer/NVIDIA/CUDA-7.5 in [cuda] section I copied the code from theano website and pasted it into test.py file: from theano import function, config, shared, sandbox import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in range(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') But when I run this line: THEANO_FLAGS='floatX=float32,device=gpu0,nvcc.fastmath=True' python test.py I got this error: nvcc fatal: The version ('70300') of the host compiler ('Apple clang') is not supported and a warning looks like this: WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available (error: cuda unavailable) Is it something because of my Xcode version(it is Version 7.3)? How to solve this problem?",
        "answers": [
            [
                "I fixed this error: \"nvcc fatal: The version ('70300')..\" installing the last version of the CUDA SDK 7.5.27, for OSX 10.11.4"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I'm trying to implement a simple sample to show how to calculate two theano.tensor.dot in two different GPUs. Where the two dot shares the same A and different B. theano.tensor.dot(A,B0); theano.tensor.dot(A,B1) I'm willing to store the B0 and B1 in different GPUs. And A was originally stored in one GPU, and then I made a copy to another GPU with explicit transfer function. Finally, I dot separately in the two GPUs. My implementation is as below: import numpy import theano va0 = theano.shared(numpy.random.random((1024, 1024)).astype('float32'), target='dev0') va1 = va0.transfer('dev1') vb0 = theano.shared(numpy.random.random((1024, 512)).astype('float32'), target='dev0') vb1 = theano.shared(numpy.random.random((1024, 2048)).astype('float32'), target='dev1') vc0 = theano.tensor.dot(va0,vb0) vc1 = theano.tensor.dot(va1,vb1) f = theano.function([], [vc1,vc0]) print f() While I was looking into the nvprof result, I found that the two dot still run in the same GPU. And the va0.tranfer('dev1') doesn't work. Actually it copied vb1 into dev0 instead, and both the dots computed in dev0. I tried sever combinations of Theano Flags but doesn't work. Any one can help? nvprof: two dot in same gpu",
        "answers": [
            [
                "The Theano Flag below solves the issue. export THEANO_FLAGS=\"contexts=dev0-&gt;cuda0;dev1-&gt;cuda1,optimizer_verbose=True,optimizer_excluding=local_cut_gpua_host_gpua\" optimizer_verbose provides the optimization done by theano function. I notice one line like below: local_cut_gpu_transfers HostFromGpu(gpuarray).0 HostFromGpu(gpuarray).0 where local_cut_gpu_transfers is the reason HostFromGpu(gpuarray).0 is original node the last segment is what the original node be replaced to. Then, I searched the keyword \"local_cut_gpu_transfer\" in source code of Theano, until I found: optdb['canonicalize'].register('local_cut_gpua_host_gpua', local_cut_gpu_transfers, 'fast_compile', 'fast_run', 'gpuarray') Then I add 'local_cut_gpua_host_gpua'to optimizer_excluding in Theano Flag. Hopes that Theano will provide a detailed map of the reason and the optimizer Theano Flag?"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I could see element wise matrix multiplication using numpy can be done with * operator. print np.mat(np.ones((10,10)))*np.mat(np.ones((10,10))) But couldnt get it working under theano. The code I tried is x = T.dmatrix('x') y = T.dmatrix('y') z = x * y f1 = theano.function([x, y], z) print f1(np.mat(np.ones((10,10))),np.mat(np.ones((10,10))))",
        "answers": [
            [
                "If I try the following (which is basically your code): import theano import theano.tensor as T import numpy as np x = T.dmatrix('x') y = T.dmatrix('y') z = x * y f1 = theano.function([x, y], z) print f1(np.mat(np.ones((10,10))),np.mat(np.ones((10,10)))) I get the following: [[ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]] So, it works for me."
            ]
        ],
        "votes": [
            4.0000001
        ]
    },
    {
        "question": "I use theano on a remote server that I first ssh into (I don't have root on that system). This works fine, however, if I start a screen, I get an error when trying to import theano. Behavior when not using screen: &gt;&gt;&gt; import theano Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 4007) Behavior when using screen: &gt;&gt;&gt; import theano ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.5: cannot open shared object file: No such file or directory Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; File \"/home/2012/enewel3/.local/lib/python2.7/site-packages/theano/__init__.py\", line 103, in &lt;module&gt; import theano.sandbox.cuda File \"/home/2012/enewel3/.local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py\", line 697, in &lt;module&gt; use(device=config.device, force=config.force_device, test_driver=False) File \"/home/2012/enewel3/.local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py\", line 496, in use device, cuda_initialization_error_message)) EnvironmentError: You forced the use of gpu device gpu, but CUDA initialization failed with error: cuda unavailable How should I use theano within a screen session?",
        "answers": [
            [
                "The problem was due to the fact that, although screen inherits most environment variables, it adds, removes, and alters some of them. In my case, it was changing the value of LD_LIBRARY_PATH. Upon entering a screen, manually setting the environment variable to it's proper value fixed the problem. For me, that looks like this: export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/pkgs/gurobi502/linux64/lib Adding that line to my .bashrc makes sure that screens always get the right value. Note, adding it to .bash_profile won't work, because .bash_profile is only run at login, while .bashrc is run for every new shell."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "As soon as I try to import theano library I get this error: &gt;&gt;&gt; import theano ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device gpu failed: initCnmem: cnmemInit call failed! Reason=CNMEM_STATUS_OUT_OF_MEMORY. numdev=1 Content of my .theanorc: [global] floatX = float32 device = gpu optimizer = fast_run [lib] cnmem = 0.9 [nvcc] fastmath = True [blas] ldflags = -llapack -lblas [cmodule] mac_framework_link=True I've also tried to run python environment with theano flags, but still the same problem: $ THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32,lib.cnmem=0.9 python3 They're also mentioning similar issue on Theano Github page: Initialisation of device gpu failed!, however they're talking about float vs int value for CNMeM, which I supposed I have correctly setted to 0.9 (for no special reason, I've actually tried 1.0, 0.95, 0.5 and some other values, with same results). My setup: Mac OS X 10.11.4 Xcode 7.2 (I had to downgrade it from 7.3) Cuda 7.5.19 Python 3.5.1 Solution: First of all I didn't realize that value of CNMeM is % of total memory and because I was using the gpu with two monitors I actually didn't have much memory to spare, anyway I've tried 0.1 and it works. The second problem with cuDNN disabled I solved by adding this line to the theano config: optimizer_including = cudnn See this page for more details: sandbox/cuda/dnn",
        "answers": [
            [
                "First of all I didn't realize that value of CNMeM is % of total memory and because I was using the gpu with two monitors I actually didn't have much memory to spare, anyway I've tried 0.1 and it works. The second problem with cuDNN disabled I solved by adding this line to the theano config: optimizer_including = cudnn See this page for more details: sandbox/cuda/dnn"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "Uisng compile, Theano generates C++ code along with Cuda code and compiled lib. Can we reuse those ones after ?",
        "answers": [
            [
                "You could load them as a python module from the cache or just copy the code somewhere else and modify it to have a friendlier name. Also there is a project to have Theano produce a some C code for a library that I know works for some situations but has never really been finished. If you are interested in that I would ask on the theano-dev mailing list."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am on windows machine with python 2.7 ( 32 bit ) and pycuda with cuda 7.5 whl installed . I get error while running a sample program to test pycuda. Traceback (most recent call last): File \"C:\\Users\\newbie\\Desktop\\roo.py\", line 82, in &lt;module&gt; \"\"\") File \"C:\\Python27\\lib\\site-packages\\pycuda\\compiler.py\", line 265, in __init__ arch, code, cache_dir, include_dirs) File \"C:\\Python27\\lib\\site-packages\\pycuda\\compiler.py\", line 255, in compile return compile_plain(source, options, keep, nvcc, cache_dir, target) File \"C:\\Python27\\lib\\site-packages\\pycuda\\compiler.py\", line 137, in compile_plain stderr=stderr.decode(\"utf-8\", \"replace\")) pycuda.driver.CompileError: nvcc compilation of c:\\users\\newbie\\appdata\\local\\temp\\tmplluyeq\\kernel.cu failed [command: nvcc --cubin -arch sm_35 -m32 -Ic:\\python27\\lib\\site-packages\\pycuda\\cuda kernel.cu] [stdout: kernel.cu ] [stderr: 'C:\\Program' is not recognized as an internal or external command, What could be the possible solution . Please help !",
        "answers": [
            [
                "With limited knowledge my first guess would be that the white space after Program in a path containing C:\\Program Files\\anything is not getting handled properly. Edit: Including solutions independent of the link. You may need to escape the space in the file path. THough, I am not sure about windows slashes due to primarily using linux. Example C:/Program\\ Files/foo/bar.exe Another method may be to wrap quotes around the path. Either C:\\\"Program files\"\\foo\\bar.exe or \"C:\\Program files\\foo\\bar.exe\" A thrid option could be replacing the space with hex such as %20 like in C:\\Program%20files\\foo\\bar.exe. In c++ I think you can replace whitespace with \\u0020. So this replacement method could be an avenue as well. Suggested answers on this post may be helpful: https://superuser.com/questions/432980/how-to-call-a-program-that-contains-space-in-filenameenter link description here"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I am currently working on an ML project on my personal computer that has an AMD graphics card. I have an old NVidia 8800GT card that I could plug in for CUDA accelerated convolution, but I haven't found if it is compatible with Theano. Googling has surprisingly been unsuccessful. I know the 8800GT supports CUDA and I've done some CUDA work with it in the past, but is compatible with Theano? (or TensorFlow?) Best, Joe",
        "answers": [
            [
                "Theano has no specific requirements for cards other than \"it works with cuda\". If you want to use the cuDNN layers or other specilized things, then you might need a more recent card and the requirements for those is specified in the documentation for those libraries."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I wrote a Theano machine learning program. But I got two absolutely different results between on CPU and on GPU. Below is the log.(only a tiny part of log) result on GPU result on CPU The loss function will quickly decrease and then converg to 0.2 on CPU. However, the loss function will increase and finally become NaN on GPU. What mistakes may be in my program? Or what should I take into attention? Thank you!",
        "answers": [
            [
                "Could it be that CPU is using float64 (double precision) and the GPU is using float32 (single precision)? Here you can look up the configuration flags: http://deeplearning.net/software/theano/library/config.html"
            ],
            [
                "Check out this thread... https://github.com/fchollet/keras/issues/511 Basically adding; optimizer_excluding=cudnn in the .theanorc solved it for me, but solution runs a slower."
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I have installed Theano + CUDA + CUDNN as per instructions on official webpage. When I run on terminal: python import theano I get: Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled) When I do the same in Pycharm I get: ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again. I have added the CUDA folders to the interpreter path without any success. as you can see in the following pic: Any alternative recommendations on how to fix this?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I want to run Theano via Docker image on my PC with Windows installed. The Docker image contains Ubuntu system, CUDA drivers and Theano (https://hub.docker.com/r/kaixhin/cuda-theano/) but in order to use GPU in my algorithm I need to attach Nvidia devices to the image: docker run -it --device /dev/nvidiactl --device /dev/nvidia-uvm --device /dev/nvidia0 kaixhin/cuda-theano Is there a way to do it in Windows, since I don't have a path /dev/nvidiactl etc.? I have been looking for other Docker images but it seems that all of these are using Linux as the host system. Is there a version that will allow me to use GPU from Windows? For now I can run my script in Docker, but it uses only my CPU: WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: Unable to get the number of gpus available: no CUDA-capable device is detected)",
        "answers": [
            [
                "In order to run CUDA Docker images you need NVIDIA Docker. Unfortunately, Theano is not supported as an official image at the moment but you can write your own Dockerfile leveraging nvidia/cuda Having said that, you won't be able to do it on Windows because Docker needs a Linux VM and there is no support for VM GPU passthrough on Windows."
            ],
            [
                "You can try this image: https://hub.docker.com/r/kaixhin/cuda-theano/ It requires nvidia-docker nvidia-docker run -it kaixhin/cuda-theano"
            ]
        ],
        "votes": [
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "TL;DR: How do I give more data to a Theano function without taking more memory? The problem I'm having is that training my ML algorithm on the GPU with Theano causes the GPU to eventually run out of memory. I took a slight departure from the tutorial because my dataset is too big to read entirely into memory (this must be an issue for video algorithms too, right?), so rather than using an index input and update scheme, I just pass the Theano function the ndarrays directly. Let me give an example of what I mean. In the Logistic Regression tutorial in Theano it says to do something along the lines of: train_model = theano.function( inputs=[index], outputs=cost, updates=updates, givens={ x: train_set_x[index * batch_size: (index + 1) * batch_size], y: train_set_y[index * batch_size: (index + 1) * batch_size] } ) This requires test_set_x and test_set_y to be loaded into memory, and the tutorial uses a SharedVariable to store the complete dataset. Ok for me, the dataset is huge (many many gigabytes), which means it cannot all be loaded into memory at once, so I modified mine to take the data directly, thusly: train_model = theano.function( inputs=[input, classes], outputs=cost, updates=updates ) and then I do something that looks vaguely like this: for count, data in enumerate(extractor): observations, labels = data batch_cost = train_model(observations, labels) logger.debug(\"Generation %d: %f cost\", count, batch_cost) I think I may be fundamentally misunderstanding how to properly hand data to the GPU without some nasty python garbage-collection dirtiness. It seems like this is just occupying more and more memory in the model internally, because after training this after a (large) number of batches, I get an error like this: Error when tring to find the memory information on the GPU: initialization error Error freeing device pointer 0x500c88000 (initialization error). Driver report 0 bytes free and 0 bytes total CudaNdarray_uninit: error freeing self-&gt;devdata. (self=0x10cbbd170, self-&gt;devata=0x500c88000) Exception MemoryError: 'error freeing device pointer 0x500c88000 (initialization error)' in 'garbage collection' ignored Fatal Python error: unexpected exception during garbage collection How do I give more data to a Theano function, without taking up more memory?",
        "answers": [
            [
                "If the dataset does not fit in memory, the idea is to take a portion of it and load it each time you need. If your data does not fit in the gpu memory, as seen in the classic lasagne tutorial, you can iterate over portion of the dataset, called minibatches Then, if your data does not fit in your RAM, you need to load the minibatch each time you need it. Best way to do that is to make a separate process load the next minibatch (cpu working) as you are analysing the current one (gpu working) You can inspire yourself from AlexNet :"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I have some subtensor and for some reason, Theano cannot transfer it to the GPU. Some sample code: import numpy import theano import theano.printing import theano.compile.io import theano.compile.function_module import theano.tensor as T from theano.sandbox.cuda.basic_ops import as_cuda_ndarray_variable n_copies, n_cells = 5, 10 P = T.constant(numpy.zeros((n_copies, n_cells), dtype=\"int32\")) # (n_copies,n_cells) -&gt; list of indices meminkey = T.fmatrix() # (batch,n_cells) meminkey = as_cuda_ndarray_variable(meminkey) i_t = T.ones((meminkey.shape[0],)) batches = T.arange(0, i_t.shape[0]).dimshuffle(0, 'x', 'x') # (batch,n_copies,n_cells) P_bc = P.dimshuffle('x', 0, 1) # (batch,n_copies,n_cells) meminkeyP = meminkey[batches, P_bc] # (batch,n_copies,n_cells) meminkeyP = as_cuda_ndarray_variable(meminkeyP) func = theano.function(inputs=[meminkey], outputs=[meminkeyP]) theano.printing.debugprint(func) I added some as_cuda_ndarray_variable to make the problem more clear because in the output, you see the transfers GpuFromHost and HostFromGpu, which it would avoid if it could do the AdvancedSubtensor on GPU. Output. Using gpu device 0: GeForce GTX TITAN (CNMeM is disabled, CuDNN not available) GpuFromHost [id A] '' 5 |AdvancedSubtensor [id B] '' 4 |HostFromGpu [id C] '' 1 | |&lt;CudaNdarrayType(float32, matrix)&gt; [id D] |InplaceDimShuffle{0,x,x} [id E] '' 3 | |ARange{dtype='int64'} [id F] '' 2 | |TensorConstant{0} [id G] | |Shape_i{0} [id H] '' 0 | | |&lt;CudaNdarrayType(float32, matrix)&gt; [id D] | |TensorConstant{1} [id I] |TensorConstant{[[[4 0 1 2..5 8 9 7]]]} [id J] So, why is Theano not able to transform this into a GPU op? Also, how can I rewrite the code that Theano will do the calculation on GPU? Related question in Google Groups: here and here and here.",
        "answers": [
            [
                "Ok, so in the Google Groups posts which I linked, it's pretty good explained why it doesn't work. AdvancedSubtensor is the most generic form which works with all crazy types of indexing variants. Then there is AdvancedSubtensor1, which only works for a certain kind of subset. There only exists a GPU version for AdvancedSubtensor1, not for AdvancedSubtensor. I didn't fully understand the reason but there is an ongoing discussion about it. AdvancedSubtensor1 can be used when there is a single list of indices. However, in my example, that is not the case. The common workaround you see, also in some other example in those Google Groups post, is to flatten the array first and calculate the indices for the flattened array. Most examples work with some kind of nonzero() or so, where you also would flatten the base arguments in the same and then you get the indices for the flattened version. So, the question is, how to apply this to my code? Actually, there is a simpler solution where it will use AdvancedSubtensor1 which I didn't realized initially: meminkeyP = meminkey[:, P] # (batch,n_copies,n_cells) However, before I realized that, I came up with a generic solution which also works for other cases. I transform my indices tuple (batches, P_bc) into indices for the flattened version. This is done with this function: def indices_in_flatten_array(ndim, shape, *args): \"\"\" We expect that all args can be broadcasted together. So, if we have some array A with ndim&amp;shape as given, A[args] would give us a subtensor. We return the indices so that A[args].flatten() and A.flatten()[indices] are the same. \"\"\" assert ndim &gt; 0 assert len(args) == ndim indices_per_axis = [args[i] for i in range(ndim)] for i in range(ndim): for j in range(i + 1, ndim): indices_per_axis[i] *= shape[j] indices = indices_per_axis[0] for i in range(1, ndim): indices += indices_per_axis[i] return indices Then, I use it like this: meminkeyP = meminkey.flatten()[indices_in_flatten_array(meminkey.ndim, meminkey.shape, batches, P_bc)] This seems to work. And I get this output: Using gpu device 0: GeForce GTX TITAN (CNMeM is disabled, CuDNN not available) GpuReshape{3} [id A] '' 11 |GpuAdvancedSubtensor1 [id B] '' 10 | |GpuReshape{1} [id C] '' 2 | | |&lt;CudaNdarrayType(float32, matrix)&gt; [id D] | | |TensorConstant{(1,) of -1} [id E] | |Reshape{1} [id F] '' 9 | |Elemwise{second,no_inplace} [id G] '' 8 | | |TensorConstant{(1, 5, 10) of 0} [id H] | | |Elemwise{Mul}[(0, 0)] [id I] '' 7 | | |InplaceDimShuffle{0,x,x} [id J] '' 6 | | | |ARange{dtype='int64'} [id K] '' 4 | | | |TensorConstant{0} [id L] | | | |Shape_i{0} [id M] '' 0 | | | | |&lt;CudaNdarrayType(float32, matrix)&gt; [id D] | | | |TensorConstant{1} [id N] | | |InplaceDimShuffle{x,x,x} [id O] '' 5 | | |Shape_i{1} [id P] '' 1 | | |&lt;CudaNdarrayType(float32, matrix)&gt; [id D] | |TensorConstant{(1,) of -1} [id E] |MakeVector{dtype='int64'} [id Q] '' 3 |Shape_i{0} [id M] '' 0 |TensorConstant{5} [id R] |TensorConstant{10} [id S] Small test case: def test_indices_in_flatten_array(): n_copies, n_cells = 5, 4 n_complex_cells = n_cells / 2 n_batch = 3 static_rng = numpy.random.RandomState(1234) def make_permut(): p = numpy.zeros((n_copies, n_cells), dtype=\"int32\") for i in range(n_copies): p[i, :n_complex_cells] = static_rng.permutation(n_complex_cells) # Same permutation for imaginary part. p[i, n_complex_cells:] = p[i, :n_complex_cells] + n_complex_cells return T.constant(p) P = make_permut() # (n_copies,n_cells) -&gt; list of indices meminkey = T.as_tensor_variable(static_rng.rand(n_batch, n_cells).astype(\"float32\")) i_t = T.ones((meminkey.shape[0],)) # (batch,) n_batch = i_t.shape[0] batches = T.arange(0, n_batch).dimshuffle(0, 'x', 'x') # (batch,n_copies,n_cells) P_bc = P.dimshuffle('x', 0, 1) # (batch,n_copies,n_cells) meminkeyP1 = meminkey[batches, P_bc] # (batch,n_copies,n_cells) meminkeyP2 = meminkey.flatten()[indices_in_flatten_array(meminkey.ndim, meminkey.shape, batches, P_bc)] numpy.testing.assert_allclose(meminkeyP1.eval(), meminkeyP2.eval())"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I'm trying to install Theano, here is my situation. The system is Windows 10 (64-bit), with CUDA 7.5 installed with Visual Studio 2013. The Python distribution is Enthought Canopy (2.7.10, 32-bit) with pip, numpy (1.9.2-3) and scipy (0.17.0-2). The installation is as follows, 1. install Theano (0.7) with pip; 2. install mingw (4.8.1-2) and libpython (1.2) using enpkg tool; 3. copy the newly created libpython27.a into ${PYTHONHOME}/Libs; 4. edit and save .theanorc.txt under c:\\users\\${myName} as [global] devive=gpu floatX=float32 [blas] ldflags=${PYTHONHOME}\\Scripts -lmk2_core -lmk2_intel_thread -lmk2_rt [nvcc] flags=-LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\User\\libs compiler_bindir=C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin [gcc] cxxflags= When I try to import theano, I get the following warning and error: mod.cu(1019): warning: statement is unreachable mod.cu(1019): warning: statement is unreachable mod.cu LINK : fatal error LNK1181: cannot open input file 'cublas.lib' ['nvcc', '-shared', '-O3', '-LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\User\\libs', '--compiler-bindir', 'C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m32', '-Xcompiler', '-DCUDA_NDARRAY_CUH=11b90075e2397c684f9dc0f7276eab8f,-D NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\User\\lib\\site-packages\\theano\\sandbox\\cuda', '-IC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\lib\\site-packages\\numpy\\core\\include', '-IC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\include', '-o', 'C:\\Users\\${myName}\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_71_Stepping_1_GenuineIntel-2.7.10-32\\cuda_ndarray\\cuda_ndarray.pyd', 'mod.cu', '-LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\User\\EGG-INFO\\mingw\\usr\\x86_64-w64-mingw32\\lib', '-LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\libs', '-LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86', '-lpython27', '-lcublas', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\User\\libs --compiler-bindir C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin -Xlinker /DEBUG -D HAVE_ROUND -m32 -Xcompiler -DCUDA_NDARRAY_CUH=11b90075e2397c684f9dc0f7276eab8f,-D NPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\User\\lib\\site-packages\\theano\\sandbox\\cuda -IC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\include -o C:\\Users\\${myName}\\AppData\\Local\\Theano\\compiledir_Windows-8-6.2.9200-Intel64_Family_6_Model_71_Stepping_1_GenuineIntel-2.7.10-32\\cuda_ndarray\\cuda_ndarray.pyd mod.cu -LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\User\\EGG-INFO\\mingw\\usr\\x86_64-w64-mingw32\\lib -LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\libs -LC:\\Users\\${myName}\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86 -lpython27 -lcublas -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavilable) I'm wondering if it's the 32-bit Python vs 64-bit system that causes the problem.",
        "answers": [
            [
                "As @Robert point out in the comment, the warning suggests compatibility issue. I finally solved the problem by installing the 64-bit Enthought Canopy python distribution, the other steps are the same as described in the question. It's worth mentioning that mingw can be installed by Enthough Canopy package manager as well, so you don't have to download independent mingw if you are using the distribution."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I'm new to theano. After following this guide: http://deeplearning.net/software/theano/install_windows.html#install-windows I managed to work with theano properly. Later I upgraded to theano dev version and now I keep getting this exception: import theano ........... cuda_ndarray.cu printed out........ =============================== nvcc : fatal error : redefinition of argument 'cl-version' ['nvcc', '-shared', '-O3', '--cl-version=2010', '--cl-version=2010', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xc ompiler', '--use-local,-DCUDA_NDARRAY_CUH=18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,- -use-local,/Zi,/MD', '-IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda', ' -IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include', '-IC:\\\\WinPython-64bit-2 .7.10.3\\\\python-2.7.10.amd64\\\\include', '-IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\theano \\\\gof', '-o', 'C:\\\\Users\\\\Kostya\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7600-Intel64_Family_6_Model_42_Steppi ng_7_GenuineIntel-2.7.10-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-LC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.a md64\\\\libs', '-LC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64', '-lpython27', '-lcublas', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', -1, 'for cmd', 'nvcc -shared -O3 --cl-version=2010 --cl-version=2010 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler --use-local,-DCUDA_NDARRAY_CUH=1871546 2c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,--use-local,/Zi,/MD -IC:\\\\WinPython-64bit-2.7.10.3 \\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda -IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\li b\\\\site-packages\\\\numpy\\\\core\\\\include -IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\include -IC:\\\\WinPython-64bi t-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\theano\\\\gof -o C:\\\\Users\\\\Kostya\\\\AppData\\\\Local\\\\Theano\\\\compiledi r_Windows-7-6.1.7600-Intel64_Family_6_Model_42_Stepping_7_GenuineIntel-2.7.10-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\libs -LC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64 -lpython27 -lcublas -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available (error: cuda unavailable) The .theanorc file: [global] device = gpu floatX = float32 #optimizer = fast_run [nvcc] flags = --cl-version=2010 --use-local #fastmath = True #[blas] #ldflags = -lf77blas -latlas -lgfortran #[cuda] root=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v5.5 the nvcc.profile: TOP = $(_HERE_)/.. NVVMIR_LIBRARY_DIR = $(TOP)/nvvm/libdevice PATH += $(TOP)/open64/bin;$(TOP)/nvvm/bin;$(_HERE_);$(TOP)/lib; INCLUDES += \"-I$(TOP)/include\" $(_SPACE_) LIBRARIES =+ $(_SPACE_) \"/LIBPATH:$(TOP)/lib/$(_WIN_PLATFORM_)\" CUDAFE_FLAGS += OPENCC_FLAGS += PTXAS_FLAGS += I defenitely found out that for some reason FLAGS from .theanorc is being called twice, if I put it twice in .theanorc, I get it 4 times in exception. But I have no clue where could be those twice-mentioned flags. How does this theano-nvcc-cuda-?? chain work? Who is calling nvcc and causing this issue? BTW if I don't specify cl-version, I get nvcc : fatal error : nvcc cannot find a supported version of Microsoft Visual Studio. Only the versions 2008, 2010, and 2012 are supported ['nvcc', '-shared', '-O3', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=18715462c72e d6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.1 0.amd64\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda', '-IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-pac kages\\\\numpy\\\\core\\\\include', '-IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\include', '-IC:\\\\WinPython-64bit-2.7 .10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\theano\\\\gof', '-o', 'C:\\\\Users\\\\Kostya\\\\AppData\\\\Local\\\\Theano\\\\compiled ir_Windows-7-6.1.7600-Intel64_Family_6_Model_42_Stepping_7_GenuineIntel-2.7.10-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod .cu', '-LC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\libs', '-LC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64' , '-lpython27', '-lcublas', '-lcudart'] ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', -1, 'for cmd', 'nvcc -shared -O3 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_AP I=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\ cuda -IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -IC:\\\\WinPython-64bit -2.7.10.3\\\\python-2.7.10.amd64\\\\include -IC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\lib\\\\site-packages\\\\theano\\ \\gof -o C:\\\\Users\\\\Kostya\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7600-Intel64_Family_6_Model_42_Stepping_7_Ge nuineIntel-2.7.10-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LC:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64\\\\libs -L C:\\\\WinPython-64bit-2.7.10.3\\\\python-2.7.10.amd64 -lpython27 -lcublas -lcudart')",
        "answers": [
            [
                "seems to be issue in dev version of theano, as stated here: github.com/Theano/Theano/issues/4091"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I have been running Theano without GPU on py 2.7 for quite some time now. Then decided to check out GPU support. So followed all steps given in here: http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-microsoft-windows/index.html#abstract Then opened the device query sln in msvc 2013 and built it (as mentioned in the above link to check if installation was successful). On run it gives me an error (attached screen shot). A similar error comes up when I run the starter program with gpu in py 2.7 with Theanorc file contents: [global] device = gpu1 floatX = float32 nocleanup = True [cuda] root = /usr/local/cuda-7.5 [nvcc] fastmath = True compiler_bindir=C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin\\cl.exe received no errors for nvcc -V, and cl.exe. OS - win7 SP1 NVIDIA GeForce GT650M Can anyone please help?",
        "answers": [
            [
                "I got similar error when my video card driver mismatched with the CUDA Toolkit. Make sure you are using video driver included in CUDA installer. If you are not sure, reinstall latest CUDA Toolkit installer and update your video driver with it."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I created a simple python script (using Theano) performing linear regression which should be run on GPU. When code starts it says \"using gpu device\", but (according to the profiler) all operations are CPU-specific (ElemWise, instead of GpuElemWise, no GpuFromHost etc.). I checked the variables, THEANO_FLAGS, everything seems right and I cannot see the catch (especially when Theano tutorials with the same settings are correctly run on GPU :)). Here is the code: # linear regression import numpy import theano import theano.tensor as T input_data = numpy.matrix([[28, 1], [35, 2], [18, 1], [56, 2], [80, 3]]) output_data = numpy.matrix([1600, 2100, 1400, 2500, 3200]) TS = theano.shared(input_data, \"training-set\") E = theano.shared(output_data, \"expected\") W1 = theano.shared(numpy.zeros((1, 2))) O = T.dot(TS, W1.T) cost = T.mean(T.sqr(E - O.T)) gradient = T.grad(cost=cost, wrt=W1) update = [[W1, W1 - gradient * 0.0001]] train = theano.function([], cost, updates=update, allow_input_downcast=True) for i in range(1000): train() THEANO_FLAGS=cuda.root=/usr/local/cuda device=gpu floatX=float32 lib.cnmem=.5 profile=True CUDA_LAUNCH_BLOCKING=1 Output: Using gpu device 0: GeForce GT 650M (CNMeM is enabled) Function profiling ================== Message: /home/mw/Documents/LiClipse Workspace/theano1/test2.py:18 Time in 1000 calls to Function.__call__: 3.348637e-02s Time in Function.fn.__call__: 2.419019e-02s (72.239%) Time in thunks: 1.839781e-02s (54.941%) Total compile time: 1.350801e-01s Number of Apply nodes: 18 Theano Optimizer time: 1.101730e-01s Theano validate time: 2.029657e-03s Theano Linker time (includes C, CUDA code generation/compiling): 1.491690e-02s Import time 2.320528e-03s Time in all call to theano.grad() 8.740902e-03s Time since theano import 0.881s Class --- &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Class name&gt; 71.7% 71.7% 0.013s 6.59e-06s Py 2000 2 theano.tensor.basic.Dot 12.3% 83.9% 0.002s 3.22e-07s C 7000 7 theano.tensor.elemwise.Elemwise 5.7% 89.6% 0.001s 3.50e-07s C 3000 3 theano.tensor.elemwise.DimShuffle 4.0% 93.6% 0.001s 3.65e-07s C 2000 2 theano.tensor.subtensor.Subtensor 3.6% 97.2% 0.001s 3.31e-07s C 2000 2 theano.compile.ops.Shape_i 1.7% 98.9% 0.000s 3.06e-07s C 1000 1 theano.tensor.opt.MakeVector 1.1% 100.0% 0.000s 2.10e-07s C 1000 1 theano.tensor.elemwise.Sum ... (remaining 0 Classes account for 0.00%(0.00s) of the runtime) Ops --- &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Op name&gt; 71.7% 71.7% 0.013s 6.59e-06s Py 2000 2 dot 4.0% 75.6% 0.001s 3.65e-07s C 2000 2 Subtensor{int64} 3.5% 79.1% 0.001s 6.35e-07s C 1000 1 InplaceDimShuffle{1,0} 3.3% 82.4% 0.001s 6.06e-07s C 1000 1 Elemwise{mul,no_inplace} 2.4% 84.8% 0.000s 4.38e-07s C 1000 1 Shape_i{0} 2.3% 87.1% 0.000s 4.29e-07s C 1000 1 Elemwise{Composite{((i0 * i1) / i2)}} 2.3% 89.3% 0.000s 2.08e-07s C 2000 2 InplaceDimShuffle{x,x} 1.8% 91.1% 0.000s 3.25e-07s C 1000 1 Elemwise{Cast{float64}} 1.7% 92.8% 0.000s 3.06e-07s C 1000 1 MakeVector{dtype='int64'} 1.5% 94.3% 0.000s 2.78e-07s C 1000 1 Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)] 1.4% 95.7% 0.000s 2.53e-07s C 1000 1 Elemwise{Sub}[(0, 1)] 1.2% 96.9% 0.000s 2.24e-07s C 1000 1 Shape_i{1} 1.1% 98.0% 0.000s 2.10e-07s C 1000 1 Sum{acc_dtype=float64} 1.1% 99.1% 0.000s 1.98e-07s C 1000 1 Elemwise{Sqr}[(0, 0)] 0.9% 100.0% 0.000s 1.66e-07s C 1000 1 Elemwise{Composite{((i0 / i1) / i2)}}[(0, 0)] ... (remaining 0 Ops account for 0.00%(0.00s) of the runtime) Apply ------ &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;#call&gt; &lt;id&gt; &lt;Apply name&gt; 37.8% 37.8% 0.007s 6.95e-06s 1000 3 dot(&lt;TensorType(float64, matrix)&gt;, training-set.T) 33.9% 71.7% 0.006s 6.24e-06s 1000 14 dot(Elemwise{Composite{((i0 * i1) / i2)}}.0, training-set) 3.5% 75.1% 0.001s 6.35e-07s 1000 0 InplaceDimShuffle{1,0}(training-set) 3.3% 78.4% 0.001s 6.06e-07s 1000 11 Elemwise{mul,no_inplace}(InplaceDimShuffle{x,x}.0, InplaceDimShuffle{x,x}.0) 3.0% 81.4% 0.001s 5.58e-07s 1000 8 Subtensor{int64}(Elemwise{Cast{float64}}.0, Constant{1}) 2.4% 83.8% 0.000s 4.38e-07s 1000 2 Shape_i{0}(expected) 2.3% 86.2% 0.000s 4.29e-07s 1000 12 Elemwise{Composite{((i0 * i1) / i2)}}(TensorConstant{(1, 1) of -2.0}, Elemwise{Sub}[(0, 1)].0, Elemwise{mul,no_inplace}.0) 1.8% 87.9% 0.000s 3.25e-07s 1000 6 Elemwise{Cast{float64}}(MakeVector{dtype='int64'}.0) 1.7% 89.6% 0.000s 3.06e-07s 1000 4 MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0) 1.6% 91.2% 0.000s 3.03e-07s 1000 10 InplaceDimShuffle{x,x}(Subtensor{int64}.0) 1.5% 92.7% 0.000s 2.78e-07s 1000 16 Elemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)](&lt;TensorType(float64, matrix)&gt;, TensorConstant{(1, 1) of ..974738e-05}, dot.0) 1.4% 94.1% 0.000s 2.53e-07s 1000 5 Elemwise{Sub}[(0, 1)](expected, dot.0) 1.2% 95.3% 0.000s 2.24e-07s 1000 1 Shape_i{1}(expected) 1.1% 96.5% 0.000s 2.10e-07s 1000 15 Sum{acc_dtype=float64}(Elemwise{Sqr}[(0, 0)].0) 1.1% 97.6% 0.000s 1.98e-07s 1000 13 Elemwise{Sqr}[(0, 0)](Elemwise{Sub}[(0, 1)].0) 0.9% 98.5% 0.000s 1.72e-07s 1000 7 Subtensor{int64}(Elemwise{Cast{float64}}.0, Constant{0}) 0.9% 99.4% 0.000s 1.66e-07s 1000 17 Elemwise{Composite{((i0 / i1) / i2)}}[(0, 0)](Sum{acc_dtype=float64}.0, Subtensor{int64}.0, Subtensor{int64}.0) 0.6% 100.0% 0.000s 1.13e-07s 1000 9 InplaceDimShuffle{x,x}(Subtensor{int64}.0) ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)",
        "answers": [
            [
                "As mentioned in the comments although you have set the allow_input_downcast parameter to True, but you need to make sure all the data to be assigned to shared variables are in float32. As of Jan. 06, 2016 Theano still cannot work with any other data type rather than float32 to do the computations on GPU, as mentioned here in a more details. So you have to have to cast your data into 'float32' format. Therefore, here should be the code you need to use: import numpy import theano import theano.tensor as T input_data = numpy.matrix([[28, 1], [35, 2], [18, 1], [56, 2], [80, 3]]) output_data = numpy.matrix([1600, 2100, 1400, 2500, 3200]) TS = theano.shared(input_data.astype('float32'), \"training-set\") E = theano.shared(output_data.astype('float32'), \"expected\") W1 = theano.shared(numpy.zeros((1, 2), dtype = 'float32')) O = T.dot(TS, W1.T) cost = T.mean(T.sqr(E - O.T)) gradient = T.grad(cost=cost, wrt=W1) update = [[W1, W1 - gradient * 0.0001]] train = theano.function([], cost, updates=update, allow_input_downcast=True, profile = True) for i in range(1000): train() train.profile.print_summary() And here will be the profiling result: Message: LearnTheano.py:18 Time in 1000 calls to Function.__call__: 2.642968e-01s Time in Function.fn.__call__: 2.460811e-01s (93.108%) Time in thunks: 1.877530e-01s (71.039%) Total compile time: 2.483290e+01s Number of Apply nodes: 17 Theano Optimizer time: 2.818849e-01s Theano validate time: 3.435850e-03s Theano Linker time (includes C, CUDA code generation/compiling): 2.453926e+01s Import time 1.241469e-02s Time in all call to theano.grad() 1.206994e-02s Class --- &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Class name&gt; 34.8% 34.8% 0.065s 3.27e-05s C 2000 2 theano.sandbox.cuda.blas.GpuGemm 28.8% 63.5% 0.054s 1.80e-05s C 3000 3 theano.sandbox.cuda.basic_ops.GpuElemwise 12.9% 76.4% 0.024s 2.42e-05s C 1000 1 theano.sandbox.cuda.basic_ops.GpuCAReduce 10.3% 86.7% 0.019s 1.93e-05s C 1000 1 theano.sandbox.cuda.basic_ops.GpuFromHost 7.2% 93.9% 0.014s 1.36e-05s C 1000 1 theano.sandbox.cuda.basic_ops.HostFromGpu 1.8% 95.7% 0.003s 1.13e-06s C 3000 3 theano.sandbox.cuda.basic_ops.GpuDimShuffle 1.5% 97.2% 0.003s 2.81e-06s C 1000 1 theano.tensor.elemwise.Elemwise 1.1% 98.4% 0.002s 1.08e-06s C 2000 2 theano.compile.ops.Shape_i 1.1% 99.5% 0.002s 1.02e-06s C 2000 2 theano.sandbox.cuda.basic_ops.GpuSubtensor 0.5% 100.0% 0.001s 9.96e-07s C 1000 1 theano.tensor.opt.MakeVector ... (remaining 0 Classes account for 0.00%(0.00s) of the runtime) Ops --- &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Op name&gt; 25.3% 25.3% 0.047s 4.74e-05s C 1000 1 GpuGemm{no_inplace} 12.9% 38.1% 0.024s 2.42e-05s C 1000 1 GpuCAReduce{pre=sqr,red=add}{1,1} 12.8% 51.0% 0.024s 2.41e-05s C 1000 1 GpuElemwise{mul,no_inplace} 10.3% 61.3% 0.019s 1.93e-05s C 1000 1 GpuFromHost 9.5% 70.8% 0.018s 1.79e-05s C 1000 1 GpuGemm{inplace} 8.2% 79.0% 0.015s 1.55e-05s C 1000 1 GpuElemwise{Composite{((i0 / i1) / i2)}}[(0, 0)] 7.7% 86.7% 0.014s 1.44e-05s C 1000 1 GpuElemwise{Composite{((i0 * i1) / i2)}}[(0, 1)] 7.2% 93.9% 0.014s 1.36e-05s C 1000 1 HostFromGpu 1.5% 95.4% 0.003s 2.81e-06s C 1000 1 Elemwise{Cast{float32}} 1.1% 96.5% 0.002s 1.02e-06s C 2000 2 GpuSubtensor{int64} 1.0% 97.5% 0.002s 9.00e-07s C 2000 2 GpuDimShuffle{x,x} 0.8% 98.3% 0.002s 1.59e-06s C 1000 1 GpuDimShuffle{1,0} 0.7% 99.1% 0.001s 1.38e-06s C 1000 1 Shape_i{0} 0.5% 99.6% 0.001s 9.96e-07s C 1000 1 MakeVector 0.4% 100.0% 0.001s 7.76e-07s C 1000 1 Shape_i{1} ... (remaining 0 Ops account for 0.00%(0.00s) of the runtime) Apply ------ &lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;#call&gt; &lt;id&gt; &lt;Apply name&gt; 25.3% 25.3% 0.047s 4.74e-05s 1000 3 GpuGemm{no_inplace}(expected, TensorConstant{-1.0}, &lt;CudaNdarrayType(float32, matrix)&gt;, GpuDimShuffle{1,0}.0, TensorConstant{1.0}) 12.9% 38.1% 0.024s 2.42e-05s 1000 5 GpuCAReduce{pre=sqr,red=add}{1,1}(GpuGemm{no_inplace}.0) 12.8% 51.0% 0.024s 2.41e-05s 1000 13 GpuElemwise{mul,no_inplace}(GpuDimShuffle{x,x}.0, GpuDimShuffle{x,x}.0) 10.3% 61.3% 0.019s 1.93e-05s 1000 7 GpuFromHost(Elemwise{Cast{float32}}.0) 9.5% 70.8% 0.018s 1.79e-05s 1000 16 GpuGemm{inplace}(&lt;CudaNdarrayType(float32, matrix)&gt;, TensorConstant{-9.99999974738e-05}, GpuElemwise{Composite{((i0 * i1) / i2)}}[(0, 1)].0, training-set, TensorConstant{1.0}) 8.2% 79.0% 0.015s 1.55e-05s 1000 12 GpuElemwise{Composite{((i0 / i1) / i2)}}[(0, 0)](GpuCAReduce{pre=sqr,red=add}{1,1}.0, GpuSubtensor{int64}.0, GpuSubtensor{int64}.0) 7.7% 86.7% 0.014s 1.44e-05s 1000 15 GpuElemwise{Composite{((i0 * i1) / i2)}}[(0, 1)](CudaNdarrayConstant{[[-2.]]}, GpuGemm{no_inplace}.0, GpuElemwise{mul,no_inplace}.0) 7.2% 93.9% 0.014s 1.36e-05s 1000 14 HostFromGpu(GpuElemwise{Composite{((i0 / i1) / i2)}}[(0, 0)].0) 1.5% 95.4% 0.003s 2.81e-06s 1000 6 Elemwise{Cast{float32}}(MakeVector.0) 0.8% 96.3% 0.002s 1.59e-06s 1000 0 GpuDimShuffle{1,0}(training-set) 0.7% 97.0% 0.001s 1.38e-06s 1000 2 Shape_i{0}(expected) 0.7% 97.7% 0.001s 1.30e-06s 1000 8 GpuSubtensor{int64}(GpuFromHost.0, Constant{0}) 0.6% 98.3% 0.001s 1.08e-06s 1000 11 GpuDimShuffle{x,x}(GpuSubtensor{int64}.0) 0.5% 98.8% 0.001s 9.96e-07s 1000 4 MakeVector(Shape_i{0}.0, Shape_i{1}.0) 0.4% 99.2% 0.001s 7.76e-07s 1000 1 Shape_i{1}(expected) 0.4% 99.6% 0.001s 7.40e-07s 1000 9 GpuSubtensor{int64}(GpuFromHost.0, Constant{1}) 0.4% 100.0% 0.001s 7.25e-07s 1000 10 GpuDimShuffle{x,x}(GpuSubtensor{int64}.0) ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I am just getting started with Theano and Deep Learning. I was experimenting with an example from the Theano tutorial (http://deeplearning.net/software/theano/tutorial/using_gpu.html#returning-a-handle-to-device-allocated-data). The example code is shown here: from theano import function, config, shared, sandbox import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print(f.maker.fgraph.toposort()) t0 = time.time() for i in xrange(iters): r = f() t1 = time.time() print(\"Looping %d times took %f seconds\" % (iters, t1 - t0)) print(\"Result is %s\" % (r,)) if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print('Used the cpu') else: print('Used the gpu') I am trying to understand the expression defining 'vlen', vlen = 10 * 30 * 768 # 10 x #cores x # threads per core I can't find anywhere in the text that refers to the number of GPU cores specified in this example and why 30 was selected. Nor can I find why the value of 768 threads was used. My GPU (GeForce 840M) has 384 cores. Can I assume that if I substitute 384 in the place of the value of 30, that I will be using all 384 cores ? Also should the value of 768 threads remain fixed ?",
        "answers": [
            [
                "I believe the logic is as follows. Looking at the referenced page, we see that there is mention of a GTX 275 GPU. So the GPU being used for that tutorial may have been a very old CUDA GPU from the cc1.x generation (no longer supported by CUDA 7.0 and 7.5). In the comment, the developer seems to be using the word \"core\" to refer to a GPU SM (multiprocessor). There were a number of GPUs in that family that had 30 SMs (a cc1.x SM was a very different animal than a cc 2+ SM), including GTX 275 (240 CUDA cores = 30SMs * 8cores/SM in the cc1.x generation). So the 30 number is derived from the number of SMs in the GPU being used at the time. Furthermore, if you review old documentation for CUDA versions that supported such GPUs, you will find that cc1.0 and cc1.1 GPUs supported a max of 768 threads per multiprocessor (SM). So I believe this is where the 768 number comes from. Finally, a good CUDA code will oversubscribe the GPU (total number of threads is more than what the GPU can instantaneously handle). So I believe the factor of 10 is just to ensure \"oversubscription\". There is no magic to a particular number -- it is just the length of an array (vlen). The length of this array, after it flows through the theano framework, will ultimately determine the number of threads in CUDA kernel launch. This code isn't really a benchmark or other performance indicator. It's stated purpose is just to demonstrate that the GPU is being used. So I wouldn't read too much into that number. It was a casual choice by the developer that followed a certain amount of logic pertaining to the GPU at hand."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I started an installation of theano. My computer SPEC: - OS : Windows 7 64bit - Graphic card : NVIDIA Geforce GT 630 - CPU : AMD FX-8120 I installed theano by installation guide of deeplearning.net . (http://deeplearning.net/software/theano/install_windows.html#configure-theano-for-gpu-use) I successfully finished installation process under. Visual Studio 2010 -&gt; Windows Software Development Kit version 7.1 -&gt; CUDA -&gt; Microsoft Visual C++ Complier for Python 2.7 (adding header) -&gt; TDM GCC -&gt; WinPython-64bit-2.7.9.4 -&gt; env.bat -&gt; Theano setup When I create a test file(under) and test it, it successfully execute. -------test file---------------------------------- import numpy as np import time import theano A = np.random.rand(1000,10000).astype(theano.config.floatX) B = np.random.rand(10000,1000).astype(theano.config.floatX) np_start = time.time() AB = A.dot(B) np_end = time.time() X,Y = theano.tensor.matrices('XY') mf = theano.function([X,Y],X.dot(Y)) t_start = time.time() tAB = mf(A,B) t_end = time.time() print \"NP time: %f[s], theano time: %f[s] (times should be close when run on CPU!)\" %(np_end-np_start, t_end-t_start) print \"Result difference: %f\" % (np.abs(AB-tAB).max(), ) BUT when I add .theanorc.txt ---.theanorc.txt-------------------------------- [global] device = gpu floatX = float32 [nvcc] flags = --use-local-env --cl-version=2008 It gives me an error like this(under) https://www.dropbox.com/s/gjspcpaz4hkeep8/11.PNG?dl=0 I have no problem with CUDA-devicequery &amp; nvidia-smi.exe -------------------------DeviceQuery-------------------------- C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v7.0\\1_Utilities\\deviceQuery\\../../bin/win64/Debug/deviceQuery.exe Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: \"GeForce GT 630\" CUDA Driver Version / Runtime Version 7.0 / 7.0 CUDA Capability Major/Minor version number: 2.1 Total amount of global memory: 512 MBytes (536870912 bytes) ( 2) Multiprocessors, ( 48) CUDA Cores/MP: 96 CUDA Cores GPU Max Clock rate: 1620 MHz (1.62 GHz) Memory Clock rate: 1600 Mhz Memory Bus Width: 128-bit L2 Cache Size: 131072 bytes Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65535), 3D=(2048, 2048, 2048) Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 32768 Warp size: 32 Maximum number of threads per multiprocessor: 1536 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (65535, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time limit on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement for Surfaces: Yes Device has ECC support: Disabled CUDA Device Driver Mode (TCC or WDDM): WDDM (Windows Display Driver Model) Device supports Unified Addressing (UVA): Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.0, CUDA Runtime Version = 7.0, NumDevs = 1, Device0 = GeForce GT 630 Result = PASS -------------------------nvidia-smi.exe-------------------------- Thu May 07 20:21:50 2015 +------------------------------------------------------+ | NVIDIA-SMI 347.62 Driver Version: 347.62 | |-------------------------------+----------------------+----------------------+ | GPU Name TCC/WDDM | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GT 630 WDDM | 0000:01:00.0 N/A | N/A | | 50% 31C P12 N/A / N/A | 476MiB / 511MiB | N/A Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 C Not Supported | +-----------------------------------------------------------------------------+ Please help me..",
        "answers": [
            [
                "You should use a \".theanorc\" file, not a \".theanorc.txt\". You may also write your question on the theano-users group: https://groups.google.com/forum/#!forum/theano-users Next Winpython release will include theano+mingwpy, so it may the reduce complexity of setup."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I'm trying to use the gpu in theano. I made my .theanorc file and tried to run the following python code: from theano import function, config, shared import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy.random.RandomState(22) x = shared(numpy.asarray(rng.rand(vlen), config.floatX)) f = function([], T.exp(x)) print f.maker.fgraph.toposort() t0 = time.time() for i in xrange(iters): r = f() t1 = time.time() print 'Looping %d times took' % iters, t1 - t0, 'seconds' print 'Result is', r if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]): print 'Used the cpu' else: print 'Used the gpu' i got this code from deeplearning.net. The output: nvcc : fatal error : Unsupported host compiler 'bi' ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', -1, 'for cmd', 'nvcc -shared -g -O3 --compiler-bindir C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 10.0\\\\VC\\\\bi -Xlinker /DEBUG -m64 -Xcompiler -LC:\\\\Python26\\\\libs,-DCUDA_NDARRAY_CUH=d67f7c8a21306c67152a70a88a837011,/Zi,/MD -IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda -IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\include -o C:\\\\Users\\\\Prashanth\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_42_Stepping_7_GenuineIntel-2.7.8-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\libs -LNone\\\\lib -LNone\\\\lib64 -LC:\\\\Users\\\\Prashanth\\\\Anaconda -lpython27 -lcublas -lcudart') ERROR:theano.sandbox.cuda:Failed to compile cuda_ndarray.cu: ('nvcc return status', -1, 'for cmd', 'nvcc -shared -g -O3 --compiler-bindir C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 10.0\\\\VC\\\\bi -Xlinker /DEBUG -m64 -Xcompiler -LC:\\\\Python26\\\\libs,-DCUDA_NDARRAY_CUH=d67f7c8a21306c67152a70a88a837011,/Zi,/MD -IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda -IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include -IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\include -o C:\\\\Users\\\\Prashanth\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_42_Stepping_7_GenuineIntel-2.7.8-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -LC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\libs -LNone\\\\lib -LNone\\\\lib64 -LC:\\\\Users\\\\Prashanth\\\\Anaconda -lpython27 -lcublas -lcudart') WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available ['nvcc', '-shared', '-g', '-O3', '--compiler-bindir', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 10.0\\\\VC\\\\bi', '-Xlinker', '/DEBUG', '-m64', '-Xcompiler', '-LC:\\\\Python26\\\\libs,-DCUDA_NDARRAY_CUH=d67f7c8a21306c67152a70a88a837011,/Zi,/MD', '-IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda', '-IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include', '-IC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\include', '-o', 'C:\\\\Users\\\\Prashanth\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_42_Stepping_7_GenuineIntel-2.7.8-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-LC:\\\\Users\\\\Prashanth\\\\Anaconda\\\\libs', '-LNone\\\\lib', '-LNone\\\\lib64', '-LC:\\\\Users\\\\Prashanth\\\\Anaconda', '-lpython27', '-lcublas', '-lcudart'] [Elemwise{exp,no_inplace}(&lt;TensorType(float32, vector)&gt;)] Looping 1000 times took 16.3019998074 seconds Result is [ 1.23178029 1.61879337 1.52278066 ..., 2.20771813 2.29967761 1.62323284] Used the cpu",
        "answers": [],
        "votes": []
    },
    {
        "question": "When running theano.test() on an Ubuntu operating system, some error message about an optimization failure is produced as follows: ERROR (theano.gof.opt): Optimization failure due to: constant_folding ERROR (theano.gof.opt): TRACEBACK: ERROR (theano.gof.opt): Traceback (most recent call last): File \"/usr/local/lib/python2.7/dist-packages/theano/gof/opt.py\", line 1286, in process_node replacements = lopt.transform(node) File \"/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.py\", line 3996, in constant_folding no_recycling=[]) File \"/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py\", line 237, in make_thunk compute_map, no_recycling) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/op.py\", line 606, in make_thunk output_storage=node_output_storage) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/cc.py\", line 948, in make_thunk keep_lock=keep_lock) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/cc.py\", line 891, in __compile__ keep_lock=keep_lock) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/cc.py\", line 1322, in cthunk_factory key=key, fn=self.compile_cmodule_by_step, keep_lock=keep_lock) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.py\", line 996, in module_from_key module = next(compile_steps) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/cc.py\", line 1237, in compile_cmodule_by_step preargs=preargs) File \"/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/nvcc_compiler.py\", line 444, in compile_str return dlimport(lib_filename) File \"/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.py\", line 284, in dlimport rval = __import__(module_name, {}, {}, [module_name]) ImportError: ('/home/csz/.theano/compiledir_Linux-3.11.0-20-generic-x86_64-with-Ubuntu-12.04-precise-x86_64-2.7.3-64/tmpcF2It0/3ea6a99a1a8d1d8523de8d72c27b90f4.so: undefined symbol: _Z25CudaNdarray_CopyFromArrayP11CudaNdarrayP23tagPyArrayObject_fields', '[GpuFromHost(TensorConstant{0.0})]') Does anybody know a way to fix these problem, or what exactly is going on?",
        "answers": [
            [
                "This can be caused by many things. The error is related to the GPU. So first, make sure you can compile nvidia example and that they run fine. To be sure this isn't the problem. The problem is that Theano isn't able to import a GPU module it compiled, because he didn't found the symbol it need. This missing symbol \"_Z25CudaNdarray_CopyFromArrayP11CudaNdarrayP23tagPyArrayObject_fields\" is in a shared library that Theano already pre-compiled. What is your OS? Make sure to update to the latest development version of Theano. There was a fix recently (Monday if my memory is exact) that could solve this on some OS."
            ]
        ],
        "votes": [
            2.0000001
        ]
    }
]