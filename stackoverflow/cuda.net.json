[
    {
        "question": "I found the KMLib on the internet and I found it very interesting. But when running the sample application an error appears: \"GASS.CUDA.CUDAException\" \"Error Invalid Source\". The exception occurs in the method: protected void InitCudaModule () { deviceNr int = 0; cuda = new CUDA (deviceNr, true); cuCtx = cuda.CreateContext (deviceNr, CUCtxFlags.MapHost); / / cuda.SetCurrentContext (cuCtx); / / var ctx = cuda.PopCurrentContext (); / / var CTX2 cuda.PopCurrentContext = (); / / var ctx3 cuda.PopCurrentContext = (); modluePath String = Path.Combine (Environment.CurrentDirectory, cudaModuleName); if (! File.Exists (modluePath)) throw new ArgumentException (\"Failed to access cuda module\" + modluePath); cuModule = cuda.LoadModule (modluePath); / / ERROR! cuFunc = cuda.GetModuleFunction (cudaProductKernelName); } I'm using GTX770, Visual Studio 2010 Ultimate, Cuda SDK 5.5 and Windows 7 64-bit. What can be causing the error?",
        "answers": [
            [
                "I've had to go through some of the same issues that you went through, but I got it working on my GTX 650 + CUDA 6.5 setup. I'll describe the changes I had to make into the build/dependencies of KMLIB: CUDAfy doesn't work for CUDA 6.5: I'm not sure how KMLib uses CUDAfy at all. It might actually NOT be using it for anything except accessing the CUDA.NET API (which is a separate project from CUDAfy that is merged into it). I had to make multiple changes to CUDAfy to make it less brain-damaged than it is, but I'd suggest you attempt replacing the reference with CUDA.NET and see if it really required CUDAfy. If this doesn't work for you, please let me know, and I will find a way to share my CUDAfy/6.5 build with you The specific GASS.CUDA.CUDAException you've encountered is something that is actually documented on KMLib's web-page, albeit somewhat obscurely: -arch=sm_21 or -arch=sm_30 \u2013 indicates compute capability, former if for Fermi cards(e.g Geforce 470), latter is for Kepler cards (e.g. GeForce 690), it is very important to set this switch depending on yours card compute capability So the issue you are experiencing has to do with the architecture of the GFX card (Fermi/Kepler/Maxwell) not being in line with the nvcc command-line in the post-build step. I don't know if the sm_30 as the author specifies is correct for the 770 card, but I ended up using the following command line, changing the compute-model, shader-moderl, and the visual-studio path (since CUDA 6.5 usus VS 2013, as was I): nvcc -I./ KernelsEllpackCol2.cu KernelsCSR.cu KernelsEllpack.cu KernelsSlicedEllpack.cu gpuFanSmoSolver.cu gpuFOSmoSolver.cu -ccbin \"%VS120COMNTOOLS%../../VC/bin\" -m64 -cubin -gencode=arch=compute_30,code=sm_30 -Xptxas=\"-v\" You will need to change the port-build to reflect your build system."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "Using VS 2012, .NET 4.5, 64bit and CUDAfy 1.12 and I have the following proof of concept using System; using System.Runtime.InteropServices; using Cudafy; using Cudafy.Host; using Cudafy.Translator; namespace Test { [Cudafy(eCudafyType.Struct)] [StructLayout(LayoutKind.Sequential)] public struct ChildStruct { [MarshalAs(UnmanagedType.LPArray)] public float[] FArray; public long FArrayLength; } [Cudafy(eCudafyType.Struct)] [StructLayout(LayoutKind.Sequential)] public struct ParentStruct { public ChildStruct Child; } public class Program { [Cudafy] public static void KernelFunction(GThread gThread, ParentStruct parent) { long length = parent.Child.FArrayLength; } public static void Main(string[] args) { var module = CudafyTranslator.Cudafy( ePlatform.x64, eArchitecture.sm_35, new[] {typeof(ChildStruct), typeof(ParentStruct), typeof(Program)}); var dev = CudafyHost.GetDevice(); dev.LoadModule(module); float[] hostFloat = new float[10]; for (int i = 0; i &lt; hostFloat.Length; i++) { hostFloat[i] = i; } ParentStruct parent = new ParentStruct { Child = new ChildStruct { FArray = dev.Allocate(hostFloat), FArrayLength = hostFloat.Length } }; dev.Launch(1, 1, KernelFunction, parent); Console.ReadLine(); } } } When the program runs, I am getting the following error on the dev.Launch: Type 'Test.ParentStruct' cannot be marshaled as an unmanaged structure; no meaningful size or offset can be computed. If I remove the float array from the ChildStruct, it works as expected. Having worked in C/C++/Cli and CUDA C in the past, I am aware of the nature of the error. Some solutions to this error suggest setting the struct size manually using Size parameter of MarshalAs, but this is not possible due to the variety of types within the struct. I looked at the generated .cu file and it is generating the float array as a float * which is what I expected. Is there a way to pass an array within a struct to the Kernel? And if there isn't what is the best second alternative? This problem doesn't exist in CUDA C and it only exists because we are marshaling from CLR.",
        "answers": [
            [
                "I spent good time reading the source code of CUDAfy to see if there is a solution to this problem. CUDAfy is trying to make things too simple for .NET developers and shield them away from the IntPtr and other pointer concepts. However, the level of abstraction makes it very hard to think of an answer to this problem without a major refactor to the way this library works. Not being able to send a float array within a struct is a show stopper. I ended up doing PInvoke to the CUDA Runtime and not using CUDAfy."
            ],
            [
                "This is a limitation of .NET, not CUDAfy. Data must be blittable and a non-fixed size array is not. This is valid and based on the CUDAfy unit tests on codeplex: [Cudafy] [StructLayout(LayoutKind.Sequential, Size=64, CharSet = CharSet.Unicode)] public unsafe struct PrimitiveStruct { public fixed sbyte Message[32]; public fixed char MessageChars[16]; } There is also no reason to store the array length explicitly since you can use the Length property within device code."
            ]
        ],
        "votes": [
            1.0000001,
            1.0000001
        ]
    },
    {
        "question": "I was using CUDA C for evaluation and now started using cudafy .net. Lets assume that I have the following enum [Cudafy] public enum MyEnum { mon = 0,tue=1,wed=2,thu=3,fri=4,sat=5 } I want to pass it to a Kernel [Cudafy] public static void Enum_Kernel(GThread thread, MyEnum[] en) { MyEnum day = en[thread.threadIdx.x]; } I am allocating memory MyEnum [] enum1 = new MyEnum[10]; for (int i = 0; i &lt; 10; i++) { enum1[i] = MyEnum.mon; } MyEnum [] d_enum1 = gpu.CopyToDevice&lt;MyEnum&gt;(enum1); During runtime, the program crashes at the aboce line with the message Whats the issue i need to address ?",
        "answers": [
            [
                "You do not need to allocate memory by yourself. Just tell the cudafy module what struct type you want to use. Example from cudafy: // in your main execution method CudafyModule km = CudafyTranslator.Cudafy(typeof(ComplexFloat)); GPGPU gpu = CudafyHost.GetDevice(eGPUType.Cuda); gpu.LoadModule(km); // the struct [Cudafy] public struct ComplexFloat { public ComplexFloat(float r, float i) { Real = r; Imag = i; } public float Real; public float Imag; public ComplexFloat Add(ComplexFloat c) { return new ComplexFloat(Real + c.Real, Imag + c.Imag); } }"
            ],
            [
                "Try to replace enum with simple int."
            ]
        ],
        "votes": [
            1.0000001,
            1.0000001
        ]
    },
    {
        "question": "I would like to use the Texture Memory for Interpolation of Data. I have 2 Arrays (namely A[i] and B[i]) and I would want to interpolate Data between them. I thought I could bind them to Texture Memory and set the interpolation but I am not sure how I can do that. The examples that come with CUDA use the A[i-1] and A[i+1] for the interpolation. Is there any way to do what I planned? I'm trying this because I think I can get a good speedup.",
        "answers": [
            [
                "Yes, you can do this with texture memory, and it is fast. I personally use ArrayFire to accomplish these kinds of operations, because it is faster than I can hope to code by hand. If you want to code by hand yourself in CUDA, something like this is what you want: // outside kernel texture&lt;float,1&gt; A; cudaChannelFormatDesc desc = cudaCreateChannelDesc&lt;float&gt;(); cudaArray *arr = NULL; cudaError_t e = cudaMallocArray(&amp;arr, &amp;desc, 1, length); A.filterMode = cudaFilterModePoint; A.addressMode[0] = cudaAddressModeClamp; cudaBindTextureToArray(A, arr, desc); ... // inside kernel valA = tex1D(A,1,idx) valB = tex1D(B,1,idx) float f = 0.5; output = (f)*valA + (1-f)*valB; If you want to just plug-in ArrayFire (which in my experience is faster than what I try to code by hand, not to mention way simpler to use), then you'll want: // in arrayfire array A = randu(10,1); array B = randu(10,1); float f = 0.5; array C = (f)*A + (1-f)*B; The above assumes you want to interpolate between corresponding indices of 2 different arrays or matrices. There are other interpolation functions available too."
            ],
            [
                "If you're not used to developing with CUDA, using texture memory is not the easiest thing to start with. I'd suggest you to try writing a first parallel version of your algorithm in CUDA with no optimisation. Then, use the NVIDIA Visual Profiler on your application to figure out whether you need to set up texture memory to optimize your memory accesses. Remember that the earlier you optimize, the trickier it is to debug. Last but not least, the latest CUDA version (CUDA 5, still in release candidate) is able to automatically store your data in texture memory as long as you declare the input buffers passed as parameters to your kernel as const restrict pointers."
            ]
        ],
        "votes": [
            2.0000001,
            2.0000001
        ]
    },
    {
        "question": "Closed. This question is off-topic. It is not currently accepting answers. Want to improve this question? Update the question so it's on-topic for Stack Overflow. Closed 10 years ago. Improve this question I have two laptops: a Sony vaio z-series (vocz1) &amp; S series. The first one has Geforce with cuda model GT330M and second one has GT 640M LE. When I am trying install CUDA Geforce driver from this site http://developer.nvidia.com/cuda/cuda-downloads I am receiving below error in Windows. I am wondering would you suggest me a solution to solve this issue? all of my graphic card already installed, Nvidia installer cannot continue This graphics card could not find compatible graphics hardware. I am beginner in programming with CUDA, I want to know can I compile and run my CUDA program with out installing Nividia Driver? Cuda toolkit and SDK installed successfully in my machine but whenI run my program I cannot set my Cuda device. Does it mean I need to install Nividia Driver? cudaError_t cudaStatus1; int deviceCount; cudaGetDeviceCount(&amp;deviceCount); int device; for (device = 0; device &lt; 10; ++device) { cudaDeviceProp deviceProp; cudaGetDeviceProperties(&amp;deviceProp, device); // Choose which GPU to run on, change this on a multi-GPU system. cudaStatus1 = cudaSetDevice(device); printf(\"Device %d has compute capability %d.%d. - %d\\n\", device, deviceProp.major, deviceProp.minor,cudaStatus1 ); } output: Device 0 has compute capability 3137268.3137268. - 35 Device 1 has compute capability 3137268.3137268. - 35 Device 2 has compute capability 3137268.3137268. - 35 Device 3 has compute capability 3137268.3137268. - 35 Device 4 has compute capability 3137268.3137268. - 35 Device 5 has compute capability 3137268.3137268. - 35 Device 6 has compute capability 3137268.3137268. - 35 Device 7 has compute capability 3137268.3137268. - 35 Device 8 has compute capability 3137268.3137268. - 35 Device 9 has compute capability 3137268.3137268. - 35 35 means it is not set the device , if it became 0 means device set. after I run deviceQuery below information I received: Microsoft Windows [Version 6.1.7601] Copyright (c) 2009 Microsoft Corporation. All rights reserved. C:\\Users\\xx&gt;\"C:\\ProgramData\\NVIDIA Corporation\\NVIDIA GPU Computing SDK 4.2\\C\\ bin\\win64\\Release\\deviceQuery.exe\" [deviceQuery.exe] starting... C:\\ProgramData\\NVIDIA Corporation\\NVIDIA GPU Computing SDK 4.2\\C\\bin\\win64\\Relea se\\deviceQuery.exe Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Found 1 CUDA Capable device(s) Device 0: \"GeForce GT 640M LE\" CUDA Driver Version / Runtime Version 4.2 / 4.2 CUDA Capability Major/Minor version number: 3.0 Total amount of global memory: 1024 MBytes (1073741824 bytes) ( 2) Multiprocessors x (192) CUDA Cores/MP: 384 CUDA Cores GPU Clock rate: 405 MHz (0.41 GHz) Memory Clock rate: 900 Mhz Memory Bus Width: 128-bit L2 Cache Size: 262144 bytes Max Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536,65536), 3 D=(4096,4096,4096) Max Layered Texture Size (dim) x layers 1D=(16384) x 2048, 2D=(16384,16 384) x 2048 Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Maximum sizes of each dimension of a block: 1024 x 1024 x 64 Maximum sizes of each dimension of a grid: 2147483647 x 65535 x 65535 Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and execution: Yes with 1 copy engine(s) Run time limit on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Concurrent kernel execution: Yes Alignment requirement for Surfaces: Yes Device has ECC support enabled: No Device is using TCC driver mode: No Device supports Unified Addressing (UVA): No Device PCI Bus ID / PCI location ID: 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simu ltaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 4.2, CUDA Runtime Versi on = 4.2, NumDevs = 1, Device = GeForce GT 640M LE [deviceQuery.exe] test results... PASSED exiting in 3 seconds: 3...2...1...done!",
        "answers": [
            [
                "I want to know can I compile and run my CUDA program with out installing Nividia Driver? Cuda toolkit and SDK installed successfully in my machine but whenI run my program I cannot set my Cuda device. Does it mean I need to install Nividia Driver? You will definitely need drivers to run the program. Have you tried running deviceQuery.exe provided with the binaries. That should give you a good starting point as to what is going wrong."
            ],
            [
                "I have a VAIO too and I had the same problem. Don't download notebook version, try Desktop version of Nvidia Driver. I also had to disable my another Graphic card (Intel). It worked for me."
            ],
            [
                "Unfortunately, there are many NVIDIA GPUs for which the driver from the NVIDIA website will not install (especially for GPU versions that are specifically OEM'd for Sony, Lenovo, etc and the OEM wants to control the driver experience). This is most likely the case for you. In those cases, you can edit the .inf file to add your GPU into the list of GPUs for which the driver will install. However, it is a bit tricky and typically requires editing 3 different sections of the INF file. You can search around for details on how to mod NVIDIA inf files; there are a number of sites that do that. Of course, you have to have the appropriate CUDA driver before you can run CUDA stuff. So first things first... you've gotta get the driver installed."
            ]
        ],
        "votes": [
            1.0000001,
            1.0000001,
            1.0000001
        ]
    },
    {
        "question": "I try to develop a form application using CUDA.NET in Visual Stuio C#. However I need to create cubin file, here is my problem: I tried to create cubin file using Visual Studio. I changed the setting in Project Properties-&gt;Configuration Properties-&gt;Cuda Runtime API-&gt;GPU-&gt;NVCC Compilation Type to \"Generate 64 bit .cubin file (-m64 -cubin)\" from \"Generate hybrid object file (--compile / -c)\". But I got this error \"fatal error LNK1181: cannot open input file '.\\Debug\\histogram256.cu.obj'\". It cannot find the object of some of my .cu files. So I changed only those .cu files' \"NVCC Compilation Type\" setting to (-m64 -cubin) and compile them alone by right clicking on those files. However it did not create any .obj or .cubin file. Then I tried to compile it from the command line. I copied the line in the .cu file's Property Page-&gt;Cuda Runtime API-&gt;Command Line which is \" \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v4.0\\bin\\nvcc.exe\" -gencode=arch=compute_20,code=\\\"sm_20,compute_20\\\" -gencode=arch=compute_20,code=\\\"sm_20,compute_20\\\" --machine 32 -ccbin \"c:\\Program Files\\Microsoft Visual Studio 9.0\\VC\\bin\" -Xcompiler \"/EHsc /W3 /nologo /O2 /Zi /MT \" -I\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v4.0\\include\" -maxrregcount=0 --compile -o \"Debug/device.cubin\" \"device.cu\"\" device.cu is my cuda file. It created the .cubin file, but I got this error from CUDA.NET: \"GASS.CUDA.CUResult.ErrorInvalidImage.\" Do you have any suggestions?",
        "answers": [
            [
                "1: be sure that your viedecard support gencode-arch and code you specify. 2: You compile for 32 bit, be sure u are compiling and reference cuda.net for 32 bit also for .net. 3: Use managedcuda (codeplex) is much much better samples and documentation are provided."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "In CUDA to cover multiple blocks, and thus incerase the range of indices for arrays we do some thing like this: Host side Code: dim3 dimgrid(9,1)// total 9 blocks will be launched dim3 dimBlock(16,1)// each block is having 16 threads // total no. of threads in // the grid is thus 16 x9= 144. Device side code ... ... idx=blockIdx.x*blockDim.x+threadIdx.x;// idx will range from 0 to 143 a[idx]=a[idx]*a[idx]; ... ... What is the equivalent in OpenCL for acheiving the above case ?",
        "answers": [
            [
                "On the host, when you enqueue your kernel using clEnqueueNDRangeKernel, you have to specify the global and local work size. For instance: size_t global_work_size[1] = { 144 }; // 16 * 9 == 144 size_t local_work_size[1] = { 16 }; clEnqueueNDRangeKernel(cmd_queue, kernel, 1, NULL, global_work_size, local_work_size, 0, NULL, NULL); In your kernel, use: size_t get_global_size(uint dim); size_t get_global_id(uint dim); size_t get_local_size(uint dim); size_t get_local_id(uint dim); to retrieve the global and local work sizes and indices respectively, where dim is 0 for x, 1 for y and 2 for z. The equivalent of your idx will thus be simply size_t idx = get_global_id(0); See the OpenCL Reference Pages."
            ],
            [
                "Equivalences between CUDA and OpenCL are: blockIdx.x*blockDim.x+threadIdx.x = get_global_id(0) LocalSize = blockDim.x GlobalSize = blockDim.x * gridDim.x"
            ]
        ],
        "votes": [
            4.0000001,
            1.0000001
        ]
    },
    {
        "question": "I'm writing an article about CUDA and their wrappers and right now I'm stuck with what layer of CUDA is used by CUDA.NET or JCUDA. As this suggests: (source: tomshw.it) I guess as my program suggests when i use CUBLAS cublas = new CUBLAS(cuda); that I'm using a Library or a library on CUDA Runtime. I'm right, or what is the best definition? And wrapper is the best definition to CUDA.NET or brigde or something.",
        "answers": [
            [
                "Cuda.net is implemented via Cuda Driver"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I'm developing a program that moves a lot of data from Excel Sheets to a database. Is it possible for something like CUDA to speed up the process? Is it possible for me to use it to open more than one sheet at once and have different cores sharing the work?",
        "answers": [
            [
                "CUDA can speed up computational processing, but not bottlenecks due to network bandwidth / latency, or slow (compared to the rest of your application/machine) IO performance. In your case, you are probably not putting a lot of stress on your CPU, so your code will most likely not benefit from offloading code to the GPU. Edit: Basically, what Anon says."
            ],
            [
                "No. CUDA speeds up data processing. If you were doing a bunch of number crunching, it may help you. But simply extracting data from excel and bulk inserting to a database has nothing to do with CUDA."
            ]
        ],
        "votes": [
            2.0000001,
            2.0000001
        ]
    },
    {
        "question": "I'm trying to write a childish app with CUDA.Net, but I'm out of luck. I've figured out to: using GASS.CUDA; // ... var c = new CUDA(); // c.Launch(myfunc); // ???? how ??? myfunc apparently should be of type GASS.CUDA.Types.CUfunction but I didn't find how to define one.",
        "answers": [
            [
                "First you need a .cu file with your kernel (function to be executed on a GPU). Let's have a file mykernel.cu: extern \"C\" __global__ void fooFunction(float4* data) { // there can be some CUDA code ... } This have to be compiled into a .cubin file with the nvcc compiler. In order to let the compiler know of the Visual C++ compiler, you need to call it from within the Visual Studio Command Prompt: nvcc mykernel.cu --cubin This creates the mykernel.cubin file in the same directory. Then in a C# code you can load this binary module and execute the kernel. In the higher-level object API of GASS.CUDA it can look like this: using GASS.CUDA; // ... CUDA cuda = new CUDA(true); // select first available device (GPU) cuda.CreateContext(0); // load binary kernel module (eg. relative to from bin/Debug/) CUmodule module = cuda.LoadModule(\"../../mykernel.cubin\"); // select function from the module CUfunction function = cuda.GetModuleFunction(module, \"fooFunction\"); // execute the function fooFunction() on a GPU cuda.Launch(function); That's it! The nvcc compiler should be called as a build action better than calling it by hand. If anyone knows how to accomplish that, please let us know."
            ],
            [
                "Unfortunately CUDA.net is very badly documented, but http://www.hoopoe-cloud.com/files/cuda.net/2.0/CUDA.NET_2.0.pdf should help you get started. Furthermore you still need to write your kernel in CUDA C, so http://developer.download.nvidia.com/compute/cuda/3_2_prod/toolkit/docs/CUDA_C_Programming_Guide.pdf will be a good idea to have a look at as well, and perhaps try to start with a start CUDA C application before porting it to CUDA.net."
            ]
        ],
        "votes": [
            8.0000001,
            2.0000001
        ]
    },
    {
        "question": "I'm currently using CUDA.NET library by GASS. I need to initialize cuda arrays (actually cublas vectors, but it doesn't matters) in one CPU thread and use them in other CPU thread. But CUDA context which holding all initialized arrays and loaded functions, can be attached only to one CPU thread. There is mechanism called context migration API to detach context from one thread and attach it to another. But i don't how to properly use it in CUDA.NET. I tried something like this: class Program { private static float[] vector1, vector2; private static CUDA cuda; private static CUBLAS cublas; private static CUdeviceptr ptr; static void Main(string[] args) { cuda = new CUDA(false); cublas = new CUBLAS(cuda); cuda.Init(); cuda.CreateContext(0); AllocateVectors(); cuda.DetachContext(); CUcontext context = cuda.PopCurrentContext(); GetVectorFromDeviceAsync(context); } private static void AllocateVectors() { vector1 = new float[]{1f, 2f, 3f, 4f, 5f}; ptr = cublas.Allocate(vector1.Length, sizeof (float)); cublas.SetVector(vector1, ptr); vector2 = new float[5]; } private static void GetVectorFromDevice(object objContext) { CUcontext localContext = (CUcontext) objContext; cuda.PushCurrentContext(localContext); cuda.AttachContext(localContext); //change vector somehow vector1[0] = -1; //copy changed vector to device cublas.SetVector(vector1, ptr); cublas.GetVector(ptr, vector2); CUDADriver.cuCtxPopCurrent(ref localContext); } private static void GetVectorFromDeviceAsync(CUcontext cUcontext) { Thread thread = new Thread(GetVectorFromDevice); thread.IsBackground = false; thread.Start(cUcontext); } } But execution fails on attempt to copy changed vector to device because context is not attached. Other reasons are unlikely, because it works fine in single threaded mode. Any ideas how i can get it work?",
        "answers": [
            [
                "I still have not found a solution for this problem but i did came up with a workaround. The point is to execute all the functions which have something to deal with CUDA in one CPU thread. For example, you can do it like this: class Program { private static float[] vector1, vector2; private static CUDA cuda; private static CUBLAS cublas; private static CUdeviceptr ptr; private static readonly AutoResetEvent autoResetEvent = new AutoResetEvent(false); static void Main() { cuda = new CUDA(true); cublas = new CUBLAS(cuda); //allocate vector on cuda device in main thread CudaManager.CallMethod(AllocateVectors); //changing first vector from other thread Thread changeThread = new Thread(ChangeVectorOnDevice_ThreadRun) { IsBackground = false }; changeThread.Start(); //wait for changeThread to finish autoResetEvent.WaitOne(); //getting vector from device in another one thread Thread getThread = new Thread(GetVectorFromDevice_ThreadRun) { IsBackground = false }; getThread.Start(); //wait for getThread to finish autoResetEvent.WaitOne(); Console.WriteLine(\"({0}, {1}, {2}, {3}, {4})\", vector2[0], vector2[1], vector2[2], vector2[3], vector2[4]); Console.ReadKey(true); } private static void AllocateVectors() { vector1 = new[] { 1f, 2f, 3f, 4f, 5f }; vector2 = new float[5]; //allocate memory and copy first vector to device ptr = cublas.Allocate(vector1.Length, sizeof(float)); cublas.SetVector(vector1, ptr); } private static void GetVectorFromDevice() { cublas.GetVector(ptr, vector2); } private static void ChangeVectorOnDevice() { //changing vector and copying it to device vector1 = new[] { -1f, -2f, -3f, -4f, -5f }; cublas.SetVector(vector1, ptr); } private static void ChangeVectorOnDevice_ThreadRun() { CudaManager.CallMethod(ChangeVectorOnDevice); //releasing main thread autoResetEvent.Set(); } private static void GetVectorFromDevice_ThreadRun() { CudaManager.CallMethod(GetVectorFromDevice); //releasing main thread autoResetEvent.Set(); } } public static class CudaManager { public static Action WorkMethod { get; private set; } private static readonly AutoResetEvent actionRecived = new AutoResetEvent(false); private static readonly AutoResetEvent callbackEvent = new AutoResetEvent(false); private static readonly object mutext = new object(); private static bool isCudaThreadRunning; private static void ThreadRun() { //waiting for work method to execute while (actionRecived.WaitOne()) { //invoking recived method WorkMethod.Invoke(); //releasing caller thread callbackEvent.Set(); } } static CudaManager() { Run(); } public static void Run() { if (!isCudaThreadRunning) { Thread thread = new Thread(ThreadRun); thread.IsBackground = true; thread.Start(); isCudaThreadRunning = true; } } public static void CallMethod(Action method) { lock (mutext) { WorkMethod = method; //releasing ThreadRun method actionRecived.Set(); //blocking caller thread untill delegate invokation is complete callbackEvent.WaitOne(); } } } I hope it's gonna help someone."
            ],
            [
                "Check out CUDAContextSynchronizer class in GASS documentation."
            ]
        ],
        "votes": [
            2.0000001,
            1.0000001
        ]
    },
    {
        "question": "Trying to make an app that will compare 1-to-multiple bitmaps. there is one reference bitmap and multiple other bitmaps. Result from each compare should be new bitmap with diffs. Maybe comparing bitmaps rather as textures than arrays? My biggest problem is making kernel accept more than one input pointer, and how to compare the data.. extern \"C\" __global__ void compare(float *odata, float *idata, int width, int height) works and following does not (i call the function with enough params) extern \"C\" __global__ void compare(float *odata, float *idata, float *idata2, int width, int height)",
        "answers": [
            [
                "Your function prototypes are OK. The problem lies elsewhere. In general, make sure that you are properly allocating device memory for all input and output arrays, and make sure that you're correctly copying data to and from your device arrays."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'm trying to set my simulation params in constant memory but without luck (CUDA.NET). cudaMemcpyToSymbol function returns cudaErrorInvalidSymbol. The first parameter in cudaMemcpyToSymbol is string... Is it symbol name? actualy I don't understand how it could be resolved. Any help appreciated. //init, load .cubin float[] arr = new float[1]; arr[0] = 0.0f; int size = Marshal.SizeOf(arr[0]) * arr.Length; IntPtr ptr = Marshal.AllocHGlobal(size); Marshal.Copy(arr, 0, ptr, arr.Length); var error = CUDARuntime.cudaMemcpyToSymbol(\"param\", ptr, 4, 0, cudaMemcpyKind.cudaMemcpyHostToDevice); my .cu file contain __constant__ float param; Working solution cuda.LoadModule(Path.Combine(Environment.CurrentDirectory, \"name.cubin\")); simParams = cuda.GetModuleGlobal(\"params\"); float[] parameters = new float[N]{...} cuda.CopyHostToDevice&lt;float&gt;(simParams, parameters);",
        "answers": [
            [
                "Unfortunately the __ constant __ must be in the same file scope as the memcpy to the symbol, and in your case your __ constant __ is in a separate .cu file. The simple way around this is to provide a wrapper function in your .cu file, for example: __constant__ float param; // Host function to set the constant void setParam(float value) { cudaMemcpyToSymbol(\"param\", ptr, 4, 0, cudaMemcpyHostToDevice); } // etc. __global__ void ..."
            ],
            [
                "If this question is actual you can use cuModuleGetGlobal and next cudaMemcpy like this: private bool setValueToSymbol(CUmodule module, string symbol, int value) { CUdeviceptr devPtr = new CUdeviceptr(); uint lenBytes = 0; CUResult result = CUDADriver.cuModuleGetGlobal(ref devPtr, ref lenBytes, module, symbol); if (result == CUResult.Success) { int[] src = new int[] { value }; cudaError error = CUDARuntime.cudaMemcpy(devPtr, src, lenBytes, cudaMemcpyKind.cudaMemcpyHostToDevice); if (error == cudaError.cudaSuccess) return true; else return false; } else { return false; } } where CUmodule module = cuda.LoadModule(\"MyCode.cubin\"); This code works with NVIDIA GPU Computing SDK 3.1 and CUDA.NET 3.0."
            ],
            [
                "constant memory has implicit local scope linkage. make sure declaration is in the same file where you use it. it sounds like you have two files. may also have to declare param to array (or maybe not)"
            ]
        ],
        "votes": [
            5.0000001,
            2.0000001,
            1.0000001
        ]
    },
    {
        "question": "Is there an efficient way to take a subset of a C# array and pass it to another peice of code (without modifying the original array)? I use CUDA.net which has a function which copies an array to the GPU. I would like to e.g. pass the function a 10th of the array and thus copy each 10th of the array to the GPU seperately (for pipelining purposes). Copying the array in this way should be as efficient as copying it in one go. It can be done with unsafe code and just referencing the proper memory location but other than that I'm not sure. The CopyTo function copies the entire array to another array so this does not appear useful.",
        "answers": [
            [
                "Okay, I'd misunderstood the question before. What you want is System.Buffer.BlockCopy or System.Array.Copy. The LINQ ways will be hideously inefficient. If you're able to reuse the buffer you're copying into, that will also help the efficiency, avoiding creating a new array each time - just copy over the top. Unless you can divide your \"big\" array up equally though, you'll need a new one for the last case."
            ],
            [
                "I'm not sure how efficient this is but... int[] myInts = new int[100]; //Code to populate original arrray for (int i = 0; i &lt; myInts.Length; i += 10) { int[] newarray = myInts.Skip(i).Take(10).ToArray(); //Do stuff with new array }"
            ],
            [
                "You could try Marshal.Copy if you need to go from an array of bytes to an unmanaged pointer. That avoids creating unsafe code yourself. Edit: This would clearly only work if you reimplement their API. Sorry - misunderstood. You want an efficient subarray method. It strikes me that what you really want is an api in the original class of the form void CopyToGpu(byte[] source, int start, int length);"
            ],
            [
                "You could use extension methods and yield return: public static IEnumerable Part&lt;T&gt;(this T[] array, int startIndex, int endIndex ) { for ( var currentIndex = startIndex; currentIndex &lt; endIndex; ++currentIndex ) yield return array[currentIndex]; }"
            ]
        ],
        "votes": [
            12.0000001,
            3.0000001,
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "When writing CUDA applications, you can either work at the driver level or at the runtime level as illustrated on this image (The libraries are CUFFT and CUBLAS for advanced math): (source: tomshw.it) I assume the tradeoff between the two are increased performance for the low-evel API but at the cost of increased complexity of code. What are the concrete differences and are there any significant things which you cannot do with the high-level API? I am using CUDA.net for interop with C# and it is built as a copy of the driver API. This encourages writing a lot of rather complex code in C# while the C++ equivalent would be more simple using the runtime API. Is there anything to win by doing it this way? The one benefit I can see is that it is easier to integrate intelligent error handling with the rest of the C# code.",
        "answers": [
            [
                "The CUDA runtime makes it possible to compile and link your CUDA kernels into executables. This means that you don't have to distribute cubin files with your application, or deal with loading them through the driver API. As you have noted, it is generally easier to use. In contrast, the driver API is harder to program but provided more control over how CUDA is used. The programmer has to directly deal with initialization, module loading, etc. Apparently more detailed device information can be queried through the driver API than through the runtime API. For instance, the free memory available on the device can be queried only through the driver API. From the CUDA Programmer's Guide: It is composed of two APIs: A low-level API called the CUDA driver API, A higher-level API called the CUDA runtime API that is implemented on top of the CUDA driver API. These APIs are mutually exclusive: An application should use either one or the other. The CUDA runtime eases device code management by providing implicit initialization, context management, and module management. The C host code generated by nvcc is based on the CUDA runtime (see Section 4.2.5), so applications that link to this code must use the CUDA runtime API. In contrast, the CUDA driver API requires more code, is harder to program and debug, but offers a better level of control and is language-independent since it only deals with cubin objects (see Section 4.2.5). In particular, it is more difficult to configure and launch kernels using the CUDA driver API, since the execution configuration and kernel parameters must be specified with explicit function calls instead of the execution configuration syntax described in Section 4.2.3. Also, device emulation (see Section 4.5.2.9) does not work with the CUDA driver API. There is no noticeable performance difference between the API's. How your kernels use memory and how they are laid out on the GPU (in warps and blocks) will have a much more pronounced effect."
            ],
            [
                "I have found that for deployment of libraries in multi-threaded applications, the control over CUDA context provided by the driver API was critical. Most of my clients want to integrate GPU acceleration into existing applications, and these days, almost all applications are multi-threaded. Since I could not guarantee that all GPU code would be initialized, executed and deallocated from the same thread, I had to use the driver API. My initial attempts with various work-arounds in the runtime API all led to failure, sometimes in spectacular fashion - I found I could repeatedly, instantly reboot a machine by performing just the wrong set of CUDA calls from different threads. Since we migrated everything over the Driver API, all has been well."
            ],
            [
                "a couple of important things to note: first the differences between the APIs only apply to the host side code. The kernels are exactly the same. on the host side the complexity of the driver api is pretty trivial, the fundamental differences are: in driver api you have access to functionality that is not available in the runtime api like contexts. the emulator only works with code written for the runtime api. oh and currently cudpp which is a very handy library only works with the runtime api."
            ],
            [
                "There are some real issues with argument alignment and the driver API. Check out the CUDA 2.2 beta (or later) documentation for more information."
            ]
        ],
        "votes": [
            48.0000001,
            26.0000001,
            5.0000001,
            1e-07
        ]
    }
]