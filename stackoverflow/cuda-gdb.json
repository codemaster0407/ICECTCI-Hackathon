[
    {
        "question": "Trying to use CUDA-GDB instead of brutal printfs in the code, I found it does not give proper values at the end of a large array. The following is a simple code that creates and fills some values to the array of size 200,000. It contains some brutal printf function, and a dummy function just to make breakpoint during cuda-gdb. Dummy function includes some manipulation of array hoping the compiler does not neglect or optimize this function. test.cu #include &lt;cstdlib&gt; #include &lt;cstdio&gt; #include &lt;cuda_runtime.h&gt; __global__ void fillArray(double4 *Array, int n) { int index = blockDim.x * blockIdx.x + threadIdx.x; if (index &gt;= n) return; double4 tmpArray; tmpArray.x = (double)index + 0.1; tmpArray.y = (double)index + 0.2; tmpArray.z = (double)index + 0.3; tmpArray.w = (double)index + 0.4; Array[index] = tmpArray; } __global__ void printFromDevice(double4 *Array, int target) { double4 tmpArray = Array[target]; printf(\"Array[%d] = %e %e %e %e \\n\", target, tmpArray.x, tmpArray.y, tmpArray.z, tmpArray.w); } __global__ void dummyFunction(double4 *Array, int target) { double4 tmpArray; tmpArray = Array[target/2]; tmpArray.x = -1234.; tmpArray.y = -1235.; tmpArray.z = -1236.; tmpArray.w = -1237.; // This is the 30th line Array[target/2] = tmpArray; } int main(int argc, char **argv) { int N = 200000; double *dArray; cudaMalloc((void **)&amp;dArray, sizeof(double)*4*N); int nThreads = 128; int nBlocks = (N-1)/nThreads + 1; fillArray&lt;&lt;&lt;nBlocks,nThreads&gt;&gt;&gt; ((double4 *)dArray, N); printFromDevice&lt;&lt;&lt;1,1&gt;&gt;&gt; ((double4 *)dArray, 199999); dummyFunction&lt;&lt;&lt;1,1&gt;&gt;&gt; ((double4 *)dArray, 100); cudaDeviceSynchronize(); // This is the 46th line return 0; } I compiled this via nvcc -g -G ./test.cu -o ./exe and the following is CUDA-GDB results. $ cuda-gdb ./exe (cuda-gdb) b test.cu:30 (cuda-gdb) r Thread 1 \"exe\" hit Breakpoint 1, dummyFunction&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; (Array=0x2aaae9800000, target=100) at test.cu:31 31 Array[target/2] = tmpArray; (cuda-gdb) print Array[199999] Error: Failed to read generic memory at address 0x2aaae9e1a7e0 on device 0 sm 0 warp 1 lane 0, error=CUDBG_ERROR_INVALID_MEMORY_ACCESS(0x8). (cuda-gdb) print Array[199998] Error: Failed to read generic memory at address 0x2aaae9e1a7c0 on device 0 sm 0 warp 1 lane 0, error=CUDBG_ERROR_INVALID_MEMORY_ACCESS(0x8). (cuda-gdb) print Array[199000] $1 = {x = 199000.10000000001, y = 199000.20000000001, z = 199000.29999999999, w = 199000.39999999999} (cuda-gdb) b test.cu:46 Breakpoint 2 at 0x403d0b: file test.cu, line 46. (cuda-gdb) cont Continuing. Thread 1 \"exe\" hit Breakpoint 2, main (argc=1, argv=0x7fffffffda98) at test.cu:46 46 cudaDeviceSynchronize(); (cuda-gdb) print ((@global double4 *)dArray)[199999] Error: Failed to read 32 bytes of global memory from 0x2aaae9e1a7e0 , error=CUDBG_ERROR_INVALID_MEMORY_ACCESS(0x8). (cuda-gdb) cont Continuing. Array[199999] = 1.999991e+05 1.999992e+05 1.999993e+05 1.999994e+05 To summary, Memory is not an issue, with compute-sanitizer. Brutal printFromDevice gives proper result, thereby double4 array of size 200,000 is properly allocated and filled in the device memory. Until some point, CUDA-GDB gives the correct values but it fails to give proper value near the end of the array in both ways i) breakpoint in global function, ii) break point in the host function. Why is this?? My CUDA-GDB version is like this NVIDIA (R) CUDA Debugger 11.5 release Portions Copyright (C) 2007-2021 NVIDIA Corporation GNU gdb (GDB) 10.1 Copyright (C) 2020 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-pc-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see:",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am using this Amazon Linux 2 AMI with NVIDIA TESLA GPU Driver $ cat /etc/*-release NAME=\"Amazon Linux\" VERSION=\"2\" ID=\"amzn\" ID_LIKE=\"centos rhel fedora\" VERSION_ID=\"2\" PRETTY_NAME=\"Amazon Linux 2\" ANSI_COLOR=\"0;33\" CPE_NAME=\"cpe:2.3:o:amazon:amazon_linux:2\" HOME_URL=\"https://amazonlinux.com/\" Amazon Linux release 2 (Karoo) It came out of the box with cuda 9.2 (nvcc --version) and driver R450 I am using cmake 3.26 to create a shared library (.so) that has all of my kernels. Now, I have been trying to debug with its corresponding cuda-gdb but it seems it lacks some functionality to stop in my kernel breakpoints: NVIDIA (R) CUDA Debugger 9.2 release Portions Copyright (C) 2007-2018 NVIDIA Corporation GNU gdb (GDB) 7.12 Copyright (C) 2016 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-pc-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\". warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time ... [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib64/libthread_db.so.1\". ... warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time 0x00007fc5a6a183dc in select () from /lib64/libc.so.6 I tried: I could not find an AMI with a newer CUDA Toolkit, so I installed the cuda toolkit 12.2 (latest now) and avoided the driver. I saw in the official compatibility table that cuda 12 may run using my current driver: $ nvidia-smi Thu Jul 20 20:29:10 2023 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 450.216.04 Driver Version: 450.216.04 CUDA Version: 11.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla K80 On | 00000000:00:1E.0 Off | 0 | | N/A 38C P8 29W / 149W | 0MiB / 11441MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ ok. I rebuilt my project and when I try to debug I see that I effectively need the new driver NVIDIA (R) CUDA Debugger CUDA Toolkit 12.2 release Portions Copyright (C) 2007-2023 NVIDIA Corporation GNU gdb (GDB) 12.1 Copyright (C) 2022 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-pc-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: &lt;https://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\". Using python library libpython3.7m.so No source file named AAA.cpp. No source file named AAA.cpp. [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib64/libthread_db.so.1\". [Detaching after fork from child process 5732] Incompatible CUDA driver version. Expected 12.2.134 or later and found 8.0.129 instead.&amp;\"fatal: Incompatible CUDA driver version. (error code = CUDBG_ERROR_INCOMPATIBLE_API(0x13)\\n\" While installing again the CUDA Toolkit (now selecting the driver) I see the log: [INFO]: Driver not installed. [INFO]: Checking compiler version... [INFO]: gcc location: /bin/gcc [INFO]: gcc version: gcc version 7.3.1 20180712 (Red Hat 7.3.1-15) (GCC) [INFO]: Initializing menu [INFO]: nvidia-fs.setKOVersion(2.16.1) [INFO]: Setup complete [INFO]: Installing: Driver [INFO]: Installing: 535.54.03 [INFO]: Executing NVIDIA-Linux-x86_64-535.54.03.run --ui=none --no-questions --accept-license --disable-nouveau --no-cc-version-check --install-libglvnd 2&gt;&amp;1 [INFO]: Finished with code: 3840 [ERROR]: Install of driver component failed. Consult the driver log at /var/log/nvidia-installer.log for more details. [ERROR]: Install of 535.54.03 failed, quitting later, /var/log/nvidia-installer.log is empty. I suspect some protection from the Amazon distro. question: how may I debug my code? I am stuck at installing the updated driver (to get newer functionality), but maybe it is unnecessary. PD: vscode debug launch { \"name\": \"mytests\", \"type\": \"cuda-gdb\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/build/myTests\", }, deleting urls to avoid being flagged as spam update 1 So, I finally got another VM : Deep Learning AMI Amazon Linux 2 with Support by Supported Images By: Supported Images Latest Version: 20210714 I have rebuilt the shared library correctly. $ nvidia-smi Fri Jul 21 18:42:30 2023 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 450.119.03 Driver Version: 450.119.03 CUDA Version: 11.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla K80 On | 00000000:00:1E.0 Off | 0 | | N/A 36C P8 28W / 149W | 0MiB / 11441MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ and now again I am finding that cuda-gdb hangs: NVIDIA (R) CUDA Debugger 10.0 release Portions Copyright (C) 2007-2018 NVIDIA Corporation GNU gdb (GDB) 7.12 Copyright (C) 2016 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-pc-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\". warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time [New LWP 2701] [New LWP 2702] [New LWP 2710] [New LWP 2711] [New LWP 2731] [New LWP 2732] [New LWP 2733] attached to process 2693 warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib64/libthread_db.so.1\". warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time 0x00007fbd4e4f5f6c in select () from /lib64/libc.so.6 now it looks like \"Cuda-gdb hangs indefinitely\" https://forums.developer.nvidia.com/t/cuda-gdb-hangs-indefinitely/217087 I will try to explain how I use de debugger. The main app is Python, using a shared library built with cmake and cuda. The tests are smaller scripts cuda-only. Anyway, running without the debugger it does not hang. While running my Python app I use: launch my python app and stop at some break-point. (wherever in the code I want it to be paused) cuda attach, then select the process. at pressing continue (vscode F5) it hangs. Finally: Comments on checking this unsolved issue would be appreciated. I think I may discard the LZMA tags. Maybe I should use some printf() or write content to a text file in order to understand what threads are doing. I may show some cmake code if needed.",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm getting the following error while trying to install mp4box and running the make lib command. /usr/bin/ld: cannot find -lglut collect2: ld returned 1 exit status make[1]: *** [libgpac.so] Error 1 make[1]: Leaving directory `/gpac/src' make: *** [lib] Error 2 After I check the libraries that's what I get: lrwxrwxrwx 1 root root 13 Feb 15 18:25 libGL.so -&gt; mesa/libGL.so -rw-r--r-- 1 root root 905952 Aug 23 2011 libGLU.a lrwxrwxrwx 1 root root 11 Feb 15 18:26 libGLU.so -&gt; libGLU.so.1 lrwxrwxrwx 1 root root 20 Feb 15 18:25 libGLU.so.1 -&gt; libGLU.so.1.3.071000 -rw-r--r-- 1 root root 453272 Aug 23 2011 libGLU.so.1.3.071000 baseem@348588:/usr/lib$ ln -s libGLU.so.1.3.071000 libGL.so ln: creating symbolic link `libGL.so': File exists Note: I'm a total newb in linux so please take that into consideration! Thanks a lot!",
        "answers": [
            [
                "You're going to need an implementation of GLUT. The easiest one to get is FreeGLUT: sudo apt-get install freeglut3 freeglut3-dev"
            ],
            [
                "I was running on the same problem when i was trying to install MP4Box then i found the solution. first of all check to see if your configuration file produce any errors. for example (permission denied error) : in this case you need to change the TMPDIR1 line in your configure file (line 7 before fi) to the following: TMPDIR1=/usr/local/src then you need to install glut using this command : yum install glut-devel now if you run the following command ls /usr/lib64 |grep glut you will se that you have libglut.so (if you cant libglut.so@ you need to create symbolic link to it) then everything should work properly"
            ]
        ],
        "votes": [
            29.0000001,
            1e-07
        ]
    },
    {
        "question": "I write a hello.py that is simply print(\"hi\") and then run cuda-gdb python3 hello.py I get: Reading symbols from python3... (No debugging symbols found in python3) \"/home/x/Desktop/py_projects/hello.py\" is not a core dump: file format not recognized How to debug if I call cuda functions in python code?",
        "answers": [
            [
                "Its possible to use cuda-gdb from python, assuming you only need to debug the C/C++ portion. I don't know of a debugger that can jump from debugging python to debugging CUDA C++. Here is one possible approach, a copy of what is presented here. To debug a CUDA C/C++ library function called from python, the following is one possibility, inspired from this article. For this walk through, I will use the t383.py and t383.cu files verbatim from this answer, and I'll be using CUDA 10, python 2.7.5, on CentOS7 Compile your CUDA C/C++ library using the -G and -g switches, as you would to do ordinary debug: $ nvcc -Xcompiler -fPIC -std=c++11 -shared -arch=sm_60 -G -g -o t383.so t383.cu -DFIX We'll need two terminal sessions for this. I will refer to them as session 1 and session 2. In session 1, start your python interpreter: $ python ... &gt;&gt;&gt; In session 2, find the process ID associated with your python interpreter (replace USER with your actual username): $ ps -ef |grep USER ... USER 23221 22694 0 23:55 pts/0 00:00:00 python ... $ In the above example, 23221 is the process ID for the python interpreter (use man ps for help) In session 2, start cuda-gdb so as to attach to that process ID: $ cuda-gdb -p 23221 ... (lots of spew here) (cuda-gdb) In session 2, at the (cuda-gdb) prompt, set a breakpoint at a desired location in your CUDA C/C++ library. For this example, we will set a breakpoint at one of the first lines of kernel code, line 70 in the t383.cu file. If you haven't yet loaded the library (we haven't, in this walk through), then cuda-gdb will point this out and ask you if you want to make the breakpoint pending on a future library load. Answer y to this (alternatively, before starting this cuda-gdb session, you could have run your python script once from within the interpreter, as we will do in step 7 below. This would load the symbol table for the library and avoid this prompt). After the breakpoint is set, we will issue the continue command in cuda-gdb in order to get the python interpreter running again: (cuda-gdb) break t383.cu:70 No symbol table is loaded. Use the \"file\" command. Make breakpoint pending on future shared library load? (y or [n]) y Breakpoint 1 (t383.cu:70) pending. (cuda-gdb) continue Continuing. In session 1, run your python script: &gt;&gt;&gt; execfile(\"t383.py\") init terrain_height_map 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, our python interpreter has now halted (and is unresponsive), because in session 2 we see that the breakpoint has been hit: [New Thread 0x7fdb0ffff700 (LWP 23589)] [New Thread 0x7fdb0f7fe700 (LWP 23590)] [Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (0,0,0), device 0, sm 0, warp 0, lane 0] Thread 1 \"python\" hit Breakpoint 1, update_water_flow&lt;&lt;&lt;(1,1,1),(1024,1,1)&gt;&gt;&gt; ( water_height_map=0x80080000800000, water_flow_map=0xfffcc000800600, d_updated_water_flow_map=0x7fdb00800800, SIZE_X=4, SIZE_Y=4) at t383.cu:70 70 int col = index % SIZE_X; (cuda-gdb) and we see that the breakpoint is at line 70 of our library (kernel) code, just as expected. ordinary C/C++ cuda-gdb debug can proceed at this point within session 2, as long as you stay within the library function. When you are finished debugging (you may need to remove any breakpoints set) you can once again type continue in session 2, to allow control to return to the python interpreter in session 1, and for your application to finish."
            ],
            [
                "To complete Robert's answer, if you are using CUDA-Python, you can use option --args in order to pass a command-line that contains arguments. For example, this is a valid command-line: $ cuda-gdb --args python3 hello.py Your original command is not valid because, without --args, cuda-gdb takes in parameter a host coredump file. Here is the complete command line with an example from the CUDA-Python repository: $ cuda-gdb -q --args python3 simpleCubemapTexture_test.py Reading symbols from python3... (No debugging symbols found in python3) (cuda-gdb) set cuda break_on_launch application (cuda-gdb) run Starting program: /usr/bin/python3 simpleCubemapTexture_test.py. ... [Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (0,0,0), device 0, sm 0, warp 0, lane 0] 0x00007fff67858600 in transformKernel&lt;&lt;&lt;(8,8,1),(8,8,1)&gt;&gt;&gt; () (cuda-gdb) p $pc $1 = (void (*)()) 0x7fff67858600 &lt;transformKernel&gt; (cuda-gdb) bt #0 0x00007fff67858600 in transformKernel&lt;&lt;&lt;(8,8,1),(8,8,1)&gt;&gt;&gt; ()"
            ]
        ],
        "votes": [
            1.0000001,
            1.0000001
        ]
    },
    {
        "question": "This question already has answers here: Cuda In-Situ memory race issue for algorithms such as convolution of morphologicam dilation (1 answer) Inter-block synchronization in CUDA (1 answer) question about modifing flag array in cuda (1 answer) Closed 10 months ago. I am trying to implement a GPU application which requires the use of a MUTEX. I know this isn't ideal, but for correctness it is required. When the MUTEX is retrieved, which isn't often, all other threads will halt, and then only the single thread is allowed to continue, until it finishes, at which point all threads may continue normal operation. I have tried to implement this using atomic operations to modify the flags, and busy waiting for the waiting threads however, at some point the execution just stops. I thought there was simply a deadlock somewhere in my execution, but this doesn't seem to be the case. The execution seems to simply get stuck in a seemingly arbitrary print statement. Therefore, I was wondering, is there some guarantee that all threads will eventually be processed, or is it possible that the busy waiting loop is hogging all the scheduling cycles of the GPU? This is the busy waiting loop: while (flag) { if(count &gt; 10000){ count = 0; //Only used as breakpoint to see when the cycle has been entered } if (failFlag) { return false; } count++; } This is how the flags are set bool setFlag(int* loc, int val, bool strict=true) { int val_i = val == 0 ? 1 : 0; //In devices, atomically exchange uint64_cu res = atomicCAS(loc, val_i, val); //Make sure the value hasn't changed in the meantime if ( (res != val_i) &amp;&amp; strict) { return false; } __threadfence(); return true; } and this is the seemingly arbitrary line the execution of the second thread never seems to move past printf(\"%i:\\t\\t\\t\\tRebuild\\n\", getThreadID()); where getThreadID() returns threadIdx.x I first tried using memcheck to see if some issue with the memory was coming up, which gave no errors. Then I tried racecheck which also didn't show any issues. I then used some print statements to see roughly where the execution was hanging in the executing thread. Finally, I used the debugger, which showed that the first thread was moving through the busy waiting loop, while the other thread was seemingly stuck on a random print statement I was using to debug (While there were several other similar statements before that point). Here is the debugger, lines 377 to 385 are the busy wait loop, while line 206 is just a statement which prints Thread 1 \"main\" hit Breakpoint 1, MyProgram::insert (this=0x7fffba000000, k=152796131036661202) at /home/User/MyProgramParallel/src/DataStructure.cu:379 379 in /home/User/MyProgramParallel/src/DataStructure.cu (cuda-gdb) info cuda thread Unrecognized option: 'thread'. (cuda-gdb) info cuda threads BlockIdx ThreadIdx To BlockIdx ThreadIdx Count Virtual PC Filename Line Kernel 0 (0,0,0) (0,0,0) (0,0,0) (0,0,0) 1 0x0000555558f25e00 /home/User/MyProgramParallel/src/DataStructure.cu 206 * (0,0,0) (1,0,0) (0,0,0) (1,0,0) 1 0x0000555558f20c70 /home/User/MyProgramParallel/src/DataStructure.cu 379 (cuda-gdb) step 381 in /home/User/MyProgramParallel/src/DataStructure.cu (cuda-gdb) info cuda threads BlockIdx ThreadIdx To BlockIdx ThreadIdx Count Virtual PC Filename Line Kernel 0 (0,0,0) (0,0,0) (0,0,0) (0,0,0) 1 0x0000555558f25e00 /home/User/MyProgramParallel/src/DataStructure.cu 206 * (0,0,0) (1,0,0) (0,0,0) (1,0,0) 1 0x0000555558f20ce0 /home/User/MyProgramParallel/src/DataStructure.cu 381 (cuda-gdb) step 384 in /home/User/MyProgramParallel/src/DataStructure.cu (cuda-gdb) info cuda threads BlockIdx ThreadIdx To BlockIdx ThreadIdx Count Virtual PC Filename Line Kernel 0 (0,0,0) (0,0,0) (0,0,0) (0,0,0) 1 0x0000555558f25e00 /home/User/MyProgramParallel/src/DataStructure.cu 206 * (0,0,0) (1,0,0) (0,0,0) (1,0,0) 1 0x0000555558f20ea0 /home/User/MyProgramParallel/src/DataStructure.cu 384 I would expect both threads to execute steps, with the first moving past line 206, and the other moving through the busy waiting loop. However, this is not the case, no matter how many times I continue the execution the breakpoint. That is why I'm wondering whether there is a liveness guarantee in CUDA? Or is this what a thread looks like after it has crashed? And otherwise, what is another possible reason for this behaviour? Before this point, the two threads seemed to be working in Lockstep. The CUDA version is 11.3, and the operating system is Ubuntu",
        "answers": [],
        "votes": []
    },
    {
        "question": "I am accelerating a MPI program using cuBlas function. To evaluate the application's efficiency, I want to know the FLOPS, memory usage and other stuff of GPU after the program has ran, especially FLOPS. I have read the relevant question:How to calculate Gflops of a kernel. I think the answers give two ways to calculate the FLOPS of a program: The model count of an operation divided by the cost time of the operation Using NVIDIA's profiling tools The first solution doesn't depend on any tools. But I'm not sure the meaning of model count. It's O(f(N))? Like the model count of GEMM is O(N^3)? And if I multiply two matrices of 4 x 5 and 5 x 6 and the cost time is 0.5 s, is the model count 4 x 5 x 6 = 120? So the FLOPS is 120 / 0.5 = 240? The second solution uses nvprof, which is deprecated now and replaced by Nsight System and Nsight Compute. But those two tools only work for CUDA program, instead of MPI program launching CUDA function. So I am wondering whether there is a tool to profile the program launching CUDA function. I have been searching for this question for two days but still can't find an acceptable solution.",
        "answers": [
            [
                "But I'm not sure the meaning of model count. It's O(f(N))? Like the model count of GEMM is O(N^3)? And if I multiply two matrices of 4 x 5 and 5 x 6 and the cost time is 0.5 s, is the model count 4 x 5 x 6 = 120? So the FLOPS is 120 / 0.5 = 240? The standard BLAS GEMM operation is C &lt;- alpha * (A dot B) + beta * C and for A (m by k), B (k by n) and C (m by n), each inner product of a row of A and a column of B multiplied by alpha is 2 * k + 1 flop and there are m * n inner products in A dot B and another 2 * m * n flop for adding beta * C to that dot product. So the total model FLOP count is (2 * k + 3) * (m * n) when alpha and beta are both non-zero. For your example, assuming alpha = 1 and beta = 0 and the implementation is smart enough to skip the extra operations (and most are) GEMM flop count is (2 * 5) * (4 * 6) = 240, and if the execution time is 0.5 seconds, the model arithmetic throughput is 240 / 0.5 = 480 flop/s. I would recommend using that approach if you really need to calculate performance of GEMM (or other BLAS/LAPACK operations). This is the way that most of the computer linear algebra literature and benchmarking has worked since the 1970\u2019s and how most reported results you will find are calculated, including the HPC LINPACK benchmark."
            ],
            [
                "The Using the CLI to Analyze MPI Codes states clearly how to use nsys to collect MPI program runtime information. And the gitlab Roofline Model on NVIDIA GPUs uses ncu to collect real time FLOPS and memory usage of the program. The methodology to compute these metrics is: Time: sm__cycles_elapsed.avg / sm__cycles_elapsed.avg.per_second FLOPs: DP: sm__sass_thread_inst_executed_op_dadd_pred_on.sum + 2 x sm__sass_thread_inst_executed_op_dfma_pred_on.sum + sm__sass_thread_inst_executed_op_dmul_pred_on.sum SP: sm__sass_thread_inst_executed_op_fadd_pred_on.sum + 2 x sm__sass_thread_inst_executed_op_ffma_pred_on.sum + sm__sass_thread_inst_executed_op_fmul_pred_on.sum HP: sm__sass_thread_inst_executed_op_hadd_pred_on.sum + 2 x sm__sass_thread_inst_executed_op_hfma_pred_on.sum + sm__sass_thread_inst_executed_op_hmul_pred_on.sum Tensor Core: 512 x sm__inst_executed_pipe_tensor.sum Bytes: DRAM: dram__bytes.sum L2: lts__t_bytes.sum L1: l1tex__t_bytes.sum"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "my CMakeLists.txt: cmake_minimum_required(VERSION 3.16) project(cmake_and_cuda CUDA CXX C) find_package(CUDA REQUIRED) set(CMAKE_CUDA_COMPILER /usr/local/cuda-11.4/bin/nvcc) set(CMAKE_CUDA_FLAGS ${CMAKE_CUDA_FLAGS} \" -g -G \") # enable cuda-gdb cuda_add_executable(a a.cu) my cuda code: #include&lt;stdio.h&gt; __global__ void helloFromGPU(void){ printf(\"Hello thread %d!\\n\",threadIdx.x); } int main(void){ helloFromGPU&lt;&lt;&lt;1,10&gt;&gt;&gt;(); cudaDeviceReset(); return 0; } then I use CUDA-gdb add a breakpoint at function helloFromGPU(void), but I can't enter the kernel function helloFromGPU(void)\uff0cprogram break at the end of the function. I think the cmake file is not written correctly, how can I modify it?",
        "answers": [
            [
                "set the \u201c CUDA_NVCC_FLAGS\u201d as follow\uff1a set( CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS}; -g -G )"
            ]
        ],
        "votes": [
            -0.9999999
        ]
    },
    {
        "question": "I am trying to set up cuda programming in vs code and ran into this problem where cuda-gdb just returns an error. I tried running it with regular gdb and that works. I am using wsl. running the \"CUDA C++: Launch\" outputs this in the debug console: warning: File \"/usr/lib/debug/.build-id/45/87364908de169dec62ffa538170118c1c3a078.debug\" has no build-id, file skipped warning: File \"/usr/lib/debug/.build-id/ce/016c975d94bc4770ed8c62d45dea6b71405a2c.debug\" has no build-id, file skipped [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". warning: File \"/usr/lib/debug/.build-id/c0/f40155b3f8bf8c494fa800f9ab197ebe20ed6e.debug\" has no build-id, file skipped warning: File \"/usr/lib/debug/.build-id/18/78e6b475720c7c51969e69ab2d276fae6d1dee.debug\" has no build-id, file skipped warning: File \"/usr/lib/debug/.build-id/fe/91b4090ea04c1559ff71dd9290062776618891.debug\" has no build-id, file skipped Cannot find user-level thread for LWP 4949: generic error Just running Cuda-gdb in the terminal outputs this: BFD: /usr/lib/debug/.build-id/45/87364908de169dec62ffa538170118c1c3a078.debug: unable to initialize decompress status for section .debug_aranges BFD: /usr/lib/debug/.build-id/45/87364908de169dec62ffa538170118c1c3a078.debug: unable to initialize decompress status for section .debug_aranges warning: File \"/usr/lib/debug/.build-id/45/87364908de169dec62ffa538170118c1c3a078.debug\" has no build-id, file skipped BFD: /usr/lib/debug/.build-id/ce/016c975d94bc4770ed8c62d45dea6b71405a2c.debug: unable to initialize decompress status for section .debug_aranges BFD: /usr/lib/debug/.build-id/ce/016c975d94bc4770ed8c62d45dea6b71405a2c.debug: unable to initialize decompress status for section .debug_aranges warning: File \"/usr/lib/debug/.build-id/ce/016c975d94bc4770ed8c62d45dea6b71405a2c.debug\" has no build-id, file skipped [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". BFD: /usr/lib/debug/.build-id/c0/f40155b3f8bf8c494fa800f9ab197ebe20ed6e.debug: unable to initialize decompress status for section .debug_aranges BFD: /usr/lib/debug/.build-id/c0/f40155b3f8bf8c494fa800f9ab197ebe20ed6e.debug: unable to initialize decompress status for section .debug_aranges warning: File \"/usr/lib/debug/.build-id/c0/f40155b3f8bf8c494fa800f9ab197ebe20ed6e.debug\" has no build-id, file skipped BFD: /usr/lib/debug/.build-id/18/78e6b475720c7c51969e69ab2d276fae6d1dee.debug: unable to initialize decompress status for section .debug_aranges BFD: /usr/lib/debug/.build-id/18/78e6b475720c7c51969e69ab2d276fae6d1dee.debug: unable to initialize decompress status for section .debug_aranges warning: File \"/usr/lib/debug/.build-id/18/78e6b475720c7c51969e69ab2d276fae6d1dee.debug\" has no build-id, file skipped BFD: /usr/lib/debug/.build-id/fe/91b4090ea04c1559ff71dd9290062776618891.debug: unable to initialize decompress status for section .debug_aranges BFD: /usr/lib/debug/.build-id/fe/91b4090ea04c1559ff71dd9290062776618891.debug: unable to initialize decompress status for section .debug_aranges warning: File \"/usr/lib/debug/.build-id/fe/91b4090ea04c1559ff71dd9290062776618891.debug\" has no build-id, file skipped Hello World1 Hello World2 Hello World3 Cannot find user-level thread for LWP 4077: generic error (cuda-gdb) My tasks.json: { \"version\": \"2.0.0\", \"tasks\": [ { \"type\": \"cppbuild\", \"label\": \"C/C++: nvcc build active file\", \"command\": \"/usr/bin/nvcc\", \"args\": [ \"-g\", \"-G\", \"${file}\", \"-o\", \"${fileDirname}/${fileBasenameNoExtension}\" ], \"options\": { \"cwd\": \"${fileDirname}\" }, \"problemMatcher\": [ \"$gcc\" ], \"group\": \"build\", \"detail\": \"compiler: /usr/bin/nvcc\" } ] } My launch.json: { \"configurations\": [ { \"name\": \"(gdb) Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/maintest\", \"args\": [], \"stopAtEntry\": false, \"cwd\": \"${fileDirname}\", \"environment\": [], \"externalConsole\": false, \"MIMode\": \"gdb\", \"setupCommands\": [ { \"description\": \"Enable pretty-printing for gdb\", \"text\": \"-enable-pretty-printing\", \"ignoreFailures\": true } ] }, { \"name\": \"CUDA C++: Launch\", \"type\": \"cuda-gdb\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/maintest\" } ] }",
        "answers": [
            [
                "Updating wsl and changing to wsl version 2 fixed it however cuda specific functions are not debuggable as cuda-gdb is not supporting wsl yet :("
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "Background: Running VSCode on Ubuntu 20.04 The following have been accomplished: (a) Compiled and build the Cython wrapper for CUDA code (packaged as shared library .so); (b) Python script importing said .so file runs, and can be debugged directly from cuda-gdb in terminal (thanks to this link as well as enabling the ptrace_scope), can see GPU variables and switch focus (c) separately I have been able to set breakpoint in a different CUDA code (no wrapping, pure CUDA code linked and compiled to an executable) in both command-line cuda-gdb and VSCode's native IDE. As seen here in this youtube video Problem: from (b) I know that the GPU debugging symbols are there, and can be picked up by cuda-gdb. But ultimately I would like to be able to debug in VSCode instead. I have tried the following 4 approaches in launch.json (as I have done so for the executable but cannot for the Cython-interfaced python script) use the command:cuda.pickProcess, and then picking the python process: { \u201cname\u201d: \u201cCUDA C++: Attach\u201d, \u201ctype\u201d: \u201ccuda-gdb\u201d, \u201crequest\u201d: \u201cattach\u201d, \u201cprocessId\u201d: \u201c${command:cuda.pickProcess}\u201d Result 1: nothing comes up on the Debug Console tab, no breakpoint hitting Using ps grep to find the process ID, put it directly in the processId { \u201cname\u201d: \u201cCUDA C++: Attach\u201d, \u201ctype\u201d: \u201ccuda-gdb\u201d, \u201crequest\u201d: \u201cattach\u201d, \u201cprocessId\u201d: \u201c12345\u201d #The Process ID = 12345 }, Result 2: same as 1., nothing happens 3) Trying to invoke the python executable and providing the python script as argument (test.py runs the cuda code, as it has been verified with command line cuda-gdb) { \u201cname\u201d: \u201c(gdb) Launch Python\u201d, \u201ctype\u201d: \u201ccuda-gdb\u201d, \u201crequest\u201d: \u201claunch\u201d, \u201cprogram\u201d: \u201c/home/jeff/JTDev/venv/bin/python3\u201d, \u201cargs\u201d:\u201d/home/jeff/JTDev/03 Cython/JTCudaLibCython/test.py\u201d, \u201cstopAtEntry\u201d: false, } Result 3: cuda-gdb appears to be launched in \u201cDEBUG CONSOLE\u201d tab but it seems to have not done any thing (if the script + CUDA code were run, it would have output if the summation has been finished or not): 11.7 release Portions Copyright (C) 2007-2022 NVIDIA Corporation GNU gdb (GDB) 10.2 Copyright (C) 2021 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u201cshow copying\u201d and \u201cshow warranty\u201d for details. This GDB was configured as \u201cx86_64-pc-linux-gnu\u201d. Type \u201cshow configuration\u201d for configuration details. For bug reporting instructions, please see: . Find the GDB manual and other documentation resources online at: . For help, type \u201chelp\u201d. Type \u201capropos word\u201d to search for commands related to \u201cword\u201d. [Thread debugging using libthread_db enabled] Using host libthread_db library \u201c/lib/x86_64-linux-gnu/libthread_db.so.1\u201d. [Inferior 1 (process 211846) exited with code 02]\" switching the type in settings.json from \u2018cuda-gdb\u2019 to \u2018cppdbg\u2019 in the launch.json: { \u201cname\u201d: \u201c(gdb) Launch 1123\u201d, \u201ctype\u201d: \u201ccppdbg\u201d, \u201crequest\u201d: \u201claunch\u201d, \u201cprogram\u201d: \u201c/home/jeff/JTDev/venv/bin/python3\u201d, \u201cargs\u201d: [ \u201c/home/jeff/JTDev/03 Cython/CythonCUDA/test.py\u201d ], \u201cstopAtEntry\u201d: false, \u201ccwd\u201d: \u201c${workspaceFolder}\u201d, \u201cexternalConsole\u201d: false, \u201cMIMode\u201d: \u201cgdb\u201d, \u201csetupCommands\u201d: [ { \u201cdescription\u201d: \u201cEnable pretty-printing for gdb\u201d, \u201ctext\u201d: \u201c-enable-pretty-printing\u201d, \u201cignoreFailures\u201d: true } ] } Result 4: Now it will run the python script unlike in attempt 3, and it will break at the line leaving the kernel (not where the CUDA individual thread lines). So the VSCode Can run Python script in this setting, and the CPU debug symbol can be picked up by the VSCode IDE. As seen from before, cuda-gdb proves the GPU debugging symbols is here, but somehow when invoking the cuda-gdb in \u201ctype\u201d in launch.json, the cuda debugger is not launched correctly in VSCode for it to pick up the GPU debugging symbol and break at the device code lines. Any help/tips are greatly appreciated.",
        "answers": [
            [
                "Make sure to compile cu file with debug symbol info. Try using -G -g -O0 flag"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am developing a fairly big project (have around 1200 kernels so far). I have 1 kernel that possibly has some memory race which is why it's giving different answers every time. I want to find it by performing cuda-memcheck on that specific kernel. So naturally, I am trying to use --filter option in cuda-memcheck with --tool racecheck option. The codebase is big and performing cuda-memcheck on all kernels especially with racecheck enabled will take an eternity. The official documentation says using key value pair as: {key1=val1}[{,key2=val2}]. I am not really sure what exactly this means and whatever I have tried resulted in invalid options message. I could not find any example online as well as Nvidia cuda-samples provided with the toolkit. So far, I have tried these (and probably all combinations of these): cuda-memcheck --filter &lt;kernel_name&gt;,kns &lt;Executable&gt; cuda-memcheck --filter key1=&lt;kernel_name&gt;, key2=kns &lt;Executable&gt; cuda-memcheck --filter key1='&lt;kernel_name&gt;', key2='kns' &lt;Executable&gt; cuda-memcheck --filter &lt;kernel_name&gt;,[kns] &lt;Executable&gt; I am not sure exactly how to interpret the documentation. An example would be great. Thanks. Note: I can use cuda-memcheck with other options and my executable is compiled correctly with flags like Xcompiler, lineinfo etc.",
        "answers": [
            [
                "As answered by @paleonix in the comments the correct format is: cuda-memcheck --filter kns=&lt;kernel_name_substring&gt; &lt;Executable&gt; or cuda-memcheck --filter kne=&lt;kernel_name&gt; &lt;Executable&gt; The key difference between these two options is: (According to Nvidia-documentation) kns: User specifies the complete mangled kernel name. kne: User specifies a substring in the mangled kernel name. Note: starting cuda 11.0 the cuda-memcheck tool is deprecated and replaced with compute-sanitizer it works as a drop-in replacement."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I'm trying to debug a test program with VS CODE, CMake in Ubuntu 20. I referred mainly to the CUDA debugger document: https://docs.nvidia.com/nsight-visual-studio-code-edition/cuda-debugger/index.html. However, I'm not sure about how to write a correct launch.json in a project based on CMake. Here is my CMakeLists.txt cmake_minimum_required(VERSION 3.2) project(cudaDebug CXX CUDA) find_package(CUDA REQUIRED) add_executable(main main.cu) Here is my launch.json generated by VS CODE { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"CUDA C++: Launch\", \"type\": \"cuda-gdb\", \"request\": \"launch\", \"program\": \"main.cu\" }, { \"name\": \"CUDA C++: Attach\", \"type\": \"cuda-gdb\", \"request\": \"attach\" } ] } When I press F5 to start debugging, an error information poped up: main.cu: 346262241346234211351202243344270252346226207344273266346210226347233256345275225.",
        "answers": [
            [
                "I think you have to change the following line: \"program\": \"main.cu\" to \"program\": \"${command:cmake.launchTargetPath}\" and select the executable in VSCode (usually on the bottom row where you can also select build targets). Have also a look here: https://vector-of-bool.github.io/docs/vscode-cmake-tools/debugging.html"
            ],
            [
                "you can try to update your cmake version to higher than 3.10, which no longer need to use find_package(CUDA) here is one template for vscode and cmake to use cuda-gdb CMakeLists.txt cmake_minimum_required(VERSION 3.16) project(your_project_name CUDA CXX C) # enable cuda language set(CMAKE_CUDA_COMPILER /usr/local/cuda/bin/nvcc) set(CMAKE_CUDA_STANDARD 11) set(CMAKE_CUDA_FLAGS ${CMAKE_CUDA_FLAGS} \"-g -G\") # enable cuda-gdb add_executable(${PROJECT_NAME}) target_sources(${PROJECT_NAME} PRIVATE your_source_files) set_target_properties(${PROJECT_NAME} PROPERTIES CUDA_SEPARABLE_COMPILATION ON) tasks.json { \"options\": { \"cwd\": \"${workspaceFolder}/build\" }, \"tasks\": [ { \"label\": \"cmake\", \"command\":\"cmake\", \"args\": [\"-DCMAKE_BUILD_TYPE=Debug\", \"..\"] }, { \"label\": \"make\", \"command\":\"make\", }, { \"label\": \"cmake build\", \"dependsOn\":[ \"cmake\", \"make\" ], } ], \"version\": \"2.0.0\" } launch.json { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"CUDA C++: Launch\", \"type\": \"cuda-gdb\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/build/your_executable_file\", \"stopAtEntry\": false, \"cwd\": \"${workspaceFolder}\", \"preLaunchTask\": \"cmake build\" } ] } wish it could help you :)"
            ]
        ],
        "votes": [
            2.0000001,
            1.0000001
        ]
    },
    {
        "question": "I am having trouble using cuda-gdb. My program starts from python and it loads a shared library containing tensorflow and cuda code. The command I used to start cuda-gdb is cuda-gdb --args python test_cr_bbp_tf2.py. After typing run in cuda-gdb, I waited for about 10 minutes before the execution finished, and the program hung long time as new threads information showed up. This long hang makes cuda-gdb useless in debugging my program. Another execution using gdb --args python test_cr_bbp_tf2.py only took 10 seconds. The log from cuda-gdb is shown below (both cuda-gdb and gdb showed the same log): Starting program: /usr/bin/python test_cr_bbp_tf2.py [Thread debugging using libthread_db enabled] Using host libthread_db library \"/usr/lib/x86_64-linux-gnu/libthread_db.so.1\". 2022-05-04 19:44:17.020132: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0 [Detaching after fork from child process 61729] warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time warning: Cannot parse .gnu_debugdata section; LZMA support was disabled at compile time testmatching 2022-05-04 19:44:18.724780: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0 2022-05-04 19:44:19.270957: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcuda.so.1 [Detaching after fork from child process 61762] [New Thread 0x7fff83ec3700 (LWP 61868)] 2022-05-04 19:44:23.413363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: pciBusID: 0000:01:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:23.414389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 1 with properties: pciBusID: 0000:41:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:23.415424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 2 with properties: pciBusID: 0000:61:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:23.416413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 3 with properties: pciBusID: 0000:81:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:23.417823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 4 with properties: pciBusID: 0000:c1:00.0 name: NVIDIA A40 computeCapability: 8.6 coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.56GiB deviceMemoryBandwidth: 648.29GiB/s 2022-05-04 19:44:23.417844: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0 2022-05-04 19:44:23.460000: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11 2022-05-04 19:44:23.460044: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11 2022-05-04 19:44:23.484264: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcufft.so.10 2022-05-04 19:44:23.507764: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcurand.so.10 2022-05-04 19:44:23.531913: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcutensor.so.1 2022-05-04 19:44:23.554745: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusolver.so.11 2022-05-04 19:44:23.577344: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusparse.so.11 2022-05-04 19:44:23.598496: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8 2022-05-04 19:44:23.610402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0, 1, 2, 3, 4 [New Thread 0x7fff8349a700 (LWP 61869)] [New Thread 0x7fff82c99700 (LWP 61870)] [New Thread 0x7fff82498700 (LWP 61871)] [New Thread 0x7fff81c97700 (LWP 61872)] [New Thread 0x7fff81496700 (LWP 61873)] [New Thread 0x7fff80c95700 (LWP 61874)] [New Thread 0x7fff0fa23700 (LWP 61875)] [New Thread 0x7fff0f222700 (LWP 61876)] [New Thread 0x7fff0ea21700 (LWP 61877)] [New Thread 0x7fff0e220700 (LWP 61878)] [New Thread 0x7fff0da1f700 (LWP 61879)] [New Thread 0x7fff0d21e700 (LWP 61880)] [New Thread 0x7fff0ca1d700 (LWP 61881)] [New Thread 0x7ffedffff700 (LWP 61882)] [New Thread 0x7ffedf7fe700 (LWP 61883)] [New Thread 0x7ffedeffd700 (LWP 61884)] [New Thread 0x7ffede7fc700 (LWP 61885)] [New Thread 0x7ffeddffb700 (LWP 61886)] [New Thread 0x7ffedd7fa700 (LWP 61887)] [New Thread 0x7ffedcff9700 (LWP 61888)] [New Thread 0x7ffebbfff700 (LWP 61889)] [New Thread 0x7ffebb7fe700 (LWP 61890)] [New Thread 0x7ffebaffd700 (LWP 61891)] [New Thread 0x7ffeba7fc700 (LWP 61892)] [New Thread 0x7ffeb9ffb700 (LWP 61893)] [New Thread 0x7ffeb97fa700 (LWP 61894)] [New Thread 0x7ffeb8ff9700 (LWP 61895)] [New Thread 0x7ffe9bfff700 (LWP 61896)] [New Thread 0x7ffe9b7fe700 (LWP 61897)] [New Thread 0x7ffe9affd700 (LWP 61898)] [New Thread 0x7ffe9a7fc700 (LWP 61899)] [New Thread 0x7ffe99ffb700 (LWP 61900)] [New Thread 0x7ffe997fa700 (LWP 61901)] [New Thread 0x7ffe98ff9700 (LWP 61902)] [New Thread 0x7ffe7bfff700 (LWP 61903)] [New Thread 0x7ffe7b7fe700 (LWP 61904)] [New Thread 0x7ffe7affd700 (LWP 61905)] [New Thread 0x7ffe7a7fc700 (LWP 61906)] [New Thread 0x7ffe79ffb700 (LWP 61907)] [New Thread 0x7ffe797fa700 (LWP 61908)] [New Thread 0x7ffe78ff9700 (LWP 61909)] [New Thread 0x7ffe63fff700 (LWP 61910)] [New Thread 0x7ffe637fe700 (LWP 61911)] [New Thread 0x7ffe62ffd700 (LWP 61912)] [New Thread 0x7ffe627fc700 (LWP 61913)] [New Thread 0x7ffe61ffb700 (LWP 61914)] [New Thread 0x7ffe617fa700 (LWP 61915)] [New Thread 0x7ffe60ff9700 (LWP 61916)] [New Thread 0x7ffe3ffff700 (LWP 61917)] [New Thread 0x7ffe3f7fe700 (LWP 61918)] [New Thread 0x7ffe3effd700 (LWP 61919)] [New Thread 0x7ffe3e7fc700 (LWP 61920)] [New Thread 0x7ffe3dffb700 (LWP 61921)] [New Thread 0x7ffe3d7fa700 (LWP 61922)] [New Thread 0x7ffe3cff9700 (LWP 61923)] [New Thread 0x7ffe1bfff700 (LWP 61924)] [New Thread 0x7ffe1b7fe700 (LWP 61925)] [New Thread 0x7ffe1affd700 (LWP 61926)] [New Thread 0x7ffe1a7fc700 (LWP 61927)] [New Thread 0x7ffe19ffb700 (LWP 61928)] [New Thread 0x7ffe197fa700 (LWP 61929)] [New Thread 0x7ffe18ff9700 (LWP 61930)] [New Thread 0x7ffdfbfff700 (LWP 61931)] [New Thread 0x7ffdf3fff700 (LWP 61932)] [New Thread 0x7ffdfb7fe700 (LWP 61933)] [New Thread 0x7ffdfaffd700 (LWP 61934)] [New Thread 0x7ffdfa7fc700 (LWP 61935)] [New Thread 0x7ffdf9ffb700 (LWP 61936)] [New Thread 0x7ffdf97fa700 (LWP 61937)] [New Thread 0x7ffdf8ff9700 (LWP 61938)] [New Thread 0x7ffdf37fe700 (LWP 61939)] [New Thread 0x7ffdf2ffd700 (LWP 61940)] [New Thread 0x7ffdf27fc700 (LWP 61941)] [New Thread 0x7ffdf1ffb700 (LWP 61942)] [New Thread 0x7ffdf17fa700 (LWP 61943)] [New Thread 0x7ffdf0ff9700 (LWP 61944)] [New Thread 0x7ffdbbfff700 (LWP 61945)] [New Thread 0x7ffdbb7fe700 (LWP 61946)] [New Thread 0x7ffdbaffd700 (LWP 61947)] [New Thread 0x7ffdba7fc700 (LWP 61948)] [New Thread 0x7ffdb9ffb700 (LWP 61949)] [New Thread 0x7ffdb97fa700 (LWP 61950)] [New Thread 0x7ffdb8ff9700 (LWP 61951)] [New Thread 0x7ffd9bfff700 (LWP 61952)] [New Thread 0x7ffd9b7fe700 (LWP 61953)] [New Thread 0x7ffd9affd700 (LWP 61954)] [New Thread 0x7ffd9a7fc700 (LWP 61955)] [New Thread 0x7ffd99ffb700 (LWP 61956)] [New Thread 0x7ffd997fa700 (LWP 61957)] [New Thread 0x7ffd98ff9700 (LWP 61958)] [New Thread 0x7ffd7bfff700 (LWP 61959)] [New Thread 0x7ffd737fe700 (LWP 61960)] [New Thread 0x7ffd7b7fe700 (LWP 61961)] [New Thread 0x7ffd7affd700 (LWP 61962)] [New Thread 0x7ffd7a7fc700 (LWP 61963)] [New Thread 0x7ffd79ffb700 (LWP 61964)] [New Thread 0x7ffd797fa700 (LWP 61965)] [New Thread 0x7ffd78ff9700 (LWP 61966)] [New Thread 0x7ffd73fff700 (LWP 61967)] [New Thread 0x7ffd72ffd700 (LWP 61968)] [New Thread 0x7ffd727fc700 (LWP 61986)] [New Thread 0x7ffd71ffb700 (LWP 61987)] [New Thread 0x7ffd717fa700 (LWP 61988)] [New Thread 0x7ffd70ff9700 (LWP 61989)] [New Thread 0x7ffd41fff700 (LWP 62007)] [New Thread 0x7ffd417fe700 (LWP 62008)] 2022-05-04 19:44:32.857957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: pciBusID: 0000:01:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:32.859130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 1 with properties: pciBusID: 0000:41:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:32.862621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 2 with properties: pciBusID: 0000:61:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:32.864706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 3 with properties: pciBusID: 0000:81:00.0 name: NVIDIA A10 computeCapability: 8.6 coreClock: 1.695GHz coreCount: 72 deviceMemorySize: 22.20GiB deviceMemoryBandwidth: 558.88GiB/s 2022-05-04 19:44:32.866416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 4 with properties: pciBusID: 0000:c1:00.0 name: NVIDIA A40 computeCapability: 8.6 coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.56GiB deviceMemoryBandwidth: 648.29GiB/s 2022-05-04 19:44:32.877182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0, 1, 2, 3, 4 2022-05-04 19:46:31.513555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix: 2022-05-04 19:46:31.513646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264] 0 1 2 3 4 2022-05-04 19:46:31.513655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0: N Y Y Y Y 2022-05-04 19:46:31.513660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1: Y N Y Y Y 2022-05-04 19:46:31.513664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2: Y Y N Y Y 2022-05-04 19:46:31.513668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3: Y Y Y N Y 2022-05-04 19:46:31.513672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 4: Y Y Y Y N 2022-05-04 19:46:32.375262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20566 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA A10, pci bus id: 0000:01:00.0, compute capability: 8.6) [New Thread 0x7ffd40ffd700 (LWP 63758)] [New Thread 0x7ffcf3fff700 (LWP 63759)] 2022-05-04 19:46:33.726341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 20566 MB memory) -&gt; physical GPU (device: 1, name: NVIDIA A10, pci bus id: 0000:41:00.0, compute capability: 8.6) [New Thread 0x7ffcf37fe700 (LWP 63788)] [New Thread 0x7ffcf2f14700 (LWP 63789)] 2022-05-04 19:46:35.095419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 20566 MB memory) -&gt; physical GPU (device: 2, name: NVIDIA A10, pci bus id: 0000:61:00.0, compute capability: 8.6) [New Thread 0x7ffcf2713700 (LWP 63813)] [New Thread 0x7ffcf1f12700 (LWP 63814)] 2022-05-04 19:46:36.507977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 20566 MB memory) -&gt; physical GPU (device: 3, name: NVIDIA A10, pci bus id: 0000:81:00.0, compute capability: 8.6) [New Thread 0x7ffcf1711700 (LWP 63878)] [New Thread 0x7ffcf0f10700 (LWP 63879)] 2022-05-04 19:46:37.914435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 43434 MB memory) -&gt; physical GPU (device: 4, name: NVIDIA A40, pci bus id: 0000:c1:00.0, compute capability: 8.6) [New Thread 0x7ffc9bfff700 (LWP 63908)] [New Thread 0x7ffc9b7fe700 (LWP 63909)] 2022-05-04 19:46:39.270650: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 96. Tune using inter_op_parallelism_threads for best performance. [New Thread 0x7ffc9affd700 (LWP 63910)] [New Thread 0x7ffc9a7fc700 (LWP 63911)] [New Thread 0x7ffc99ffb700 (LWP 63912)] [New Thread 0x7ffc997fa700 (LWP 63913)] [New Thread 0x7ffc98ff9700 (LWP 63914)] [New Thread 0x7ffc7ffff700 (LWP 63915)] [New Thread 0x7ffc7f7fe700 (LWP 63916)] [New Thread 0x7ffc7effd700 (LWP 63917)] [New Thread 0x7ffc7e7fc700 (LWP 63918)] [New Thread 0x7ffc7dffb700 (LWP 63919)] [New Thread 0x7ffc7d7fa700 (LWP 63920)] [New Thread 0x7ffc7cff9700 (LWP 63921)] [New Thread 0x7ffc53fff700 (LWP 63922)] [New Thread 0x7ffc537fe700 (LWP 63923)] [New Thread 0x7ffc52ffd700 (LWP 63924)] [New Thread 0x7ffc527fc700 (LWP 63925)] [New Thread 0x7ffc51ffb700 (LWP 63926)] [New Thread 0x7ffc517fa700 (LWP 63927)] [New Thread 0x7ffc50ff9700 (LWP 63928)] [New Thread 0x7ffc3bfff700 (LWP 63929)] [New Thread 0x7ffc3b7fe700 (LWP 63930)] [New Thread 0x7ffc3affd700 (LWP 63931)] [New Thread 0x7ffc3a7fc700 (LWP 63932)] [New Thread 0x7ffc39ffb700 (LWP 63933)] [New Thread 0x7ffc397fa700 (LWP 63934)] [New Thread 0x7ffc38ff9700 (LWP 63935)] [New Thread 0x7ffc17fff700 (LWP 63936)] [New Thread 0x7ffc177fe700 (LWP 63937)] [New Thread 0x7ffc16ffd700 (LWP 63938)] [New Thread 0x7ffc167fc700 (LWP 63939)] [New Thread 0x7ffc15ffb700 (LWP 63940)] [New Thread 0x7ffc157fa700 (LWP 63941)] [New Thread 0x7ffc14ff9700 (LWP 63942)] [New Thread 0x7ffbf7fff700 (LWP 63943)] [New Thread 0x7ffbef7fe700 (LWP 63944)] [New Thread 0x7ffbf77fe700 (LWP 63945)] [New Thread 0x7ffbf6ffd700 (LWP 63946)] [New Thread 0x7ffbf67fc700 (LWP 63947)] [New Thread 0x7ffbf5ffb700 (LWP 63948)] [New Thread 0x7ffbf57fa700 (LWP 63949)] [New Thread 0x7ffbf4ff9700 (LWP 63950)] [New Thread 0x7ffbeffff700 (LWP 63951)] [New Thread 0x7ffbeeffd700 (LWP 63952)] [New Thread 0x7ffbee7fc700 (LWP 63953)] [New Thread 0x7ffbedffb700 (LWP 63954)] [New Thread 0x7ffbed7fa700 (LWP 63955)] [New Thread 0x7ffbecff9700 (LWP 63956)] [New Thread 0x7ffbb7fff700 (LWP 63957)] [New Thread 0x7ffbaffff700 (LWP 63958)] [New Thread 0x7ffbb77fe700 (LWP 63959)] [New Thread 0x7ffbb6ffd700 (LWP 63960)] [New Thread 0x7ffbb67fc700 (LWP 63961)] [New Thread 0x7ffbb5ffb700 (LWP 63962)] [New Thread 0x7ffbb57fa700 (LWP 63963)] [New Thread 0x7ffbb4ff9700 (LWP 63964)] [New Thread 0x7ffbaf7fe700 (LWP 63965)] [New Thread 0x7ffbaeffd700 (LWP 63966)] [New Thread 0x7ffbae7fc700 (LWP 63967)] [New Thread 0x7ffbadffb700 (LWP 63968)] [New Thread 0x7ffbad7fa700 (LWP 63969)] [New Thread 0x7ffbacff9700 (LWP 63970)] [New Thread 0x7ffb77fff700 (LWP 63971)] [New Thread 0x7ffb777fe700 (LWP 63972)] [New Thread 0x7ffb76ffd700 (LWP 63973)] [New Thread 0x7ffb767fc700 (LWP 63974)] [New Thread 0x7ffb75ffb700 (LWP 63975)] [New Thread 0x7ffb757fa700 (LWP 63976)] [New Thread 0x7ffb74ff9700 (LWP 63977)] [New Thread 0x7ffb57fff700 (LWP 63978)] [New Thread 0x7ffb4f7fe700 (LWP 63979)] [New Thread 0x7ffb577fe700 (LWP 63980)] [New Thread 0x7ffb56ffd700 (LWP 63981)] [New Thread 0x7ffb567fc700 (LWP 63982)] [New Thread 0x7ffb55ffb700 (LWP 63983)] [New Thread 0x7ffb557fa700 (LWP 63984)] [New Thread 0x7ffb54ff9700 (LWP 63985)] [New Thread 0x7ffb4ffff700 (LWP 63986)] [New Thread 0x7ffb4effd700 (LWP 63987)] [New Thread 0x7ffb4e7fc700 (LWP 63988)] [New Thread 0x7ffb4dffb700 (LWP 63989)] [New Thread 0x7ffb4d7fa700 (LWP 63990)] [New Thread 0x7ffb4cff9700 (LWP 63991)] [New Thread 0x7ffb17fff700 (LWP 63992)] [New Thread 0x7ffb0f7fe700 (LWP 63993)] [New Thread 0x7ffb177fe700 (LWP 63994)] [New Thread 0x7ffb16ffd700 (LWP 63995)] [New Thread 0x7ffb167fc700 (LWP 63996)] [New Thread 0x7ffb15ffb700 (LWP 63997)] [New Thread 0x7ffb157fa700 (LWP 63998)] [New Thread 0x7ffb14ff9700 (LWP 63999)] [New Thread 0x7ffb0ffff700 (LWP 64000)] [New Thread 0x7ffb0effd700 (LWP 64001)] [New Thread 0x7ffb0e7fc700 (LWP 64002)] [New Thread 0x7ffb0dffb700 (LWP 64003)] [New Thread 0x7ffb0d7fa700 (LWP 64004)] [New Thread 0x7ffb0cff9700 (LWP 64005)] inBox: [ 8 1527 56 839] outBox: [ 9 1526 57 838] msdiffGPUBBP 9.787128717049706 8.836871411244479 8.792443641292834 1.0240484074218186 msdiffGPUBBP 8.284130262488215 8.504984482311862 8.468490694873381 0.9001938761471568 msdiffGPUBBP 7.607680601497159 8.326243672859956 8.302741359766436 0.7882571994561002 msdiffGPUBBP 9.01851150047646 8.826698188773078 8.800456119590438 0.852269245604869 msdiffGPUBBP 10.002452782253538 9.02661007092474 9.003068931959348 0.7974960688804729 msdiffGPUBBP 9.362822708408418 8.672302889066888 8.648869787310186 0.8399175541051185 msdiffGPUBBP 13.275880608755909 13.290950955327459 13.297561482034173 0.5154759081244825 mean (GPU-BBP) 0.8168083228200026 mean diff Median (GPU-BBP) 0.0 [Thread 0x7ffb4f7fe700 (LWP 63979) exited] [Thread 0x7ffb0dffb700 (LWP 64003) exited] [Thread 0x7ffb0e7fc700 (LWP 64002) exited] [Thread 0x7ffb167fc700 (LWP 63996) exited] [Thread 0x7ffb157fa700 (LWP 63998) exited] [Thread 0x7ffb0ffff700 (LWP 64000) exited] [Thread 0x7ffb177fe700 (LWP 63994) exited] [Thread 0x7ffb0f7fe700 (LWP 63993) exited] [Thread 0x7ffb0d7fa700 (LWP 64004) exited] [Thread 0x7ffb0effd700 (LWP 64001) exited] [Thread 0x7ffb15ffb700 (LWP 63997) exited] [Thread 0x7ffb0cff9700 (LWP 64005) exited] [Thread 0x7ffb14ff9700 (LWP 63999) exited] [Thread 0x7ffb16ffd700 (LWP 63995) exited] [Thread 0x7ffb17fff700 (LWP 63992) exited] [Thread 0x7ffb4cff9700 (LWP 63991) exited] [Thread 0x7ffb4d7fa700 (LWP 63990) exited] [Thread 0x7ffb4dffb700 (LWP 63989) exited] [Thread 0x7ffb4e7fc700 (LWP 63988) exited] [Thread 0x7ffb4effd700 (LWP 63987) exited] [Thread 0x7ffb4ffff700 (LWP 63986) exited] [Thread 0x7ffb54ff9700 (LWP 63985) exited] [Thread 0x7ffb557fa700 (LWP 63984) exited] [Thread 0x7ffb55ffb700 (LWP 63983) exited] [Thread 0x7ffb567fc700 (LWP 63982) exited] [Thread 0x7ffb56ffd700 (LWP 63981) exited] [Thread 0x7ffb577fe700 (LWP 63980) exited] [Thread 0x7ffb57fff700 (LWP 63978) exited] [Thread 0x7ffb74ff9700 (LWP 63977) exited] [Thread 0x7ffb757fa700 (LWP 63976) exited] [Thread 0x7ffb75ffb700 (LWP 63975) exited] [Thread 0x7ffb767fc700 (LWP 63974) exited] [Thread 0x7ffb76ffd700 (LWP 63973) exited] [Thread 0x7ffb777fe700 (LWP 63972) exited] [Thread 0x7ffb77fff700 (LWP 63971) exited] [Thread 0x7ffbacff9700 (LWP 63970) exited] [Thread 0x7ffbad7fa700 (LWP 63969) exited] [Thread 0x7ffbadffb700 (LWP 63968) exited] [Thread 0x7ffbae7fc700 (LWP 63967) exited] [Thread 0x7ffbaeffd700 (LWP 63966) exited] [Thread 0x7ffbaf7fe700 (LWP 63965) exited] [Thread 0x7ffbb4ff9700 (LWP 63964) exited] [Thread 0x7ffbb57fa700 (LWP 63963) exited] [Thread 0x7ffbb5ffb700 (LWP 63962) exited] [Thread 0x7ffbb67fc700 (LWP 63961) exited] [Thread 0x7ffbb6ffd700 (LWP 63960) exited] [Thread 0x7ffbb77fe700 (LWP 63959) exited] [Thread 0x7ffbaffff700 (LWP 63958) exited] [Thread 0x7ffbb7fff700 (LWP 63957) exited] [Thread 0x7ffbecff9700 (LWP 63956) exited] [Thread 0x7ffbed7fa700 (LWP 63955) exited] [Thread 0x7ffbedffb700 (LWP 63954) exited] [Thread 0x7ffbee7fc700 (LWP 63953) exited] [Thread 0x7ffbeeffd700 (LWP 63952) exited] [Thread 0x7ffbeffff700 (LWP 63951) exited] [Thread 0x7ffbf4ff9700 (LWP 63950) exited] [Thread 0x7ffbf57fa700 (LWP 63949) exited] [Thread 0x7ffbf5ffb700 (LWP 63948) exited] [Thread 0x7ffbf67fc700 (LWP 63947) exited] [Thread 0x7ffbf6ffd700 (LWP 63946) exited] [Thread 0x7ffbf77fe700 (LWP 63945) exited] [Thread 0x7ffbef7fe700 (LWP 63944) exited] [Thread 0x7ffbf7fff700 (LWP 63943) exited] [Thread 0x7ffc14ff9700 (LWP 63942) exited] [Thread 0x7ffc157fa700 (LWP 63941) exited] [Thread 0x7ffc15ffb700 (LWP 63940) exited] [Thread 0x7ffc167fc700 (LWP 63939) exited] [Thread 0x7ffc16ffd700 (LWP 63938) exited] [Thread 0x7ffc177fe700 (LWP 63937) exited] [Thread 0x7ffc17fff700 (LWP 63936) exited] [Thread 0x7ffc38ff9700 (LWP 63935) exited] [Thread 0x7ffc397fa700 (LWP 63934) exited] [Thread 0x7ffc39ffb700 (LWP 63933) exited] [Thread 0x7ffc3a7fc700 (LWP 63932) exited] [Thread 0x7ffc3affd700 (LWP 63931) exited] [Thread 0x7ffc3b7fe700 (LWP 63930) exited] [Thread 0x7ffc3bfff700 (LWP 63929) exited] [Thread 0x7ffc50ff9700 (LWP 63928) exited] [Thread 0x7ffc517fa700 (LWP 63927) exited] [Thread 0x7ffc51ffb700 (LWP 63926) exited] [Thread 0x7ffc527fc700 (LWP 63925) exited] [Thread 0x7ffc52ffd700 (LWP 63924) exited] [Thread 0x7ffc537fe700 (LWP 63923) exited] [Thread 0x7ffc53fff700 (LWP 63922) exited] [Thread 0x7ffc7cff9700 (LWP 63921) exited] [Thread 0x7ffc7d7fa700 (LWP 63920) exited] [Thread 0x7ffc7dffb700 (LWP 63919) exited] [Thread 0x7ffc7e7fc700 (LWP 63918) exited] [Thread 0x7ffc7effd700 (LWP 63917) exited] [Thread 0x7ffc7f7fe700 (LWP 63916) exited] [Thread 0x7ffc7ffff700 (LWP 63915) exited] [Thread 0x7ffc98ff9700 (LWP 63914) exited] [Thread 0x7ffc997fa700 (LWP 63913) exited] [Thread 0x7ffc99ffb700 (LWP 63912) exited] [Thread 0x7ffc9a7fc700 (LWP 63911) exited] [Thread 0x7ffc9affd700 (LWP 63910) exited] [Thread 0x7ffc9b7fe700 (LWP 63909) exited] [Thread 0x7ffc9bfff700 (LWP 63908) exited] [Thread 0x7ffcf0f10700 (LWP 63879) exited] [Thread 0x7ffcf1711700 (LWP 63878) exited] [Thread 0x7ffcf1f12700 (LWP 63814) exited] [Thread 0x7ffcf2713700 (LWP 63813) exited] [Thread 0x7ffcf2f14700 (LWP 63789) exited] [Thread 0x7ffcf37fe700 (LWP 63788) exited] [Thread 0x7ffcf3fff700 (LWP 63759) exited] [Thread 0x7ffd40ffd700 (LWP 63758) exited] [Thread 0x7ffd417fe700 (LWP 62008) exited] [Thread 0x7ffd41fff700 (LWP 62007) exited] [Thread 0x7ffd70ff9700 (LWP 61989) exited] [Thread 0x7ffd717fa700 (LWP 61988) exited] [Thread 0x7ffd71ffb700 (LWP 61987) exited] [Thread 0x7ffd727fc700 (LWP 61986) exited] [Thread 0x7ffd72ffd700 (LWP 61968) exited] [Thread 0x7ffd73fff700 (LWP 61967) exited] [Thread 0x7ffd78ff9700 (LWP 61966) exited] [Thread 0x7ffd797fa700 (LWP 61965) exited] [Thread 0x7ffd79ffb700 (LWP 61964) exited] [Thread 0x7ffd7a7fc700 (LWP 61963) exited] [Thread 0x7ffd7affd700 (LWP 61962) exited] [Thread 0x7ffd7b7fe700 (LWP 61961) exited] [Thread 0x7ffd737fe700 (LWP 61960) exited] [Thread 0x7ffd7bfff700 (LWP 61959) exited] [Thread 0x7ffd98ff9700 (LWP 61958) exited] [Thread 0x7ffd997fa700 (LWP 61957) exited] [Thread 0x7ffd99ffb700 (LWP 61956) exited] [Thread 0x7ffd9a7fc700 (LWP 61955) exited] [Thread 0x7ffd9affd700 (LWP 61954) exited] [Thread 0x7ffd9b7fe700 (LWP 61953) exited] [Thread 0x7ffd9bfff700 (LWP 61952) exited] [Thread 0x7ffdb8ff9700 (LWP 61951) exited] [Thread 0x7ffdb97fa700 (LWP 61950) exited] [Thread 0x7ffdb9ffb700 (LWP 61949) exited] [Thread 0x7ffdba7fc700 (LWP 61948) exited] [Thread 0x7ffdbaffd700 (LWP 61947) exited] [Thread 0x7ffdbb7fe700 (LWP 61946) exited] [Thread 0x7ffdbbfff700 (LWP 61945) exited] [Thread 0x7ffdf0ff9700 (LWP 61944) exited] [Thread 0x7ffdf17fa700 (LWP 61943) exited] [Thread 0x7ffdf1ffb700 (LWP 61942) exited] [Thread 0x7ffdf27fc700 (LWP 61941) exited] [Thread 0x7ffdf2ffd700 (LWP 61940) exited] [Thread 0x7ffdf37fe700 (LWP 61939) exited] [Thread 0x7ffdf8ff9700 (LWP 61938) exited] [Thread 0x7ffdf97fa700 (LWP 61937) exited] [Thread 0x7ffdf9ffb700 (LWP 61936) exited] [Thread 0x7ffdfa7fc700 (LWP 61935) exited] [Thread 0x7ffdfaffd700 (LWP 61934) exited] [Thread 0x7ffdfb7fe700 (LWP 61933) exited] [Thread 0x7ffdf3fff700 (LWP 61932) exited] [Thread 0x7ffdfbfff700 (LWP 61931) exited] [Thread 0x7ffe18ff9700 (LWP 61930) exited] [Thread 0x7ffe197fa700 (LWP 61929) exited] [Thread 0x7ffe19ffb700 (LWP 61928) exited] [Thread 0x7ffe1a7fc700 (LWP 61927) exited] [Thread 0x7ffe1affd700 (LWP 61926) exited] [Thread 0x7ffe1b7fe700 (LWP 61925) exited] [Thread 0x7ffe1bfff700 (LWP 61924) exited] [Thread 0x7ffe3cff9700 (LWP 61923) exited] [Thread 0x7ffe3d7fa700 (LWP 61922) exited] [Thread 0x7ffe3dffb700 (LWP 61921) exited] [Thread 0x7ffe3e7fc700 (LWP 61920) exited] [Thread 0x7ffe3effd700 (LWP 61919) exited] [Thread 0x7ffe3ffff700 (LWP 61917) exited] [Thread 0x7ffe60ff9700 (LWP 61916) exited] [Thread 0x7ffe617fa700 (LWP 61915) exited] [Thread 0x7ffe61ffb700 (LWP 61914) exited] [Thread 0x7ffe627fc700 (LWP 61913) exited] [Thread 0x7ffe62ffd700 (LWP 61912) exited] [Thread 0x7ffe637fe700 (LWP 61911) exited] [Thread 0x7ffe63fff700 (LWP 61910) exited] [Thread 0x7ffe78ff9700 (LWP 61909) exited] [Thread 0x7ffe797fa700 (LWP 61908) exited] [Thread 0x7ffe79ffb700 (LWP 61907) exited] [Thread 0x7ffe7a7fc700 (LWP 61906) exited] [Thread 0x7ffe7affd700 (LWP 61905) exited] [Thread 0x7ffe7b7fe700 (LWP 61904) exited] [Thread 0x7ffe7bfff700 (LWP 61903) exited] [Thread 0x7ffe98ff9700 (LWP 61902) exited] [Thread 0x7ffe997fa700 (LWP 61901) exited] [Thread 0x7ffe99ffb700 (LWP 61900) exited] [Thread 0x7ffe9a7fc700 (LWP 61899) exited] [Thread 0x7ffe9affd700 (LWP 61898) exited] [Thread 0x7ffe9b7fe700 (LWP 61897) exited] [Thread 0x7ffe9bfff700 (LWP 61896) exited] [Thread 0x7ffeb8ff9700 (LWP 61895) exited] [Thread 0x7ffeb97fa700 (LWP 61894) exited] [Thread 0x7ffeb9ffb700 (LWP 61893) exited] [Thread 0x7ffeba7fc700 (LWP 61892) exited] [Thread 0x7ffebaffd700 (LWP 61891) exited] [Thread 0x7ffebb7fe700 (LWP 61890) exited] [Thread 0x7ffebbfff700 (LWP 61889) exited] [Thread 0x7ffedcff9700 (LWP 61888) exited] [Thread 0x7ffedd7fa700 (LWP 61887) exited] [Thread 0x7ffeddffb700 (LWP 61886) exited] [Thread 0x7ffede7fc700 (LWP 61885) exited] [Thread 0x7ffedeffd700 (LWP 61884) exited] [Thread 0x7ffedf7fe700 (LWP 61883) exited] [Thread 0x7ffedffff700 (LWP 61882) exited] [Thread 0x7fff0ca1d700 (LWP 61881) exited] [Thread 0x7fff0d21e700 (LWP 61880) exited] [Thread 0x7fff0da1f700 (LWP 61879) exited] [Thread 0x7fff0e220700 (LWP 61878) exited] [Thread 0x7fff0ea21700 (LWP 61877) exited] [Thread 0x7fff0f222700 (LWP 61876) exited] [Thread 0x7fff0fa23700 (LWP 61875) exited] [Thread 0x7fff80c95700 (LWP 61874) exited] [Thread 0x7fff81496700 (LWP 61873) exited] [Thread 0x7fff81c97700 (LWP 61872) exited] [Thread 0x7fff82498700 (LWP 61871) exited] [Thread 0x7fff82c99700 (LWP 61870) exited] [Thread 0x7fff8349a700 (LWP 61869) exited] [Thread 0x7fff83ec3700 (LWP 61868) exited] [Thread 0x7ffff7c09740 (LWP 61655) exited] I am confused in that in my understanding, without setting breakpoints in CUDA kernels, gdb and cuda-gdb should be approximately the same. Then why is cuda-gdb much slower in executing a program than gdb? Further, is there a way to improve the performance?",
        "answers": [
            [
                ".... without setting breakpoints in CUDA kernels, gdb and cuda-gdb should be approximately the same. That is an assumption that you yourself are proving to be false. The internal workings of debugging and profiling implementations on CUDA GPUs is not public, but there is plenty of empirical evidence that debugging requires a different execution mode from normal kernel execution. This includes the use of hardware or software pre-emption so the debugger running on the host can control execution of the gpu on an instruction by instruction basis, trap errors and capture GPU stack traces, and perform register file mirroring so that GPU state can be examined at runtime, as examples. None of this is free. If you run cuda-gdb, you get all of this additional instrumentation and diagnostic capabilities, but at a performance cost. Whether this depends on breakpoints on the GPU side or not has been proved false by your own benchmarking as described in your question. If you don't run cuda-gdb, but use a purely host side debugger that can't interrogate or control the GPU execution, you don't incur these performance penalties. The choice is yours."
            ],
            [
                "The debugging instrumentation for supporting breakpoints in GPU code has to be put in place during compile-time, since placing or removing breakpoints is a choice you make at run-time (or debug-time if you will)."
            ]
        ],
        "votes": [
            3.0000001,
            -0.9999999
        ]
    },
    {
        "question": "Short Version I have a kernel that launches a lot of blocks and I know that there is are illegal memory reads happening for blockIdx.y = 312. Running it under cuda-gdb results in sequential execution of blocks 16 at a time and it takes very long for the execution to reach this block index, even with a conditional breakpoint. Is there any way to change the order in thread blocks are scheduled when running under cuda-gdb? If not, is there any other debugging strategy that I might have missed? Longer Version I have a baseline convolution CUDA kernel that scales with problem size by launching more blocks. There is a bug for input images with dimensions of the order of 10_000 x 10_000. Running it under cuda-memcheck, I see the following. ... ========= Invalid __global__ read of size 4 ========= at 0x00000150 in convolution_kernel_sharedmem(float*, float*, float*) ========= by thread (30,31,0) in block (0,312,0) ... All illegal accesses appear to be happening for blockDim.y = 312. So, upon running it with cuda-gdb, 16 blocks are being launched at a time starting from (0, 0, 0). I have set a conditional breakpoint at the kernel to stop at the desired block index, but it is taking a very long time to get there. Is there any way change the order in which thread blocks are scheduled on the device? If not, is there any alternative debugging strategy that I might have missed? P.S: I know that I can use grid-strided loops instead of launching these many blocks, but I would like to know what is wrong with this particular implementation.",
        "answers": [
            [
                "Is there any way to change the order in thread blocks are scheduled when running under cuda-gdb? There is no way to change the threadblock scheduling order unless you want to rewrite the code, and take control of threadblock scheduling yourself. Note that that linked example is not exactly how to redefine threadblock scheduled order, but it has all the necessary ingredients. In practice I don't see a lot of people wanting to do this level of refactoring, but I mention it for completeness. If not, is there any other debugging strategy that I might have missed? The method described here can localize your error to a specific line of kernel code. From there you can use e.g. conditioned printf to identify illegal index calculation, etc. Note that for that method, there is no need to compile your code with debug switches, but you do need to compile with -lineinfo. This training topic provides a longer treatment of CUDA debugging."
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I am in cuda-gdb, I can use ((@global float *)array)[0] but how to use constant memory in gdb ? I try ((@parameter float *)const_array) I declared const_array like this : __constant__ float const_array[1 &lt;&lt; 14] I tried with 1 &lt;&lt; 5, and it's the same problem.",
        "answers": [
            [
                "I don't seem to have any trouble with it. In order to print device memory, you must be stopped at a breakpoint in device code. Example: $ cat t1973.cu const int cs = 1 &lt;&lt; 14; __constant__ int cdata[cs]; __global__ void k(int *gdata){ gdata[0] = cdata[0]; } int main(){ int *hdata = new int[cs]; for (int i = 0; i &lt; cs; i++) hdata[i] = i+1; cudaMemcpyToSymbol(cdata, hdata, cs*sizeof(cdata[0])); int *gdata; cudaMalloc(&amp;gdata, sizeof(gdata[0])); cudaMemset(gdata, 0, sizeof(gdata[0])); k&lt;&lt;&lt;1,1&gt;&gt;&gt;(gdata); cudaDeviceSynchronize(); } $ nvcc -o t1973 t1973.cu -g -G -arch=sm_70 $ cuda-gdb ./t1973 sh: python3: command not found Unable to determine python3 interpreter version. Python integration disabled. NVIDIA (R) CUDA Debugger 11.4 release Portions Copyright (C) 2007-2021 NVIDIA Corporation GNU gdb (GDB) 10.1 Copyright (C) 2020 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-pc-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: &lt;https://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from ./t1973... (cuda-gdb) b 5 Breakpoint 1 at 0x403b0c: file t1973.cu, line 6. (cuda-gdb) run Starting program: /home/user2/misc/t1973 [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib64/libthread_db.so.1\". [Detaching after fork from child process 22872] [New Thread 0x7fffef475700 (LWP 22879)] [New Thread 0x7fffeec74700 (LWP 22880)] [Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (0,0,0), device 0, sm 0, warp 0, lane 0] Thread 1 \"t1973\" hit Breakpoint 1, k&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; ( gdata=0x7fffcdc00000) at t1973.cu:5 5 gdata[0] = cdata[0]; (cuda-gdb) print gdata[0] $1 = 0 (cuda-gdb) print cdata[0] $2 = 1 (cuda-gdb) s 6 } (cuda-gdb) print gdata[0] $3 = 1 (cuda-gdb) print cdata[0] $4 = 1 (cuda-gdb) print cdata[1] $5 = 2 (cuda-gdb)"
            ],
            [
                "Try putting you __constant__ into .cuh, then use as a classic C global variable."
            ]
        ],
        "votes": [
            2.0000001,
            -1.9999999
        ]
    },
    {
        "question": "I'm trying to extract feathers from BertTopic model and I'm using jupyter notebook. The first feature is sentiment analysis and it's done by following code: df-DataFrame, df[\"title_selftext\"] - this data frame column contain a text (str) def get_sentiment(model, tokenizer, data): inputs = tokenizer(data, padding=True, return_tensors=\"pt\") outputs = model(**inputs.to(device)) return torch.nn.functional.softmax(outputs.logits.detach()) res = [] for txt in tqdm(batches(df[\"title_selftext\"],20), total=len(df)//32): **res.append(get_sentiment(model,tokenizer, list(txt)))** when im trying to append the get_sentiment output i for this error: RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasSgemm( handle, opa, opb, m, n, k, &amp;alpha, a, lda, b, ldb, &amp;beta, c, ldc) please help me to solve this error Thank you",
        "answers": [],
        "votes": []
    },
    {
        "question": "I have a simple cuda code in ttt.cu #include &lt;iostream&gt; __global__ void example(){ printf(\"__CUDA_ARCH__: %d \\n\", __CUDA_ARCH__); } int main(){ example&lt;&lt;&lt;1,1&gt;&gt;&gt;(); } with CMakeLists.txt: cmake_minimum_required(VERSION 3.18) project(Hello) find_package(CUDA REQUIRED) cuda_add_executable(sss ttt.cu) Then I got the error: identifier \"__CUDA_ARCH__\" is undefined. I would like to know why does this happen and what should I do for making the __CUDA_ARCH__ valid? And can we use valid __CUDA_ARCH__ in host code within a header .h file? Update: I intended to use the following cmake for generating a 750 cuda arch, however, this always results in a __CUDA_ARCH__ = 300 (2080 ti with cuda 10.1). I tried both set_property and target_compile_options, which all failed. cmake_minimum_required(VERSION 3.18) project(Hello) find_package(CUDA REQUIRED) cuda_add_executable(oounne ttt.cu) set_property(TARGET oounne PROPERTY CUDA_ARCHITECTURES 75) #target_compile_options(oounne PRIVATE $&lt;$&lt;COMPILE_LANGUAGE:CUDA&gt;:-gencode arch=compute_75,code=sm_75&gt;)",
        "answers": [
            [
                "__CUDA_ARCH__ is a compiler macro. can we use valid __CUDA_ARCH__ in host code No, it is intended to be used in device code only: The host code (the non-GPU code) must not depend on it. You cannot print a compiler macro the way you are imagining. It is not an ordinary numerical variable defined in C++. You could do something like this but that would print at compile-time, not at run-time. To print at run-time, you could do something like this: $ cat t2.cu #include &lt;cstdio&gt; #define STR_HELPER(x) #x #define STR(x) STR_HELPER(x) __device__ void print_arch(){ const char my_compile_time_arch[] = STR(__CUDA_ARCH__); printf(\"__CUDA_ARCH__: %s\\n\", my_compile_time_arch); } __global__ void example() { print_arch(); } int main(){ example&lt;&lt;&lt;1,1&gt;&gt;&gt;(); cudaDeviceSynchronize(); } $ nvcc -o t2 t2.cu $ ./t2 __CUDA_ARCH__: 520 $ Note that there are quite a few questions here on the cuda tag discussing __CUDA_ARCH__, you may wish to review some of them."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I am compiling the following fragment of code with nvcc -g -G gdbfail.cu. #include &lt;cstdio&gt; #include &lt;cinttypes&gt; __global__ void mykernel() { uint8_t* ptr = (uint8_t*) malloc(8); for (int i = 0; i &lt; 8; i++) { ptr[i] = 7 - i; } for (int i = 0; i &lt; 8; i++) { // PUT BREAKPOINT HERE printf(\"%\" PRIx8 \" \", ptr[i]); } printf(\"\\n\"); } int main() { uint8_t* ptr = (uint8_t*) malloc(8); for (int i = 0; i &lt; 8; i++) { ptr[i] = 7 - i; } for (int i = 0; i &lt; 8; i++) { // PUT BREAKPOINT HERE printf(\"%\" PRIx8 \" \", ptr[i]); } printf(\"\\n\"); mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); cudaDeviceSynchronize(); } When I run cuda-gdb ./a.out and put breakpoint at line 10 (b 10), run the code (r), and trying to print values at the address located in ptr I get surprising results (cuda-gdb) x/8b ptr 0x7fffcddff920: 7 6 5 4 3 2 1 0 (cuda-gdb) x/8b 0x7fffcddff920 0x7fffcddff920: 0 0 0 0 0 0 0 0 When I am doing the same thing in the host code (b 23, r), I get expected results: (cuda-gdb) x/8b ptr 0x5555556000a0: 7 6 5 4 3 2 1 0 (cuda-gdb) x/8b 0x5555556000a0 0x5555556000a0: 7 6 5 4 3 2 1 0 Why cuda-gdb doesn't show correct memory values when it is provided with address as a number (0x7fffcddff920) instead of a symbol (ptr)?",
        "answers": [
            [
                "Evidently, not all gdb command features that are usable in host code are also usable in device code. When used in device code, the supported commands may have different syntax or expectations. This is indicated in the cuda-gdb docs. Those docs indicate that the way to inspect memory is the print command and indicate some additional decode syntax that is needed for a \"bare\" address/pointer. Here is your example: $ cuda-gdb ./t1869 NVIDIA (R) CUDA Debugger 11.4 release Portions Copyright (C) 2007-2021 NVIDIA Corporation GNU gdb (GDB) 10.1 Copyright (C) 2020 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-pc-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: &lt;https://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from ./t1869... (cuda-gdb) b 10 Breakpoint 1 at 0x403b05: file t1869.cu, line 14. (cuda-gdb) r Starting program: /home/user2/misc/t1869 [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib64/libthread_db.so.1\". 7 6 5 4 3 2 1 0 [Detaching after fork from child process 25822] [New Thread 0x7fffef475700 (LWP 25829)] [New Thread 0x7fffeec74700 (LWP 25830)] [Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (0,0,0), device 0, sm 0, warp 0, lane 0] Thread 1 \"t1869\" hit Breakpoint 1, mykernel&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; () at t1869.cu:10 10 for (int i = 0; i &lt; 8; i++) { // PUT BREAKPOINT HERE (cuda-gdb) x/8b ptr 0x7fffbcdff920: 7 6 5 4 3 2 1 0 (cuda-gdb) p/x *(@global unsigned char *)0x7fffbcdff920@8 $1 = {0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0} (cuda-gdb) Note the above print command needs some help in interpreting which \"space\" you are expecting the memory address to refer to (e.g. @shared, @global, etc.) If we give your command the same \"help\" we get the expected result: (cuda-gdb) x/8b ptr 0x7fffbcdff920: 7 6 5 4 3 2 1 0 (cuda-gdb) x/8b (@global unsigned char *)0x7fffbcdff920 0x7fffbcdff920: 7 6 5 4 3 2 1 0 (cuda-gdb)"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have been trying to debug cuda programs that use inline PTX assembly. Specifically, I am debugging at the instruction level, and am trying to determine the values of arguments to the instructions. Occasionally, the disassembly includes a reference to constant memory. I am trying to have gdb print the value of this constant memory, but have not found any documentation that shows how to do this. For instance, a disassembly includes IADD R0, R0, c[0x0] [0x148] I want to determine how to have gdb print the value of c[0x0] [0x148]. I have tried using print * (@constant) ... but this does not seem to work (I pass 0x148 here and it prints out nothing). Is this possible to do in cuda-gdb? I have tried to avoid this by passing the compiler option --disable-optimizer-constants during compilation, but this does not work.",
        "answers": [
            [
                "The way to do this is to print *(void * @parameter *) addr where addr is the address inside the constant bank 0 that should be printed. Example Suppose we have a simple kernel in a file called foo.cu: #include &lt;cuda.h&gt; #include &lt;stdio.h&gt; #include &lt;cuda_runtime.h&gt; __global__ void myKernel(int a, int b, int *d) { *d = a + b; } int main(int argc, char *argv[]) { if (argc &lt; 3) { printf(\"Requires inputs a and b to be specified\\n\"); return 0; } int * dev_d; int d; cudaMalloc(&amp;dev_d, sizeof(*dev_d)); myKernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(atoi(argv[1]), atoi(argv[2]), dev_d); cudaMemcpy(&amp;d, dev_d, sizeof(d), cudaMemcpyDeviceToHost); cudaFree(dev_d); printf(\"D is: %d\\n\", d); return 0; } which is compiled via $ nvcc foo.cu -o foo.out Next, suppose we are interested in disassembling this program, so we execute cuda-gdb with a command-line for our program: $ cuda-gdb --args ./foo.out 10 15 Inside cuda-gdb, we get to the kernel by typing (cuda-gdb) set cuda break_on_launch application (cuda-gdb) start Temporary breakpoint 1, 0x000055555555b12a in main () (cuda-gdb) cont Inside the kernel, we view the disassembly we are interested in debugging: (cuda-gdb) x/15i $pc =&gt; 0x555555b790a8 &lt;_Z8myKerneliiPi+8&gt;: MOV R1, c[0x0][0x20] 0x555555b790b0 &lt;_Z8myKerneliiPi+16&gt;: MOV R0, c[0x0][0x144] 0x555555b790b8 &lt;_Z8myKerneliiPi+24&gt;: MOV R2, c[0x0][0x148] 0x555555b790c0 &lt;_Z8myKerneliiPi+32&gt;: 0x555555b790c8 &lt;_Z8myKerneliiPi+40&gt;: MOV R3, c[0x0][0x14c] 0x555555b790d0 &lt;_Z8myKerneliiPi+48&gt;: IADD R0, R0, c[0x0][0x140] 0x555555b790d8 &lt;_Z8myKerneliiPi+56&gt;: STG.E [R2], R0 0x555555b790e0 &lt;_Z8myKerneliiPi+64&gt;: 0x555555b790e8 &lt;_Z8myKerneliiPi+72&gt;: NOP 0x555555b790f0 &lt;_Z8myKerneliiPi+80&gt;: NOP 0x555555b790f8 &lt;_Z8myKerneliiPi+88&gt;: NOP 0x555555b79100 &lt;_Z8myKerneliiPi+96&gt;: 0x555555b79108 &lt;_Z8myKerneliiPi+104&gt;: EXIT 0x555555b79110 &lt;_Z8myKerneliiPi+112&gt;: BRA 0x70 0x555555b79118 &lt;_Z8myKerneliiPi+120&gt;: NOP The second argument being passed to the IADD instruction is in one of the constant memory banks. Let's find out what its value actually is. We advance go to the IADD instruction: (cuda-gdb) stepi 4 0x0000555555b790d0 in myKernel(int, int, int*)&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; () (cuda-gdb) x/i $pc =&gt; 0x555555b790d0 &lt;_Z8myKerneliiPi+48&gt;: IADD R0, R0, c[0x0][0x140] We can now obtain the contents of c[0x0][0x140] as follows: (cuda-gdb) print (int) *(void * @parameter *) 0x140 $1 = 10 Here, we knew the argument should have 32 bits, so we cast it as an (32-bit) int. If we hadn't done this, we would get too many bits, e.g.: (cuda-gdb) print *(void * @parameter *) 0x140 $2 = 0xf0000000a Note the hexadecimal format can be retained by adding /x after the print command: (cuda-gdb) print/x (int) *(void * @parameter *)0x140 $3 = 0xa"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I tried to attach to running process(python3) after I found GPU-related log in the dmesg. ex) Xid 13, 31, 45 But i couldn't get any clue because of below message. Does anyone know what this message means? Couldn't write extended state status: Bad address. A program is being debugged already. Kill it? $ cuda-gdb python3 1243 NVIDIA (R) CUDA Debugger 10.2 release Portions Copyright (C) 2007-2019 NVIDIA Corporation GNU gdb (GDB) 7.12 Copyright (C) 2016 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; (omit) Reading symbols from /usr/lib64/libcuda.so.1...(no debugging symbols found)...done. Reading symbols from /usr/local/lib64/python3.6/site-packages/PIL/_imaging.cpython-36m-x86_64-linux-gnu.so...(no debugging symbols found)...done. Reading symbols from /usr/local/lib64/python3.6/site-packages/PIL/../Pillow.libs/libjpeg-ba7bf5af.so.9.4.0...(no debugging symbols found)...done. Reading symbols from /usr/local/lib64/python3.6/site-packages/PIL/../Pillow.libs/libopenjp2-b3d7668a.so.2.3.1...(no debugging symbols found)...done. Reading symbols from /usr/local/lib64/python3.6/site-packages/PIL/../Pillow.libs/libtiff-41910f6d.so.5.5.0...(no debugging symbols found)...done. Reading symbols from /usr/local/lib64/python3.6/site-packages/PIL/../Pillow.libs/./liblzma-99449165.so.5.2.5...(no debugging symbols found)...done. 0x00007ffcd4ed4980 in clock_gettime () Couldn't write extended state status: Bad address. A program is being debugged already. Kill it? (y or n) y /home1/irteam/apps/pytorch-app/src/1243: No such file or directory. (cuda-gdb) bt No stack. (cuda-gdb) exit",
        "answers": [],
        "votes": []
    },
    {
        "question": "Operating System: CentOS 7 Cuda Toolkit Version: 11.0 Nvidia Driver and GPU Info: NVIDIA-SMI 450.51.05 Driver Version: 450.51.05 CUDA Version: 11.0 GPU: Quadro M2000M screenshot of nvidia-smi details I'm very new to cuda programming so any guidance is extremely appreciated. I have a very simple cuda c++ program that computes the sum of two arrays in unified memory on the GPU. However, it appears that the kernel fails to launch due to a cudaErrorNoKernelImageForDevice error. The code is below: using namespace std; #include &lt;iostream&gt; #include &lt;math.h&gt; #include &lt;cuda_runtime_api.h&gt; __global__ void add(int n, float *x, float*y){ for (int i = 0; i &lt; n; i++) y[i] = x[i] + y[i]; } int main() { cout &lt;&lt; \"!!!Hello World!!!\" &lt;&lt; endl; // prints !!!Hello World!!! int N = 1&lt;&lt;20; float *x, *y; cudaMallocManaged((void**)&amp;x, N*sizeof(float)); cudaMallocManaged((void**)&amp;y, N*sizeof(float)); for(int i = 0; i &lt; N; i++){ x[i] = 1.0f; y[i] = 2.0f; } add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, x, y); cudaGetLastError(); /** * This indicates that there is no kernel image available that is suitable * for the device. This can occur when a user specifies code generation * options for a particular CUDA source file that do not include the * corresponding device configuration. * * cudaErrorNoKernelImageForDevice = 209, */ cudaDeviceSynchronize(); float maxError = 0.0f; for (int i = 0; i &lt; N; i++){ maxError = fmax(maxError, fabs(y[i]-3.0f)); } cudaFree(x); cudaFree(y); return 0; }",
        "answers": [
            [
                "The error here comes about due to the fact that a CUDA kernel must be compiled in a way that the resulting code (PTX, or SASS) is compatible with the GPU that it is being run on. This is a topic with a lot of nuance, so please refer to questions like this (and the links there) for additional background. The GPU architecture when we want to be precise is referred to as the compute capability. You can discover the compute capability of your GPU either with a google search or by running the deviceQuery CUDA sample code. The compute capability is expressed as (major).(minor) so something like compute capability 5.2, or 7.0, etc. When compiling code, it's necessary to specify a compute capability (or if not, a default compute capability will be implied). If you specify the compute capability when compiling in a way that matches your GPU, everything should be fine. However newer/higher compute capability code will generally not run on older/lower compute capability GPUs. In that case, you will see errors like what you describe: cudaErrorNoKernelImageForDevice 209 \"no binary for GPU\" or similar. You may also see no explicit error at all if you are not doing proper CUDA error checking. The solution is to match the compute capability specified at compile time with the GPU you intend to run on. The method to do this will vary depending on the toolchain/IDE you are using. For basic nvcc command line usage: nvcc -arch=sm_XY ... will specify a compute capability of X.Y For Eclipse/Nsight Eclipse/Nsight Visual Studio, the compute capability can be specified in the project properties. Depending on the tool it may be expressed as switch values (e.g. compute_XY, sm_XY) or it may be expressed numerically as X.Y"
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I am trying to debug a program in cuda-gdb. I am able to successfully set breakpoints in code that runs on the host (CPU), but whenever I try to set a breakpoint in code that runs on the GPU, the debugger skips over the breakpoints and gives me the following error: \"warning: Cuda API error detected: cudaLaunchKernel returned (0x7)\" It then continues to successfully execute the rest of the code. How can I make these work?",
        "answers": [
            [
                "I was able to get the breakpoints to work based on this answer from NVIDIA dev forums. Namely, in the nvcc compiler options you need to limit the amount of registers used by using the maxrregcount flag, e.g: nvcc -arch sm_60 -g -G -dc --maxrregcount=64 --compiler-options -Wall -std=c++14 basic.cu (Note: to see how much registers you have, enter info cuda devices into cuda-gdb and check the Regs/Lane column)"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I have an application which generates CUDA C++ source code, compiles it into PTX at runtime using NVRTC, and then creates CUDA modules from it using the CUDA driver API. If I debug this application using cuda-gdb, it displays the kernel (where an error occured) in the backtrace, but does not show the line number. I export the generated source code into a file, and give the directory to cuda-gdb using the --directory option. I also tried passing its file name to nvrtcCreateProgram() (name argument). I use the compile options --device-debug and --generate-line-info with NVRTC. Is there a way to let cuda-gdb know the location of the generated source code file, and display the line number information in its backtrace?",
        "answers": [
            [
                "For those who may not be familiar with nvrtc, it is a CUDA facility that allows runtime-compilation of CUDA C++ device code. As a result, device code generated at runtime (including modifications) can be used on a CUDA GPU. There is documentation for nvrtc and there are various CUDA sample codes for nvrtc, most or all of which have _nvrtc in the file name. I was able to do kernel source-level debugging on a nvrtc-generated kernel with cuda-gdb as follows: start with vectorAdd_nvrtc sample code modify the compileFileToPTX routine (provided by nvrtc_helper.h) to add the --device-debug switch during the compile-cu-to-ptx step. modify the loadPTX routine (provided by nvrtc_helper.h) to add the CU_JIT_GENERATE_DEBUG_INFO option (set to 1) for the cuModuleLoadDataEx load/JIT PTX-to-binary step. compile the main function (vectorAdd.cpp) with -g option. Here is a complete test case/session. I'm only showing the vectorAdd.cpp file from the project because that is the only file I modified. Other project file(s) are identical to what is in the sample project: $ cat vectorAdd.cpp /** * Copyright 1993-2015 NVIDIA Corporation. All rights reserved. * * Please refer to the NVIDIA end user license agreement (EULA) associated * with this source code for terms and conditions that govern your use of * this software. Any use, reproduction, disclosure, or distribution of * this software and related documentation outside the terms of the EULA * is strictly prohibited. * */ /** * Vector addition: C = A + B. * * This sample is a very basic sample that implements element by element * vector addition. It is the same as the sample illustrating Chapter 2 * of the programming guide with some additions like error checking. */ #include &lt;stdio.h&gt; #include &lt;cmath&gt; // For the CUDA runtime routines (prefixed with \"cuda_\") #include &lt;cuda.h&gt; #include &lt;cuda_runtime.h&gt; // helper functions and utilities to work with CUDA #include &lt;helper_functions.h&gt; #include &lt;nvrtc_helper.h&gt; #include &lt;iostream&gt; #include &lt;fstream&gt; /** * Host main routine */ void my_compileFileToPTX(char *filename, int argc, char **argv, char **ptxResult, size_t *ptxResultSize, int requiresCGheaders) { std::ifstream inputFile(filename, std::ios::in | std::ios::binary | std::ios::ate); if (!inputFile.is_open()) { std::cerr &lt;&lt; \"\\nerror: unable to open \" &lt;&lt; filename &lt;&lt; \" for reading!\\n\"; exit(1); } std::streampos pos = inputFile.tellg(); size_t inputSize = (size_t)pos; char *memBlock = new char[inputSize + 1]; inputFile.seekg(0, std::ios::beg); inputFile.read(memBlock, inputSize); inputFile.close(); memBlock[inputSize] = '\\x0'; int numCompileOptions = 0; char *compileParams[2]; std::string compileOptions; if (requiresCGheaders) { char HeaderNames[256]; #if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64) sprintf_s(HeaderNames, sizeof(HeaderNames), \"%s\", \"cooperative_groups.h\"); #else snprintf(HeaderNames, sizeof(HeaderNames), \"%s\", \"cooperative_groups.h\"); #endif compileOptions = \"--include-path=\"; std::string path = sdkFindFilePath(HeaderNames, argv[0]); if (!path.empty()) { std::size_t found = path.find(HeaderNames); path.erase(found); } else { printf( \"\\nCooperativeGroups headers not found, please install it in %s \" \"sample directory..\\n Exiting..\\n\", argv[0]); } compileOptions += path.c_str(); compileParams[0] = reinterpret_cast&lt;char *&gt;( malloc(sizeof(char) * (compileOptions.length() + 1))); #if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64) sprintf_s(compileParams[0], sizeof(char) * (compileOptions.length() + 1), \"%s\", compileOptions.c_str()); #else snprintf(compileParams[0], compileOptions.size(), \"%s\", compileOptions.c_str()); #endif numCompileOptions++; } compileOptions = \"--device-debug \"; compileParams[numCompileOptions] = reinterpret_cast&lt;char *&gt;(malloc(sizeof(char) * (compileOptions.length() + 1))); snprintf(compileParams[numCompileOptions], compileOptions.size(), \"%s\", compileOptions.c_str()); numCompileOptions++; // compile nvrtcProgram prog; NVRTC_SAFE_CALL(\"nvrtcCreateProgram\", nvrtcCreateProgram(&amp;prog, memBlock, filename, 0, NULL, NULL)); nvrtcResult res = nvrtcCompileProgram(prog, numCompileOptions, compileParams); // dump log size_t logSize; NVRTC_SAFE_CALL(\"nvrtcGetProgramLogSize\", nvrtcGetProgramLogSize(prog, &amp;logSize)); char *log = reinterpret_cast&lt;char *&gt;(malloc(sizeof(char) * logSize + 1)); NVRTC_SAFE_CALL(\"nvrtcGetProgramLog\", nvrtcGetProgramLog(prog, log)); log[logSize] = '\\x0'; if (strlen(log) &gt;= 2) { std::cerr &lt;&lt; \"\\n compilation log ---\\n\"; std::cerr &lt;&lt; log; std::cerr &lt;&lt; \"\\n end log ---\\n\"; } free(log); NVRTC_SAFE_CALL(\"nvrtcCompileProgram\", res); // fetch PTX size_t ptxSize; NVRTC_SAFE_CALL(\"nvrtcGetPTXSize\", nvrtcGetPTXSize(prog, &amp;ptxSize)); char *ptx = reinterpret_cast&lt;char *&gt;(malloc(sizeof(char) * ptxSize)); NVRTC_SAFE_CALL(\"nvrtcGetPTX\", nvrtcGetPTX(prog, ptx)); NVRTC_SAFE_CALL(\"nvrtcDestroyProgram\", nvrtcDestroyProgram(&amp;prog)); *ptxResult = ptx; *ptxResultSize = ptxSize; #ifdef DUMP_PTX std::ofstream my_f; my_f.open(\"vectorAdd.ptx\"); for (int i = 0; i &lt; ptxSize; i++) my_f &lt;&lt; ptx[i]; my_f.close(); #endif if (requiresCGheaders) free(compileParams[0]); } CUmodule my_loadPTX(char *ptx, int argc, char **argv) { CUmodule module; CUcontext context; int major = 0, minor = 0; char deviceName[256]; // Picks the best CUDA device available CUdevice cuDevice = findCudaDeviceDRV(argc, (const char **)argv); // get compute capabilities and the devicename checkCudaErrors(cuDeviceGetAttribute( &amp;major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, cuDevice)); checkCudaErrors(cuDeviceGetAttribute( &amp;minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, cuDevice)); checkCudaErrors(cuDeviceGetName(deviceName, 256, cuDevice)); printf(\"&gt; GPU Device has SM %d.%d compute capability\\n\", major, minor); checkCudaErrors(cuInit(0)); checkCudaErrors(cuDeviceGet(&amp;cuDevice, 0)); checkCudaErrors(cuCtxCreate(&amp;context, 0, cuDevice)); CUjit_option opt[1]; opt[0] = CU_JIT_GENERATE_DEBUG_INFO; void **vals = new void *[1]; vals[0] = (void *)(size_t)1; checkCudaErrors(cuModuleLoadDataEx(&amp;module, ptx, 1, opt, vals)); free(ptx); return module; } int main(int argc, char **argv) { char *ptx, *kernel_file; size_t ptxSize; kernel_file = sdkFindFilePath(\"vectorAdd_kernel.cu\", argv[0]); my_compileFileToPTX(kernel_file, argc, argv, &amp;ptx, &amp;ptxSize, 0); CUmodule module = my_loadPTX(ptx, argc, argv); CUfunction kernel_addr; checkCudaErrors(cuModuleGetFunction(&amp;kernel_addr, module, \"vectorAdd\")); // Print the vector length to be used, and compute its size int numElements = 50000; size_t size = numElements * sizeof(float); printf(\"[Vector addition of %d elements]\\n\", numElements); // Allocate the host input vector A float *h_A = reinterpret_cast&lt;float *&gt;(malloc(size)); // Allocate the host input vector B float *h_B = reinterpret_cast&lt;float *&gt;(malloc(size)); // Allocate the host output vector C float *h_C = reinterpret_cast&lt;float *&gt;(malloc(size)); // Verify that allocations succeeded if (h_A == NULL || h_B == NULL || h_C == NULL) { fprintf(stderr, \"Failed to allocate host vectors!\\n\"); exit(EXIT_FAILURE); } // Initialize the host input vectors for (int i = 0; i &lt; numElements; ++i) { h_A[i] = rand() / static_cast&lt;float&gt;(RAND_MAX); h_B[i] = rand() / static_cast&lt;float&gt;(RAND_MAX); } // Allocate the device input vector A CUdeviceptr d_A; checkCudaErrors(cuMemAlloc(&amp;d_A, size)); // Allocate the device input vector B CUdeviceptr d_B; checkCudaErrors(cuMemAlloc(&amp;d_B, size)); // Allocate the device output vector C CUdeviceptr d_C; checkCudaErrors(cuMemAlloc(&amp;d_C, size)); // Copy the host input vectors A and B in host memory to the device input // vectors in device memory printf(\"Copy input data from the host memory to the CUDA device\\n\"); checkCudaErrors(cuMemcpyHtoD(d_A, h_A, size)); checkCudaErrors(cuMemcpyHtoD(d_B, h_B, size)); // Launch the Vector Add CUDA Kernel int threadsPerBlock = 256; int blocksPerGrid = (numElements + threadsPerBlock - 1) / threadsPerBlock; printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock); dim3 cudaBlockSize(threadsPerBlock, 1, 1); dim3 cudaGridSize(blocksPerGrid, 1, 1); void *arr[] = {reinterpret_cast&lt;void *&gt;(&amp;d_A), reinterpret_cast&lt;void *&gt;(&amp;d_B), reinterpret_cast&lt;void *&gt;(&amp;d_C), reinterpret_cast&lt;void *&gt;(&amp;numElements)}; checkCudaErrors(cuLaunchKernel(kernel_addr, cudaGridSize.x, cudaGridSize.y, cudaGridSize.z, /* grid dim */ cudaBlockSize.x, cudaBlockSize.y, cudaBlockSize.z, /* block dim */ 0, 0, /* shared mem, stream */ &amp;arr[0], /* arguments */ 0)); checkCudaErrors(cuCtxSynchronize()); // Copy the device result vector in device memory to the host result vector // in host memory. printf(\"Copy output data from the CUDA device to the host memory\\n\"); checkCudaErrors(cuMemcpyDtoH(h_C, d_C, size)); // Verify that the result vector is correct for (int i = 0; i &lt; numElements; ++i) { if (fabs(h_A[i] + h_B[i] - h_C[i]) &gt; 1e-5) { fprintf(stderr, \"Result verification failed at element %d!\\n\", i); exit(EXIT_FAILURE); } } printf(\"Test PASSED\\n\"); // Free device global memory checkCudaErrors(cuMemFree(d_A)); checkCudaErrors(cuMemFree(d_B)); checkCudaErrors(cuMemFree(d_C)); // Free host memory free(h_A); free(h_B); free(h_C); printf(\"Done\\n\"); return 0; } $ nvcc -g -I/usr/local/cuda/samples/common/inc -o test vectorAdd.cpp -lnvrtc -lcuda $ cuda-gdb ./test NVIDIA (R) CUDA Debugger 10.0 release Portions Copyright (C) 2007-2018 NVIDIA Corporation GNU gdb (GDB) 7.12 Copyright (C) 2016 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-pc-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from ./test...done. (cuda-gdb) break vectorAdd Function \"vectorAdd\" not defined. Make breakpoint pending on future shared library load? (y or [n]) y Breakpoint 1 (vectorAdd) pending. (cuda-gdb) r Starting program: /home/user2/misc/junk/vectorAdd_nvrtc/test [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib64/libthread_db.so.1\". [New Thread 0x7fffedc00700 (LWP 16789)] &gt; Using CUDA Device [1]: Tesla K40m &gt; GPU Device has SM 3.5 compute capability [New Thread 0x7fffed3ff700 (LWP 16790)] [Vector addition of 50000 elements] Copy input data from the host memory to the CUDA device CUDA kernel launch with 196 blocks of 256 threads [Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (0,0,0), device 0, sm 0, warp 0, lane 0] Thread 1 \"test\" hit Breakpoint 1, vectorAdd&lt;&lt;&lt;(196,1,1),(256,1,1)&gt;&gt;&gt; (A=0x7fffce800000, B=0x7fffce830e00, C=0x7fffce861c00, numElements=50000) at ./vectorAdd_kernel.cu:21 21 int i = blockDim.x * blockIdx.x + threadIdx.x; (cuda-gdb) step 23 if (i &lt; numElements) { (cuda-gdb) step 24 C[i] = A[i] + B[i]; (cuda-gdb) step 26 } (cuda-gdb) quit A debugging session is active. Inferior 1 [process 16777] will be killed. Quit anyway? (y or n) y $"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "how do I prevent cuda-gdb from optimizing out any value ( whether device or host, local or global )? I have checked nvidia forums but most of them are years old and there seems to be not a solution for old cuda versions, but is there one for the newest one (cuda 9.2 and sm 61)? I am using flags described in nvidia's documentation: -g - \"Generate debug information for host code.\" -G - \"Generate debug information for device code. Turns off all optimizations. Don't use for profiling; use -lineinfo instead.\"",
        "answers": [
            [
                "how do I prevent cuda-gdb from optimizing out any value The cuda-gdb is not optimizing anything; it is just interpreting the debug info that the compiler (nvcc) put into the binary. If the compiler chose not to describe location of some variable, then there is nothing cuda-gdb can do to recover that info. This would generally be a quality of debugging info issue with nvcc. It's possible that nvcc did describe the location you are after, but cuda-gdb is failing to handle that description, in which case it's a bug in cuda-gdb. In either case, you can't really do anything about it, other than complaining to NVidia."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I'm having this weird issue: I have a program that uses CUPTI callbackAPI to monitor the kernels in the program. It runs well when it's directly launched; but when I put it under cuda-gdb and run, it failed with the following error: error: function cuptiSubscribe(&amp;subscriber, CUpti_CallbackFunc)my_callback, NULL) failed with error CUPTI_ERROR_NOT_INITIALIZED I've tried all examples in CUPTI/samples and concluded that programs that use callbackAPI and activityAPI will fail under cuda-gdb. (They are all well-behaved without cuda-gdb) But the fail reason differs: If I have calls from activityAPI, then once run it under cuda-gdb, it'll hang for a minute then exit with error: The CUDA driver has hit an internal error. Error code: 0x100ff00000001c Further execution or debugging is unreliable. Please ensure that your temporary directory is mounted with write and exec permissions. If I have calls from callbackAPI like my own program, then it'll fail out much sooner with the same error: CUPTI_ERROR_NOT_INITIALIZED Any experience on this kinda issue? I really appreciate that!",
        "answers": [
            [
                "According to NVIDIA forum posting here and also referred to here, the CUDA \"tools\" must be used uniquely. These tools include: CUPTI any profiler cuda-memcheck a debugger Only one of these can be \"in use\" on a code at a time. It should be fairly easy for developers to use a profiler, or cuda-memcheck, or a debugger independently, but a possible takeaway for those using CUPTI, who also wish to be able to use another CUDA \"tool\" on the same code, would be to provide a coding method to be able to disable CUPTI use in their application, when they wish to use another tool."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "When I start my program in cuda-gdb, I get an output like: [New Thread 0x7fffef8ea700 (LWP 8003)] [New Thread 0x7fffe35b2700 (LWP 8010)] [New Thread 0x7fffe2db1700 (LWP 8011)] [New Thread 0x7fffe25b0700 (LWP 8012)] I do not understand why these multiple threads are launched in the beginning. I have not launched my program in multi-threaded mode. I am using MPI, but I start one process. So, where are these threads coming from? This does not affect my debugging process in any way. Its just that I don't understand what this means.",
        "answers": [
            [
                "These threads you see are created by the CUDA runtime library, and aren't directly related to cuda-gdb itself. If you run the same code with gdb, you will also see the same messages. If you want to see what happens what these threads are doing or where they're coming from, simply compile your code with the -g flag, set a breakpoint in your code (e.g., immediately before a CUDA kernel starts), run it, and then run the following command in the gdb console: thread apply all backtrace This command has the same effect of gdb's backtrace, except that it will show the backtrace for all threads created by your program. In my case, I get the following messages after starting my program: [New Thread 0x7fffeffb3700 (LWP 7141)] [New Thread 0x7fffef731700 (LWP 7142)] [New Thread 0x7fffeef30700 (LWP 7143)] When I run the command mentioned above in my gdb console, I see the following output: (gdb) thread apply all backtrace Thread 4 (Thread 0x7fffeef30700 (LWP 7143)): #0 pthread_cond_timedwait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_timedwait.S:238 #1 0x00007ffff63c19b7 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff6386bb7 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff63c0f48 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bf064 in start_thread (arg=0x7fffeef30700) at pthread_create.c:309 #5 0x00007ffff6cce62d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111 Thread 3 (Thread 0x7fffef731700 (LWP 7142)): #0 0x00007ffff6cc5aed in poll () at ../sysdeps/unix/syscall-template.S:81 #1 0x00007ffff63bf6a3 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff642261e in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff63c0f48 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bf064 in start_thread (arg=0x7fffef731700) at pthread_create.c:309 #5 0x00007ffff6cce62d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111 Thread 2 (Thread 0x7fffeffb3700 (LWP 7141)): #0 0x00007ffff6ccfa9f in accept4 (fd=13, addr=..., addr_len=0x7fffeffb2e18, flags=-1) at ../sysdeps/unix/sysv/linux/accept4.c:45 #1 0x00007ffff63c0556 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff63b404d in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff63c0f48 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bf064 in start_thread (arg=0x7fffeffb3700) at pthread_create.c:309 #5 0x00007ffff6cce62d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111 Thread 1 (Thread 0x7ffff7fc0740 (LWP 7136)): #0 main () at cuda_heap.cu:66 As you can verify, all threads that have been created at the beginning match both thread addresses and LWP (Light Weight Process) IDs. You can see that all of them come from libcuda.so.1. In cuda-gdb, you're able to see some more detailed information: (cuda-gdb) thread apply all bt Thread 4 (Thread 0x7fffeef30700 (LWP 10019)): #0 0x00007ffff79c33f8 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0 #1 0x00007ffff63c19b7 in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff6386bb7 in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff63c0f48 in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bf064 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0 #5 0x00007ffff6cce62d in clone () from /lib/x86_64-linux-gnu/libc.so.6 Thread 3 (Thread 0x7fffef731700 (LWP 10018)): #0 0x00007ffff6cc5aed in poll () from /lib/x86_64-linux-gnu/libc.so.6 #1 0x00007ffff63bf6a3 in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff642261e in cuVDPAUCtxCreate () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff63c0f48 in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bf064 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0 #5 0x00007ffff6cce62d in clone () from /lib/x86_64-linux-gnu/libc.so.6 Thread 2 (Thread 0x7fffeffb3700 (LWP 10017)): #0 0x00007ffff6ccfa9f in accept4 () from /lib/x86_64-linux-gnu/libc.so.6 #1 0x00007ffff63c0556 in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff63b404d in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff63c0f48 in cudbgApiDetach () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bf064 in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0 #5 0x00007ffff6cce62d in clone () from /lib/x86_64-linux-gnu/libc.so.6 Thread 1 (Thread 0x7ffff7fc0740 (LWP 10007)): #0 main () at cuda_heap.cu:66"
            ],
            [
                "i don't know what exactly it is, but I think cuda-gdb need to create multiple thread to catch the errors/exceptions like: memory violation or bank conflicts."
            ]
        ],
        "votes": [
            4.0000001,
            -1.9999999
        ]
    },
    {
        "question": "I have installed the latest version of the CUDA drivers available from NVIDIA mmiller@host:~/NVIDIA_CUDA-7.5_Samples$ nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2015 NVIDIA Corporation Built on Tue_Aug_11_14:27:32_CDT_2015 Cuda compilation tools, release 7.5, V7.5.17 But when I debug a program I get an error message about python. mmiller@csit-crackin:~$ cuda-gdb hello.out NVIDIA (R) CUDA Debugger 7.5 release Portions Copyright (C) 2007-2015 NVIDIA Corporation GNU gdb (GDB) 7.6.2 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-unknown-linux-gnu\". For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;... Reading symbols from /home/mmiller/hello.out...done. (cuda-gdb) b main Breakpoint 1 at 0x402546: file hello.cu, line 3. (cuda-gdb) r Starting program: /home/mmiller/hello.out [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". Breakpoint 1, main () at hello.cu:3 3 foo: int x = 1; (cuda-gdb) s 4 int y = x+1; (cuda-gdb) p x Python Exception &lt;type 'exceptions.AttributeError'&gt; 'gdb.Type' object has no attribute 'name': Python Exception &lt;type 'exceptions.AttributeError'&gt; 'gdb.Type' object has no attribute 'name': $1 = 1 (cuda-gdb) I the program is a very simple program and I read that it may be an error dealing with python and gdb, but I am unsure of how to fix the error using the latest software from Ubuntu and Nvidia. Any suggestions as to how to fix this?",
        "answers": [
            [
                "It appears that Ubuntu will not update the path to include the latest version of nvcc and cuda-gdb. You have to update the path (or change the symlinks) manually for your to reference the correct versions of these libraries."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I would like to print information from cuda disassembly. I am able to print registers in cuda using info registers R1 for example however I am not able to figure out how to print c[0x0][0x20] in (MOV R1, c[0x0][0x20]) or deferenced [R13+0x9f] in (STL.U8 [R13+0x9f], RZ)",
        "answers": [
            [
                "When using gdb or cuda-gdb you can use the disass command to disassemble the current code or code at a specific location. cuda-gdb a.out debug the program b main break in main r run the program, when the breakpoint is hit disass disassemble the following code at the breakpoint"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "What would be the easiest way of checking which (and their size) entities that have been allocated with cudaMalloc (), reside currently on a GPU device? I want to find a memory leak inside a function, that if it's just called once and exit, there is no memory leak (checked via cuda-memcheck), but if called multiple times the memory footprint gets bigger and bigger. Nsight Visual Profiler seems too complex for what I ask and cuda-memcheck finds no leak!",
        "answers": [
            [
                "There is no way to do this with the CUDA APIs. If you did want to do this, you would need to make your own instrumentation system which wraps the CUDA memory allocation/deallocation APIs which your code calls. The simplest implementation could look something like this: #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; typedef std::pair&lt;void*, size_t&gt; mrecord; struct mymemory { std::vector&lt;mrecord&gt; mstack; mymemory() {}; cudaError_t cudaMalloc(void** p, size_t sz); cudaError_t cudaFree(void* p); void print_stack(); }; cudaError_t mymemory::cudaMalloc(void** p, size_t sz) { cudaError_t ret = ::cudaMalloc(p, sz); if (ret == cudaSuccess) { mstack.push_back(mrecord(*p,sz)); } return ret; }; cudaError_t mymemory::cudaFree(void* p) { cudaError_t ret = ::cudaFree(p); if (ret == cudaSuccess) { auto rit = std::find_if( mstack.begin(), mstack.end(), [&amp;](const mrecord&amp; r){ return r.first == p; } ); if (rit != mstack.end()) { mstack.erase(rit); } } return ret; }; void mymemory::print_stack() { auto it = mstack.begin(); for(; it != mstack.end(); ++it) { mrecord rec = *it; std::cout &lt;&lt; rec.first &lt;&lt; \" : \" &lt;&lt; rec.second &lt;&lt; std::endl; } } int main(void) { const int nallocs = 10; void* pointers[nallocs]; mymemory mdebug; for(int i=0; i&lt;nallocs; ++i) { mdebug.cudaMalloc(&amp;pointers[i], 4&lt;&lt;i); } std::cout &lt;&lt; \"After Allocation\" &lt;&lt; std::endl; mdebug.print_stack(); mdebug.cudaFree(pointers[1]); mdebug.cudaFree(pointers[7]); mdebug.cudaFree(pointers[8]); mdebug.cudaFree(0); std::cout &lt;&lt; \"After Deallocation\" &lt;&lt; std::endl; mdebug.print_stack(); return 0; } [Warning: only very lightly tested and required C++11 compiler support] which would do this: ~/SO$ nvcc -std=c++11 -g -arch=sm_52 instrumentation.cu ~/SO$ ./a.out After Allocation 0x705e40000 : 4 0x705e40200 : 8 0x705e40400 : 16 0x705e40600 : 32 0x705e40800 : 64 0x705e40a00 : 128 0x705e40c00 : 256 0x705e40e00 : 512 0x705e41000 : 1024 0x705f40000 : 2048 After Deallocation 0x705e40000 : 4 0x705e40400 : 16 0x705e40600 : 32 0x705e40800 : 64 0x705e40a00 : 128 0x705e40c00 : 256 0x705f40000 : 2048 This might be enough to understand which memory allocations are leaking. But be aware that memory management on the GPU isn't as predictable as you might believe it to be, and you need to be careful when diagnosing a memory leak just on the basis of the amount of free memory which the device reports at any given instant. See this question for some more details."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I have a problem with the \"pretty printer\" option of IDE NSight (eclipse) when I try to debug. I have googled but I have not found a solution to my problem. When I start to debug, appears the next message: Traceback (most recent call last): File \"/usr/share/gdb/auto-load/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21-gdb.py\", line 64, in &lt;module&gt; register_libstdcxx_printers(gdb.current_objfile()) File \"/usr/lib/x86_64-linux-gnu/../../share/gcc-5/python/libstdcxx/v6/__init__.py\", line 33, in register_libstdcxx_printers register_libstdcxx_xmethods(obj) File \"/usr/lib/x86_64-linux-gnu/../../share/gcc-5/python/libstdcxx/v6/xmethods.py\", line 600, in register_libstdcxx_xmethods gdb.xmethod.register_xmethod_matcher(locus, ArrayMethodsMatcher()) File \"/usr/share/gdb/python/gdb/xmethod.py\", line 266, in register_xmethod_matcher index = _lookup_xmethod_matcher(locus, matcher.name) File \"/usr/share/gdb/python/gdb/xmethod.py\", line 236, in _lookup_xmethod_matcher for i in range(0, len(locus.xmethods)): AttributeError: 'gdb.Objfile' object has no attribute 'xmethods' I'm not sure where is the problem but the variables values doesn't appear and the only solution is to disable the pretty print option. I'm using Ubuntu 16.04 and the cuda toolkit was installed from repositories. If anyone can help, I will be very grateful.",
        "answers": [
            [
                "This sounds like a bug in your gdb installation. gdb.Objfile.xmethods is something that should be provided by the gdb core, which implements gdb.Objfile. So, examining it from /usr/share/gdb/python/gdb/xmethod.py should be ok -- because that is also a file that comes with gdb."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "cudaMalloc seemed to have spawned a thread when it was called, even though it's asynchronous. This was observed during debugging using cuda-gdb. It also took a while to return. The same thread exited, although as a different LWP, at the end of the program. Can someone explain this behaviour ?",
        "answers": [
            [
                "The thread is not specifically spawned by cudaMalloc. The user side CUDA driver API library seems to spawn threads at some stage during lazy context setup which have the lifetime of the CUDA context. The exact processes are not publicly documented. You see this associated with cudaMallocbecause I would guess this is the first API to trigger whatever setup/callbacks need to be done to make the userspace driver support work. You should notice that only the first call spawns a thread. Subsequent calls do not. And the threads stay alive for the lifetime of the CUDA context, after which they are terminated. You can trigger explicit thread destruction by calling cudaDeviceReset at any point in program execution. Here is a trivial example which demonstrates cudaMemcpyToSymbol triggering the thread spawning from the driver API library, rather than cudaMalloc: __device__ float someconstant; int main() { cudaSetDevice(0); const float x = 3.14159f; cudaMemcpyToSymbol(someconstant, &amp;x, sizeof(float)); for(int i=0; i&lt;10; i++) { int *x; cudaMalloc((void **)&amp;x, size_t(1024)); cudaMemset(x, 0, 1024); cudaFree(x); } return int(cudaDeviceReset()); } In gdb I see this: (gdb) tbreak main Temporary breakpoint 1 at 0x40254f: file gdb_threads.cu, line 5. (gdb) run Starting program: /home/talonmies/SO/a.out [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". Temporary breakpoint 1, main () at gdb_threads.cu:5 5 cudaSetDevice(0); (gdb) next 6 const float x = 3.14159f; (gdb) next 7 cudaMemcpyToSymbol(someconstant, &amp;x, sizeof(float)); (gdb) next [New Thread 0x7ffff5eb5700 (LWP 14282)] [New Thread 0x7fffed3ff700 (LWP 14283)] 8 for(int i=0; i&lt;10; i++) { (gdb) info threads Id Target Id Frame 3 Thread 0x7fffed3ff700 (LWP 14283) \"a.out\" pthread_cond_timedwait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_timedwait.S:238 2 Thread 0x7ffff5eb5700 (LWP 14282) \"a.out\" 0x00007ffff74d812d in poll () at ../sysdeps/unix/syscall-template.S:81 * 1 Thread 0x7ffff7fd1740 (LWP 14259) \"a.out\" main () at gdb_threads.cu:8 (gdb) thread apply all bt Thread 3 (Thread 0x7fffed3ff700 (LWP 14283)): #0 pthread_cond_timedwait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_timedwait.S:238 #1 0x00007ffff65cad97 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff659582d in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff65ca4d8 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bc182 in start_thread (arg=0x7fffed3ff700) at pthread_create.c:312 #5 0x00007ffff74e547d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111 Thread 2 (Thread 0x7ffff5eb5700 (LWP 14282)): #0 0x00007ffff74d812d in poll () at ../sysdeps/unix/syscall-template.S:81 #1 0x00007ffff65c9953 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #2 0x00007ffff66571ae in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #3 0x00007ffff65ca4d8 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1 #4 0x00007ffff79bc182 in start_thread (arg=0x7ffff5eb5700) at pthread_create.c:312 #5 0x00007ffff74e547d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111 Thread 1 (Thread 0x7ffff7fd1740 (LWP 14259)): #0 main () at gdb_threads.cu:8"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I am using Nsight on Ubuntu 16.04. My current set up allows me to compile and run my code perfectly fine through the nsight IDE. After making sure the program was building in debug mode (wasn't originally), it finally allowed me step through my code. The problem I am having is whenever I try to debug my code, all the variables say \"not available\". Also, if I hover my mouse over the variable it was saying something like \"-var-create: unable to create variable object\". This made it seem like maybe it was the compiler? Maybe it is not adding something it was supposed to do? Nsight version is 7.5, GCC &amp; G++ version 5.3.1, GDB version 7.11, NVCC version 7.5.17.",
        "answers": [
            [
                "After messing around in the IDE I found an option that fixed the problem. I went to Window -&gt; Preferences. Then under C/C++ -&gt; Debug -&gt; GDB go to the Pretty Printing section and remove the check mark on \"Enable Pretty Printers...\" This is what fixed that issue for me. I just don't really know what pretty printing is. I hope it doesn't have side effects because of disabling it."
            ]
        ],
        "votes": [
            4.0000001
        ]
    },
    {
        "question": "Is there a way to invoke kernel failure using cuda-gdb? I've tried stepping through the kernel code and setting invalid index positions, odd values to variables, but I'm unable to trigger a \"kernel Execution Failed\" after continuing from an erroneous setting. Does anyone know of a proper way to do this through cuda-gdb? I've read through the cuda-gdb documentation twice but might have missed some clues on how to achieve this if it is at all possible. If anyone knows of any tools/techniques that would be most appreciated, thanks. I'm on CentOS 7 and my device's compute capability is 2.1. See below for the output of the uname -a command. Linux john 3.10.0-327.10.1.el7.x86_64 #1 SMP Tue Feb 16 17:03:50 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux",
        "answers": [
            [
                "Is there a way to invoke kernel failure using cuda-gdb? Yes, it's possible. Here is a fully worked example: $ cat t678.cu #include &lt;stdio.h&gt; __global__ void kernel(int *data){ int idx = 0; // line 4 idx += data[0]; int tval = data[idx]; data[1] = tval; } int main(){ int *d_data; cudaMalloc(&amp;d_data, 32*sizeof(int)); cudaMemset(d_data, 0, 32*sizeof(int)); kernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(d_data); cudaDeviceSynchronize(); cudaError_t err = cudaGetLastError(); if (err != cudaSuccess) printf(\"kernel fail %s\\n\", cudaGetErrorString(err)); } $ nvcc -g -G -o t678 t678.cu $ cuda-gdb ./t678 NVIDIA (R) CUDA Debugger 7.5 release Portions Copyright (C) 2007-2015 NVIDIA Corporation GNU gdb (GDB) 7.6.2 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-unknown-linux-gnu\". For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;... Reading symbols from /home/user2/misc/t678...done. (cuda-gdb) break t678.cu:4 Breakpoint 1 at 0x4026d5: file t678.cu, line 4. (cuda-gdb) run Starting program: /home/user2/misc/./t678 [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib64/libthread_db.so.1\". [New Thread 0x7ffff700a700 (LWP 8693)] [Switching focus to CUDA kernel 0, grid 2, block (0,0,0), thread (0,0,0), device 0, sm 14, warp 2, lane 0] Breakpoint 1, kernel&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; (data=0x13047a0000) at t678.cu:4 4 int idx = 0; // line 4 (cuda-gdb) step 5 idx += data[0]; (cuda-gdb) print idx $1 = 0 (cuda-gdb) set idx=1000000 (cuda-gdb) step 6 int tval = data[idx]; (cuda-gdb) print idx $2 = 1000000 (cuda-gdb) step CUDA Exception: Device Illegal Address The exception was triggered in device 0. Program received signal CUDA_EXCEPTION_10, Device Illegal Address. kernel&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; (data=0x13047a0000) at t678.cu:7 7 data[1] = tval; (cuda-gdb) In the above cuda-gdb output, you can see that after setting the idx variable to a large value, it results in an index-out-of-bounds (illegal address) error when executing the following line in the debugger: int tval = data[idx];"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I want to debug my application using cuda-gdb in windows. Is it possible to run cuda-gdb in windows? Will cygwin help to do it?",
        "answers": [
            [
                "cuda-gdb is not officially supported for or intended for usage in a windows environment. From here: This document introduces CUDA-GDB, the NVIDIA\u00ae CUDA\u00ae debugger for Linux and Mac OS. cygwin is not an officially supported environment for running any of the CUDA linux tools on windows. The recommended debugger for windows applications is NSIGHT Visual Studio Edition, which will be automatically installed by the CUDA 7.5 installer for windows, assuming a compatible version of visual studio is found. For supported configurations, refer to the CUDA 7.5 windows installation guide."
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I am debugging a cuda program and got the following warning: warning: Cuda API error detected: cudaMemcpy returned (0xb) warning: Cuda API error detected: cudaMemcpy returned (0xb) warning: Cuda API error detected: cudaGetLastError returned (0xb) Error in kernel GPUassert: invalid argument when I type \"where\" in cuda-gdb, it says \"no stack.\" (cuda-gdb) where No stack. How should find where my program crashed ?",
        "answers": [
            [
                "Find the answer here : http://on-demand.gputechconf.com/gtc/2012/presentations/S0027A-Monday-Debugging-Experience-CUDA.pdf @ page 27. You need to first: (cuda-gdb) set cuda api_failures stop Then when error happens, it will stop: Cuda API error detected: cudaMemcpy returned (0xb) (cuda-gdb) where #0 0x00007fffea6a06d0 in cudbgReportDriverApiError () from /usr/lib64/nvidia/libcuda.so.1 #1 0x00007fffea6a2c36 in cudbgReportDriverInternalError () from /usr/lib64/nvidia/libcuda.so.1 #2 0x00007fffea6eed93 in cudbgGetAPIVersion () from /usr/lib64/nvidia/libcuda.so.1 ..."
            ]
        ],
        "votes": [
            8.0000001
        ]
    },
    {
        "question": "since last week I got a big problem with my CUDA-development setup. I have an integrated GPU which I attached my monitors too and an extra NVIDIA Card for running my CUDA kernels on. However, i can not debug my code anymore, because it says: fatal: All CUDA devices are used for display and cannot be used while debugging. (error code = CUDBG_ERROR_ALL_DEVICES_WATCHDOGGED(0x18) Somehow it seems that my X-Server is blocking my NVIDIA GPU because if I switch to another virtual console (CTRL+ALT+F1) I am able to run my code using cuda-gdb. No monitor cable is plugged into the NVIDIA-card... \"lsof /dev/nvidia*\" does not give any output. I am using Xubuntu 14.04. Does anyone have an idea how to solve this problem?",
        "answers": [
            [
                "In devices with compute capability of at least SM35, we can apparently get around this by setting the environment variable CUDA_DEBUGGER_SOFTWARE_PREEMPTION=1 We can see it at the cuda-gdb documentation page:http://docs.nvidia.com/cuda/cuda-gdb/#axzz4BrMPoaoW Here's test. I am running on a Maxwell Quadro GPU: nvidia-smi Fri Jun 17 10:59:47 2016 +------------------------------------------------------+ | NVIDIA-SMI 352.63 Driver Version: 352.63 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Quadro M4000M Off | 0000:01:00.0 On | N/A | | N/A 37C P8 9W / 100W | 158MiB / 4087MiB | 1% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 2981 G /usr/bin/X 57MiB | | 0 9186 G ...ves-passed-by-fd --v8-snapshot-passed-by- 85MiB | +-----------------------------------------------------------------------------+ Build and run the application nvcc -g -G foo.cu cuda-gdb ./a.out ... [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". fatal: All CUDA devices are used for display and cannot be used while debugging. (error code = CUDBG_ERROR_ALL_DEVICES_WATCHDOGGED(0x18) Now set the environment variable. export CUDA_DEBUGGER_SOFTWARE_PREEMPTION=1 cuda-gdb ./a.out (cuda-gdb) r ... warning: Cuda API error detected: cudaMemcpy returned (0xb) warning: Cuda API error detected: cudaFree returned (0x11) [Thread 0x7fffed3ff700 (LWP 10302) exited] [Thread 0x7ffff7fc6780 (LWP 10293) exited]"
            ],
            [
                "For me it helped to change in the block Section \"ServerLayout\" Identifier \"layout\" Screen 0 \"intel\" EndSection the Identifier from 'nvidia' to 'intel'."
            ]
        ],
        "votes": [
            16.0000001,
            1.0000001
        ]
    },
    {
        "question": "In a CUDA C project, I have a pointer to float inside a structure called \"p\". It is a pointer to device memory and it is called \"p-&gt;deviceOutput\". I am using CUDA-GDB to check the content of this pointer during execution: when I try to print it this is what happens: (gdb) p *p-&gt;deviceOutput $1 = 0 As you can see the printing returns something that looks like an int, definitely not a float. I am really sure the pointer is a pointer to float so I am really confused by this behaviour. Specifying the float format does not help: (gdb) p/f *p-&gt;deviceOutput $2 = 0 Actually I get the same behaviour using GDB as well. I am working on Ubuntu 14.10 and my code was compiled with nvcc using -O0 and -g options. Can anybody please explain what is going on and what should I do to inspect this memory location correctly? Thanks",
        "answers": [
            [
                "gdb uses the g format specifier to printf (internally) when printing floating point values. Here's the interesting part of the description of g from the man page for printf: Trailing zeros are removed from the fractional part of the result; a decimal point appears only if it is followed by at least one digit. So you're getting 0 because the floating point value is 0, and the g format specifier (used by gdb) prints an exact 0 without a decimal point, or any trailing 0's. You can check that your variable is of type float using the ptype command, like this: (gdb) ptype p-&gt;deviceOutput"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "My CUDA Kernel, needs a lot of arrays which need to be passed as pointers to the kernel. The problem is that just before the kernel launch, all the pointers have valid addresses, moreover the cudaMalloc and cudaMemcpy calls always return cudaSuccess, but all these arguments become null once the kernel is launched! I am clueless as to what is happening. This is what I get when I run my code with cuda-gdb CUDA Exception: Device Illegal Address The exception was triggered in device 0. Program received signal CUDA_EXCEPTION_10, Device Illegal Address. [Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (64,0,0), device 0, sm 1, warp 2, lane 0] 0x00000000062a3dd8 in compute_data_and_match_kernel&lt;&lt;&lt;(2,1,1),(512,1,1)&gt;&gt;&gt; (a11=0x0, a12=0x0, a22=0x0, b1=0x0, b2=0x0, mask=0x0, wx=0x0, wy=0x0, du=0x0, dv=0x0, uu=0x0, vv=0x0, Ix_c1=0x0, Ix_c2=0x0, Ix_c3=0x0, Iy_c1=0x0, Iy_c2=0x0, Iy_c3=0x0, Iz_c1=0x0, Iz_c2=0x0, Iz_c3=0x0, Ixx_c1=0x0, Ixx_c2=0x0, Ixx_c3=0x0, Ixy_c1=0x0, Ixy_c2=0x0, Ixy_c3=0x0, Iyy_c1=0x0, Iyy_c2=0x0, Iyy_c3=0x0, Ixz_c1=0x0, Ixz_c2=0x0, Ixz_c3=0x0, Iyz_c1=0x0, Iyz_c2=0x0, Iyz_c3=0x0, desc_weight=0x0, desc_flow_x=0x0, desc_flow_y=0x0, half_delta_over3=0.0833333358, half_beta=0, half_gamma_over3=0.833333313, width=59, height=26, stride=60) at opticalflow_aux.cu:441 441 ix_c1_val = Ix_c1[index]; iy_c1_val = Iy_c1[index]; iz_c1_val = Iz_c1[index]; (cuda-gdb) Is there something very obvious that I am missing. Thanks in advance. EDIT 1 : As suggested by Gilles, I am trying to copy the host pointers and data into a struct and then onto device. For the sake of simplicity (MCVE) I am using only a single pointer inside struct: #include &lt;cuda.h&gt; #include &lt;stdio.h&gt; typedef struct test { float *ptr; } test_t; __global__ void test_kernel(test_t *s) { s-&gt;ptr[0] = s-&gt;ptr[1] = s-&gt;ptr[2] = s-&gt;ptr[3] = s-&gt;ptr[4] = 100; s-&gt;ptr[5] = s-&gt;ptr[6] = s-&gt;ptr[7] = s-&gt;ptr[8] = s-&gt;ptr[9] = 100; } int main() { float arr[] = {0,1,2,3,4,5,6,7,8,9}; test_t *h_struct; h_struct = (test_t *)malloc(sizeof(test_t)); h_struct-&gt;ptr = arr; test_t *d_struct; float *d_data; cudaMalloc((void **)&amp;d_struct, sizeof(test_t)); cudaMalloc((void **)&amp;d_data, sizeof(float)*10); // Copy the data from host to device cudaMemcpy(d_data, h_struct-&gt;ptr, sizeof(float)*10, cudaMemcpyHostToDevice); // Point the host struct ptr to device memory h_struct-&gt;ptr = d_data; // copy the host struct to device cudaMemcpy(d_struct, h_struct, sizeof(test_t), cudaMemcpyHostToDevice); // Kernel Launch test_kernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(d_struct); // copy the device array to host cudaMemcpy(h_struct-&gt;ptr, d_data, sizeof(float)*10, cudaMemcpyDeviceToHost); cudaFree(d_data); cudaFree(d_struct); // Verifying if all the values have been set to 100 int i; for(i=0 ; i&lt;10 ; i++) printf(\"%f\\t\", h_struct-&gt;ptr[i]); return 0; } When I am checking the value of d_struct-&gt;ptr, just before the kernel launch it shows me 0x0. (I have checked these values using nsight in debug mode)",
        "answers": [
            [
                "Not sure if it's the issue, but I believe the size of the stack for passing arguments to a kernel is limited. You might need to create a structure storing your arguments, copy it to the device and only pass a pointer to it as argument to your kernel. Then, inside the kernel you retrieve your arguments from the structure... EDIT: Added a corrected version of the submitted code. This works for me and exemplifies the principle I described. #include &lt;cuda.h&gt; #include &lt;stdio.h&gt; typedef struct test { float *ptr; } test_t; __global__ void test_kernel(test_t *s) { s-&gt;ptr[0] = s-&gt;ptr[1] = s-&gt;ptr[2] = s-&gt;ptr[3] = s-&gt;ptr[4] = 100; s-&gt;ptr[5] = s-&gt;ptr[6] = s-&gt;ptr[7] = s-&gt;ptr[8] = s-&gt;ptr[9] = 100; } int main() { float arr[] = {0,1,2,3,4,5,6,7,8,9}; test_t *h_struct; h_struct = (test_t *)malloc(sizeof(test_t)); test_t *d_struct; float *d_data; cudaMalloc((void **)&amp;d_struct, sizeof(test_t)); cudaMalloc((void **)&amp;d_data, sizeof(float)*10); // Copy the data from host to device cudaMemcpy(d_data, arr, sizeof(float)*10, cudaMemcpyHostToDevice); // Point the host struct ptr to device memory h_struct-&gt;ptr = d_data; // copy the host struct to device cudaMemcpy(d_struct, h_struct, sizeof(test_t), cudaMemcpyHostToDevice); // Kernel Launch test_kernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(d_struct); // copy the device array to host cudaMemcpy(arr, d_data, sizeof(float)*10, cudaMemcpyDeviceToHost); cudaFree(d_data); cudaFree(d_struct); // Verifying if all the values have been set to 100 int i; for(i=0 ; i&lt;10 ; i++) printf(\"%f\\t\", arr[i]); return 0; }"
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "CUDA document is not clear on how memory data changes after CUDA applications throws an exception. For example, a kernel launch(dynamic) encountered an exception (e.g. Warp Out-of-range Address), current kernel launch will be stopped. After this point, will data (e.g. __device__ variables) on device still kept or they are removed along with the exceptions? A concrete example would be like this: CPU launches a kernel The kernel updates the value of __device__ variableA to be 5 and then crashes CPU memcpy the value of variableA from device to host, what is the value the CPU gets in this case, 5 or something else? Can someone show the rationale behind this?",
        "answers": [
            [
                "The behavior is undefined in the event of a CUDA error which corrupts the CUDA context. This type of error is evident because it is \"sticky\", meaning once it occurs, every single CUDA API call will return that error, until the context is destroyed. Non-sticky errors are cleared automatically after they are returned by a cuda API call (with the exception of cudaPeekAtLastError). Any \"crashed kernel\" type error (invalid access, unspecified launch failure, etc.) will be a sticky error. In your example, step 3 would (always) return an API error on the result of the cudaMemcpy call to transfer variableA from device to host, so the results of the cudaMemcpy operation are undefined and unreliable -- it is as if the cudaMemcpy operation also failed in some unspecified way. Since the behavior of a corrupted CUDA context is undefined, there is no definition for the contents of any allocations, or in general the state of the machine after such an error. An example of a non-sticky error might be an attempt to cudaMalloc more data than is available in device memory. Such an operation will return an out-of-memory error, but that error will be cleared after being returned, and subsequent (valid) cuda API calls can complete successfully, without returning an error. A non-sticky error does not corrupt the CUDA context, and the behavior of the cuda context is exactly the same as if the invalid operation had never been requested. This distinction between sticky and non-sticky error is called out in many of the documented error code descriptions, for example: synchronous, non-sticky, non-cuda-context-corrupting: cudaErrorMemoryAllocation = 2 The API call failed because it was unable to allocate enough memory to perform the requested operation. asynchronous, sticky, cuda-context-corrupting: cudaErrorMisalignedAddress = 74 The device encountered a load or store instruction on a memory address which is not aligned. The context cannot be used, so it must be destroyed (and a new one should be created). All existing device memory allocations from this context are invalid and must be reconstructed if the program is to continue using CUDA. Note that cudaDeviceReset() by itself is insufficient to restore a GPU to proper functional behavior. In order to accomplish that, the \"owning\" process must also terminate. See here."
            ]
        ],
        "votes": [
            10.0000001
        ]
    },
    {
        "question": "My question is: is the CUDA hardware faulty, or is there possibly another explanation? I have a kernel which has been in use for about a year without modification. Recently, I started getting segmentation faults at irregular intervals, i.e. it could be reproduced, sometimes after a few minutes, sometimes after hours of execution. This led to a bare-minimum version of the program which still reproduced the segfault. As well as much learning from stackoverflow posts. cuda-memcheck, when run in a repeat bash loop, will eventually report: ========= Invalid __global__ read of size 4 ========= at 0x000048f0 in SegFault.cu:157:SegFault( float* ) ========= by thread (128,0,0) in block (3706,0,0) ========= Address 0x003400e8 is out of bounds The usual culprit of bad pointer operations was ruled out. Another clue was the illegal addressing was not consistent in where it occurred in the code; it was occurring irregularly for any index to a global array, throughout the kernel. At this point in my question, the most likely explanation is buggy code. What leads me to believe the hardware is faulty comes from cuda-gdb: cuda-gdb ./SegFaultTest (cuda-gdb) set cuda memcheck on (cuda-gdb) run Illegal access to address (@global)0x245684 detected. Program received signal CUDA_EXCEPTION_1, Lane Illegal Address. [Switching focus to CUDA kernel 0, grid 1, block (5537,0,0), thread (0,0,0), device 0, sm 22, warp 28, lane 0] 0x00000000004f1ff8 in kernel( float * @global )&lt;&lt;&lt;(33480,1,1),(512,1,1)&gt;&gt;&gt; ( c=0x250000 ) at SegFault.cu:37 37 c[ix] += share_c[0]; (cuda-gdb) print &amp;c[ix] $2 = (@global float *) 0x255684 The index \"ix\" is: int ix = blockIdx.x + blockIdx.y*gridDim.x; And is not modified after instantiation. Indeed, 0x245684 is below the starting address for c=0x250000. Yet, when I query print &amp;c[ix] it returns 0x255684, which is an acceptable address for this array. Reproducing takes 10-50 executions before it pops up again, but the illegal address is always one bit 0x010000 different than what print &amp;c[ix] returns. I can't explain the difference in address between the error message and print. Combined with the one bit difference, I suspect faulty hardware. FWIW, 0x010000 is equal to the maximum grid size for this Tesla C1060. And finally, I replaced the CUDA card today with a new model. I have not been able to reproduce after 100 executions.",
        "answers": [
            [
                "If cuda-gdb with memcheck enabled reports an illegal address access like: Illegal access to address (@global)0x245684 detected. Program received signal CUDA_EXCEPTION_1, Lane Illegal Address. [Switching focus to CUDA kernel 0, grid 1, block (5537,0,0), thread (0,0,0), device 0, sm 22, warp 28, lane 0] 0x00000000004f1ff8 in kernel( float * @global )&lt;&lt;&lt;(33480,1,1),(512,1,1)&gt;&gt;&gt; ( c=0x250000 ) at SegFault.cu:37 37 c[ix] += share_c[0]; And querying that address returns a different value: (cuda-gdb) print &amp;c[ix] $2 = (@global float *) 0x255684 Then the hardware is broken."
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I am encountering a very strange bug in that I get an 'illegal memory access' error when running a Heat 2D simulation of a particular size, but the simulation runs well if I run the exact same simulation, just with fewer elements. Is there a reason that increasing the size of an array would cause this exception? I am using a Titan Black GPU (6 GB of memory), but the simulation I am running is nowhere near that size. I calculated that I could run a 4000 x 4000 simulation, but I get errors if I exceed 250 x 250. The error occurs immediately after I instantiate the array of simulation objects on the device. Instantiation code is as follows: template&lt;typename PlaceType, typename StateType&gt; __global__ void instantiatePlacesKernel(Place** places, StateType *state, void *arg, int *dims, int nDims, int qty) { unsigned idx = blockDim.x * blockIdx.x + threadIdx.x; if (idx &lt; qty) { // set pointer to corresponding state object places[idx] = new PlaceType(&amp;(state[idx]), arg); places[idx]-&gt;setIndex(idx); places[idx]-&gt;setSize(dims, nDims); } } template&lt;typename PlaceType, typename StateType&gt; Place** DeviceConfig::instantiatePlaces(int handle, void *argument, int argSize, int dimensions, int size[], int qty) { // add global constants to the GPU memcpy(glob.globalDims,size, sizeof(int) * dimensions); updateConstants(glob); // create places tracking PlaceArray p; // a struct to track qty, p.qty = qty; // create state array on device StateType* d_state = NULL; int Sbytes = sizeof(StateType); CATCH(cudaMalloc((void** ) &amp;d_state, qty * Sbytes)); p.devState = d_state; // save device pointer // allocate device pointers Place** tmpPlaces = NULL; int ptrbytes = sizeof(Place*); CATCH(cudaMalloc((void** ) &amp;tmpPlaces, qty * ptrbytes)); p.devPtr = tmpPlaces; // save device pointer // handle arg if necessary void *d_arg = NULL; if (NULL != argument) { CATCH(cudaMalloc((void** ) &amp;d_arg, argSize)); CATCH(cudaMemcpy(d_arg, argument, argSize, H2D)); } // load places dimensions int *d_dims; int dimBytes = sizeof(int) * dimensions; CATCH(cudaMalloc((void** ) &amp;d_dims, dimBytes)); CATCH(cudaMemcpy(d_dims, size, dimBytes, H2D)); // launch instantiation kernel int blockDim = (qty - 1) / BLOCK_SIZE + 1; int threadDim = (qty - 1) / blockDim + 1; Logger::debug(\"Launching instantiation kernel\"); instantiatePlacesKernel&lt;PlaceType, StateType&gt; &lt;&lt;&lt;blockDim, threadDim&gt;&gt;&gt;(tmpPlaces, d_state, d_arg, d_dims, dimensions, qty); CHECK(); CATCH(cudaDeviceSynchronize()); // ERROR OCCURS HERE // clean up memory if (NULL != argument) { CATCH(cudaFree(d_arg)); } CATCH(cudaFree(d_dims)); CATCH(cudaMemGetInfo(&amp;freeMem, &amp;allMem)); return p.devPtr; } Please assume any custom types you see are working, as this code executes without error on a sufficiently small simulation. I am frustrated that it appears that the number of elements in the kernel function's places and state arrays causes an error when the size exceeds 250 x 250 elements. Any insight would be awesome. Thank you!",
        "answers": [
            [
                "I think it's likely that in-kernel new is failing, because you are allocating too much memory. In-kernel new has similar behavior and limitations as in-kernel malloc (and in-kernel cudaMalloc()). These allocations are limited to the device heap, which starts out by default at 8MB. If the 250x250 array size corresponds to something in that range (8MB), then going significantly above that would cause some of the new operations to \"silently\" fail (i.e. return null pointers). If you then try to use those null pointers, you'll get an illegal memory access. A few recommendations: Figure out how much space you need, and pre-reserve it ahead of time on the device heap using cudaDeviceSetLimit(cudaLimitMallocHeapSize, size_t size) When you're having trouble with kernels that use new or malloc, it may be useful for debug purposes to perhaps use a debug macro to check the returned pointers for NULL. This is a good practice in general. You can learn how to debug an illegal memory access with more clarity (localizing it to a specific line in a specific kernel) using the method described here. Just like any other dynamic allocation, its a good idea to free dynamically allocated memory when you are done with it. For new that would be delete or delete[], for malloc() that would be free() and for cudaMalloc() that would be cudaFree()."
            ]
        ],
        "votes": [
            10.0000001
        ]
    },
    {
        "question": "I want to copy a double pointer object to the host and compute over it on the GPU Device. When doing cudaMemcpy of the object to device it throws SEGFAULT. BMP Input; Input.ReadFromFile( fileName ); WIDTH = Input.TellWidth(); HEIGHT = Input.TellHeight(); RGBApixel** imageData = new RGBApixel* [HEIGHT]; for (int i = 0; i &lt; HEIGHT; i++) imageData[i] = new RGBApixel [WIDTH]; for(int j=0;j&lt;Input.TellHeight();j++){ for(int i=0;i&lt;Input.TellWidth();i++){ imageData[j][i] = Input.GetPixel(i,j); } } long long imageSize = WIDTH*HEIGHT*sizeof(RGBApixel *); RGBApixel** dev_imgdata,dev_imgdata_out; //Allocating cudaMemory cudaMalloc( (void **) &amp;dev_imgdata, imageSize ); cudaMalloc( (void **) &amp;dev_imgdata_out, imageSize ); Now the below line throws segfault cudaMemcpy(dev_imgdata,imageData,imageSize,cudaMemcpyHostToDevice);",
        "answers": [
            [
                "When declaring RGBApixel** imageData = new RGBApixel* [HEIGHT]; you have absolutely no guarantee that imageData will occupy a contiguous block of memory. cudaMemcpy copies contiguous blocks of memory into the device RAM. Your statement tries to copy the start addresses of each matrix row but not the actual data. Also when using cudaMalloc, you need to properly allocate for each line, exactly as you did for the host buffer. What you need to do is to declare imageData as just a RGMAPixel* - basically put the matrix in a single vector and use proper indexing and it will work. You can also copy each line at a time but that's not a very good practice since every memory access will require an extra indirection and you will mess the caching efficiency."
            ],
            [
                "Also, make sure that when you compile your program, you use -arch sm_20 to enable extra options for your graphic card ( if it has Capability 2.0). Without it I believe you can't use double and the result is unpredictable (or the double is diminished to float)"
            ]
        ],
        "votes": [
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "I'm writing a convnet using torch and cudnn and having some memory issues. I tried debugging the script with cuda-memcheck only to notice it actually runs when fed through cuda-memcheck (albeit slower than it should). Turns out if cuda-memcheck is running in the background, a separate instantiation of the script itself also runs fine. Any idea what might be happening here?",
        "answers": [],
        "votes": []
    },
    {
        "question": "I'm new in this CUDA and parallel computing staff and I have a recent problem. I have an Ubuntu 12.04 system which is host and Jetson TK1 as the target. I'm using Nsight Eclipse to write, edit and compile the algorithms. I'm using SSH protocol to connect TK1 from the host computer. When I try some file transfer operations it's okay always. However, sometimes the cross-compiling process sucks and errors \"Connect to ubuntu@192.168.0.94 was cancelled\" having title \"RSEG1058\". I don't understand the problem because this problem occurs 75% of the time. Sometimes it works perfectly. Can you help me please? I can give another info if it's needed. BY the way, I also found another possibly problematic detail. When I try to change the configuration of the run from the option \"Run Configurations\" found in the arrow near the RUN button, I discovered that we can change the library and toolkit path which is set in the first place. What I saw in that window was that cuda-gdb file has a red-cross icon with \"Operation failed. File system input or output error\" message. You can see the image and understand what I'm talking about. I don't know whether these two things are related or not, but I'm tired to try to catch the perfect timing all the time.",
        "answers": [
            [
                "Try stopping dbus daemon (by issuing \"sudo dubs stop\") on the TK1 board or recompiling sshd without ConsoleKit integration."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I tried to debug my CUDA application with cuda-gdb but got some weird error. I set option -g -G -O0 to build my application. I could run my program without cuda-gdb, but didn't get correct result. Hence I decided to use cuda-gdb, however, I got following error message while running program with cuda-gdb Error: Failed to read the valid warps mask (dev=1, sm=0, error=16). What does it means? Why sm=0 and what's the meaning of error=16? Update 1: I tried to use cuda-gdb to CUDA samples, but it fails with same problem. I just installed CUDA 6.0 Toolkit followed by instruction of NVIDIA. Is it a problem of my system? Update 2: OS - CentOS 6.5 GPU 1 Quadro 400 2 Tesla C2070 I'm using only 1 GPU for my program, but I've got same bug message from any GPU that I selected CUDA version - 6.0 GPU Driver NVRM version: NVIDIA UNIX x86_64 Kernel Module 331.62 Wed Mar 19 18:20:03 PDT 2014 GCC version: gcc version 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) Update 3: I tried to get more information in cuda-gdb, but I got following results (cuda-gdb) info cuda devices Error: Failed to read the valid warps mask (dev=1, sm=0, error=16). (cuda-gdb) info cuda sms Focus not set on any active CUDA kernel. (cuda-gdb) info cuda lanes Focus not set on any active CUDA kernel. (cuda-gdb) info cuda kernels No CUDA kernels. (cuda-gdb) info cuda contexts No CUDA contexts.",
        "answers": [
            [
                "Actually, this issue is only specific to some old NVIDIA GPUs(like \"Quadro 400\", \"GeForce GT220\", or \"GeForce GT 330M\", etc). On Liam Kim's setup, cuda-gdb should work fine by set environment variable \"CUDA_VISIBLE_DEVICES\", and let cuda-gdb running on Tesla C2070 GPUs specifically. I.e $export CUDA_VISIBLE_DEVICES=0 (or 2) - the exact CUDA devices index could be found by running cuda sample - \"deviceQuery\". And now, this issue has been fixed, the fix would be availble for CUDA developers in the next CUDA release(it will be posted out around early July, 2014)."
            ],
            [
                "This is internal cuda-gdb bug. You should report a bug. Can you try installing CUDA toolkit from the package on NVIDIA site?"
            ]
        ],
        "votes": [
            2.0000001,
            2.0000001
        ]
    },
    {
        "question": "Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers. This question appears to be off-topic because it lacks sufficient information to diagnose the problem. Describe your problem in more detail or include a minimal example in the question itself. Closed 9 years ago. Improve this question I want to implement MonteCarlo using CUDA. I write my code on Win8 PC using Visual Studio2012/CUDA 5.5/GT 720M and it runs well. Then I tried to compile my code in REHL5.3/Tesla C1060/CUDA 2.3 but the result turned out wrong. Then I want to use cuda-gdb to debug it but, when I compile my code like this: nvcc -arch=sm_13 -o my_program my_program.cu the result is wrong. However I can't debug it because it's not debug-able code. When I compile it like this: nvcc -g -G -arch=sm_13 -o my_program my_program.cu The result, this time, get correct... So still I can't find my bug by debugging it... the code looks like this, the function __device__ double monte_carlo_try() is not in the real code. the problem is, if I check the value of test[], I find the values are all correct. So there should be some error in the reduction part. #include&lt;stdio.h&gt; #include&lt;cuda_runtime.h&gt; #include&lt;device_launch_parameters.h&gt; #include&lt;cuda.h&gt; #include&lt;malloc.h&gt; #include&lt;time.h&gt; #define B 4 //block number #define T 4 //number of threads per block #define P 4 //number of paths per thread __device__ float monte_carlo_try() { return 3.0; } __global__ void monte_carlo(float*test, float*result) { int bid=blockIdx.x; int tid=threadIdx.x + blockIdx.x * blockDim.x; int idx=threadIdx.x; __shared__ float cache[T]; cache[idx]=0; float temp=0; for(int i=0;i&lt;P;i++) { temp+=monte_carlo_try(); //monte_carlo_try: __device__ function do monte carlo test } cache[idx]=temp; test[tid]=cache[idx]; __syncthreads(); //result[] is the output, and I use test[] to check whether I have got the right cache[idx] //and the value of test[] is same with what I expect int i=blockDim.x/2; while(i&gt;0) { if(idx&lt;i) cache[idx]+=cache[idx+i]; __syncthreads(); i/=2; } result[bid]=cache[0]; } int main() { void check_err(cudaError_t ); cudaSetDevice(0); cudaError_t s_flag; float *dev_v; float *dev_test; s_flag=cudaMalloc((void**)&amp;dev_v,B*sizeof(float)); check_err(s_flag); cudaMalloc((void**)&amp;dev_test,B*T*sizeof(float)); check_err(s_flag); monte_carlo&lt;&lt;&lt;B,T&gt;&gt;&gt;(dev_test,dev_v); s_flag=cudaGetLastError(); check_err(s_flag); float v[B]; float test[B*T]; s_flag=cudaMemcpy(v,dev_v,B*sizeof(float),cudaMemcpyDeviceToHost); check_err(s_flag); s_flag=cudaMemcpy(test,dev_test,B*T*sizeof(float),cudaMemcpyDeviceToHost); check_err(s_flag); float sum=0; for(int i=0;i&lt;B;i++) { sum+=v[i]; } printf(\"result:%f\\n\",sum/(B*T*P)); for(int i=0;i&lt;B*T;i++) { printf(\"test[%d]=%f\\n\",i,test[i]); } cudaFree(dev_v); cudaFree(dev_test); return 0; } void check_err(cudaError_t f) { if(f != cudaSuccess) printf(\"error msg:%s\\n\",cudaGetErrorString(f)); }",
        "answers": [
            [
                "You probably mean for this line in main(): cudaMalloc((void**)*dev_test,B*T*sizeof(float)); to read like this instead: cudaMalloc((void**)&amp;dev_test,B*T*sizeof(float)); Additionally, you call monte_carlo(dev_test,dev_v); Since monte_carlo is a CUDA kernel, you probably should be setting the number of blocks and threads the kernel should launch with: monte_carlo&lt;&lt;&lt;num_blocks, threads_per_block&gt;&gt;&gt;(dev_test, dev_v);"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "cudamemcpy2d is returning error -- following is the code in the code below i have mentioned the line where i am getting an error. please look through and help me. main(){ int nrow = 16,ncol = 41; // double **x = new double*[nrow]; double **y = new double*[nrow]; for(int i=0; i&lt;nrow; i++){ x[i] = new double[ncol]; y[i] = new double[ncol]; } // both x and y are filled with some values and function is called; function(x,y, nrow, ncol); } void function(double **x, double **y, int nrow, ncol){ double *dev_x, *dev_y; size_t pitch_x, pitch_y; cudaMallocPitch((void **) &amp;dev_x, &amp;pitch_x, (n_col*sizeof(double)), nrow); cudaMallocPitch((void **) &amp;dev_y, &amp;pitch_y, (n_col*sizeof(double)), nrow); // this below line is returning error invalid value cudaMemcpy2D((void *)dev_x, pitch_x, (void *) *x, sizeof(double)*ncol, sizeof(double)*ncol, nrow, cudaMemcpyDeviceToHost); //launch a kernel kernel&lt;&lt;&lt; 1, 1&gt;&gt;&gt;(dev_x, dev_y, nrow, ncol); //below also gives the same error.. cudaMemcpy2D((void *) *x, sizeof(double)*ncol, dev_x, pitch_x, sizeof(double)*ncol, nrow, cudaMemcpyHostToDevice); } please help thank you",
        "answers": [
            [
                "You have your directions reversed. The first cudaMemcpy2D operation is copying from the Host to the Device, and you should specify cudaMemcpyHostToDevice. Likewise the second cudaMemcpy2D is going in the other direction (based on the order of pointers you are passing) and so should specify cudaMemcpyDeviceToHost. The first pointer you pass to cudaMemcpy2D is the destination pointer. Your usage of *d_IntPts_X may be a problem as well. Normally you should pass a single pointer (*) flattened 1D array to cudaMemcpy type operations. But since you haven't shown the definition of that variable/pointer, I can't say for sure. EDIT: Now that you've changed the parameters, you can't use your x array this way in cudaMemcpy2D. Instead, flatten x into a one dimensional array, perhaps something like this: double *flat_x = new double[nrow*ncol]; and use that instead in your cudaMemcpy2D calls. Also, there are plenty of questions like this on the CUDA tag. Please search and read some of those before asking \"why?\" \"Doesn't it handle 2D matrices?\" \"What if I really want to use a 2D matrix?\" etc."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I get the following error when trying to use a GTX 750 Ti with CUDA 5.5 in Ubuntu 12.04 64-bit: The driver installation is unable to locate the kernel source. Please make sure that the kernel source packages are installed and set up correctly. If you know that the kernel source packages are installed and set up correctly, you may pass the location of the kernel source ith the --kernel-source-path flag. How do I fix this error?",
        "answers": [
            [
                "The GeForce GTX 750 Ti is based on NVIDIA's new Maxwell architecture (compute capability 5.0) and requires CUDA 6.0."
            ],
            [
                "The CUDA SDK is not related to your hardware if you got a problem of with a driver you might go on nvidia.com and find the right driver for your card. On their web site, there's an automatic setup. You just have to download what's noticed/"
            ]
        ],
        "votes": [
            2.0000001,
            1e-07
        ]
    },
    {
        "question": "I am trying to resolve a CUDA runtime error. Debug information reported by cuda-gdb (with cuda-memcheck on): warning: Cuda API error detected: cudaLaunch returned (0xb) warning: Cuda API error detected: cudaGetLastError returned (0xb) [Thread 0x7fa1a28c5700 (LWP 43041) exited] [Thread 0x7fa1a16a5700 (LWP 43042) exited] [Thread 0x7fa18df0e700 (LWP 43056) exited] I have checked the block, grid dimensions, and the size of the dynamic shared memory being used, they are well below the limit. Please tell me what (0xb) error type stands for, I didn't find it in the cuda documentation. Also, please tell me any suggestion on how to solve this issue? Device : Kepler K20 (CC=3.5) and CUDA 5.5 Code is too big to paste here.",
        "answers": [
            [
                "If you do proper cuda error checking in your code, you can retrieve that 0xb error that is being reported from a cudaGetLastError call, and pass it to a decoder (cudaGetErrorString) that will tell you something more meaningful. CUDA runtime API error codes are enumerated in driver_types.h, which on a standard linux install will be in /usr/local/cuda/include Search on cudaSuccess which will be the first enumerated type (i.e. 0) then continue on until you find your error number. In this case 0xb (= 11) refers to cudaErrorInvalidValue: /** * This indicates that one or more of the parameters passed to the API call * is not within an acceptable range of values. */ cudaErrorInvalidValue = 11,"
            ],
            [
                "I encountered this error, and apparently resolved it by unpinning the related host memory."
            ]
        ],
        "votes": [
            6.0000001,
            1.0000001
        ]
    },
    {
        "question": "Cuda-gdb was obeying all the breakpoints I would set, before adding '-arch sm_20' flag while compiling. I had to add this to avoid error being thrown : 'atomicAdd is undefined' (as pointed here). Here is my current statement to compile the code: nvcc -g -G --maxrregcount=32 Main.cu -o SW_exe (..including header files...) -arch sm_20 and when I set a breakpoint inside kernel, cuda-gdb stops once at the last line of the kernel, and then the program continues. (cuda-gdb) b SW_kernel_1.cu:49 Breakpoint 1 at 0x4114a0: file ./SW_kernel_1.cu, line 49. ... [Launch of CUDA Kernel 5 (diagonalComputation&lt;&lt;&lt;(1024,1,1),(128,1,1)&gt;&gt;&gt;) on Device 0] Breakpoint 1, diagonalComputation (__cuda_0=15386, __cuda_1=128, __cuda_2=0xf00400000, __cuda_3=0xf00200000, __cuda_4=100, __cuda_5=0xf03fa0000, __cuda_6=0xf04004000, __cuda_7=0xf040a0000, __cuda_8=0xf00200200, __cuda_9=15258, __cuda_10=5, __cuda_11=-3, __cuda_12=8, __cuda_13=1) at ./SW_kernel_1.cu:183 183 } (cuda-gdb) c Continuing. But as I said, if I remove the 'atomicAdd()' call and the flag '-arch sm_20' which though makes my code incorrect, but now the cuda-gdb stops at the breakpoint I specify. Please tell me the reasons of this behaviour. I am using CUDA 5.5 on Tesla M2070 (Compute Capability = 2.0). Thanks!",
        "answers": [
            [
                "From the CUDA DEBUGGER User Manual, Section 3.3.1: NVCC, the NVIDIA CUDA compiler driver, provides a mechanism for generating the debugging information necessary for CUDA-GDB to work properly. The -g -G option pair must be passed to NVCC when an application is compiled in order to debug with CUDA-GDB; for example, nvcc -g -G foo.cu -o foo Using this line to compile the CUDA application foo.cu forces -O0 compilation, with the exception of very limited dead-code eliminations and register-spilling optimizations. makes the compiler include debug information in the executable This means that, in principle, breakpoints could not be hit in kernel functions even when the code is compiled in debug mode since the CUDA compiler can perform some code optimizations and so the disassembled code could not correspond to the CUDA instructions. When breakpoints are not hit, a workaround is to put a printf statement immediately after the variable one wants to check, as suggested by Robert Crovella at CUDA debugging with VS - can't examine restrict pointers (Operation is not valid) The OP has chosen here a different workaround, i.e., to compile for a different architecture. Indeed, the optimization the compiler does can change from architecture to architecture."
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I'm running CUDA 5.5 on an SUSE Linux machine with 2 M2050 cards installed, neither of which are used for running X11. I am trying to step through a kernel that is specifically only using device 0 using the Nsight Eclipse debugger. If I set an (unconditional) breakpoint inside a kernel, the debugger breaks on block 0/thread 0 first, and then if I continue execution it will break again at the same point 5 or 6 times on seemingly random threads in different blocks, before exiting the kernel and continuing to the next kernel. The program execution in the kernel is happening correctly and displayed correctly. The host code debugs without problems. If I make the same breakpoint conditional, as outlined in this post: using nsight to debug I am seeing no difference in the behavior of the debugger. The condition on the breakpoint seems to be ignored and the debugger breaks on 5 or 6 random threads before exiting the kernel. Neither of these behaviors seem to make much sense to me. I would think the unconditional breakpoint should break on thread 0 or all threads. And I would think that the conditional breakpoint should break on only the thread it's conditioned on. I've looked all over the NVIDIA documentation, stackoverflow etc and seem to have exhausted my options at this point. I was wondering if anyone else has seen similar behavior or might have some pointers.",
        "answers": [
            [
                "Unconditional breakpoint breaks for every new \"batch\" of threads arriving to the device. This is needed so you can explore all your threads. Because of some technical issues, conditional breakpoints should be set after you break in kernel at least once. This will be fixed in CUDA Toolkit 6.0."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I am trying to do a sample code with constant memory with CUDA 5.5. I have 2 constant arrays of size 3000 each. I have another global array X of size N. I want to compute Y[tid] = X[tid]*A[tid%3000] + B[tid%3000] Here is the code. #include &lt;iostream&gt; #include &lt;stdio.h&gt; using namespace std; #include &lt;cuda.h&gt; __device__ __constant__ int A[3000]; __device__ __constant__ int B[3000]; __global__ void kernel( int *dc_A, int *dc_B, int *X, int *out, int N) { int tid = threadIdx.x + blockIdx.x*blockDim.x; if( tid&lt;N ) { out[tid] = dc_A[tid%3000]*X[tid] + dc_B[tid%3000]; } } int main() { int N=100000; // set affine constants on host int *h_A, *h_B ; //host vectors h_A = (int*) malloc( 3000*sizeof(int) ); h_B = (int*) malloc( 3000*sizeof(int) ); for( int i=0 ; i&lt;3000 ; i++ ) { h_A[i] = (int) (drand48() * 10); h_B[i] = (int) (drand48() * 10); } //set X and Y on host int * h_X = (int*) malloc( N*sizeof(int) ); int * h_out = (int *) malloc( N*sizeof(int) ); //set the vector for( int i=0 ; i&lt;N ; i++ ) { h_X[i] = i; h_out[i] = 0; } // copy, A,B,X,Y to device int * d_X, *d_out; cudaMemcpyToSymbol( A, h_A, 3000 * sizeof(int) ) ; cudaMemcpyToSymbol( B, h_B, 3000 * sizeof(int) ) ; cudaMalloc( (void**)&amp;d_X, N*sizeof(int) ) ); cudaMemcpy( d_X, h_X, N*sizeof(int), cudaMemcpyHostToDevice ) ; cudaMalloc( (void**)&amp;d_out, N*sizeof(int) ) ; //call kernel for vector addition kernel&lt;&lt;&lt; (N+1024)/1024,1024 &gt;&gt;&gt;(A,B, d_X, d_out, N); cudaPeekAtLastError() ; cudaDeviceSynchronize() ; // D --&gt; H cudaMemcpy(h_out, d_out, N * sizeof(int), cudaMemcpyDeviceToHost ) ; free(h_A); free(h_B); return 0; } I am trying to run the debugger over this code to analyze. Turns out that on the line which copies to constant memory I get the following error with debugger Coalescing of the CUDA commands output is off. [Thread debugging using libthread_db enabled] [New Thread 0x7ffff5c5b700 (LWP 31200)] Can somebody please help me out with constant memory",
        "answers": [
            [
                "There are several problems here. It is probably easier to start by showing the \"correct\" way to use those two constant arrays, then explain why what you did doesn't work. So the kernel should look like this: __global__ void kernel(int *X, int *out, int N) { int tid = threadIdx.x + blockIdx.x*blockDim.x; if( tid&lt;N ) { out[tid] = A[tid%3000]*X[tid] + B[tid%3000]; } } ie. don't try passing A and B to the kernel. The reasons are as follows: Somewhat confusingly, A and B in host code are not valid device memory addresses. They are host symbols which provide hooks into a runtime device symbol lookup. It is illegal to pass them to a kernel- If you want their device memory address, you must use cudaGetSymbolAddress to retrieve it at runtime. Even if you did call cudaGetSymbolAddress and retrieve the symbols device addresses in constant memory, you shouldn't pass them to a kernel as an argument, because doing do would not yield uniform memory access in the running kernel. Correct use of constant memory requires the compiler to emit special PTX instructions, and the compiler will only do that when it knows that a particular global memory location is in constant memory. If you pass a constant memory address by value as an argument, the __constant__ property is lost and the compiler can't know to produce the correct load instructions Once you get this working, you will find it is terribly slow and if you profile it you will find that there is very high degrees of instruction replay and serialization. The whole idea of using constant memory is that you can exploit a constant cache broadcast mechanism in cases when every thread in a warp accesses the same value in constant memory. Your example is the complete opposite of that - every thread is accessing a different value. Regular global memory will be faster in such a use case. Also be aware that the performance of the modulo operator on current GPUs is poor, and you should avoid it wherever possible."
            ]
        ],
        "votes": [
            4.0000001
        ]
    },
    {
        "question": "Let's say I have this __device__ function: __device__ unsigned char* dev_kernel(unsigned char* array_sh, int params){ return array_sh + params; } And within the __global__ kernel I use it in this way: uarray = dev_kernel (uarray, params); Where uarray is an array located in shared memory. But when i use cuda-gdb to see the addresss of uarray within __global__ kernel I get: (@generic unsigned char * @shared) 0x1000010 \"z\\377*\" And within __device__ kernel I get: (unsigned char * @generic) 0x1000010 &lt;Error reading address 0x1000010: Operation not permitted&gt; Despite the error, the program in running ok (maybe it is some limitation of cuda-gdb). So, I want to know: Within the __device__ kernel, uarray is shared yet? I'm changing the array from global to shared memory and the time is almost the same (with shared memory the time is a little worse).",
        "answers": [
            [
                "So, i want to know: Within the __device__ kernel, uarray is shared yet? Yes, when you pass a pointer to shared memory to a device function this way, it still points to the same place in shared memory. In response to the questions posted below which are perplexing me, I elected to show a simple example: $ cat t249.cu #include &lt;stdio.h&gt; #define SSIZE 256 __device__ unsigned char* dev_kernel(unsigned char* array_sh, int params){ return array_sh + params; } __global__ void mykernel(){ __shared__ unsigned char myshared[SSIZE]; __shared__ unsigned char *u_array; for (int i = 0; i&lt; SSIZE; i++) myshared[i] = (unsigned char) i; unsigned char *loc = dev_kernel(myshared, 5); u_array = loc; printf(\"val = %d\\n\", *loc); printf(\"val = %d\\n\", *u_array); } int main(){ mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); cudaDeviceSynchronize(); return 0; } $ nvcc -arch=sm_20 -g -G -o t249 t249.cu $ cuda-gdb ./t249 NVIDIA (R) CUDA Debugger 5.5 release .... Reading symbols from /home/user2/misc/t249...done. (cuda-gdb) break mykernel Breakpoint 1 at 0x4025dc: file t249.cu, line 9. (cuda-gdb) run Starting program: /home/user2/misc/t249 [Thread debugging using libthread_db enabled] Breakpoint 1, mykernel () at t249.cu:9 9 __global__ void mykernel(){ (cuda-gdb) break 14 Breakpoint 2 at 0x4025e1: file t249.cu, line 14. (cuda-gdb) continue Continuing. [New Thread 0x7ffff725a700 (LWP 26184)] [Context Create of context 0x67e360 on Device 0] [Launch of CUDA Kernel 0 (mykernel&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt;) on Device 0] [Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (0,0,0), device 0, sm 2, warp 0, lane 0] Breakpoint 1, mykernel&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; () at t249.cu:12 12 for (int i = 0; i&lt; SSIZE; i++) (cuda-gdb) continue Continuing. Breakpoint 2, mykernel&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; () at t249.cu:14 14 unsigned char *loc = dev_kernel(myshared, 5); (cuda-gdb) print &amp;(myshared[0]) $1 = (@shared unsigned char *) 0x8 \"\" ^ | cuda-gdb is telling you that this pointer is defined in a __shared__ statement, and therefore it's storage is implicit and it is unmodifiable. (cuda-gdb) print &amp;(u_array) $2 = (@generic unsigned char * @shared *) 0x0 ^ ^ | u_array is stored in shared memory. u_array is a generic pointer, meaning it can point to anything. (cuda-gdb) step dev_kernel(unsigned char * @generic, int) (array_sh=0x1000008 \"\", params=5) at t249.cu:6 6 return array_sh + params; (cuda-gdb) print array_sh $3 = (@generic unsigned char * @register) 0x1000008 \"\" ^ ^ | array_sh is stored in a register. array_sh is a generic pointer, it can point to anything. (cuda-gdb) print u_array No symbol \"u_array\" in current context. (note that I can't access u_array from inside the __device__ function, so I don't understand your comment there.) (cuda-gdb) step mykernel&lt;&lt;&lt;(1,1,1),(1,1,1)&gt;&gt;&gt; () at t249.cu:15 15 u_array = loc; (cuda-gdb) step 16 printf(\"val = %d\\n\", *loc); (cuda-gdb) print u_array $4 = ( @generic unsigned char * @shared) 0x100000d ...... ^ ^ | u_array is stored in shared memory u_array is a generic pointer, it can point to anything (cuda-gdb) Although you haven't provided it, I am assuming your definition of u_array is similar to mine, based on the cuda-gdb output you are getting. Note that the indicators like @shared are not telling you what kind of memory a pointer is pointing to, they are telling you either what kind of pointer it is (defined implicitly in a __shared__ statement) or else where it is stored (in shared memory). If this doesn't sort out your questions, please provide a complete example, along with complete cuda-gdb session output, just as I have."
            ]
        ],
        "votes": [
            5.0000001
        ]
    },
    {
        "question": "I have a CentOS 6.0 x64 server with 2 Geforce 480GTX cards equipped and I am using it to debug my cuda programs. Today I tried to use cuda-gdb on my notebook to remote debug my program. So I tried like this: I opened my bash shell and use ssh to connect to the server, then enter the directory where the program resides. I start the cuda-gdbserver by typing this: cuda-gdbserver :9999 ./a.out After that I got this on the bash: Process ./a.out created; pid = 4356 Listening on port 9999 It seems the cuda-gdbserver works well. So I opened a new bash shell, and decide to debug the program using cuda-gdb. First I opened the cuda-gdb, now the shell is like this: (cuda-gdb) Then I tried to connect the remote server: target remote 192.168.2.105:9999 where 192.168.2.105 is my server's ip address But, however, to my disappointment, I got error information from shell, which says: 192.168.2.105:9999: No route to host. What's wrong? I googled for some time, someone told me that I should stop the iptables service on the server, so I did as they said(service iptables stop), but it still doesn't work. By the way, I have also tried the target extended-remote command in cuda-gdb, no good. In addition, both the server and my notebook(running ubuntu 12.10 x64) installed the same subversion of cuda toolkit 5.5, and I can debug locally on my server well. So, is there anybody know what I need to do? It really puzzled me for a long time(Actually I encountered this problem long long ago). I'd like to thank anybody answering my question in advance!",
        "answers": [
            [
                "Can you ping/ssh the remote host? In our testing, we noticed that the CentOS and Fedora have a firewall enabled by default. Please consult your OS documentation on how to open the ports."
            ],
            [
                "It could be that cuda-gdbserver only listens on the loopback interface by default. Try cuda-gdbserver 0.0.0.0:9999 ./a.out"
            ]
        ],
        "votes": [
            1.0000001,
            1e-07
        ]
    },
    {
        "question": "I have a Server running CentOS 6.0 and I'm trying to use it as a remote host for cuda debugging. In order to do this, I installed cuda-toolkit 5.5 both on the server and my notebook, which is running ubuntu 12.10 OS. I configured the two machines as the NVIDIA-cuda-instruction told me, yet when I started the Nsight eclipse edition and tried to remote debug my cuda applications, I ran into error, whcih says: Failed to execute MI command: -target-select remote 192.168.2.105:2345 Error message from debugger back end: 192.168.2.105:2345: Connection timed out I googled this error, someones says it is a firewall issue and I need to open the port manually, so I modified the /etc/sysconfig/iptables file and add this: -A INPUT -m state --state NEW -m tcp -p tcp --dport 2345 -j ACCEPT to open the 2345 port. But it turn out to be of no use. Can anyone give me some suggestion and help me solve this problem? By the way, I have tested local debugging using nsight eclipse edition on my server, and it works well.",
        "answers": [
            [
                "I have the same problem in an OpenSuse server. I have managed to make it work by disabling the firewall in the server. #/sbin/rcSuSEfirewall2 stop You can start later by #/sbin/rcSuSEfirewall2 start"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I have a Server running CentOS 6.0 and I'm trying to use it as a remote host for cuda debugging. In order to do this, I installed cuda-toolkit 5.5 both on the server and my notebook, which is running ubuntu 12.10 OS. I configured the two machines as the NVIDIA-cuda-instruction told me, yet when I started the Nsight eclipse edition and tried to remote debug my cuda applications, I ran into error, whcih says: Failed to execute MI command: -target-select remote 192.168.2.105:2345 Error message from debugger back end: 192.168.2.105:2345: Connection timed out I googled this error, someones says it is a firewall issue and I need to open the port manually, so I modified the /etc/sysconfig/iptables file and add this: -A INPUT -m state --state NEW -m tcp -p tcp --dport 2345 -j ACCEPT to open the 2345 port. But it turn out to be of no use. Can anyone give me some suggestion and help me solve this problem? By the way, I have tested local debugging using nsight eclipse edition on my server, and it works well.",
        "answers": [
            [
                "I have the same problem in an OpenSuse server. I have managed to make it work by disabling the firewall in the server. #/sbin/rcSuSEfirewall2 stop You can start later by #/sbin/rcSuSEfirewall2 start"
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "Disclaimer: I know that this question has been asked numerous times, but before Nsight 5.5 the answer simply was \"You can't.\" I'm trying to debug a CUDA program with Nsight 5.5 on Ubuntu. The remote machine is also an Ubuntu with CUDA Toolkit 5.5. I setup debugging in NSight using the \"Debug an application on a remote system\". Whenever I try to run the application I get a \"Could not start gdbserver on the remote host\" error. This is what I get on the console: Last login: Thu Aug 1 16:09:26 2013 from host.whatever.edu echo $PWD'&gt;' :2345 /tmp/nsight-debug/flow;exit someuser@remotehost:~$ echo $PWD'&gt;' /home/someuser&gt; someuser@remotehost:~$ :2345 /tmp/nsight-debug/flow;exit :2345: command not found logout Both gdbserver and cuda-gdbserver are installed on both machines. If I ssh to the remote host, I can run /tmp/nsight-debug/flow manually. What might be the problem here? Is there anything missing from the setup?",
        "answers": [
            [
                "This looks like a bug in Nsight, we will take a look into this matter. Please make sure that you have remote toolkit configured for your connection. From the main menu, select Run -&gt; Debug Configurations... In the left-hand tree, select you debug configuration under C/C++ Remote Application Make sure that Remote toolkit combo has proper toolkit selected. If you don't have any toolkit configured, click Manage... and setup the toolkit. Usually you will only have to setup the toolkit once per your connection - e.g. you will not have to setup it if you want to debug another application on the same remote system."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'd like to know what is the best debugger for a JCuda project (if exists). I know that for normal CUDA applications there are tools like cuda-gdb and cuda-memcheck and I wonder if I can use any of them or similar ones for a JCuda project. Thank you!",
        "answers": [
            [
                "You should be able to use regular CUDA debugger (e.g. Nsight or cuda-gdb) to debug the GPU code in your JCuda application. You can use Java debuggers (e.g. Eclipse) to debug Java code. There is no debugger that can seamlessly debug Java and CUDA code though."
            ],
            [
                "On Linux, you can use Nvidia Nsight (cuda-gdb). To set up a debugging session that launches your executable: launch Nsight as root (surprising, but necessary for me) go to Run menu &gt; Debug Configurations... Right-click \"C/C++ Application\", choose New Under Main tab Set the executable (field C/C++ Application) to /usr/bin/java or whatever the correct path Under Arguments tab set the startup arguments, eg -jar target/MyApp.jar set the working directory Under Debugger tab set the \"CUDA GDB init file\" path (see below) set additional options, like enabling CUDA memcheck Because Java uses segmentation faults internally for some too-clever purposes, you will need to create a file with the following GDB option and point to it as the \"CUDA GDB init file\". Note that by setting this option you won't be able to catch segmentation fault bugs inside your own JNI code. This shouldn't be a problem. handle SIGSEGV nostop noprint pass If you compile your kernels with debug symbols, you'll be able to debug them."
            ]
        ],
        "votes": [
            4.0000001,
            1.0000001
        ]
    },
    {
        "question": "I am trying the walking-through example in CUDA-GDB manual, and follow exactly the same compilation command. I am using CUDA-4 on Fermi M2090, and CUDA-GDB failed with the following message when I type \"run\" under GDB environment: /home/buildmeister/build/rel/gpgpu/toolkit/r4.1/debugger/cuda-gdb/7.2/gdb/cuda-tdep.c:1203: internal-error: cuda_get_bfd_abi_version: Assertion `CUDA_ELFOSABIV_16BIT &lt;= abiv &amp;&amp; abiv &lt;= CUDA_ELFOSABIV_LATEST' failed. A problem internal to GDB has been detected, further debugging may prove unreliable.",
        "answers": [
            [
                "I have experienced same problem. (Kepler architecture, ubuntu 13.04) I have done some research and found out this link. The problem occurs because of your driver version is higher than your toolkit version. Your toolkit isn't able to recognize your driver. I have solved this problem by installing Cuda-Toolkit-5.5 (Release Candidate) and display driver from the same self extracting package. I have done this because it is almost impossible to install cuda toolkit 5.0 on a kernel 3.8+. You can find the instructions here on my blog page."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I am trying to get memory traces from cuda-gdb. However, I am not able to step into the kernel code. I use the nvcc flags -g -G and -keep but to no effect. I am able to put a breakpoint on the kernel function but when I try to access the next instruction, it jump to the end of the kernel function. I have tried this on the sdk examples and I observe the same behaviour. I am working on cuda 5 toolkit. Any suggestions? Thanks!",
        "answers": [
            [
                "This behavior is typical for kernel launch failure. Make sure you check return codes of the CUDA calls. Note that for debugging you may want to add additional call cudaDeviceSynchronize immediately after the kernel call and to check the return code from this call - it is the most precise way to obtain the cause of the asynchronous kernel launch failure. Update: The code running outside of debugger but not in cuda-gdb most often is caused by trying to debug on a single-GPU system from graphical environment. cuda-gdb cannot share GPU with Xwindows as this would hang the OS. You need to exit the graphical environment (e.g. quit X window) and debug from the console if your system only has one GPU. If you have a multi-GPU system, then you should check your Xwindow configuration (Xorg.conf) so it does not use the GPU you reserve for debugging."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'm using CAPS OpenACC on CUDA. I'm trying debugging with cuda-gdb. And i can debug normally c/c++ code with cuda-gdb. In other words i couldn't debug codelet code. Is there a anybody who debugged openACC on cuda? or i couldn't put breakpoint in the codelet. What should i do to debug? I addition to i compiled with that hmpp -d2 -kk -g gcc -g vecadd.c -o vecadd.x And my openACC code is very simple : #pragma acc kernels copyin(a[0:n],b[0:n]), copyout(c[0:n]) for(i=0; i&lt;n; i++) { c[i] = a[i] + b[i]; }",
        "answers": [
            [
                "According to this post you need to pass -G options to capsmc so that the CUDA code is compiled with debug symbols. Since CAPS Compilers generates just plain CUDA code, you should be able to use cuda-gdb just fine then."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "I am using cudaMallocPitch and cudaMemcpy2D for 2D array. I am not sure that I have coded correct even though I could not get the output correctly. Can any one help please? Can any one debug my error? Thanks in advance. #include&lt;stdio.h&gt; #include&lt;cuda.h&gt; #define siz 4*sizeof(int) __global__ void addmatrix(int *m1,int *m2,size_t pitch) { int r=threadIdx.x; int *r1=m1+r*pitch; int *r2=m2+r*pitch; int c; for(c=1;c&lt;=4;c++) { r1[c]+=r2[c]; } } int main() { int i,j; int **m1_c,**m2_c; int *m1_d,*m2_d; size_t pitch; cudaError_t err; m1_c=(int **)malloc(4*sizeof(int *)); for(i=1;i&lt;=4;i++) { m1_c[i]=(int *)malloc(siz); } m2_c=(int **)malloc(4*sizeof(int *)); for(i=1;i&lt;=4;i++) { m2_c[i]=(int *)malloc(siz); } for(i=1;i&lt;=4;i++) { for(j=1;j&lt;=4;j++) { m1_c[i][j]=rand()%10; m2_c[i][j]=rand()%10; } } for(i=1;i&lt;=4;i++) { for(j=1;j&lt;=4;j++) { printf(\"%d\\t\",m1_c[i][j]); } printf(\"\\n\"); } printf(\"\\n\\n\"); for(i=1;i&lt;=4;i++) { for(j=1;j&lt;=4;j++) { printf(\"%d\\t\",m2_c[i][j]); } printf(\"\\n\"); } err=cudaMallocPitch((void **)&amp;m1_d,&amp;pitch,siz,siz); err=cudaMallocPitch((void **)&amp;m2_d,&amp;pitch,siz,siz); err=cudaMemcpy2D(m1_d,pitch,m1_c,siz,siz,4,cudaMemcpyHostToDevice); err=cudaMemcpy2D(m2_d,pitch,m2_c,siz,siz,4,cudaMemcpyHostToDevice); dim3 grid(1); dim3 block(16); addmatrix&lt;&lt;&lt;grid,block&gt;&gt;&gt;(m1_d,m2_d,siz); cudaMemcpy2D(m1_c,siz,m1_d,pitch,siz,4,cudaMemcpyDeviceToHost); for(i=1;i&lt;=4;i++) { for(j=1;j&lt;=4;j++) { printf(\"%d\\t\",m1_c[i][j]); } printf(\"\\n\"); } err=cudaFree(m1_d); err=cudaFree(m2_d); err=cudaDeviceReset(); }",
        "answers": [
            [
                "So there are several problems with this code. In no particular order: You are indexing through your various arrays from 1 to 4, but this is not correct in C. C indexing starts at zero and goes to one less than the dimension. This has nothing to do with CUDA. cudaMemcpy2D expects two pointers (src and dst) both of which are pointers to linear arrays in memory. I realize this is confusing since 2D appears all over the description, but the two pointer parameters are fundamentally both of the same type (a pointer to memory) and you are passing pointers of 2 different types (one is a pointer to memory, the other is a pointer to a pointer to memory). So cleary from the definition of cudaMemcpy2D, your usage cannot be correct. There are plenty of answered questions with examples about how to use cudaMemcpy2D, I suggest you search and review some of them. Note that fixing this issue will probably cause you to fundamentally re-think how you want to store the data on the host matrices. There are plenty of questions such as this one about handling multidimensional matrices -- you should flatten them if possible. Note that in your current code, this error with cudaMemcpy2D usage is destroying the pointer array on your host matrices, which is resulting in a seg fault when you try to print the results. Your parameters passed to cudaMallocPitch are not quite right. For both the width and height parameters you are passing siz which is the matrix dimension in bytes. But you should only pass the byte-dimension for the width parameter. For the height parameter you should pass the number of rows, i.e. 4 in your case. There is a similar requirement on the call to cudaMemcpy2D but you got it right there. Now let's look at your kernel. In the invocation, you are launching a grid of one block of 16 threads. Since your matrices have 16 elements, that seems sensible. That implies a thread strategy where each thread will be responsible for a single element of the result. But looking at your kernel code, you have each thread computing the result of an entire row, i.e. 4 elements. There are 2 ways to fix this: you could either reduce your grid to 4 threads instead of 16 threads (simpler, probably, from a code modification standpoint), or you could re-write your kernel (eliminate the for-loop) and have each thread compute a single output element (which will probably do more work in parallel). Additionally, in your kernel, you are using the pitch parameter in pointer-arithmetic based indexing. But remember that pitch is in bytes and for pointer-arithmetic indexing, the compiler expects the parameters to be in elements - it does the conversion to bytes for you, based on the data type. Again, this is really a C issue, and not specific to CUDA. You could fix this by using (pitch/sizeof(int)) wherever you are using pitch in the kernel. You are passing siz for the pitch to your kernel. You should be passing pitch for the pitch parameter. siz is effectively the \"pitch\" on the host data storage, but pitch is the pitch of the storage on the device. The kernel is operating on the device storage, so it needs the correct pitch. As a recommendation, do cuda error checking on all cuda API calls and kernel calls. Here is some code which addresses all of the above issues, in one fashion or another: #include&lt;stdio.h&gt; #define siz (4*sizeof(int)) #define cudaCheckErrors(msg) \\ do { \\ cudaError_t __err = cudaGetLastError(); \\ if (__err != cudaSuccess) { \\ fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\ msg, cudaGetErrorString(__err), \\ __FILE__, __LINE__); \\ fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\ exit(1); \\ } \\ } while (0) __global__ void addmatrix(int *m1,int *m2,size_t pitch) { int r=threadIdx.x; int *r1=m1+r*(pitch/sizeof(int)); int *r2=m2+r*(pitch/sizeof(int)); int c; for(c=0;c&lt;4;c++) { r1[c]+=r2[c]; } } int main() { int i,j; int *m1_c,*m2_c; int *m1_d,*m2_d; size_t pitch; cudaError_t err; m1_c=(int *)malloc(16*sizeof(int)); m2_c=(int *)malloc(16*sizeof(int)); for(i=0;i&lt;4;i++) { for(j=0;j&lt;4;j++) { m1_c[(i*4)+j]=rand()%10; m2_c[(i*4)+j]=rand()%10; } } for(i=0;i&lt;4;i++) { for(j=0;j&lt;4;j++) { printf(\"%d\\t\",m1_c[(i*4)+j]); } printf(\"\\n\"); } printf(\"\\n\\n\"); for(i=0;i&lt;4;i++) { for(j=0;j&lt;4;j++) { printf(\"%d\\t\",m2_c[(i*4)+j]); } printf(\"\\n\"); } err=cudaMallocPitch((void **)&amp;m1_d,&amp;pitch,siz,4); cudaCheckErrors(\"cm1\"); err=cudaMallocPitch((void **)&amp;m2_d,&amp;pitch,siz,4); cudaCheckErrors(\"cm2\"); err=cudaMemcpy2D(m1_d,pitch,m1_c,siz,siz,4,cudaMemcpyHostToDevice); cudaCheckErrors(\"cm3\"); err=cudaMemcpy2D(m2_d,pitch,m2_c,siz,siz,4,cudaMemcpyHostToDevice); cudaCheckErrors(\"cm4\"); dim3 grid(1); dim3 block(4); addmatrix&lt;&lt;&lt;grid,block&gt;&gt;&gt;(m1_d,m2_d,pitch); cudaMemcpy2D(m1_c,siz,m1_d,pitch,siz,4,cudaMemcpyDeviceToHost); cudaCheckErrors(\"cm5\"); for(i=0;i&lt;4;i++) { for(j=0;j&lt;4;j++) { printf(\"%d\\t\",m1_c[(i*4)+j]); } printf(\"\\n\"); } err=cudaFree(m1_d); err=cudaFree(m2_d); err=cudaDeviceReset(); }"
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'm trying to use cuda-gdb debug my code on a remote cluster via ssh. There're 6 Tesla C2070 gpu on the node: $ deviceQuery | grep \"^Device\" Device 0: \"Tesla C2070\" Device 1: \"Tesla C2070\" Device 2: \"Tesla C2070\" Device 3: \"Tesla C2070\" Device 4: \"Tesla C2070\" Device 5: \"Tesla C2070\" But when I run code under cuda-gdb, it still gives me error code=24: \"fatal: All CUDA devices are used for display and cannot be used while debugging. \" I've already set -gencode arch=compute_20,code=sm_20 and compiles well. When I type info cuda devices in the debugger, it spits No CUDA devices. I also tried export CUDA_VISIBLE_DEVICES=\"0,2\" but still not working. What should I do? I'm using cuda 5.0. Thanks in advance.",
        "answers": [
            [
                "Try running \"lsof /dev/nvidia*\", it will show you which program is holding the device nodes open. If X is using those GPUs, it will be evident from the output."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "For some reason, the breakpoints I set in a specific kernel are completely ignored... I have checked the error status with cudaGetLastError(), which told me that everything ran fine so I am quite sure this should mean that the kernel has executed. Placing printf statements also yields no extra information, as nothing is printed. Even in a kernel that is entered in debug mode, the printf calls have no effect. What could go wrong here?! We are running Cuda 4.2 on a Tesla M2075 (driver version 295.41). Output when debugging: (cuda-gdb) break cudaCalcBeamIntersect Breakpoint 1 at 0x401cfb: file cudacalcbeamintersect.cu, line 109. (cuda-gdb) r Starting program: /home/heit/cuda/vfind/vfind singleevent.txt 1 1 1 [Thread debugging using libthread_db enabled] [New Thread 0x7ffff5dd5700 (LWP 20241)] [Context Create of context 0x634220 on Device 0] [Launch of CUDA Kernel 0 (memset32_post&lt;&lt;&lt;(64,1,1),(64,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 1 (memset32_post&lt;&lt;&lt;(8,1,1),(64,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 2 (memset32_post&lt;&lt;&lt;(64,1,1),(64,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 3 (memset32_post&lt;&lt;&lt;(1,1,1),(64,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 4 (memset32_post&lt;&lt;&lt;(1,1,1),(64,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 5 (memset32_post&lt;&lt;&lt;(8,1,1),(64,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 6 (cudaInitializeGlobals&lt;&lt;&lt;(256,1,1),(128,1,1)&gt;&gt;&gt;) on Device 0] no error [Launch of CUDA Kernel 7 (cudaCalcBeamIntersect&lt;&lt;&lt;(256,1,1),(128,1,1)&gt;&gt;&gt;) on Device 0] no error Elapsed time: 0.876842 seconds. [Thread 0x7ffff5dd5700 (LWP 20241) exited] [Termination of CUDA Kernel 6 (cudaInitializeGlobals&lt;&lt;&lt;(256,1,1),(128,1,1)&gt;&gt;&gt;) on Device 0] Program exited normally. The \"no error\" prints are printed outside the kernels by calling cout &lt;&lt; cudaGetErrorString(cudaGetLastError()) &lt;&lt; '\\n';, and indicate that both cudaInitializeGlobals() (which can be stepped through in cuda-gdb) and cudaCalcBeamIntersect() are executed without problems. The latter however, cannot be debugged. The kernel in question is still a preliminary one, and calculates some values to be stored in (static) global memory. Nothing else is done with these values, so could it be that the compiler optimizes this call away completely? If so, why??!! And how to prevent this behavior?? (-O0 has no effect) Cheers! Edit - The code: ** Code calling the kernels ** uint const nEvents = events.size(); // total number of events /* Not important ... */ // Allocate memory to hold the events Track *dev_events; cudaMalloc(&amp;dev_events, linearEvents.size() * sizeof(Track)); // Copy all events to the GPU cudaMemcpy(dev_events, &amp;linearEvents[0], linearEvents.size() * sizeof(Track), cudaMemcpyHostToDevice); // Initialize the global data, like the histogram and the array of z-values cudaInitializeGlobals &lt;&lt;&lt; tpb, bpg &gt;&gt;&gt; (); cout &lt;&lt; cudaGetErrorString(cudaGetLastError()) &lt;&lt; '\\n'; cout &lt;&lt; \"Processing \" &lt;&lt; nEvents &lt;&lt; \" event(s)\\n\"; uint linearIdx = 0; for (uint event = 0; event != nEvents; ++event) { uint nTracks = events[event].size(); if (nTracks &gt; MAX_NUMBER_OF_TRACKS) { cout &lt;&lt; \"Number of tracks in event \" &lt;&lt; event &lt;&lt; \" exceeds maximum number of tracks.\\n\"; exit(1); } cudaCalcBeamIntersect &lt;&lt;&lt; tpb, bpg &gt;&gt;&gt; (dev_events + linearIdx, nTracks, bipThresh, binWidth); cout &lt;&lt; cudaGetErrorString(cudaGetLastError()) &lt;&lt; '\\n'; // Update linear index linearIdx += nTracks; } cudacalcbeamintersect.cu #include \"vfind.cuh\" __device__ float dev_zMin; __device__ float dev_zMax; __device__ float dev_zValues[MAX_NUMBER_OF_TRACKS]; __device__ uint dev_histogram[MAX_NUMBER_OF_BINS]; __constant__ Track dev_beam = { {0, 0, 1}, {0, 0, 0} }; __global__ void cudaInitializeGlobals() { uint const tid = threadIdx.x + blockIdx.x * blockDim.x; uint const nThreads = blockDim.x * gridDim.x; if (tid == 0) { dev_zMin = 1e6; dev_zMax = -1e6; } uint idx = tid; while (idx &lt; MAX_NUMBER_OF_BINS || idx &lt; MAX_NUMBER_OF_TRACKS) { if (idx &lt; MAX_NUMBER_OF_BINS) dev_histogram[idx] = 0; if (idx &lt; MAX_NUMBER_OF_TRACKS) dev_zValues[idx] = 0; idx += nThreads; } } __device__ float dot(float const v1[3], float const v2[3]) { // Stuff } __device__ float distance(Track const &amp;t1, Track const &amp;t2) { // Even more boring unimportant stuff } __device__ Vertex vertex(Track const &amp;t1, Track const &amp;t2) { // Yet even more boring unimportant stuff } __global__ void cudaCalcBeamIntersect(Track const *tracks, uint nTracks, float bipTresh, float binWidth) { uint const tid = threadIdx.x + blockIdx.x * blockDim.x; uint const nThreads = blockDim.x * gridDim.x; uint idx = tid; while (idx &lt; nTracks) { float dist = distance(tracks[idx], dev_beam); if (dist &lt; bipTresh) { float z = vertex(tracks[idx], dev_beam).z; if (z &lt; dev_zMin) atomicExch(&amp;dev_zMin, z); if (z &gt; dev_zMax) atomicExch(&amp;dev_zMax, z); dev_zValues[idx] = z; } idx += nThreads; } __syncthreads(); // To be continued here }",
        "answers": [
            [
                "@JorenHeit Your kernel cudaCalcBeamIntersect has global memory side effects and should not be getting optimized out. Based on the posted cuda-gdb output, it looks like the host thread that had launched the work is not waiting on the work to complete (via a cudaDeviceSynchronize() call or via a cudaMemcpy from device to host). As a result, the host thread is exiting before the cudaCalcBeamIntersect kernel could be executed on the GPU. Please try adding a cudaDeviceSynchronize() call after every kernel launch in your application."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "when I debugging my cuda project remotely on the host it ignore breakpoints but execute completely . but when I debug my project locally on the target machine it works fine . I checked my driver version it was 301.42 and my nsight version is 2.2 my target machine has Geforce 8600GT and host machine has Geforce 6200 turboCache .I think that my host machine's GPU is not TCC enable. nsight Analysis activity work fine in both locally and remotely but cuda debugging is work only in local mode",
        "answers": [
            [
                "This is most likely a driver version problem. My experience is that not every driver version works with Nsight. Currently i am running the latest driver version (310.90) and Nsight 3.0 is working fine locally and also remotely. When in doubt, use the driver version that is listed on the Nsight download page."
            ],
            [
                "that problem was because I bring project that already has built on my target to the host , but when I clean the project on host and rebuild it it dosent work because of one link error I search the link error and find the solution solution was doing flowing instruction : project -&gt; propertiy-&gt;configuration properties-&gt;linker-&gt;general -&gt; enable Incremental linking and update it to NO(/INCREMENT:NO) and then debugging is work remotely I am sorry about my ignorance :D"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I'm working on an nvcc compiled static library for a g++ linked project. How do I use cuda-gdb on the final executable? All I get is \"Program exited normally\" without any printf output or anything. nvcc is definitely being given the -g -G arguments when compiling the static library. Here is my command line buffer: cuda-gdb /home/sean/cuda-workspace/cudasplat/Debug/cudasplat NVIDIA (R) CUDA Debugger 5.0 release Portions Copyright (C) 2007-2012 NVIDIA Corporation GNU gdb (GDB) 7.2 Copyright (C) 2010 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-unknown-linux-gnu\". For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;... Reading symbols from /home/sean/cuda-workspace/cudasplat/Debug/cudasplat...done. (cuda-gdb) set args -t a1-31 a2-31 a3-31 a4-31 -L 30 -o tx_coverage -d /var/www/userman/plot-temp/ -db -85 -ngs -dbm -R 20 (cuda-gdb) run Starting program: /home/sean/cuda-workspace/cudasplat/Debug/cudasplat -t a1-31 a2-31 a3-31 a4-31 -L 30 -o tx_coverage -d /var/www/userman/plot-temp/ -db -85 -ngs -dbm -R 20 [Thread debugging using libthread_db enabled] Exiting... Program exited normally. (cuda-gdb) This is what normally happens without debugging: /home/sean/cuda-workspace/cudasplat/Debug/cudasplat -t a1-31 a2-31 a3-31 a4-31 -L 30 -o tx_coverage -d /var/www/userman/plot-temp/ -db -85 -ngs -dbm -R 20 --==[ Welcome To CUDASPLAT! HD v1.4.0a ]==-- Loading \"51:52:113:114-hd.sdf\" into page 1... Done! Loading \"50:51:113:114-hd.sdf\" into page 2... Done! Loading \"50:51:114:115-hd.sdf\" into page 3... Done! Loading \"51:52:114:115-hd.sdf\" into page 4... Done! copying 444 mb into device memory (3878 mb free) finished copy min_north 50, max_north 52, min_west 113, max_west 115 allocated antenna memory invalid argument in ../cudapath.cu at line 551",
        "answers": [
            [
                "You should set a breakpoint before issuing a run command. Does your application perform proper error checking? Note that cuda-gdb may \"hide\" GPUs used to render you OS graphical interface. E.g. if you have a single GPU system and run CUDA application from cuda-gdb in windowing environment (such as GTK or KDE) you application may fail because no GPUs will be detected."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I am running Nsight Eclipse edition on my MacBook PRO (OS X 10.8.2, mountain lion, CUDA 5.0, GT650M) and I am getting a strange error each time I try to start the debugger in Nsight. In the console I get: Coalescing of the CUDA commands output is off. and an error screen. Here is a screenshot of the error: I went through the Nsight documentation and found this line: GPUs used to run X11 (on Linux) or Aqua (on Mac) cannot be used to debug CUDA applications in Nsight Eclipse Edition. Consult cuda-gdb documentation for details. Does this mean I can't run the debugger form Nsight, but just from terminal?",
        "answers": [
            [
                "The message you are seein means the debugger was not properly setup on your system (e.g. it will not even work from the console). Please follow the steps outlined in \"Setting Up the Debugger Environment\" of the cuda-gdb manual You will need a two-GPU system to debug a CUDA code using visual debugger. Unfortunately, no Mac laptops qualify even though they have Intel graphics. The issue been the OS can start using NVIDIA GPU at any moment and may hang if the device is suspended on a breakpoint."
            ],
            [
                "Your cuda-gdb is not properly code signed, which is required by the Darwin kernel to debug applications. Follow this guideline to create a System code sign certificate http://www.noktec.be/archives/1251 Then, code sign the following binaries (assuming the certificate you created is cuda_gdb) sudo codesign -s cuda_gdb /usr/local/cuda/bin/cuda-gdb sudo codesign -s cuda_gdb /usr/local/cuda/bin/cuda-binary-gdb Also, in order to launch the application, you also need to make sure the DYLD_LIBRARY_PATH contains the cuda runtime library path DYLB_LIBRARY_PATH /usr/local/cuda/lib"
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I'm trying to debug my CUDA code on OS X, and I need to run it in &gt;console mode, since running it normally freezes the screen. But it keeps giving me the \" permission denied \" error. Is there a work around for this?.",
        "answers": [
            [
                "Please follow the steps outlined in \"Setting Up the Debugger Environment\" in CUDA-GDB manual. This problem is caused by the debugger requiring special permissions."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I installed cuda 5 on my Ubuntu 12.10 64 bits. I have a GTX 675M, so I'm using bumblebee to run apps on my cuda device. I'm running nsight through bumblebee (optirun): frederico@zeus:~$ optirun /usr/local/cuda/libnsight/nsight And it works just fine, I can compile and execute applications. The problem is when I try to use cuda-gdb in nsight, I got the following error when click on debug button: No source available for \"main() at 0x403c6f\" But if I try to use cuda-gdb on console it works: frederico@zeus:~/Dropbox/coisas/projetos/delta_cuda$ optirun cuda-gdb bin/linux/release/gpu_md5 NVIDIA (R) CUDA Debugger 5.0 release Portions Copyright (C) 2007-2012 NVIDIA Corporation GNU gdb (GDB) 7.2 Copyright (C) 2010 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-unknown-linux-gnu\". For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;... Reading symbols from /home/frederico/Dropbox/coisas/projetos/delta_cuda/bin/linux/release/gpu_md5...done. (cuda-gdb) run Starting program: /home/frederico/Dropbox/coisas/projetos/delta_cuda/bin/linux/release/gpu_md5 [Thread debugging using libthread_db enabled] [New Thread 0x7ffff1dfe700 (LWP 10437)] [New Thread 0x7ffff07f7700 (LWP 10438)] [New Thread 0x7fffb07f6700 (LWP 10439)] [New Thread 0x7fff6bfff700 (LWP 10440)] [New Thread 0x7fff23fff700 (LWP 10441)] [New Thread 0x7ffedbfff700 (LWP 10442)] [New Thread 0x7ffe93fff700 (LWP 10443)] [New Thread 0x7ffe4bfff700 (LWP 10444)] [New Thread 0x7ffe03fff700 (LWP 10445)] [Thread 0x7ffe03fff700 (LWP 10445) exited] [Thread 0x7fffb07f6700 (LWP 10439) exited] [Thread 0x7ffe4bfff700 (LWP 10444) exited] [Thread 0x7fff23fff700 (LWP 10441) exited] [Thread 0x7ffe93fff700 (LWP 10443) exited] [Thread 0x7ffedbfff700 (LWP 10442) exited] [Thread 0x7ffff07f7700 (LWP 10438) exited] [Thread 0x7fff6bfff700 (LWP 10440) exited] [Thread 0x7ffff1dfe700 (LWP 10437) exited] Program exited with code 030. (cuda-gdb) Any idea of what can be going on?",
        "answers": [
            [
                "That message gets printed when your application suspends. It means your application was not compiled with debug information - in this case debugger is not able to map your instructions to the source lines. To reproduce this message in the command-line cuda-gdb you need to suspend on a breakpoint, e.g. do \"break main\" before doing \"run\" Update - for people who have similar problem sometime in the future Application was built as follows: CUDA kernel code was compiled with NVCC and included debug information. E.g. NVCC call was: nvcc -g -G -c mykernel.cu -o mykernel.o This object file was linked with other object files that were compiled by GCC without generating the debug information - g++ mycpp1.cpp mycpp2.cpp mykernel.cu -o mycudaapplication. This resulted in some partial debug information that was not enough for cuda-gdb to properly resolve the path. Nsight Eclipse Edition by default is relying on cuda-gdb source path resolution to find a file to open in an editor when debugging CUDA application."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I installed cuda 5 in my Ubuntu 12.10 and it is working well, I can compile and debug through cuda-gdb in terminal as well. I'm trying to use nsight, it compiles and executes my code with no issues, but when I try to debug I got the following error Error in final launch sequence Failed to execute MI command: -gdb-set cuda api_failures ignore Error message from debugger back end: Undefined set cuda command: \"api_failures ignore\". Try \"help set cuda\". Undefined set cuda command: \"api_failures ignore\". Try \"help set cuda\". I'm using ubuntu 12.10 64 bits and launching cuda executables and nsight with optirun (bumblebee) because I have a GTX 675M (optimus). I installed cuda-gdb throught apt-get, I got version 4.2: frederico@zeus:~/Dropbox/coisas/projetos/delta_cuda$ cuda-gdb --version NVIDIA (R) CUDA Debugger 4.2 release Portions Copyright (C) 2007-2012 NVIDIA Corporation GNU gdb (GDB) 7.2 I think this is not a problem since I can use it alone (without nsight). I changed nsight to launch cuda-gdb with optirun as well, keep receiving the same error.",
        "answers": [
            [
                "The problem was the version of cuda-gdb, I had to use cuda-gdb version 5. It comes with the toolkit version 5, just did a symbolic lick to /usr/bin and it's working."
            ],
            [
                "It is possible to debug CUDA programs with nsight and bumblebee. (nsight v.5.0.0, bumblebee 3.2.1, Debian sid) You just have to replace the debugger command line (CUDA GDB Executable) in: Project Explorer -&gt; right click on your project -&gt; select \"Debug as\" -&gt; click on \"Debug configurations...\" -&gt; select \"Debugger\" tab CUDA GDB Executable: optirun --no-xorg cuda-gdb (another possibility is to make a small shell script like the one that follows: /usr/bin/opti-cuda-gdb) #!/bin/bash optirun --no-xorg /usr/bin/cuda-gdb $* This way optirun does not start a virtual screen for gdb, the GPU is not accepting graphics and debug is possible. Hope that helps!"
            ],
            [
                "There's no need to create this link. You can select the cuda-gdb executable used by nsight in the Run/Debug Configurations... Menu. In this menu, click on your application under C/C++ Application, then choose the Debugger tab where you can browse your filesystem and set the path to the cuda-gdb-5.0 executable."
            ]
        ],
        "votes": [
            3.0000001,
            2.0000001,
            1.0000001
        ]
    },
    {
        "question": "I have this cuda code, that when I execute with cuda-memcheck it returns no errors, it exits normally, and the results I get are actually the expected... At the same time, there is a file \"cuda-memcheck-(put various mumbers here).out\" created, that is empty. When I run the same program under cuda-gdb, it also exits normally with no error reports. But when I do \"set cuda memcheck on\" (under cuda-gdb) and then run the program, then a file \"cuda-memcheck.out\" is created that says: Starting cuda-memcheck... cuda-memcheck encountered an error (3,2,2) that happens as soon as I execute 'run' from within cuda-gdb. Then, soon after the execution starts (and actually very close to a CUFFT kernel execution) i get the following: Program received signal CUDA_EXCEPTION_1, Lane Illegal Address. [Switching focus to CUDA kernel 81, grid 82, block (0,0,0), thread (1,17,0), device 0, sm 0, warp 2, lane 5] *** glibc detected *** cuda-gdb: double free or corruption (!prev): 0x000000001070e5d0 *** ======= Backtrace: ========= /lib/libc.so.6(+0x774b6)[0x7f597c4814b6] /lib/libc.so.6(cfree+0x73)[0x7f597c487c83] /lib/libc.so.6(obstack_free+0x48)[0x7f597c48b128] cuda-gdb[0x5c5a25] cuda-gdb[0x4352d0] cuda-gdb[0x5649c4] cuda-gdb[0x5e42d7] cuda-gdb[0x5e45fd] cuda-gdb[0x56436c] cuda-gdb[0x50d772] cuda-gdb[0x50e3c3] cuda-gdb[0x51373b] cuda-gdb[0x50faff] cuda-gdb[0x510194] cuda-gdb[0x51373b] cuda-gdb[0x50eaac] cuda-gdb[0x504311] cuda-gdb[0x50a09d] cuda-gdb[0x4ffc4f] cuda-gdb[0x410b9d] cuda-gdb[0x519c48] cuda-gdb[0x51a82c] cuda-gdb[0x5f9b57] cuda-gdb[0x519cb9] cuda-gdb[0x5186c8] cuda-gdb[0x51995a] cuda-gdb[0x51373b] cuda-gdb[0x4a1a40] cuda-gdb[0x407529] cuda-gdb[0x51373b] cuda-gdb[0x408056] cuda-gdb[0x51373b] cuda-gdb[0x407464] cuda-gdb[0x40742e] /lib/libc.so.6(__libc_start_main+0xfe)[0x7f597c428d8e] cuda-gdb[0x407339] ======= Memory map: ======== 00400000-008b6000 r-xp 00000000 08:01 190634 /usr/local/cuda/bin/cuda-gdb 00ab5000-00ab6000 r--p 004b5000 08:01 190634 /usr/local/cuda/bin/cuda-gdb 00ab6000-00ac9000 rw-p 004b6000 08:01 190634 /usr/local/cuda/bin/cuda-gdb 00ac9000-0f0f8000 rw-p 00000000 00:00 0 0fef3000-11b2c000 rw-p 00000000 00:00 0 [heap] 7f5974000000-7f5974021000 rw-p 00000000 00:00 0 7f5974021000-7f5978000000 ---p 00000000 00:00 0 7f597a4df000-7f597aacc000 rw-p 00000000 00:00 0 7f597aacc000-7f597aacd000 rw-p 00000000 00:00 0 7f597b538000-7f597b54d000 r-xp 00000000 08:01 954799 /lib/libgcc_s.so.1 7f597b54d000-7f597b74c000 ---p 00015000 08:01 954799 /lib/libgcc_s.so.1 7f597b74c000-7f597b74d000 r--p 00014000 08:01 954799 /lib/libgcc_s.so.1 7f597b74d000-7f597b74e000 rw-p 00015000 08:01 954799 /lib/libgcc_s.so.1 7f597b75d000-7f597b764000 r-xp 00000000 08:01 954961 /lib/libthread_db-1.0.so 7f597b764000-7f597b963000 ---p 00007000 08:01 954961 /lib/libthread_db-1.0.so 7f597b963000-7f597b964000 r--p 00006000 08:01 954961 /lib/libthread_db-1.0.so 7f597b964000-7f597b965000 rw-p 00007000 08:01 954961 /lib/libthread_db-1.0.so 7f597b965000-7f597b966000 ---p 00000000 00:00 0 7f597b966000-7f597c166000 rw-p 00000000 00:00 0 7f597c166000-7f597c40a000 r--p 00000000 08:01 49399 /usr/lib/locale/locale-archive 7f597c40a000-7f597c584000 r-xp 00000000 08:01 954957 /lib/libc-2.12.1.so 7f597c584000-7f597c783000 ---p 0017a000 08:01 954957 /lib/libc-2.12.1.so 7f597c783000-7f597c787000 r--p 00179000 08:01 954957 /lib/libc-2.12.1.so 7f597c787000-7f597c788000 rw-p 0017d000 08:01 954957 /lib/libc-2.12.1.so 7f597c788000-7f597c78d000 rw-p 00000000 00:00 0 7f597c78d000-7f597c78f000 r-xp 00000000 08:01 954973 /lib/libdl-2.12.1.so 7f597c78f000-7f597c98f000 ---p 00002000 08:01 954973 /lib/libdl-2.12.1.so 7f597c98f000-7f597c990000 r--p 00002000 08:01 954973 /lib/libdl-2.12.1.so 7f597c990000-7f597c991000 rw-p 00003000 08:01 954973 /lib/libdl-2.12.1.so 7f597c991000-7f597c9b7000 r-xp 00000000 08:01 954792 /lib/libexpat.so.1.5.2 7f597c9b7000-7f597cbb7000 ---p 00026000 08:01 954792 /lib/libexpat.so.1.5.2 7f597cbb7000-7f597cbb9000 r--p 00026000 08:01 954792 /lib/libexpat.so.1.5.2 7f597cbb9000-7f597cbba000 rw-p 00028000 08:01 954792 /lib/libexpat.so.1.5.2 7f597cbba000-7f597cc3c000 r-xp 00000000 08:01 954964 /lib/libm-2.12.1.so 7f597cc3c000-7f597ce3b000 ---p 00082000 08:01 954964 /lib/libm-2.12.1.so 7f597ce3b000-7f597ce3c000 r--p 00081000 08:01 954964 /lib/libm-2.12.1.so 7f597ce3c000-7f597ce3d000 rw-p 00082000 08:01 954964 /lib/libm-2.12.1.so 7f597ce3d000-7f597ce53000 r-xp 00000000 08:01 954914 /lib/libz.so.1.2.3.4 7f597ce53000-7f597d053000 ---p 00016000 08:01 954914 /lib/libz.so.1.2.3.4 7f597d053000-7f597d054000 r--p 00016000 08:01 954914 /lib/libz.so.1.2.3.4 7f597d054000-7f597d055000 rw-p 00017000 08:01 954914 /lib/libz.so.1.2.3.4 7f597d055000-7f597d095000 r-xp 00000000 08:01 954818 /lib/libncurses.so.5.7 7f597d095000-7f597d294000 ---p 00040000 08:01 954818 /lib/libncurses.so.5.7 7f597d294000-7f597d298000 r--p 0003f000 08:01 954818 /lib/libncurses.so.5.7 7f597d298000-7f597d299000 rw-p 00043000 08:01 954818 /lib/libncurses.so.5.7 7f597d299000-7f597d2b1000 r-xp 00000000 08:01 954959 /lib/libpthread-2.12.1.so 7f597d2b1000-7f597d4b0000 ---p 00018000 08:01 954959 /lib/libpthread-2.12.1.so 7f597d4b0000-7f597d4b1000 r--p 00017000 08:01 954959 /lib/libpthread-2.12.1.so 7f597d4b1000-7f597d4b2000 rw-p 00018000 08:01 954959 /lib/libpthread-2.12.1.so 7f597d4b2000-7f597d4b6000 rw-p 00000000 00:00 0 7f597d4b6000-7f597d4d6000 r-xp 00000000 08:01 954965 /lib/ld-2.12.1.so 7f597d4df000-7f597d672000 rw-p 00000000 00:00 0 7f597d672000-7f597d678000 r--p 00a01000 08:06 26722558 /home/user/workspace/cuda/fullcu/current_debug/Default/shl_3D_cu 7f597d678000-7f597d67e000 r--p 00a15000 08:06 26722558 /home/user/workspace/cuda/fullcu/current_debug/Default/shl_3D_cu 7f597d67e000-7f597d687000 r--p 00a06000 08:06 26722558 /home/user/workspace/cuda/fullcu/current_debug/Default/shl_3D_cu 7f597d687000-7f597d6c0000 r--p 009c5000 08:06 26722558 /home/user/workspace/cuda/fullcu/current_debug/Default/shl_3D_cu 7f597d6c0000-7f597d6c5000 rw-p 00000000 00:00 0 7f597d6c5000-7f597d6ca000 r--p 009fd000 08:06 26722558 /home/user/workspace/cuda/fullcu/current_debug/Default/shl_3D_cu 7f597d6cb000-7f597d6cd000 rw-p 00000000 00:00 0 7f597d6cd000-7f597d6d4000 r--s 00000000 08:01 49265 /usr/lib/gconv/gconv-modules.cache0x000000000366a8d0 in fdividef&lt;&lt;&lt;(16,1,1),(4,64,1)&gt;&gt;&gt; (Aborted and cuda-gdb crashes. Should I take it that there is actually a faulty mem access in my code? or is it the error that hits upon the initialization of cuda-memcheck??? anyone seen that behaviour before?? Thank you for any ideas.",
        "answers": [
            [
                "It looks like you have a memcheck-detectable error in your application. For some reason, cuda-gdb crashes when your application is suspended on the breakpoint. Does your cuda-gdb crash when you stop on regular breakpoints in the device code? What CUDA Toolkit and NVIDIA display driver versions are you using? We recommend you trying the latest CUDA Toolkit 5.0RC build as it has numerous stability and functionality improvements. It would be invaluable if you could contact out team directly at cudatools@nvidia.com to provide more information (this way we may be able to fix the problem in the next CUDA Toolkit version). Can you also provide the application that triggers the crash? Thank you in advance."
            ],
            [
                "Based on Eugene's question on what happens on regular breakpoints, I added some in key points in the code ('key' with respect to the debugging output I have gotten until now) and I have the following 'odd' gdb output to report: The following is from a CUFFT kernel call: [Launch of CUDA Kernel 41 (spVector0016B_kernelTex&lt;(fftDirection_t)-1&gt;&lt;&lt;&lt;(16,1,1),(4,64,1)&gt;&gt;&gt;) on Device 0] 0x00007ffff569c8b3 in select () from /lib/libc.so.6 (cuda-gdb) n Single stepping until exit from function select, which has no line number information. 0x00007ffff3fe8de7 in ?? () from /usr/lib/libcuda.so Is '??' normal output in that case because it's a CUFFT kernel? The following is from another kernel launch, mine this time and I don't understand why it says 'no such file': Breakpoint 5, BCSG&lt;&lt;&lt;(1,1,1),(512,1,1)&gt;&gt;&gt; (glerror=0x200620df8, sL=0x2009ffff8, ijL=0x200aa7ffc, X=0x2006035f8, D=0x2006075f8, Pre=0x200941ff8, error=1.00000001e-10, L=700, N=1024, flag=0x200c00000, r=0x2006095f8, r0=0x20060b5f8, p1=0x20060d5f8, p2=0x20060f5f8, vv=0x2006115f8, s1=0x2006135f8, s2=0x2006155f8, t=0x2006175f8, T=0x2006195f8, r1=0x20061b600, a=0x20061cbf8, w=0x20061e1f8, beta=0x20061f7f8, ns1=0x200affffc) at BCGC_solver.cu:96 96 BCGC_solver.cu: No such file or directory. in BCGC_solver.cu Also i would like to ask if this: warning: Warp(s) other than the current warp had to be single-stepped. ...happens because of the execution within cuda-gdb, or if it is something that would happen in normal program execution as well. I do have the program hanging at parts of the code, soon after it freezes for good. But I think that if it was only a matter of serial execution, it would continue soon after, as it does in conventional code."
            ],
            [
                "To well trace this issue, it is better to file a bug to Nvidia. The steps of filing a bug is listed as below: 1. Open page http://developer.nvidia.com/cuda/join-cuda-registered-developer-program; 2. If not registered, please click \"Join Now\", otherwise click \"Login Now\"; 3. Input e-mail and password to login; 4. On the left panel, there is a \"Bug Report\" item in Home section, click it to file a bug; 5. Fill the required itmes, other items are optional, but detailed information will help us to target and fix the issue a lot; 6. If necessary, an attachment should be uploaded; 7. For Linux system, it is better to attach an nvidia-bug-report; 8. If an issue is related to specific code pattern, a sample code and instructions to compile it are desired for reproduction."
            ]
        ],
        "votes": [
            1.0000001,
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I am doing GPGPU development on Arch Linux with the cuda-sdk and cuda-toolkit packages. My attempts to run cuda-gdb as a normal user on a simple program results in: $ cuda-gdb ./driver NVIDIA (R) CUDA Debugger 4.2 release Portions Copyright (C) 2007-2012 NVIDIA Corporation GNU gdb (GDB) 7.2 Copyright (C) 2010 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-unknown-linux-gnu\". For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;... Reading symbols from /home/nwh/Dropbox/projects/G4CU/driver...done. (cuda-gdb) run Starting program: /home/nwh/Dropbox/projects/G4CU/driver warning: Could not load shared library symbols for linux-vdso.so.1. Do you need \"set solib-search-path\" or \"set sysroot\"? [Thread debugging using libthread_db enabled] fatal: The CUDA driver initialization failed. (error code = 1) If I run cuda-gdb as root, it behaves normally: # cuda-gdb ./driver NVIDIA (R) CUDA Debugger 4.2 release Portions Copyright (C) 2007-2012 NVIDIA Corporation GNU gdb (GDB) 7.2 Copyright (C) 2010 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-unknown-linux-gnu\". For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;... Reading symbols from /home/nwh/Dropbox/work/2012-09-06-cuda_gdb/driver...done. (cuda-gdb) run Starting program: /home/nwh/Dropbox/work/2012-09-06-cuda_gdb/driver warning: Could not load shared library symbols for linux-vdso.so.1. Do you need \"set solib-search-path\" or \"set sysroot\"? [Thread debugging using libthread_db enabled] [New Thread 0x7ffff5ba8700 (LWP 11386)] [Context Create of context 0x6e8a30 on Device 0] [Launch of CUDA Kernel 0 (thrust::detail::backend::cuda::detail::launch_closure_by_value&lt;thrust::detail::backend::cuda::for_each_n_closure&lt;thrust::device_ptr&lt;unsigned long long&gt;, unsigned int, thrust::detail::device_generate_functor&lt;thrust::detail::fill_functor&lt;unsigned long long&gt; &gt; &gt; &gt;&lt;&lt;&lt;(1,1,1),(704,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 1 (set_vector&lt;&lt;&lt;(1,1,1),(10,1,1)&gt;&gt;&gt;) on Device 0] vd[0] = 0 vd[1] = 1 vd[2] = 2 vd[3] = 3 vd[4] = 4 vd[5] = 5 vd[6] = 6 vd[7] = 7 vd[8] = 8 vd[9] = 9 [Thread 0x7ffff5ba8700 (LWP 11386) exited] Program exited normally. [Termination of CUDA Kernel 1 (set_vector&lt;&lt;&lt;(1,1,1),(10,1,1)&gt;&gt;&gt;) on Device 0] [Termination of CUDA Kernel 0 (thrust::detail::backend::cuda::detail::launch_closure_by_value&lt;thrust::detail::backend::cuda::for_each_n_closure&lt;thrust::device_ptr&lt;unsigned long long&gt;, unsigned int, thrust::detail::device_generate_functor&lt;thrust::detail::fill_functor&lt;unsigned long long&gt; &gt; &gt; &gt;&lt;&lt;&lt;(1,1,1),(704,1,1)&gt;&gt;&gt;) on Device 0] The test program driver.cu is: // needed for nvcc with gcc 4.7 and iostream #undef _GLIBCXX_ATOMIC_BUILTINS #undef _GLIBCXX_USE_INT128 #include &lt;iostream&gt; #include &lt;thrust/device_vector.h&gt; #include &lt;thrust/host_vector.h&gt; __global__ void set_vector(int *a) { // get thread id int id = threadIdx.x + blockIdx.x * blockDim.x; a[id] = id; __syncthreads(); } int main(void) { // settings int len = 10; int trd = 10; // allocate vectors thrust::device_vector&lt;int&gt; vd(len); // get the raw pointer int *a = thrust::raw_pointer_cast(vd.data()); // call the kernel set_vector&lt;&lt;&lt;1,trd&gt;&gt;&gt;(a); // print vector for (int i=0; i&lt;len; i++) std::cout &lt;&lt; \"vd[\" &lt;&lt; i &lt;&lt; \"] = \" &lt;&lt; vd[i] &lt;&lt; std::endl; return 0; } driver.c is compiled with the command: $ nvcc -g -G -gencode arch=compute_20,code=sm_20 driver.cu -o driver How can I get cuda-gdb to run with out root permissions? Some more information: the output from nvidia-smi is: $ nvidia-smi Mon Sep 10 07:16:32 2012 +------------------------------------------------------+ | NVIDIA-SMI 4.304.43 Driver Version: 304.43 | |-------------------------------+----------------------+----------------------+ | GPU Name | Bus-Id Disp. | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 Quadro FX 1700 | 0000:01:00.0 N/A | N/A | | 60% 52C N/A N/A / N/A | 4% 20MB / 511MB | N/A Default | +-------------------------------+----------------------+----------------------+ | 1 Tesla C2070 | 0000:02:00.0 Off | 0 | | 30% 82C P8 N/A / N/A | 0% 11MB / 5375MB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Compute processes: GPU Memory | | GPU PID Process name Usage | |=============================================================================| | 0 Not Supported | +-----------------------------------------------------------------------------+ The display is connected to the Quadro and I run CUDA applications on the Tesla.",
        "answers": [
            [
                "Thank you. From the sounds of it, your problem is that the device nodes required are not getting initialized. Usually, running X will create the device nodes that are required for the CUDA software stack to communicate with the hardware. When X is not running, as the case is here, running as root creates the nodes. A normal user cannot create the nodes due to a lack of permissions. The recommended approach when running a Linux system without X is to run the following script as root (from the getting started guide at http://developer.download.nvidia.com/compute/DevZone/docs/html/C/doc/CUDA_Getting_Started_Linux.pdf) #!/bin/bash /sbin/modprobe nvidia if [ \"$?\" -eq 0 ]; then # Count the number of NVIDIA controllers found. NVDEVS=`lspci | grep -i NVIDIA` N3D=`echo \"$NVDEVS\" | grep \"3D controller\" | wc -l` NVGA=`echo \"$NVDEVS\" | grep \"VGA compatible controller\" | wc -l` N=`expr $N3D + $NVGA - 1` for i in `seq 0 $N`; do mknod -m 666 /dev/nvidia$i c 195 $i done mknod -m 666 /dev/nvidiactl c 195 255 else exit 1 fi Note, you will need to recreate the device nodes on each boot, so it would be best to add this script (or a similar one) to your startup sequence. @Till : Apologies about the questions as an answer :). I am new to SO and do not have enough reputation to create comments."
            ],
            [
                "This problem has been fixed with the latest Nvidia driver (304.60) and latest version of cuda (5.0.35). cuda-gdb does not require root permissions to run."
            ]
        ],
        "votes": [
            3.0000001,
            1.0000001
        ]
    },
    {
        "question": "My original problem, is that I have functions with a long list of arguments, that exceeded the memory that is allowed to be passed as an argument to a cuda kernel (I don't remember how many bytes, because it's been a while since I dealt with that). So, the way I bypassed this problem, was to define a new structure that its members are pointers pointing to other structures that I can dereference from within the kernel later. ... this is where the current problem begins: at the point where I'm trying to dereference the pointers (members of the structure I created earlier) from within the kernel, I get CUDA_EXCEPTION_5, Warp Out-of-range Address ...from the cuda-gdb. And of top of that, the kernel name and arguments (which are reported 'not live at this point' which cuda-gdb gives as the one with the error, is not one that I created in my code. Now, for the more specifics : here are the structures involved: typedef struct { int strx; int stry; int strz; float* el; } manmat; typedef struct { manmat *x; manmat *y; manmat *z; } manmatvec; here's how i'm trying to group the kernel's arguments inside the main: int main () { ... ... manmat resu0; resu0.strx = n+2; resu0.stry = m+2; resu0.strz = l+2; if (cudaMalloc((void**)&amp;resu0.el,sizeof(float) * (n+2)*(m+2)*(l+2)) != cudaSuccess) cout &lt;&lt; endl &lt;&lt; \" ERROR allocating memory for manmat resu0\" &lt;&lt; endl ; manmat resv0; resv0.strx = n+2; resv0.stry = m+2; resv0.strz = l+2; if (cudaMalloc((void**)&amp;resv0.el,sizeof(float) * (n+2)*(m+2)*(l+2)) != cudaSuccess) cout &lt;&lt; endl &lt;&lt; \" ERROR allocating memory for manmat resv0\" &lt;&lt; endl ; manmat resw0; resw0.strx = n+2; resw0.stry = m+2; resw0.strz = l+2; if (cudaMalloc((void**)&amp;resw0.el,sizeof(float) * (n+2)*(m+2)*(l+2)) != cudaSuccess) cout &lt;&lt; endl &lt;&lt; \" ERROR allocating memory for manmat resw0\" &lt;&lt; endl ; manmatvec residues0 ; residues0.x = &amp;resu0; residues0.y = &amp;resv0; residues0.z = &amp;resw0; exec_res_std_2d &lt;&lt;&lt;numBlocks2D, threadsPerBlock2D&gt;&gt;&gt; (residues0, ......) ; ..... } ... and this is what happens in the kernel : __global__ void exec_res_std_2d (manmatvec residues, ......) { int i = blockIdx.x * blockDim.x + threadIdx.x; int k = blockIdx.y * blockDim.y + threadIdx.y; manmat *resup; manmat *resvp; manmat *reswp; resup = residues.x; resvp = residues.y; reswp = residues.z; manmat resu, resv, resw ; resu.strx = (*resup).strx; //LINE 1626 resu.stry = (*resup).stry; resu.strz = (*resup).strz; resu.el = (*resup).el; resv = *resvp; resw = *reswp; ..... } and finally, this is what cuda-gdb gives as output : .................. [Launch of CUDA Kernel 1065 (exec_res_std_2d&lt;&lt;&lt;(1,2,1),(32,16,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 1066 (exec_res_bot_2d&lt;&lt;&lt;(1,2,1),(32,16,1)&gt;&gt;&gt;) on Device 0] Program received signal CUDA_EXCEPTION_5, Warp Out-of-range Address. [Switching focus to CUDA kernel 1065, grid 1066, block (0,0,0), thread (0,2,0), device 0, sm 0, warp 2, lane 0] 0x0000000003179020 in fdivide&lt;&lt;&lt;(1,2,1),(32,16,1)&gt;&gt;&gt; (a=warning: Variable is not live at this point. Value is undetermined. ..., pt=warning: Variable is not live at this point. Value is undetermined. ..., cells=warning: Variable is not live at this point. Value is undetermined. ...) at ola.cu:1626 1626 ola.cu: No such file or directory. in ola.cu I have to note that I haven't defined ANY function , __device__ or __global__ in my code called fdivide..... Also, it might be important to say that, in the beginning of the run of the program inside the debugger, despite the fact that I compile my cuda c files with -arch=sm_20 -g -G -gencode arch=compute_20,code=sm_20, I get, [New Thread 0x7ffff3b69700 (LWP 12465)] [Context Create of context 0x1292340 on Device 0] warning: no loadable sections found in added symbol-file /tmp/cuda-dbg/12456/session1/elf.1292340.1619c10.o.LkkWns warning: no loadable sections found in added symbol-file /tmp/cuda-dbg/12456/session1/elf.1292340.1940ad0.o.aHtC7W warning: no loadable sections found in added symbol-file /tmp/cuda-dbg/12456/session1/elf.1292340.2745680.o.bVXEWl warning: no loadable sections found in added symbol-file /tmp/cuda-dbg/12456/session1/elf.1292340.2c438b0.o.cgUqiP warning: no loadable sections found in added symbol-file /tmp/cuda-dbg/12456/session1/elf.1292340.2c43980.o.4diaQ4 warning: no loadable sections found in added symbol-file /tmp/cuda-dbg/12456/session1/elf.1292340.2dc9380.o.YYJAr5 Any answers or hints, or suggestions that could help me with this issue are very welcome! please note that i've only recently started programming with cuda-c, and I'm not very experienced with cuda-gdb. Most of the debugging I did in C code I did it 'manually' by checking the output at various points of the code.... Also, this code is running on tesla M2090, and is also compiled to run on 2.0 architecture.",
        "answers": [
            [
                "This will be a problem: manmatvec residues0 ; residues0.x = &amp;resu0; residues0.y = &amp;resv0; residues0.z = &amp;resw0; The resu0, resv0, and resw0 variables are allocated in host memory - on the host stack. You're putting host addresses into the manmatvec structure, then passing the manmatvec into the kernel. On the receiving end, the CUDA code cannot access the host memory addresses provided in the structure. If you're going to pass the addresses of the resu0, resv0, resw0 variables, you need to allocate them from device memory. I don't know if this is the entire problem, but I'm pretty sure it's a top contributor."
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I'm using RHEL 6.2 and nsight eclipse edition on it to debug my cuda programs. There exists a problem with the debug mode, i.e. cuda-gdb on a customized Eclipse. When the PC enters the first Cuda API call, debugging terminates with these warnings: warning: Can not parse XML OS data; XML support was disabled at compile time warning: Error removing breakpoint 0 I've also found a relevant bug report in eclipse bugs, but it seems that it had been forwarded to gdb: https://bugs.eclipse.org/bugs/show_bug.cgi?id=350426 After some observation it seemed as if libexpat.so should have been linked to cuda-gdb in compile time. Have you been able to work around this problem? cuda-gdb on my system has such an output: [cbekar@ergo Research]$ ldd /usr/local/cuda/bin/cuda-gdb linux-vdso.so.1 =&gt; (0x00007fff8e1ff000) libncurses.so.5 =&gt; /lib64/libncurses.so.5 (0x0000003498600000) libz.so.1 =&gt; /lib64/libz.so.1 (0x000000348e600000) libm.so.6 =&gt; /lib64/libm.so.6 (0x000000348da00000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x000000348e200000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x000000348de00000) libutil.so.1 =&gt; /lib64/libutil.so.1 (0x000000349da00000) libpython2.6.so.1.0 =&gt; /usr/lib64/libpython2.6.so.1.0 (0x0000003499200000) libc.so.6 =&gt; /lib64/libc.so.6 (0x000000348d600000) libtinfo.so.5 =&gt; /lib64/libtinfo.so.5 (0x000000349e600000) /lib64/ld-linux-x86-64.so.2 (0x000000348d200000) But, here is a hint of how ldd should have been like: https://bugs.archlinux.org/task/27841 ps. I'm also aware of incompatibility of Cuda SDK 5.0 RC with my RHEL 6.2; Nsight is documented as only compatible for RHEL 6.0 and 6.1 whereas the download link says RHEL 6.x.",
        "answers": [
            [
                "(Reposting my comment as an answer in case someone else stumbles upon this thread). Unfortunately, due to some technical constraints CUDA debuggers require a dedicated GPU on Linux and Mac platforms. The underlying issue is that suspending the GPU on a breakpoint may hang a desktop environment when it tries to do rendering on the suspended GPU. \"warning: Can not parse ...\" is not a bug, it is simply a message about GDB flavour used as a basis for cuda-gdb. In no way it limits features available in cuda-gdb and Nsight Visual Debugger."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "With a fresh CUDA 5.0 Linux install on CentOS 5.5, I am not able to gdb. So I am wondering if you still need a dedicated GPU for the Linux cuda-gdb? I tried it with the Vesa device driver for X11, but get the same result. Profiling works, running the app works, but trying to run cuda-gdb gives : warning: no loadable sections found in added symbol-file system-supplied DSO at 0x2aaaaaaab000 Any suggestions?",
        "answers": [
            [
                "cuda-gdb still needs a GPU that is not used by graphical environment (e.g. if you are running Gnome/KDE/etc. you need to have system with several GPUs - not necessary all of them must be NVIDIA GPUs) This particular message is not about this problem - you can ignore it. cuda-gdb will tell if it fails because no GPU can be used for debugging."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have a problem with passing a pointer to the struct to the device function. I want to create a struct in local memory (i know it's slow, it's just an example) and pass it to the other function by pointer. The problem is that when i debug it with memcheck on, i get error: Program received signal CUDA_EXCEPTION_1, Lane Illegal Address. Switching focus to CUDA kernel 0, grid 1, block (0,0,0), thread (0,0,0), device 0, sm 7, warp 0, lane 0 0x0000000000977608 in foo (st=0x3fffc38) at test.cu:15 15 st-&gt;m_tx = 99; If I debug it without memcheck on, it works fine and gives expected results. My OS is RedHat 6.3 64-bits with Kernel 2.6.32-220. I use GTX680, CUDA 5.0 and compile the program with sm=30. Code I used for testing this is below: typedef struct __align__(8) { int m_x0; int m_tx; } myStruct; __device__ void foo(myStruct *st) { st-&gt;m_tx = 99; st-&gt;m_x0 = 123; } __global__ void myKernel(){ myStruct m_struct ; m_struct.m_tx = 45; m_struct.m_x0 = 90; foo(&amp;m_struct); } int main(void) { myKernel &lt;&lt;&lt;1,1 &gt;&gt;&gt;(); cudaThreadSynchronize(); return 0; } Any suggestions? Thanks for any help.",
        "answers": [
            [
                "Your example code is completely optimised away by the compiler because none of the code contributes to a global memory write. This is easily proved by compiling the kernel to a cubin file and disassembling the result with cuobjdump: $ nvcc -arch=sm_20 -Xptxas=\"-v\" -cubin struct.cu ptxas info : Compiling entry function '_Z8myKernelv' for 'sm_20' ptxas info : Function properties for _Z8myKernelv 0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads ptxas info : Used 2 registers, 32 bytes cmem[0] $ cuobjdump -sass struct_dumb.cubin code for sm_20 Function : _Z8myKernelv /*0000*/ /*0x00005de428004404*/ MOV R1, c [0x1] [0x100]; /*0008*/ /*0x00001de780000000*/ EXIT; ............................. ie. the kernel is completely empty. The debugger can't debug the code you want to investigate because it does not exist in what the compiler/assembler emitted. If we take a few liberties with your code: typedef struct __align__(8) { int m_x0; int m_tx; } myStruct; __device__ __noinline__ void foo(myStruct *st) { st-&gt;m_tx = 99; st-&gt;m_x0 = 123; } __global__ void myKernel(int dowrite, int *output){ myStruct m_struct ; m_struct.m_tx = 45; m_struct.m_x0 = 90; if (dowrite) { foo(&amp;m_struct); output[threadIdx.x] = m_struct.m_tx + m_struct.m_x0; } } int main(void) { int * output; cudaMalloc((void **)(&amp;output), sizeof(int)); myKernel &lt;&lt;&lt;1,1 &gt;&gt;&gt;(1, output); cudaThreadSynchronize(); return 0; } and repeat the same compilation and disassembly steps, things look somewhat different: $ nvcc -arch=sm_20 -Xptxas=\"-v\" -cubin struct_dumb.cu ptxas info : Compiling entry function '_Z8myKerneliPi' for 'sm_20' ptxas info : Function properties for _Z8myKerneliPi 8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads ptxas info : Function properties for _Z3fooP8myStruct 0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads ptxas info : Used 5 registers, 40 bytes cmem[0] $ /usr/local/cuda/bin/cuobjdump -sass struct_dumb.cubin code for sm_20 Function : _Z8myKerneliPi /*0000*/ /*0x00005de428004404*/ MOV R1, c [0x1] [0x100]; /*0008*/ /*0x20105d034800c000*/ IADD R1, R1, -0x8; /*0010*/ /*0x68009de218000001*/ MOV32I R2, 0x5a; /*0018*/ /*0xb400dde218000000*/ MOV32I R3, 0x2d; /*0020*/ /*0x83f1dc23190e4000*/ ISETP.EQ.AND P0, pt, RZ, c [0x0] [0x20], pt; /*0028*/ /*0x00101c034800c000*/ IADD R0, R1, 0x0; /*0030*/ /*0x00109ca5c8000000*/ STL.64 [R1], R2; /*0038*/ /*0x000001e780000000*/ @P0 EXIT; /*0040*/ /*0x10011c0348004000*/ IADD R4, R0, c [0x0] [0x4]; /*0048*/ /*0xc001000750000000*/ CAL 0x80; /*0050*/ /*0x00009ca5c0000000*/ LDL.64 R2, [R0]; /*0058*/ /*0x84011c042c000000*/ S2R R4, SR_Tid_X; /*0060*/ /*0x90411c4340004000*/ ISCADD R4, R4, c [0x0] [0x24], 0x2; /*0068*/ /*0x0c201c0348000000*/ IADD R0, R2, R3; /*0070*/ /*0x00401c8590000000*/ ST [R4], R0; /*0078*/ /*0x00001de780000000*/ EXIT; /*0080*/ /*0x8c00dde218000001*/ MOV32I R3, 0x63; /*0088*/ /*0xec009de218000001*/ MOV32I R2, 0x7b; /*0090*/ /*0x1040dc8590000000*/ ST [R4+0x4], R3; /*0098*/ /*0x00409c8590000000*/ ST [R4], R2; /*00a0*/ /*0x00001de790000000*/ RET; ............................... we get actual code in the assembler output. You might have more luck in the debugger with that."
            ],
            [
                "I am from the CUDA developer tools team. When compiled for device side debug (i.e. -G), the original code will not be optimized out. The issue looks like a memcheck bug. Thank you for finding this. We will look into it."
            ]
        ],
        "votes": [
            4.0000001,
            2.0000001
        ]
    },
    {
        "question": "I have already checked earlier questions on SO about this issue but not able to see how it relates here. I am solving 2d diffusion equation with CUDA and it turns out that my GPU code is slower than its CPU counterpart. Here is my code: //kernel definition __global__ void diffusionSolver(double* A, int n_x,int n_y) { int i = blockIdx.x * blockDim.x + threadIdx.x; int j = blockIdx.y * blockDim.y + threadIdx.y; if(i&lt;n_x &amp;&amp; j &lt;n_y &amp;&amp; i*(n_x-i-1)*j*(n_y-j-1)!=0) A[i+n_y*j] = A[i+n_y*j] + (A[i-1+n_y*j]+A[i+1+n_y*j]+A[i+(j-1)*n_y]+A[i+(j+1)*n_y] -4.0*A[i+n_y*j])/40.0; } int main function int main() { int n_x = 200 ; int n_y = 200 ; double *phi; double *dummy; double *phi_old; int i,j ; phi = (double *) malloc( n_x*n_y* sizeof(double)); phi_old = (double *) malloc( n_x*n_y* sizeof(double)); dummy = (double *) malloc( n_x*n_y* sizeof(double)); int iterationMax =200; for(j=0;j&lt;n_y ;j++) { for(i=0;i&lt;n_x;i++) { if((.4*n_x-i)*(.6*n_x-i)&lt;0) phi[i+n_y*j] = -1; else phi[i+n_y*j] = 1; } } double *dev_phi; cudaMalloc((void **) &amp;dev_phi, n_x*n_y*sizeof(double)); cudaMemcpy(dev_phi, phi, n_x*n_y*sizeof(double), cudaMemcpyHostToDevice); dim3 threadsPerBlock(10,100); dim3 numBlocks(n_x*n_y / threadsPerBlock.x, n_x*n_y / threadsPerBlock.y); for(int z=0; z&lt;iterationMax; z++) { if(z%100==0) cout &lt;&lt;z/100 &lt;&lt;\"\\n\";; diffusionSolver&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(dev_phi, n_x,n_y); } cudaMemcpy(phi, dev_phi,n_x*n_y*sizeof(double), cudaMemcpyDeviceToHost); cudaFree(dev_phi); return 0; } The problem with this code is that it runs slower than a simple CPU-only iterative method. I don't know much about profiler and until now I tried with cuda-memcheck which gives 0 errors. How can I know which portion of the code is performing slowly and speed that up? I am working on a Linux environment. Thanks in advance for any help.",
        "answers": [
            [
                "The worst problem I see is that you are launching far too many blocks for the size of the input array. At the moment you are computing the grid size as: dim3 numBlocks(n_x*n_y / threadsPerBlock.x, n_x*n_y / threadsPerBlock.y); which should yield a grid size of (400,4000) blocks for an input array of only 200x200. That is clearly incorrect. The calculation should be something like: int nbx = (n_x / threadsPerBlock.x) + (((n_x % threadsPerBlock.x) == 0) ? 0 : 1); int nby = (n_y / threadsPerBlock.y) + (((n_y % threadsPerBlock.y) == 0) ? 0 : 1); dim3 numBlocks(nbx,nby); which would yield a grid size of (2,20) blocks, or 40000 times fewer than you are currently launching. There are other optimisations which you could consider making to the kernel, but those pale into insignificance compared with mistakes of this magnitude."
            ],
            [
                "You are doing a lot of integer multiplication and have a lot of global memory reads, both of which are slow in CUDA. I also imagine that there are not a lot of coalesced global memory reads. The only way to speed up your kernel is to stage coalesced memory reads through shared memory and/or re-arrange your data so that you can index it without using lots of integer multiplication. I don't have a great grasp of diffusion equations, but I don't think there is a lot of naive parallelism to be exploited. Take a look at the CUDA Programming Guide and the Best Practices Guide and maybe you'll get some ideas about how to improve your algorithm."
            ],
            [
                "In case anybody is interested, I'm posting below a fully worked code concerning the optimization of the solution approach for the 2D heat equation. Five approaches are considered, using: Global memory, essentially the OP's approach; Shared memory of size BLOCK_SIZE_X x BLOCK_SIZE_Y not loading the halo regions; Shared memory of size BLOCK_SIZE_X x BLOCK_SIZE_Y loading the halo regions; Shared memory of size (BLOCK_SIZE_X + 2) x (BLOCK_SIZE_Y + 2) loading the halo regions; Texture memory. Everybody can run the code and check out which approach is faster for his own GPU architecture. #include &lt;iostream&gt; #include \"cuda_runtime.h\" #include \"device_launch_parameters.h\" #include \"Utilities.cuh\" #include \"InputOutput.cuh\" #include \"TimingGPU.cuh\" #define BLOCK_SIZE_X 16 #define BLOCK_SIZE_Y 16 #define DEBUG texture&lt;float, 2, cudaReadModeElementType&gt; tex_T; texture&lt;float, 2, cudaReadModeElementType&gt; tex_T_old; /***********************************/ /* JACOBI ITERATION FUNCTION - GPU */ /***********************************/ __global__ void Jacobi_Iterator_GPU(const float * __restrict__ T_old, float * __restrict__ T_new, const int NX, const int NY) { const int i = blockIdx.x * blockDim.x + threadIdx.x ; const int j = blockIdx.y * blockDim.y + threadIdx.y ; // N int P = i + j*NX; // node (i,j) | int N = i + (j+1)*NX; // node (i,j+1) | int S = i + (j-1)*NX; // node (i,j-1) W ---- P ---- E int E = (i+1) + j*NX; // node (i+1,j) | int W = (i-1) + j*NX; // node (i-1,j) | // S // --- Only update \"interior\" (not boundary) node points if (i&gt;0 &amp;&amp; i&lt;NX-1 &amp;&amp; j&gt;0 &amp;&amp; j&lt;NY-1) T_new[P] = 0.25 * (T_old[E] + T_old[W] + T_old[N] + T_old[S]); } /******************************************************/ /* JACOBI ITERATION FUNCTION - GPU - SHARED MEMORY V1 */ /******************************************************/ __global__ void Jacobi_Iterator_GPU_shared_v1(const float * __restrict__ T_old, float * __restrict__ T_new, const int NX, const int NY) { const int i = blockIdx.x * blockDim.x + threadIdx.x ; const int j = blockIdx.y * blockDim.y + threadIdx.y ; // N int P = i + j*NX; // node (i,j) | int N = i + (j+1)*NX; // node (i,j+1) | int S = i + (j-1)*NX; // node (i,j-1) W ---- P ---- E int E = (i+1) + j*NX; // node (i+1,j) | int W = (i-1) + j*NX; // node (i-1,j) | // S __shared__ float T_sh[BLOCK_SIZE_X][BLOCK_SIZE_Y]; // --- Load data to shared memory. Halo regions are NOT loaded. T_sh[threadIdx.x][threadIdx.y] = T_old[P]; __syncthreads(); if ((threadIdx.x &gt; 0) &amp;&amp; (threadIdx.x &lt; (BLOCK_SIZE_X - 1)) &amp;&amp; (threadIdx.y &gt; 0) &amp;&amp; (threadIdx.y &lt; (BLOCK_SIZE_Y \u2010 1))) // --- If we do not need halo region elements, then use shared memory. T_new[P] = 0.25 * (T_sh[threadIdx.x][threadIdx.y - 1] + T_sh[threadIdx.x][threadIdx.y + 1] + T_sh[threadIdx.x - 1][threadIdx.y] + T_sh[threadIdx.x + 1][threadIdx.y]); else if (i&gt;0 &amp;&amp; i&lt;NX-1 &amp;&amp; j&gt;0 &amp;&amp; j&lt;NY-1) // --- Only update \"interior\" (not boundary) node points // --- If we need halo region elements, then use global memory. T_new[P] = 0.25 * (T_old[E] + T_old[W] + T_old[N] + T_old[S]); } /******************************************************/ /* JACOBI ITERATION FUNCTION - GPU - SHARED MEMORY V2 */ /******************************************************/ __global__ void Jacobi_Iterator_GPU_shared_v2(const float * __restrict__ T_old, float * __restrict__ T_new, const int NX, const int NY) { const int i = blockIdx.x * (BLOCK_SIZE_X - 2) + threadIdx.x ; const int j = blockIdx.y * (BLOCK_SIZE_Y - 2) + threadIdx.y ; int P = i + j*NX; if ((i &gt;= NX) || (j &gt;= NY)) return; __shared__ float T_sh[BLOCK_SIZE_X][BLOCK_SIZE_Y]; // --- Load data to shared memory. Halo regions ARE loaded. T_sh[threadIdx.x][threadIdx.y] = T_old[P]; __syncthreads(); if (((threadIdx.x &gt; 0) &amp;&amp; (threadIdx.x &lt; (BLOCK_SIZE_X - 1)) &amp;&amp; (threadIdx.y &gt; 0) &amp;&amp; (threadIdx.y &lt; (BLOCK_SIZE_Y \u2010 1))) &amp;&amp; (i&gt;0 &amp;&amp; i&lt;NX-1 &amp;&amp; j&gt;0 &amp;&amp; j&lt;NY-1)) T_new[P] = 0.25 * (T_sh[threadIdx.x][threadIdx.y - 1] + T_sh[threadIdx.x][threadIdx.y + 1] + T_sh[threadIdx.x - 1][threadIdx.y] + T_sh[threadIdx.x + 1][threadIdx.y]); } /******************************************************/ /* JACOBI ITERATION FUNCTION - GPU - SHARED MEMORY V2 */ /******************************************************/ __global__ void Jacobi_Iterator_GPU_shared_v3(const float * __restrict__ T_old, float * __restrict__ T_new, const int NX, const int NY) { const int i = blockIdx.x * blockDim.x + threadIdx.x ; const int j = blockIdx.y * blockDim.y + threadIdx.y ; const int tid_block = threadIdx.y * BLOCK_SIZE_X + threadIdx.x; // --- Flattened thread index within a block const int i1 = tid_block % (BLOCK_SIZE_X + 2); const int j1 = tid_block / (BLOCK_SIZE_Y + 2); const int i2 = (BLOCK_SIZE_X * BLOCK_SIZE_Y + tid_block) % (BLOCK_SIZE_X + 2); const int j2 = (BLOCK_SIZE_X * BLOCK_SIZE_Y + tid_block) / (BLOCK_SIZE_Y + 2); int P = i + j * NX; if ((i &gt;= NX) || (j &gt;= NY)) return; __shared__ float T_sh[BLOCK_SIZE_X + 2][BLOCK_SIZE_Y + 2]; if (((blockIdx.x * BLOCK_SIZE_X - 1 + i1) &lt; NX) &amp;&amp; ((blockIdx.y * BLOCK_SIZE_Y - 1 + j1) &lt; NY)) T_sh[i1][j1] = T_old[(blockIdx.x * BLOCK_SIZE_X - 1 + i1) + (blockIdx.y * BLOCK_SIZE_Y - 1 + j1) * NX]; if (((i2 &lt; (BLOCK_SIZE_X + 2)) &amp;&amp; (j2 &lt; (BLOCK_SIZE_Y + 2))) &amp;&amp; (((blockIdx.x * BLOCK_SIZE_X - 1 + i2) &lt; NX) &amp;&amp; ((blockIdx.y * BLOCK_SIZE_Y - 1 + j2) &lt; NY))) T_sh[i2][j2] = T_old[(blockIdx.x * BLOCK_SIZE_X - 1 + i2) + (blockIdx.y * BLOCK_SIZE_Y - 1 + j2) * NX]; __syncthreads(); if ((threadIdx.x &lt;= (BLOCK_SIZE_X - 1) &amp;&amp; (threadIdx.y &lt;= (BLOCK_SIZE_Y \u2010 1))) &amp;&amp; (i&gt;0 &amp;&amp; i&lt;NX-1 &amp;&amp; j&gt;0 &amp;&amp; j&lt;NY-1)) T_new[P] = 0.25 * (T_sh[threadIdx.x + 1][threadIdx.y] + T_sh[threadIdx.x + 1][threadIdx.y + 2] + T_sh[threadIdx.x][threadIdx.y + 1] + T_sh[threadIdx.x + 2][threadIdx.y + 1]); } /*********************************************/ /* JACOBI ITERATION FUNCTION - GPU - TEXTURE */ /*********************************************/ __global__ void Jacobi_Iterator_GPU_texture(float * __restrict__ T_new, const bool flag, const int NX, const int NY) { const int i = blockIdx.x * blockDim.x + threadIdx.x ; const int j = blockIdx.y * blockDim.y + threadIdx.y ; float P, N, S, E, W; if (flag) { // N P = tex2D(tex_T_old, i, j); // node (i,j) | N = tex2D(tex_T_old, i, j + 1); // node (i,j+1) | S = tex2D(tex_T_old, i, j - 1); // node (i,j-1) W ---- P ---- E E = tex2D(tex_T_old, i + 1, j); // node (i+1,j) | W = tex2D(tex_T_old, i - 1, j); // node (i-1,j) | // S } else { // N P = tex2D(tex_T, i, j); // node (i,j) | N = tex2D(tex_T, i, j + 1); // node (i,j+1) | S = tex2D(tex_T, i, j - 1); // node (i,j-1) W ---- P ---- E E = tex2D(tex_T, i + 1, j); // node (i+1,j) | W = tex2D(tex_T, i - 1, j); // node (i-1,j) | // S } // --- Only update \"interior\" (not boundary) node points if (i&gt;0 &amp;&amp; i&lt;NX-1 &amp;&amp; j&gt;0 &amp;&amp; j&lt;NY-1) T_new[i + j*NX] = 0.25 * (E + W + N + S); } /***********************************/ /* JACOBI ITERATION FUNCTION - CPU */ /***********************************/ void Jacobi_Iterator_CPU(float * __restrict T, float * __restrict T_new, const int NX, const int NY, const int MAX_ITER) { for(int iter=0; iter&lt;MAX_ITER; iter=iter+2) { // --- Only update \"interior\" (not boundary) node points for(int j=1; j&lt;NY-1; j++) for(int i=1; i&lt;NX-1; i++) { float T_E = T[(i+1) + NX*j]; float T_W = T[(i-1) + NX*j]; float T_N = T[i + NX*(j+1)]; float T_S = T[i + NX*(j-1)]; T_new[i+NX*j] = 0.25*(T_E + T_W + T_N + T_S); } for(int j=1; j&lt;NY-1; j++) for(int i=1; i&lt;NX-1; i++) { float T_E = T_new[(i+1) + NX*j]; float T_W = T_new[(i-1) + NX*j]; float T_N = T_new[i + NX*(j+1)]; float T_S = T_new[i + NX*(j-1)]; T[i+NX*j] = 0.25*(T_E + T_W + T_N + T_S); } } } /******************************/ /* TEMPERATURE INITIALIZATION */ /******************************/ void Initialize(float * __restrict h_T, const int NX, const int NY) { // --- Set left wall to 1 for(int j=0; j&lt;NY; j++) h_T[j * NX] = 1.0; } /********/ /* MAIN */ /********/ int main() { const int NX = 256; // --- Number of discretization points along the x axis const int NY = 256; // --- Number of discretization points along the y axis const int MAX_ITER = 100; // --- Number of Jacobi iterations // --- CPU temperature distributions float *h_T = (float *)calloc(NX * NY, sizeof(float)); float *h_T_old = (float *)calloc(NX * NY, sizeof(float)); Initialize(h_T, NX, NY); Initialize(h_T_old, NX, NY); float *h_T_GPU_result = (float *)malloc(NX * NY * sizeof(float)); float *h_T_GPU_tex_result = (float *)malloc(NX * NY * sizeof(float)); float *h_T_GPU_sh1_result = (float *)malloc(NX * NY * sizeof(float)); float *h_T_GPU_sh2_result = (float *)malloc(NX * NY * sizeof(float)); float *h_T_GPU_sh3_result = (float *)malloc(NX * NY * sizeof(float)); // --- GPU temperature distribution float *d_T; gpuErrchk(cudaMalloc((void**)&amp;d_T, NX * NY * sizeof(float))); float *d_T_old; gpuErrchk(cudaMalloc((void**)&amp;d_T_old, NX * NY * sizeof(float))); float *d_T_tex; gpuErrchk(cudaMalloc((void**)&amp;d_T_tex, NX * NY * sizeof(float))); float *d_T_old_tex; gpuErrchk(cudaMalloc((void**)&amp;d_T_old_tex, NX * NY * sizeof(float))); float *d_T_sh1; gpuErrchk(cudaMalloc((void**)&amp;d_T_sh1, NX * NY * sizeof(float))); float *d_T_old_sh1; gpuErrchk(cudaMalloc((void**)&amp;d_T_old_sh1, NX * NY * sizeof(float))); float *d_T_sh2; gpuErrchk(cudaMalloc((void**)&amp;d_T_sh2, NX * NY * sizeof(float))); float *d_T_old_sh2; gpuErrchk(cudaMalloc((void**)&amp;d_T_old_sh2, NX * NY * sizeof(float))); float *d_T_sh3; gpuErrchk(cudaMalloc((void**)&amp;d_T_sh3, NX * NY * sizeof(float))); float *d_T_old_sh3; gpuErrchk(cudaMalloc((void**)&amp;d_T_old_sh3, NX * NY * sizeof(float))); gpuErrchk(cudaMemcpy(d_T, h_T, NX * NY * sizeof(float), cudaMemcpyHostToDevice)); gpuErrchk(cudaMemcpy(d_T_tex, h_T, NX * NY * sizeof(float), cudaMemcpyHostToDevice)); gpuErrchk(cudaMemcpy(d_T_sh1, h_T, NX * NY * sizeof(float), cudaMemcpyHostToDevice)); gpuErrchk(cudaMemcpy(d_T_sh2, h_T, NX * NY * sizeof(float), cudaMemcpyHostToDevice)); gpuErrchk(cudaMemcpy(d_T_sh3, h_T, NX * NY * sizeof(float), cudaMemcpyHostToDevice)); gpuErrchk(cudaMemcpy(d_T_old, d_T, NX * NY * sizeof(float), cudaMemcpyDeviceToDevice)); gpuErrchk(cudaMemcpy(d_T_old_tex, d_T_tex, NX * NY * sizeof(float), cudaMemcpyDeviceToDevice)); gpuErrchk(cudaMemcpy(d_T_old_sh1, d_T_sh1, NX * NY * sizeof(float), cudaMemcpyDeviceToDevice)); gpuErrchk(cudaMemcpy(d_T_old_sh2, d_T_sh2, NX * NY * sizeof(float), cudaMemcpyDeviceToDevice)); gpuErrchk(cudaMemcpy(d_T_old_sh3, d_T_sh3, NX * NY * sizeof(float), cudaMemcpyDeviceToDevice)); //cudaChannelFormatDesc desc = cudaCreateChannelDesc&lt;float&gt;(); cudaChannelFormatDesc desc = cudaCreateChannelDesc(32, 0, 0, 0, cudaChannelFormatKindFloat); gpuErrchk(cudaBindTexture2D(NULL, &amp;tex_T, d_T_tex, &amp;desc, NX, NY, sizeof(float) * NX)); gpuErrchk(cudaBindTexture2D(NULL, &amp;tex_T_old, d_T_old_tex, &amp;desc, NX, NY, sizeof(float) * NX)); tex_T.addressMode[0] = cudaAddressModeWrap; tex_T.addressMode[1] = cudaAddressModeWrap; tex_T.filterMode = cudaFilterModePoint; tex_T.normalized = false; tex_T_old.addressMode[0] = cudaAddressModeWrap; tex_T_old.addressMode[1] = cudaAddressModeWrap; tex_T_old.filterMode = cudaFilterModePoint; tex_T_old.normalized = false; // --- Grid size dim3 dimBlock(BLOCK_SIZE_X, BLOCK_SIZE_Y); dim3 dimGrid (iDivUp(NX, BLOCK_SIZE_X), iDivUp(NY, BLOCK_SIZE_Y)); // --- Jacobi iterations on the host Jacobi_Iterator_CPU(h_T, h_T_old, NX, NY, MAX_ITER); // --- Jacobi iterations on the device TimingGPU timerGPU; timerGPU.StartCounter(); for (int k=0; k&lt;MAX_ITER; k=k+2) { Jacobi_Iterator_GPU&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T, d_T_old, NX, NY); // --- Update d_T_old starting from data stored in d_T #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif Jacobi_Iterator_GPU&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T_old, d_T , NX, NY); // --- Update d_T starting from data stored in d_T_old #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif } printf(\"Timing = %f ms\\n\", timerGPU.GetCounter()); // --- Jacobi iterations on the device - shared memory v1 timerGPU.StartCounter(); for (int k=0; k&lt;MAX_ITER; k=k+2) { Jacobi_Iterator_GPU_shared_v1&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T_sh1, d_T_old_sh1, NX, NY); // --- Update d_T_old starting from data stored in d_T #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif Jacobi_Iterator_GPU_shared_v1&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T_old_sh1, d_T_sh1 , NX, NY); // --- Update d_T starting from data stored in d_T_old #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif } printf(\"Timing with shared memory v1 = %f ms\\n\", timerGPU.GetCounter()); // --- Jacobi iterations on the device - shared memory v2 dim3 dimBlock2(BLOCK_SIZE_X, BLOCK_SIZE_Y); dim3 dimGrid2 (iDivUp(NX, BLOCK_SIZE_X - 2), iDivUp(NY, BLOCK_SIZE_Y - 2)); timerGPU.StartCounter(); for (int k=0; k&lt;MAX_ITER; k=k+2) { Jacobi_Iterator_GPU_shared_v2&lt;&lt;&lt;dimGrid2, dimBlock&gt;&gt;&gt;(d_T_sh2, d_T_old_sh2, NX, NY); // --- Update d_T_old starting from data stored in d_T #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif Jacobi_Iterator_GPU_shared_v2&lt;&lt;&lt;dimGrid2, dimBlock&gt;&gt;&gt;(d_T_old_sh2, d_T_sh2 , NX, NY); // --- Update d_T starting from data stored in d_T_old #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif } printf(\"Timing with shared memory v2 = %f ms\\n\", timerGPU.GetCounter()); // --- Jacobi iterations on the device - shared memory v3 timerGPU.StartCounter(); for (int k=0; k&lt;MAX_ITER; k=k+2) { Jacobi_Iterator_GPU_shared_v3&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T_sh3, d_T_old_sh3, NX, NY); // --- Update d_T_old starting from data stored in d_T #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif Jacobi_Iterator_GPU_shared_v3&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T_old_sh3, d_T_sh3 , NX, NY); // --- Update d_T starting from data stored in d_T_old #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif } printf(\"Timing with shared memory v3 = %f ms\\n\", timerGPU.GetCounter()); // --- Jacobi iterations on the device - texture case timerGPU.StartCounter(); for (int k=0; k&lt;MAX_ITER; k=k+2) { Jacobi_Iterator_GPU_texture&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T_old_tex, 0, NX, NY); // --- Update d_T_tex starting from data stored in d_T_old_tex #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif Jacobi_Iterator_GPU_texture&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_T_tex, 1, NX, NY); // --- Update d_T_old_tex starting from data stored in d_T_tex #ifdef DEBUG gpuErrchk(cudaPeekAtLastError()); gpuErrchk(cudaDeviceSynchronize()); #endif } printf(\"Timing with texture = %f ms\\n\", timerGPU.GetCounter()); saveCPUrealtxt(h_T, \"C:\\\\Users\\\\Documents\\\\Project\\\\Differential_Equations\\\\Heat_Equation\\\\2D\\\\DiffusionEquationJacobi\\\\DiffusionEquation\\\\CPU_result.txt\", NX * NY); saveGPUrealtxt(d_T_tex, \"C:\\\\Users\\\\Documents\\\\Project\\\\Differential_Equations\\\\Heat_Equation\\\\2D\\\\DiffusionEquationJacobi\\\\DiffusionEquation\\\\GPU_result_tex.txt\", NX * NY); saveGPUrealtxt(d_T, \"C:\\\\Users\\\\Documents\\\\Project\\\\Differential_Equations\\\\Heat_Equation\\\\2D\\\\DiffusionEquationJacobi\\\\DiffusionEquation\\\\GPU_result.txt\", NX * NY); saveGPUrealtxt(d_T_sh1, \"C:\\\\Users\\\\Documents\\\\Project\\\\Differential_Equations\\\\Heat_Equation\\\\2D\\\\DiffusionEquationJacobi\\\\DiffusionEquation\\\\GPU_result_sh1.txt\", NX * NY); saveGPUrealtxt(d_T_sh2, \"C:\\\\Users\\\\Documents\\\\Project\\\\Differential_Equations\\\\Heat_Equation\\\\2D\\\\DiffusionEquationJacobi\\\\DiffusionEquation\\\\GPU_result_sh2.txt\", NX * NY); saveGPUrealtxt(d_T_sh3, \"C:\\\\Users\\\\Documents\\\\Project\\\\Differential_Equations\\\\Heat_Equation\\\\2D\\\\DiffusionEquationJacobi\\\\DiffusionEquation\\\\GPU_result_sh3.txt\", NX * NY); // --- Copy results from device to host gpuErrchk(cudaMemcpy(h_T_GPU_result, d_T, NX * NY * sizeof(float), cudaMemcpyDeviceToHost)); gpuErrchk(cudaMemcpy(h_T_GPU_tex_result, d_T_tex, NX * NY * sizeof(float), cudaMemcpyDeviceToHost)); gpuErrchk(cudaMemcpy(h_T_GPU_sh1_result, d_T_sh1, NX * NY * sizeof(float), cudaMemcpyDeviceToHost)); gpuErrchk(cudaMemcpy(h_T_GPU_sh2_result, d_T_sh2, NX * NY * sizeof(float), cudaMemcpyDeviceToHost)); gpuErrchk(cudaMemcpy(h_T_GPU_sh3_result, d_T_sh3, NX * NY * sizeof(float), cudaMemcpyDeviceToHost)); // --- Calculate percentage root mean square error between host and device results float sum = 0.f, sum_tex = 0.f, sum_ref = 0.f, sum_sh1 = 0.f, sum_sh2 = 0.f, sum_sh3 = 0.f; for (int j=0; j&lt;NY; j++) for (int i=0; i&lt;NX; i++) { sum = sum + (h_T_GPU_result [j * NX + i] - h_T[j * NX + i]) * (h_T_GPU_result [j * NX + i] - h_T[j * NX + i]); sum_tex = sum_tex + (h_T_GPU_tex_result[j * NX + i] - h_T[j * NX + i]) * (h_T_GPU_tex_result[j * NX + i] - h_T[j * NX + i]); sum_sh1 = sum_sh1 + (h_T_GPU_sh1_result[j * NX + i] - h_T[j * NX + i]) * (h_T_GPU_sh1_result[j * NX + i] - h_T[j * NX + i]); sum_sh2 = sum_sh2 + (h_T_GPU_sh2_result[j * NX + i] - h_T[j * NX + i]) * (h_T_GPU_sh2_result[j * NX + i] - h_T[j * NX + i]); sum_sh3 = sum_sh3 + (h_T_GPU_sh3_result[j * NX + i] - h_T[j * NX + i]) * (h_T_GPU_sh3_result[j * NX + i] - h_T[j * NX + i]); sum_ref = sum_ref + h_T[j * NX + i] * h_T[j * NX + i]; } printf(\"Percentage root mean square error = %f\\n\", 100.*sqrt(sum / sum_ref)); printf(\"Percentage root mean square error texture = %f\\n\", 100.*sqrt(sum_tex / sum_ref)); printf(\"Percentage root mean square error shared v1 = %f\\n\", 100.*sqrt(sum_sh1 / sum_ref)); printf(\"Percentage root mean square error shared v2 = %f\\n\", 100.*sqrt(sum_sh2 / sum_ref)); printf(\"Percentage root mean square error shared v3 = %f\\n\", 100.*sqrt(sum_sh3 / sum_ref)); return 0; }"
            ]
        ],
        "votes": [
            4.0000001,
            1.0000001,
            1.0000001
        ]
    },
    {
        "question": "I am using cuda-memcheck for checking for memory errors. A simple question. What exactly means Misaligned Shared or Local Address ?",
        "answers": [
            [
                "Additional information on CUDA-MEMCHECK errors can be found in CUDA-MEMCHECK User Manual. Misaligned address exceptions occur when the address does not meet the natural alignment of the data access size. error if (address &amp; (access_size_in_bytes - 1)) For example if you tried to perform a 32-bit shared load from address 0x1 you would receive a misaligned address exception. The address needs to be a multiple of 4."
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "I am using nsight eclipse edition for mac to debug my cuda code. I was able to run cuda-gdb all fine from a terminal but was not able to use the debug function in Nsight. Whenever I started to debug, an error window pops up saying \"Error in final launch sequence Connection is shut down\". My OS is Mac Lion (10.7.4). I understand the big thing in Cuda 5.0 is the interactive debugging with eclipse but sadly I won't be able to use it unless I switch to Windows or Linux. If anybody has seen this or knows a workaround for this, please let me know and your help will be very much appreciated. Thank you!",
        "answers": [
            [
                "I'm afraid you've hit a known issue in CUDA 5.0 Toolkit. Due to some last-minute change, cuda-gdb (which is a shell script) is not entirely valid in Mac OS X. To remedy the problem: Edit cuda-gdb shell script. Make line #!/bin/sh the first line in this script. Save the changes We apologize for inconvenience. This (and many other) issues will be fixed in the upcoming CUDA 5.0 RC release."
            ],
            [
                "I had this problem in linux recently. Error in final launch sequence Connection is shut down which means nsight can not start debugger correctly. first you have to make sure you can run cuda-gdb in terminal. just type cuda-gdb in terminal, if it says like cuda-gdb cannot find some lib in /usr/lib, just download or relink it. after you done this , rerun cuda-gdb in terminal, it should work fine. then you can use nsight debugging tool."
            ]
        ],
        "votes": [
            1e-07,
            1e-07
        ]
    },
    {
        "question": "I'm trying to debug a source code that works fine and gives no errors or warnings when compiling. The problem is that when I run it with cuda-gdb step by step, no CUDA kernels are launched at all (the output I get from the debugger is totally different from the one shown in the Nvidia cuda-gdb guide), but the program still works without any errors. At all times I get No CUDA kernels, devices or threads. Apparently Focus is not set on anything too. I'm using the 4.2 release of CUDA-GDB. This is what I get from the debugger when it should launch the kernel: Breakpoint 1, matrixMulGPU (M=0x609160, N=0x609270, P=0x609490, Width=8) at matrixMul1.cu:141 141 MatrixMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(Md, Nd, Pd, Width); (cuda-gdb) step MatrixMulKernel (__cuda_0=0x210000, __cuda_1=0x210100, __cuda_2=0x210200, __cuda_3=8) at matrixMul1.cu:103 103 __global__ void MatrixMulKernel(float *Md, float *Nd, float *Pd, int Width){ (cuda-gdb) step __device_stub__Z15MatrixMulKernelPfS_S_i (__par0=0x210000, __par1=0x210100, __par2=0x210200, __par3=8) at tmpxft_000016d4_00000000-1_matrixMul1.cudafe1.stub.c:5 5 tmpxft_000016d4_00000000-1_matrixMul1.cudafe1.stub.c: Arquivo ou diret\u00f3rio n\u00e3o encontrado. in tmpxft_000016d4_00000000-1_matrixMul1.cudafe1.stub.c (cuda-gdb) step cudaLaunch&lt;char&gt; ( entry=0x4011ea \"UH\\211\\345SH\\203\\354(H\\211}\\350H\\211u\\340H\\211U\u0609M\u050bM\\324H\\213U\\330H\\213]\\340H\\213E\\350H\\211\\336H\\211\\307\\350\\024\\377\\377\\377H\\203\\304([\\311\\303UH\\211\\345SH\\203\\354(\\277Pn@\") at cuda_runtime.h:958 958 return cudaLaunch((const char*)entry); (cuda-gdb) step 959 } (cuda-gdb) step MatrixMulKernel (__cuda_0=0x210000, __cuda_1=0x210100, __cuda_2=0x210200, __cuda_3=8) at matrixMul1.cu:121 121 } My CUDA device is a GeForce 8400M GS and I had no problems with the deviceQuery check. I've no clue about how to solve this as the Nvidia forum is offline these days! Thanks a lot in advance.",
        "answers": [
            [
                "Looking at the cuda-gdb output, you seem to be on the host component of the kernel launch (i.e. the &lt;&lt;&lt; &gt;&gt;&gt;). CUDA kernel launches are asynchronous. The host call prepares the launch and will return before it has completed (or in some cases before the launched work has even started). As a result, while you are stopped on the host, the launched work may not have yet been dispatched to the GPU. Stepping into the host side kernel launch call will not step onto the kernel launch on the device. Instead, try to set a break point inside the kernel itself, and let the app run freely. A breakpoint can be set by file:linenumber (e.g. break matrixMul1.cu:&lt;line&gt; or by name (e.g. break MatrixMulKernel). When the device side breakpoint is hit, cuda-gdb will return to the prompt and set focus on the device as appropriate."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I have a rather large and complex CUDA code that hangs quite reliably for large numbers of blocks/threads. I am trying to figure out exactly where the code hangs. When I run the code in cuda-gdb, I can see which threads/blocks are hanging, but I can't see where, beyond the \"virtual PC\". If I compile the code with \"-G\" to get the debug information, it runs a lot slower and refuses to hang, no matter how long I run it for. Is there any way to map a \"virtual PC\" to a line of code in the source code, even approximately? Or is there a way to get the debugging information in without turning off all optimization? I've tried using \"-G3\", yet to no avail. This just gives me warnings of the type \"nvcc warning : Setting optimization level to 0 as optimized debugging is not supported\". I am using CUDA compilation tools release 4.1.",
        "answers": [
            [
                "Ok, I think I've figured it out on my own. If cuobjdump is in the path, then in cuda-gdb, the command x $pc will give you the assembler at which the current thread is stopped. The problem is that if the source was not compiled with -G, you won't be able to relate the assembler statement to a line in your code. To match the assembler to the kernel code, first make sure that you compiled your kernel with nvcc -keep [..] mykernel.cu. This should generate the files mykernel.sm_20.cubin (or whatever arch you chose) and mykernel.ptx. To get the assembler of your entire kernel, run cuobjdump -sass mykernel.cubin &gt; output.ptx. In cuda-gdb, do x/20i $pc-80 to get a bit of context, and look for those lines in the file output.ptx. You can then try to match those lines to the PTX code in mykernel.ptx which contains .loc statements which refer to the line in source. This approach requires a bit of creativity in matching the PTX from the cubin-file and the PTX from nvcc, as the instructions may be re-ordered somewhat. In my code, I had large blocks of FFMA instructions I could look for to get my bearings. You can use the \"output.ptx\" to find the exact line from the debugger and then look in \"mykernel.ptx\" at the same relative position. This all involves quite a bit of work, but it does allow you to narrow-down the location of the \"Virtual PC\" in your original source."
            ]
        ],
        "votes": [
            11.0000001
        ]
    },
    {
        "question": "I'm pretty new to CUDA and flying a bit by the seat of my pants here... I'm trying to debug my CUDA program on a remote machine I don't have admin rights on. I compile my program with nvcc -g -G and then try to debug it with cuda-gdb. However, as soon as gdb hits a call to a kernel (doesn't even have to enter it, and it doesn't happen in host code), I get: (cuda-gdb) run Starting program: /path/to/my/binary/cuda_clustered_tree [Thread debugging using libthread_db enabled] [1]+ Stopped cuda-gdb cuda_clustered_tree cuda-gdb then dumps me back to my terminal. If I try to run cuda-gdb again, I get An instance of cuda-gdb (pid 4065) is already using device 0. If you believe you are seeing this message in error, try deleting /tmp/cuda-dbg/cuda-gdb.lock. The only way to recover is to kill -9 cuda-gdb and cuda_clustered_ (I assume the latter is part of my binary). This machine has two GPUs, is running CUDA 4.1 (I believe -- there were a lot installed, but that's the one I set the PATH and LD_LIBRARY_PATH to) and compile + runs deviceQuery and bandwidthTest fine. I can provide more info if need be. I've searched everywhere I could find online and found no help with this.",
        "answers": [
            [
                "Figured it out! Turns out, cuda-gdb hates csh. If you are running csh, it will cause cuda-gdb to exhibit the above anomalous behavior. Even running bash from within csh, then running cuda-gdb, I still saw the behavior. You need to start your shell as bash, and only bash. On the machine, the default shell was csh, but I use bash. I wasn't allowed to change it directly, so I added 'exec /bin/bash --login' to my .login script. So even though I was running bash, because it was started by csh, cuda-gdb would exhibit the above anomalous behavior. Getting rid of 'exec' command, so I was running csh directly with nothing on top, still showed the behavior. In the end, I had to get IT to change my shell to bash directly (after much patient troubleshooting by them.) Now it works as intended."
            ]
        ],
        "votes": [
            1e-07
        ]
    },
    {
        "question": "Does there exist a debugging application similar to the Visual Profiler for CUDA? It shows information about the application at the function level in terms of execution time. Is there something for regular C/C++ applications so I can see which functions are taking the most time and memory? I'm trying to debug an application that reads in a lot of data files and uses a custom class to read the file and represent it internally as a vector of vectors. I have another class which represents the operations performed on the data from the data file. As I read more and more files in a loop and operate upon them, the memory usage just increases until the OS just kills the application. I've been pretty good about cleaning up from using dynamic memory. Something visual to help me wade through all the files and functions to see which use the most time and memory would be hugely beneficial! I am able to use libproc from within my application to confirm that with each iteration of the loop, the memory usage goes from a cool ~500 megs to a whopping 19 GB. This shouldn't be since the scope of the data is within the loop, so by the next iteration of the loop the C++ objects using the data should have been cleared and returned to the OS, but this isn't happening. I hope this isn't too vague, and thanks!",
        "answers": [
            [
                "Search for \"c++ memory leak\" on SO. See for instance: Memory leak tool for C++ under Windows I'm guessing folks will close this as a duplicate."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "Where I can find *.debug file with debugging info for CUDA libraries from CUDA SDK, namely CUFFT and CUDA Runtime API (cudart), and how to provide them to debugger and/or profiler? Without this info debugging application that uses CUDA libraries is very difficult, especially when the error is in CUDA code.",
        "answers": [
            [
                "These libraries are not open source, and so naturally debug symbols are not provided. If you find that there is a bug in a library, I recommend you become a registered CUDA developer and report the issue using the online bug report form. Alternatively (but less preferably), report the issue in more detail here or on the NVIDIA forums. Before you report a bug, make sure you are confident it is not in your own code first. :)"
            ]
        ],
        "votes": [
            3.0000001
        ]
    },
    {
        "question": "There are four CUDA-capable devices available: teslabot$ ./deviceQuery | grep -i \"device [0-9]\\|capability\" Device 0: \"Tesla C2050 / C2070\" CUDA Capability Major/Minor version number: 2.0 Device 1: \"Tesla C2050 / C2070\" CUDA Capability Major/Minor version number: 2.0 Device 2: \"GeForce GTX 295\" CUDA Capability Major/Minor version number: 1.3 Device 3: \"GeForce GTX 295\" CUDA Capability Major/Minor version number: 1.3 cuda-dbg sees only one of them: teslabot$ cuda-gdb vector_add NVIDIA (R) CUDA Debugger 4.0 release Portions Copyright (C) 2007-2011 NVIDIA Corporation GNU gdb 6.6 Copyright (C) 2006 Free Software Foundation, Inc. [...] (cuda-gdb) break vector_add_gpu Breakpoint 1 at 0x400ddb: file vector_add.cu, line 7. (cuda-gdb) run [...] (cuda-gdb) info cuda devices Dev Description SM Type SMs Warps/SM Lanes/Warp Max Regs/Lane Active SMs Mask * 0 gt200 sm_13 30 32 32 128 0x00000001 I have checked that code build with -gencode arch=compute_20,code=sm_20 compiles without errors on said machine, and when compiled for sm_20 then using printf in CUDA kernel works correctly. How can I make cuda-gdb see all devices (perhaps except one used for graphics... though in said case I am logging remotely via SSH), or at least one Tesla / sm_20 device? When following advise in Michael Foukarakis response by setting CUDA_VISIBLE_DEVICES environment variable to contain only \"0,1\" i.e. make visible only Teslas, I get the following error after running info cuda devices: (cuda-gdb) info cuda devices fatal: All CUDA devices are used for X11 and cannot be used while debugging. (error code = 24) How to check which devices are used by X11 (X.Org), and how to make X Window System to use GeForce and not Tesla?",
        "answers": [
            [
                "Can you make sure the CUDA_VISIBLE_DEVICES environment variable contains all the devices you want to be used, such as: $ ./deviceQuery -noprompt | egrep \"^Device\" Device 0: \"Tesla C2050\" Device 1: \"Tesla C1060\" Device 2: \"Quadro FX 3800\" By setting the variable you can make only a subset of them visible to the runtime: $ export CUDA_VISIBLE_DEVICES=\"0,2\" $ ./deviceQuery -noprompt | egrep \"^Device\" Device 0: \"Tesla C2050\" Device 1: \"Quadro FX 3800\""
            ]
        ],
        "votes": [
            2.0000001
        ]
    },
    {
        "question": "I've been trying to debug my code, as I know something is going wrong in the Kernel, and I've been trying to figure out what specifically. If I try to step into the kernel it seems to completely step over the kernel functions, and will eventually cause an error on quitting: Single stepping until exit from function dyld_stub_cudaSetupArgument, which has no line number information. [Launch of CUDA Kernel 0 (incrementArrayOnDevice&lt;&lt;&lt;(3,1,1),(4,1,1)&gt;&gt;&gt;) on Device 0] [Termination of CUDA Kernel 0 (incrementArrayOnDevice&lt;&lt;&lt;(3,1,1), (4,1,1)&gt;&gt;&gt;) on Device 0] [Launch of CUDA Kernel 1 (fillinBoth&lt;&lt;&lt;(40,1,1),(1,1,1)&gt;&gt;&gt;) on Device 0] [Termination of CUDA Kernel 1 (fillinBoth&lt;&lt;&lt;(40,1,1),(1,1,1)&gt;&gt;&gt;) on Device 0] add (below=0x124400, newtip=0x124430, newfork=0x125ac0) at test.cu:1223 And if I try to break in the Kernel my entire computer crashes and I have to restart it. I figure there must be something wrong with the way I'm calling the kernel, but I can't figure out what. The code is rather long, so I'm only including an excerpt of it: __global__ void fillinOne(seqptr qset, long max) { int i, j; aas aa; int idx = blockIdx.x; __shared__ long qs[3]; if(idx &lt; max) { memcpy(qs, qset[idx], sizeof(long[3])); for (i = 0; i &lt;= 1; i++) { for (aa = ala; (long)aa &lt;= (long)stop; aa = (aas)((long)aa + 1)) { if (((1L &lt;&lt; ((long)aa)) &amp; qs[i]) != 0) { for (j = i + 1; j &lt;= 2; j++) qs[j] |= cudaTranslate[(long)aa - (long)ala][j - i]; } } } } } //Kernel for left!= NULL and rt != NULL void fillin(node *p, node *left, node *rt) { cudaError_t err = cudaGetLastError(); size_t stepsize = chars * sizeof(long); size_t sitesize = chars * sizeof(sitearray); //int i, j; if (left == NULL) { //copy rt-&gt;numsteps into p-&gt;numsteps--doesn't actually require CUDA, because no computation to do memcpy(p-&gt;numsteps, rt-&gt;numsteps, stepsize); checkCUDAError(\"memcpy\"); //allocate siteset (array of sitearrays) on device seqptr qsites; //as in array of qs's cudaMalloc((void **) &amp;qsites, sitesize); checkCUDAError(\"malloc\"); //copy rt-&gt;siteset into device array (equivalent to memcpy(qs, rs) but for whole array) cudaMemcpy(qsites, rt-&gt;siteset, sitesize, cudaMemcpyHostToDevice); checkCUDAError(\"memcpy\"); //do loop in device int block_size = 1; //each site operated on independently int n_blocks = chars; fillinOne &lt;&lt;&lt; n_blocks, block_size&gt;&gt;&gt; (qsites, chars); cudaThreadSynchronize(); //put qset in p-&gt;siteset--equivalent to memcpy(p-&gt;siteset[m], qs) cudaMemcpy(p-&gt;siteset, qsites, sitesize, cudaMemcpyDeviceToHost); checkCUDAError(\"memcpy\"); //Cleanup cudaFree(qsites); } If anyone has any ideas at all, please resond! Thanks in advance!",
        "answers": [
            [
                "I suppose you have a single card configuration. When you are debugging a cuda kernel and you break inside it you effectively put the display driver in pause. That causes what you think is a crash. If you want to use the cuda-gdb with only one graphics card you must use it in command line mode (don't start X or press ctrl-alt-fn from X). If you have two cards you must run the code in the card not running the display. Use cudaSelectDevice(n)."
            ]
        ],
        "votes": [
            1.0000001
        ]
    },
    {
        "question": "I'm following the CUDA-GDB guide (page 10, getting started) on Ubuntu Linux and got this: antonio@antonio-desktop:~$ export PATH=/usr/local/cuda/bin:$PATH antonio@antonio-desktop:~$ export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/ antonio@antonio-desktop:~$ lib:$LD_LIBRARY_PATH bash: lib:/usr/local/cuda/lib64:/usr/local/cuda/: No such file or directory Well, how do I fix this? I have the current toolkit.",
        "answers": [
            [
                "You have broken a line in two - it should be: $ export PATH=/usr/local/cuda/bin:$PATH $ export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/lib:$LD_LIBRARY_PATH You probably got confused by the line wrap in the nVidia PDF."
            ]
        ],
        "votes": [
            2.0000001
        ]
    }
]